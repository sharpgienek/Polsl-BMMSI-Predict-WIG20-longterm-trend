FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.40750108276023810000e-001) (1, -1.50135307093473360000e+000) (2, -6.18852851795193070000e-002) (3, 3.25487259009535180000e-001) (4, 1.95560226694285330000e-001) (5, 2.92096706909192930000e-001) (6, 2.25720973498242490000e-001) (7, 1.01781552580762090000e+000) (8, -4.83638697100901020000e-002) (9, -6.99272604333361470000e-001) (10, 7.31330547001004420000e-001) (11, -2.26075525987503630000e-001) (12, -1.53248196924378020000e-001) (13, 2.58658398105718170000e-001) (14, 2.36412954211608210000e-001) (15, -1.59279279017455160000e+000) (16, -6.24562787831501740000e-002) (17, 5.77285906962408560000e-001) (18, 1.32931098726736830000e-001) (19, -6.95485355746221080000e-002) (0, 5.31630176340794240000e-001) (1, 1.79763175267972120000e+000) (2, -4.96106597668754030000e-001) (3, -5.04181425364757410000e-001) (4, -9.07487491015886020000e-002) (5, 1.86045540630887660000e-002) (6, -6.45660919660466130000e-001) (7, 9.25286336610423730000e-002) (8, -1.27809296528833770000e-001) (9, 1.04247820083718670000e+000) (10, -4.90302030626688370000e-001) (11, -4.39579494832873840000e-001) (12, 5.23318381796886500000e-001) (13, 7.65307847728138980000e-001) (14, 9.76364851051070990000e-002) (15, 4.54488018903442700000e-001) (16, 4.67964005638064890000e-001) (17, 2.96494235451459640000e-002) (18, -8.74406435835439890000e-002) (19, 4.89210343845285000000e-001) (0, 2.51919225860842840000e-002) (1, -1.31449279739834200000e+000) (2, 8.35297252162791050000e-001) (3, 1.07473528139597980000e+000) (4, 8.21805231552801000000e-002) (5, 1.07346283414185630000e-002) (6, 1.11194841671612380000e+000) (7, 4.56509860764474700000e-001) (8, 1.16628765856098910000e-001) (9, -6.73462433746615960000e-001) (10, 1.12526628800832550000e+000) (11, 4.55235652045843990000e-001) (12, -6.30882710736147660000e-001) (13, -2.08796846563767290000e-001) (14, 6.22999408338897330000e-001) (15, 2.15889826621001590000e-002) (16, -2.23903047960742230000e-001) (17, 1.90933790252057030000e-001) (18, 6.47598415996713640000e-001) (19, -9.28802109221896100000e-001) (0, 1.11208410118624200000e-001) (1, 5.17428556485007190000e-001) (2, 4.47073599464504760000e-001) (3, -3.20592889593797450000e-001) (4, 3.13513894823699350000e-001) (5, 9.60168267814491830000e-002) (6, -6.31897491721000070000e-001) (7, 5.31536390290497230000e-002) (8, 2.08810351687109180000e-001) (9, 2.94005222973240780000e-001) (10, 4.06976907863337180000e-001) (11, 5.80134388995322770000e-001) (12, -2.56433995659090140000e-001) (13, -2.10280266715239530000e-002) (14, 2.91065234224751780000e-001) (15, 6.73973743095389040000e-002) (16, -1.18318067183758510000e-001) (17, 4.38575002047818460000e-001) (18, 2.59097217670816890000e-001) (19, 1.03611990527092980000e-001) (0, 5.69172901509599320000e-001) (1, 1.63208658057416130000e-001) (2, 5.23164201773111850000e-001) (3, -2.78130702287475660000e-001) (4, -1.86543428263415520000e-001) (5, -1.83537158998386740000e-001) (6, -6.81158967064428240000e-001) (7, 4.88445569335893980000e-002) (8, 2.30001758252885740000e-001) (9, 3.49791356617018930000e-001) (10, 1.02796259262807860000e-001) (11, 5.85658099188718470000e-001) (12, 8.53924090406948250000e-002) (13, 2.86789504571043410000e-001) (14, 4.75218057065281810000e-001) (15, 3.52334358503976600000e-001) (16, 1.77493848645536300000e-001) (17, 3.57041111353678390000e-002) (18, 1.63717577577674490000e-001) (19, 6.23359515766138350000e-001) (20, -1.46629864021809300000e-001) (21, -1.00384134157127440000e-001) (22, 4.98434048467136290000e-001) (23, 2.33414231164603970000e-001) (24, 3.00235521222818770000e-001) (25, 1.42270430978330560000e-001) (20, 7.72818238265625010000e-001) (21, 2.87065505313722490000e-002) (22, 4.89204926717064110000e-001) (23, -7.26721084732844690000e-001) (24, -3.16675430730342430000e-001) (25, 1.54262411262149880000e+000) (20, -2.69369551260314140000e-001) (21, 1.59228805559933790000e+000) (22, -1.39541320876040010000e+000) (23, 6.93536500909758940000e-001) (24, 7.09387331224079710000e-001) (25, 1.04730754149508520000e+000) 

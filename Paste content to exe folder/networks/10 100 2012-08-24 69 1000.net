FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.25597375271147890000e+000) (1, 1.94691868503733910000e-001) (2, 2.00014032631440520000e+001) (3, -2.12647729873746850000e+000) (4, -1.92661716995753520000e+001) (5, -1.79162715185407230000e+000) (6, -8.75842383266208110000e-001) (7, 9.26958346448248790000e-002) (8, 4.41675139400654540000e+001) (9, -9.54199757507291360000e-001) (10, 5.40121880503734800000e+000) (11, -5.89241051769413660000e-001) (12, 1.82845386154682470000e+001) (13, 3.85879917433169070000e-001) (14, 1.19322605874266150000e+001) (15, -2.79535542092915590000e-001) (16, 1.46702081345849380000e+001) (17, 2.85492441984855630000e-001) (18, 1.84447311474767060000e+001) (19, 2.12469262300193410000e+000) (0, 1.13089332595294660000e+001) (1, -8.46988735723412380000e-001) (2, -1.82015884425236540000e+001) (3, -4.97613591597865760000e+000) (4, -5.41811694926535590000e+001) (5, 5.40433732864535000000e-001) (6, 2.29042702818262780000e+001) (7, -7.43233250179959560000e-001) (8, -3.18779819682692920000e+001) (9, 1.00114262416459240000e+000) (10, -4.30395617986219610000e+001) (11, -2.43614195583543090000e+000) (12, 8.18440199596084210000e+000) (13, 5.83318913334678890000e-001) (14, -2.08520802427893410000e+001) (15, 5.81921712461102820000e+000) (16, -2.63410761426159150000e+001) (17, 1.77851148967881820000e-001) (18, 8.87987725741717430000e+000) (19, 1.05631961759436830000e+000) (0, -4.11211597830055280000e+000) (1, -7.12019434243649550000e-001) (2, -5.92026266852230810000e-001) (3, 3.40708557052764090000e-001) (4, 9.72346772043132820000e+000) (5, 2.35666644139139040000e-001) (6, 1.33817356974847490000e+000) (7, 7.94888379241894260000e-001) (8, 1.56945296210559880000e+001) (9, -1.00555867532949720000e+000) (10, 2.91810485077857000000e+001) (11, 7.03180870201797870000e-001) (12, 2.20060650098041820000e+001) (13, 8.94702068979904770000e-003) (14, 2.41274195480264810000e+001) (15, 3.94570009249023590000e+000) (16, 8.11615652218759460000e+000) (17, 3.56367363019585660000e-001) (18, 1.04874589982390740000e+001) (19, 5.83201788513325490000e-001) (0, -1.89638169622716250000e+001) (1, -7.52005037014073090000e+000) (2, 8.60954242166780830000e+001) (3, 1.47997835767678220000e-001) (4, 4.58310749548085920000e+001) (5, -2.24185461096051510000e+000) (6, -1.26386230511078420000e+002) (7, 5.67560468619481200000e+000) (8, 9.33696083709855710000e+000) (9, -2.49586345216872330000e+000) (10, 8.09431928030228530000e+001) (11, 1.26467464156258470000e+001) (12, 3.29706164475866930000e+001) (13, 2.95219914234323430000e+000) (14, 4.66836049976350440000e+001) (15, 2.79442079416875050000e+001) (16, -8.42763567216755120000e+001) (17, 2.78700940447310510000e+000) (18, -1.08360052559902980000e+002) (19, 1.18613311404674740000e+001) (0, 4.99281729115596630000e+001) (1, -1.70534401177846510000e+000) (2, 3.65805967226250490000e+000) (3, -5.74369375441723060000e-001) (4, 4.14799504262104610000e+000) (5, 3.03672272314317620000e+000) (6, 3.66760651452324920000e+001) (7, -4.11790352885528450000e-001) (8, -2.13363662092616980000e+001) (9, 4.93241388607408380000e+000) (10, 4.26928849882408630000e+001) (11, -2.68153950087095310000e+000) (12, 3.19403142777300250000e+001) (13, 1.01529871699228540000e+000) (14, 2.83518674038770830000e+001) (15, 6.49495642597999550000e+000) (16, -3.65839504101095230000e+001) (17, -3.19190072035738170000e-002) (18, -1.11568968877887510000e+001) (19, 6.46561445558266110000e-001) (0, -1.03177479551310810000e+001) (1, -2.80858306242349030000e-001) (2, -3.38800122634567980000e+001) (3, 1.32933787003172710000e+000) (4, 4.34961912027231040000e+001) (5, 4.80341743001004760000e+000) (6, 2.02559443064936920000e+001) (7, 8.78680114570049690000e-001) (8, -6.41139847932969220000e+001) (9, 1.05327036686905110000e+000) (10, -8.37025237189146410000e+000) (11, 1.78549180891027650000e+000) (12, -4.97039646732804880000e+001) (13, -5.85562909088676140000e-001) (14, -5.28824454054616490000e+000) (15, 1.45796333110068280000e+000) (16, -1.27521711215639490000e+001) (17, -4.85610852008236280000e-001) (18, -2.75840986191876600000e+001) (19, -2.79570186455595370000e+000) (20, -2.62454817723418100000e+000) (21, 2.46278344610798160000e+000) (22, 1.43583840876976890000e+000) (23, -4.64921972730117160000e-002) (24, -2.58357603826963180000e+000) (25, -2.35242955687774250000e+000) (26, 9.23731851900171820000e-001) (20, 1.30231057428311820000e+000) (21, -2.70754922322514660000e+000) (22, 6.04923832184947050000e-001) (23, -1.77262890911203370000e+000) (24, 2.37076834228629880000e+000) (25, 8.60537123376049150000e-001) (26, 2.03390543638970960000e+000) (20, 5.44705090236010660000e-001) (21, 3.45292451705704990000e-001) (22, -2.27078315967349020000e+000) (23, 1.93522275632862570000e+000) (24, -5.38355526356718450000e-003) (25, 7.15069263400992860000e-001) (26, 1.47129152760451080000e-001) 

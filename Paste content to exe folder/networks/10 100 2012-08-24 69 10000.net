FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.23083594928764370000e+002) (1, 6.73697788167253340000e-001) (2, -2.17660014471399530000e+001) (3, 3.61047983440623720000e+000) (4, 2.96695410192741560000e+001) (5, -6.93975027585059670000e+000) (6, -8.33628459529265060000e+001) (7, -1.44345743688868770000e+000) (8, -6.22332580127949200000e+001) (9, 5.12185890831530430000e-001) (10, -8.20468416670250100000e+000) (11, -8.18565323929277500000e-001) (12, -8.75763966604872190000e+001) (13, -1.76551487434441450000e+000) (14, -1.37774579678421190000e+002) (15, 1.38060203252508050000e+000) (16, -2.52070265000923360000e+001) (17, -1.09308772503556000000e+000) (18, -4.85924217059471320000e+001) (19, -1.97063966106780450000e+000) (0, 2.16701983204902800000e+002) (1, 8.20996171277941780000e-001) (2, 2.45397853449508660000e+002) (3, -1.58234451642253490000e+000) (4, 6.75447174321188870000e+001) (5, 5.81748916614744700000e-001) (6, 1.45718408306198430000e+002) (7, 5.65254088359814140000e+000) (8, 3.61421586204238220000e+002) (9, 3.94368850592543440000e+001) (10, 1.63066647319810190000e+002) (11, 2.54756694799328050000e+001) (12, -5.24930190679878710000e+002) (13, 5.88089367708920400000e-001) (14, -1.72917146878736700000e+002) (15, 1.76820676169580930000e+000) (16, -2.11601819560836010000e+001) (17, -6.84394802887713900000e+000) (18, -2.36178025177009260000e+002) (19, 3.04662849432846980000e+001) (0, -1.39049801458888190000e+003) (1, 8.51617107897444820000e+000) (2, -9.03215576937335750000e+002) (3, -4.31100492547056650000e+001) (4, 5.21256923373310660000e+002) (5, -2.61880338882826640000e+001) (6, 1.54098571182590860000e+002) (7, -9.17935955985495870000e+000) (8, -3.16915968392065790000e+002) (9, -2.72495846089196480000e+001) (10, -6.68371266086376290000e+002) (11, -3.64644626004942430000e+000) (12, 2.95548199457907570000e+002) (13, -1.17146390968603350000e+001) (14, 1.50000000000000000000e+003) (15, 1.77376011408941310000e+002) (16, 1.15039689530133680000e+003) (17, 2.34222200458987470000e+001) (18, -2.88482420964973470000e+002) (19, 7.69981869928655130000e+001) (0, -3.17102072609074130000e+001) (1, 1.12680667260058000000e-001) (2, -1.00729049805997930000e+001) (3, -9.01394802544197240000e-001) (4, 2.43062310342177240000e+001) (5, -1.24929908448798770000e-001) (6, 4.22304898709874340000e+001) (7, 1.55993016049362550000e-001) (8, 7.27526681613922490000e+000) (9, -9.92760913976119540000e-002) (10, -8.26897772048501520000e+000) (11, -3.40487724180577540000e-001) (12, 1.40946562738735860000e+001) (13, -1.49007657418880390000e-001) (14, 2.78855005953688820000e+001) (15, 2.86724402161993060000e+000) (16, 7.18097841511184940000e+000) (17, 4.46120874456328590000e-001) (18, 1.86192784419250220000e+001) (19, 2.32665974263479970000e+000) (0, 8.78834598493962600000e+001) (1, -2.11566121084243090000e+001) (2, 1.50000000000000000000e+003) (3, 1.63079407720044290000e+001) (4, 3.21130959151366140000e+002) (5, -2.06838212081918550000e+001) (6, -1.02474309965582640000e+003) (7, 2.69608422351642570000e+001) (8, 1.50000000000000000000e+003) (9, 2.62900225428858960000e+002) (10, -1.44400160745175500000e+003) (11, -3.15099330989776320000e+002) (12, 1.50516619811350320000e+002) (13, 1.89184683634221250000e+001) (14, -2.87116324338257700000e+002) (15, 6.00860952337621820000e+002) (16, 7.64383804182889150000e+001) (17, 3.01933157670651160000e+000) (18, -6.56182430269439010000e+002) (19, 8.08876018930354800000e+001) (0, 3.26540846027183990000e+002) (1, 6.10645708197824620000e+000) (2, 1.78154712590038940000e+002) (3, 3.66232903578374050000e+001) (4, 2.33825428313649040000e+002) (5, -7.95320867744393120000e+000) (6, 2.33305981569805620000e+000) (7, -1.13935186615006410000e+001) (8, 6.07708023020898850000e+002) (9, -6.77495370458047310000e+000) (10, 5.59854395853215690000e+002) (11, -1.89427456626554800000e+000) (12, 1.38800811262981940000e+002) (13, -6.27725272071298070000e+000) (14, -5.57626024617059810000e+001) (15, 7.30270091400666390000e+000) (16, 2.27735491575321050000e+002) (17, 7.62638057841966420000e-002) (18, 4.05973410163590390000e+000) (19, 6.11109299471932930000e+000) (20, -1.29359032260844510000e+000) (21, -2.09319875151743910000e+000) (22, 5.62539445490558010000e-001) (23, -5.38238891140705220000e-001) (24, 1.96882153140103960000e-001) (25, 1.36161290856787010000e+000) (26, 2.21815851849557390000e+000) (20, 9.26910051381274800000e-001) (21, 2.04897102250291670000e+000) (22, -2.13261242852022900000e+000) (23, 3.36494241513438120000e+000) (24, -1.90134971412367930000e+000) (25, -1.02759790150311250000e-001) (26, -3.44439529896135410000e-001) (20, 2.11036519814744810000e-001) (21, -4.71785340114102700000e-002) (22, 1.05127727048842680000e+000) (23, -2.40331684819951130000e+000) (24, 1.42500819377764330000e+000) (25, -1.42272868960871500000e+000) (26, 1.45562938607993210000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.03214480672563540000e+000) (1, -4.33127122222870530000e-003) (2, 1.20446030332791710000e+000) (3, -1.41303332898092220000e-001) (4, 1.14650131808926090000e+000) (5, 1.70960513364619450000e-001) (6, -3.05749270749397350000e+000) (7, 1.53838083943521910000e-001) (8, -2.92622334090372750000e-001) (9, 1.13857584890611770000e+000) (10, -1.04279159497861910000e+000) (11, -2.54515055086367570000e-001) (12, -3.38319356255686430000e-001) (13, 1.58369772245909810000e-001) (14, -8.67367059760536300000e-001) (15, 6.88023698014539660000e-001) (16, 1.75300381768824480000e-001) (17, 1.05148745032261720000e-001) (18, -9.78344572533908610000e-001) (19, 9.69840518563999530000e-002) (0, -1.15547837377265110000e+000) (1, -1.61356359328989530000e-001) (2, -3.35239002854378580000e-001) (3, -1.24251680304409030000e-001) (4, -1.18758286643854530000e+000) (5, 2.05151359428798590000e-001) (6, -4.32328103775344590000e-002) (7, 2.95298925077483790000e-001) (8, 1.11633774342103860000e+000) (9, 1.81975628007820550000e-001) (10, 2.00552647232368920000e+000) (11, 5.57653467477153690000e-002) (12, 1.13151718700660500000e+000) (13, 1.14798037847560190000e-001) (14, 2.02501499800471580000e+000) (15, 1.53697360467456080000e-001) (16, 2.14787716937047230000e-001) (17, -2.94762882671456490000e-002) (18, 1.42043687858296200000e+000) (19, -4.50030811358123170000e-001) (0, -3.13937747433915160000e+000) (1, -3.33257467328624480000e-002) (2, -1.08762191791226790000e+000) (3, -6.46272813980527520000e-002) (4, -1.05003036461773510000e+000) (5, 9.67939574550685660000e-002) (6, -2.34394794160214800000e-001) (7, 6.70290430124194650000e-001) (8, 4.94292238371124070000e-001) (9, 3.56712779800949400000e-001) (10, 5.68129784070632420000e-001) (11, -2.05543475370921660000e-001) (12, 3.57579479032614220000e-001) (13, -1.86528517555186100000e-001) (14, 1.42385779812601640000e-001) (15, 7.56015857551264100000e-001) (16, 4.98259412769533560000e-001) (17, 1.89238297107132610000e-001) (18, 1.05798202966084580000e+000) (19, -1.95105534299819110000e-001) (0, 1.03358627734419570000e+000) (1, 2.44861490350683840000e-002) (2, -1.31125840539082940000e+000) (3, 3.77246632692794130000e-001) (4, -1.30406846387744090000e+000) (5, 1.40447827613775580000e-001) (6, 1.68809878463671480000e+000) (7, 5.05166695064347190000e-001) (8, 1.11448837815910600000e+000) (9, -5.64615586448629080000e-002) (10, 1.30635606633615040000e+000) (11, 3.95261483997309590000e-001) (12, 3.58424306887915930000e-001) (13, 1.58576879270333690000e-002) (14, 3.08480594032284740000e+000) (15, 4.56353833657351990000e-001) (16, 4.13426087038479830000e-001) (17, -2.51929647333114510000e-002) (18, 1.34729844975873950000e+000) (19, 4.34802899431031430000e-002) (0, -8.01808872102574010000e-002) (1, 8.34238909664721250000e-002) (2, -3.85043691096526250000e-001) (3, 1.14903630851143840000e-001) (4, -2.37907347780597360000e-001) (5, -4.46597382046707680000e-001) (6, 4.16859366352416160000e-001) (7, 8.06410044365082480000e-002) (8, 1.20974594793792930000e+000) (9, -1.35263785876214990000e-001) (10, 5.30644777975319170000e-001) (11, -1.74704704432680460000e-001) (12, 5.28547367742039140000e-001) (13, -3.33629367596714740000e-003) (14, 3.71559072708639190000e-001) (15, -4.87281400554833570000e-002) (16, 1.52372445288741810000e+000) (17, -1.19754063889124320000e-001) (18, 5.33464602236087830000e-001) (19, -1.27579459589834600000e-001) (0, 1.17307369836812060000e-001) (1, -1.48657622937518300000e-001) (2, 3.14562137091656790000e+000) (3, -3.16898477570626420000e-002) (4, 6.04644841081748210000e-001) (5, -1.19456649841260050000e-001) (6, -1.36572210438599520000e-001) (7, -8.32558959640807010000e-003) (8, -4.48570680533978420000e-001) (9, 2.16025040359311970000e-003) (10, -3.10427005194101020000e+000) (11, -7.12350657128718370000e-001) (12, -6.56605696828412850000e-002) (13, 1.60713122983997310000e-001) (14, 1.30448239173251270000e-001) (15, -1.51898589782687470000e-001) (16, 3.12856047136135960000e-001) (17, 5.07241796409164780000e-001) (18, -1.86157031035397070000e+000) (19, -1.05041899631343390000e-001) (0, 1.42628887560972440000e-001) (1, -1.38455924595656560000e-001) (2, -9.34728849227733690000e-001) (3, 1.09170942039826020000e-001) (4, -6.24066267018757660000e-002) (5, -1.62754020660851400000e-001) (6, -1.57258757536517190000e-001) (7, 3.54577083674269040000e-001) (8, 2.66407703954261780000e-001) (9, -1.28531608041522720000e-001) (10, 1.04020932496943950000e+000) (11, 8.63926213879026020000e-002) (12, 5.00078371269844220000e-001) (13, -3.56788234547833900000e-002) (14, 9.24921429999088770000e-002) (15, 2.76768634941587270000e-001) (16, 6.09021602578311840000e-002) (17, 9.83254359602092070000e-002) (18, 1.06246811371206860000e+000) (19, 2.48399493893854130000e-001) (20, 7.66184759379994330000e-002) (21, 2.24120141589470380000e-001) (22, 2.43760838372006460000e-001) (23, 3.42693538575315430000e-001) (24, 4.01364421721753930000e-002) (25, -1.19385161563824640000e-001) (26, 3.54391697322779480000e-001) (27, 4.23221044051541650000e-001) (20, -2.65309396615466230000e-002) (21, -2.40851720036271140000e-001) (22, -5.10311982605504260000e-001) (23, 4.22204312808519940000e-001) (24, 1.69496212070826600000e-001) (25, -3.49625921143973560000e-001) (26, -3.04249901779505700000e-002) (27, 6.69326747868342010000e-001) (20, 6.68056424504568920000e-001) (21, -3.67981273039962480000e-001) (22, -2.27870461639858470000e-001) (23, -7.78359156958873920000e-001) (24, -1.49714987148989840000e-001) (25, 1.84363445435248370000e-002) (26, 2.32765106011348200000e-001) (27, 8.80761144126263500000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.55442658189619910000e+000) (1, -6.40047724829152730000e-001) (2, 5.72717890386989610000e-001) (3, -2.24356704919586400000e-001) (4, -7.22679365843017240000e+000) (5, -4.51581985739833820000e-001) (6, 1.04864262697430810000e+001) (7, 9.78610231727815030000e-001) (8, 7.90715546848251180000e+000) (9, -1.84325544467847640000e+000) (10, 2.73924325115016300000e+000) (11, 9.58339986375657680000e-002) (12, 2.52158771726716320000e+000) (13, -3.22774374523899510000e-001) (14, -3.13517374787530700000e+000) (15, -2.60440328362372590000e+000) (16, 4.30943798063071350000e+000) (17, -8.96328648672153340000e-001) (18, 3.52312743861264540000e+000) (19, 2.00153678336135150000e-001) (0, 4.86773876323410450000e+000) (1, 7.46290514656163810000e-001) (2, -6.85115433110076390000e+000) (3, 5.49442581529881800000e-002) (4, -1.23521174140237000000e+001) (5, 3.15101706083354300000e-001) (6, 5.89276360294245990000e+000) (7, -7.93098743379741510000e-001) (8, 1.13828398881770260000e+001) (9, 2.36601711711644580000e-002) (10, 1.51061856677438460000e+001) (11, -3.58337274697586750000e-001) (12, 2.83596837373422130000e+001) (13, -2.96419505128692360000e-001) (14, -3.75937279024317440000e+000) (15, 5.76713302721164330000e-002) (16, -4.07366956661260190000e+000) (17, 5.80096027282687610000e-001) (18, 7.79869126418877380000e+000) (19, 3.30847927916194160000e-001) (0, 1.24228771192581490000e+000) (1, -1.40662192595909900000e-001) (2, 9.93337726420888250000e+000) (3, 2.53514824547346910000e+000) (4, 6.98759622299005230000e+001) (5, -2.01740978514508830000e+000) (6, -1.28003991356237940000e+001) (7, 6.41885321507691400000e-001) (8, -2.14726660917953750000e-001) (9, -5.70020952301101950000e-001) (10, 2.70855533097139370000e+001) (11, 2.26663390500525750000e+000) (12, -1.00087931874042190000e+001) (13, -3.01943308084212970000e-002) (14, 2.90930608152675490000e+001) (15, -3.98944649868707040000e+000) (16, 1.57478665255972960000e+001) (17, -5.71436080555895450000e-001) (18, 1.67886967154204140000e+001) (19, 5.14772817937063750000e-001) (0, -1.81265804022483690000e+001) (1, 1.23836666798580450000e+000) (2, -2.46774318069741620000e+001) (3, 1.29163881030453530000e+000) (4, -4.84687563839897620000e+000) (5, -2.92804958235463010000e-003) (6, -1.89433218269393390000e+001) (7, -2.17533508477696750000e-002) (8, 2.40549353979507070000e+000) (9, 1.43712718391570980000e+000) (10, -8.02109271734072320000e+000) (11, 1.45476904848959310000e-001) (12, -1.09779532022644850000e+001) (13, 1.31674633669691620000e-001) (14, -2.38652716275866080000e+001) (15, -1.33380974331430280000e+000) (16, 6.21051776455669200000e+000) (17, 1.20833847217489930000e+000) (18, 1.31629191586231860000e+001) (19, 5.99591403737463000000e-001) (0, 1.69678938987664150000e+000) (1, 3.43674401103172430000e-001) (2, -9.92455590645360260000e-001) (3, 1.43049371642110180000e+000) (4, -9.65649682688570320000e-001) (5, 2.49709237273400300000e-001) (6, 1.41073845431419400000e+001) (7, 3.04172408677837350000e-001) (8, 1.72022856629050940000e+001) (9, 2.81308382727434080000e-001) (10, -7.36135941938984570000e-001) (11, -5.11933600732541240000e-001) (12, 7.09461363429349490000e+000) (13, -4.55238692488192760000e-001) (14, -1.24383505236972490000e+001) (15, 8.01075237308422010000e-001) (16, 7.49625760840831920000e+000) (17, 1.77546619047491760000e+000) (18, 7.08076997041090020000e+000) (19, 6.84652377443855540000e-001) (0, 1.17107352815799840000e+001) (1, 2.28284213568232780000e-001) (2, -3.56262357266497890000e+000) (3, -7.57562977500502050000e-001) (4, 1.27042394099354860000e+001) (5, 2.20948506447374790000e-001) (6, -3.69607894177913680000e-001) (7, -8.07972187183570780000e-001) (8, -3.94149671169579690000e+000) (9, 1.46749522279967510000e+000) (10, 1.12543605301347080000e-001) (11, 3.83231227685140450000e-001) (12, -2.66472671459484970000e+001) (13, 9.01807134050721220000e-001) (14, 1.98931110127759790000e+001) (15, 1.61905401665211500000e+000) (16, -2.59431669588762270000e+000) (17, -9.35781211300122260000e-001) (18, 1.08733645617072640000e+001) (19, 6.54858055177294230000e-001) (0, -2.17071137154138240000e+000) (1, 1.04396696299994640000e+000) (2, 3.29018830546596770000e+000) (3, -8.20246254441429850000e-001) (4, -1.15365508919797830000e+001) (5, 6.48445525966857670000e-001) (6, 8.27317284875628830000e-001) (7, -6.12845941475305130000e-001) (8, -6.63101046534500500000e+000) (9, 1.09619102970369120000e+000) (10, -5.93597227190282780000e+000) (11, 2.31672795817738340000e-001) (12, 6.67179065748312090000e+000) (13, 3.56913555212942490000e-001) (14, -6.77912000262589580000e+000) (15, -4.13126667683800620000e+000) (16, 3.03726004628135950000e+000) (17, 6.66331363237733650000e-002) (18, -4.79011383297451500000e+000) (19, 4.97749787640748910000e-002) (20, 1.07961187897056270000e+000) (21, 1.10993752716507870000e+000) (22, -3.75722468351018580000e-001) (23, 1.61049574544373030000e+000) (24, -1.11391988832544750000e+000) (25, -1.30420535877396580000e-001) (26, -1.75876314248847380000e+000) (27, 7.51620283912860290000e-001) (20, 4.41022298019479060000e-001) (21, 3.34300613137080980000e-001) (22, 1.26911423789323540000e+000) (23, -1.77890857626286650000e+000) (24, 2.19706682264226630000e+000) (25, 1.31223188593157340000e+000) (26, 1.18534691970901270000e+000) (27, 7.12110719129969590000e-001) (20, -1.48095834097654790000e+000) (21, -1.46533665226139860000e+000) (22, -8.89666393509855320000e-001) (23, 4.17676761485584820000e-002) (24, -9.35576886447339720000e-001) (25, -1.11814820731695000000e+000) (26, 7.01808002497202880000e-001) (27, 1.05713504697415120000e+000) 

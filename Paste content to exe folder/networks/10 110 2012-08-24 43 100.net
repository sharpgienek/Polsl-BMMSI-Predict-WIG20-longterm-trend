FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 4 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.32591148927010760000e-001) (1, 1.00971743859928800000e+000) (2, -3.26842953916541750000e+001) (3, 2.88699062898977980000e+000) (4, -3.28711551549670200000e+001) (5, 2.85443475705468410000e-001) (6, 9.82972778217910380000e+000) (7, 2.08136847794865300000e+000) (8, 1.80658303792757770000e+001) (9, 3.84675216081879380000e-001) (10, -1.15306709915172600000e+001) (11, 1.03098102053994060000e+000) (12, 1.01338826559020170000e-001) (13, 2.64607084692311120000e-002) (14, 3.09469556812478300000e+000) (15, -3.47563569483099330000e-002) (16, 1.61715425896000550000e+001) (17, 1.75227926932820910000e-001) (18, 2.12047000596058130000e+001) (19, 2.67350938938470950000e-001) (0, 1.80873622684187050000e+001) (1, -1.39549439933633360000e+000) (2, 1.91417697682394170000e+001) (3, -1.20407418630836880000e+000) (4, 1.14395484139622220000e+000) (5, 1.43582331457669330000e-002) (6, 1.67371434655035540000e+001) (7, -1.64359357962839350000e-001) (8, -5.39862045816251080000e-001) (9, -1.00414406895545660000e+000) (10, 5.58443781855499300000e+000) (11, -6.53887378172552710000e-001) (12, 3.94736641704592550000e+000) (13, 4.17069788586860170000e-001) (14, 8.90797275795112680000e+000) (15, 1.34328165115631660000e+000) (16, -2.62026005411086070000e+000) (17, -8.77661708001811200000e-001) (18, 3.36959631121329070000e+000) (19, -3.31174060866362970000e-001) (0, 8.78651089401187590000e+000) (1, -1.10789997815564470000e+000) (2, -1.07967031474559350000e+001) (3, -1.05967406650698930000e+000) (4, -1.79828093310622740000e+001) (5, 2.52400388387048650000e-001) (6, 1.15014055667286200000e+001) (7, 1.46731839265315830000e-001) (8, 1.15577526803180410000e+001) (9, -9.66273866543356450000e-001) (10, 3.66791613331901000000e+000) (11, -1.00920456207436950000e+000) (12, 9.95033237593120570000e+000) (13, 8.05134302755680650000e-001) (14, 1.32867994926310650000e+001) (15, 2.33311892919888080000e+000) (16, -1.93817982253700570000e+000) (17, -3.68291434694172080000e-001) (18, 2.99822409873156910000e+001) (19, 4.56059330570588800000e-002) (20, 8.20482248027445400000e-002) (21, -2.41083805829009590000e+000) (22, 2.19788874978414620000e+000) (23, -1.08503777766546320000e-001) (20, 1.01440819654699020000e+000) (21, 1.52601843149623710000e+000) (22, -1.40615999175498940000e+000) (23, 8.36905021049671460000e-001) (20, -1.11797273130605680000e+000) (21, 3.47382247710479430000e-001) (22, -3.45260266233847810000e-001) (23, 1.50919312972129840000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.17971547098442460000e+000) (1, 4.32879943472962210000e-001) (2, -3.81574419896488880000e+001) (3, 6.46650151191756950000e-001) (4, -4.40306519950516350000e+001) (5, -8.67835385616550490000e-002) (6, 1.20504438957150930000e+001) (7, 6.59706736769515970000e-001) (8, 1.27647813875138710000e+001) (9, 7.56034696075072680000e-001) (10, 2.77574934899480360000e+001) (11, -3.10388945333771150000e-001) (12, 3.26609252374518720000e+000) (13, 1.71265513507437910000e-001) (14, -1.16173867526081600000e+001) (15, 2.43569898832134530000e-001) (16, -7.35177181865185150000e+000) (17, 2.05785724592114510000e+000) (18, 1.98480517929553100000e+001) (19, 2.23441016106668760000e+000) (0, 1.63947197793950890000e+001) (1, 8.25471154823830600000e-001) (2, 7.03846287636203800000e+000) (3, -3.25987403420293480000e-001) (4, -2.02470340341634700000e+001) (5, -1.45379715164842160000e-001) (6, 4.94545884190454200000e-001) (7, -4.88890472410656580000e-001) (8, -1.30874500382580890000e+001) (9, 1.45310504882626600000e+000) (10, -2.57267643667821810000e+001) (11, -9.02630191388529730000e-001) (12, -9.16926455368478880000e+000) (13, 1.96194230944057500000e-001) (14, -4.57007119688287930000e+000) (15, -5.50379376234420990000e+000) (16, -5.07436082829567980000e-001) (17, -6.37802502110560890000e-001) (18, -8.85301661262567130000e+000) (19, 5.28079482744603150000e-001) (0, 2.25307785353559000000e+001) (1, 1.07148539279428470000e+000) (2, -1.03037472494788260000e+001) (3, 4.40486943157442080000e-001) (4, -1.12166058867887180000e+001) (5, 6.74745136001288160000e-001) (6, 2.32365979922929950000e-003) (7, -1.54966333423602250000e-001) (8, 6.13028442863146330000e+000) (9, 6.36012588411164480000e-001) (10, 1.65370534648051230000e+001) (11, 1.54691074780609280000e-001) (12, 3.24054576378268470000e+000) (13, 4.46552693202458000000e-001) (14, -1.13332908470270380000e+000) (15, -4.71646369229048850000e-001) (16, 8.77131343962071770000e+000) (17, 1.88093557475861270000e+000) (18, 1.57708058238081960000e+001) (19, 1.38690928507319810000e+000) (0, 1.73970472551945510000e+001) (1, 8.14115710447138820000e-001) (2, 3.97915021669602780000e+001) (3, 6.42717490036010530000e-001) (4, 3.40346703790928800000e+001) (5, 1.14982411759640260000e+000) (6, -1.65192633803160760000e+001) (7, -4.46284862691281700000e-001) (8, -1.59692641032013420000e+001) (9, 1.93100820766128420000e-001) (10, 6.86798343908767880000e+000) (11, 1.42091017381731710000e+000) (12, -6.14287690572295820000e+000) (13, 7.24241560610482530000e-002) (14, 8.28684733385737000000e+000) (15, 6.29384599621664600000e-001) (16, 1.62281159613096090000e+001) (17, -1.53453509514382250000e-001) (18, -1.62444525997784870000e+001) (19, 1.91391028931024730000e+000) (0, -4.57075794408897360000e+000) (1, -2.53306447126480260000e-001) (2, 1.81566565426828500000e+001) (3, 5.22924578916945220000e-001) (4, 2.39312924562819380000e+001) (5, 2.32689391027880800000e+000) (6, -2.77625312644455950000e+001) (7, -2.48629473815074160000e-001) (8, 2.61708521678438370000e+000) (9, -5.38959093593299630000e-001) (10, 2.52954833525468670000e+001) (11, 7.57288225489355370000e-001) (12, 1.99674032933570760000e+001) (13, 3.96909420286656430000e-001) (14, 6.15140093639699440000e+000) (15, 5.42544691288145400000e+000) (16, -2.24830309070042440000e+000) (17, 1.96938677924768340000e+000) (18, 9.10745212445330130000e+000) (19, 8.03206619245965810000e-001) (20, -1.07506264389786280000e+000) (21, -5.92732090504051730000e-001) (22, 1.03798818057692780000e+000) (23, -1.37824389344647180000e+000) (24, 3.35635382927717150000e-003) (25, 1.39371754344208010000e+000) (20, 8.92592064670822190000e-001) (21, -1.10467161823096190000e+000) (22, 4.22231778237618590000e-001) (23, 1.43077580993598800000e+000) (24, -1.72074675071104190000e+000) (25, -6.06425541602060580000e-002) (20, 3.96000410946940380000e-001) (21, 2.05073522250306710000e+000) (22, -1.59369057650343640000e+000) (23, -9.85241130410858810000e-002) (24, 2.08057425748846030000e+000) (25, 9.87894225104464450000e-001) 

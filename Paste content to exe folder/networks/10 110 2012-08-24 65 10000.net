FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.55976790980333480000e+002) (1, 4.39451235095288200000e+001) (2, 1.50000000000000000000e+003) (3, 4.66368073540863580000e+001) (4, 6.69007276417256660000e+002) (5, -1.28688373604692230000e+002) (6, -4.94221129732700770000e+002) (7, -7.43264703293753910000e+000) (8, -5.05156029616381430000e+002) (9, 1.34934214630710160000e+001) (10, 7.39913107954047400000e+002) (11, -4.24920852649589520000e+000) (12, -2.03944072982126930000e+002) (13, -8.95416746297890140000e+001) (14, -2.64773551812762610000e+002) (15, -2.18165877962228620000e+002) (16, 1.61295242688614980000e+001) (17, -3.91706691310007480000e+000) (18, -1.39555116204708220000e+003) (19, 2.68760627840677060000e+001) (0, -4.27918957106283140000e+000) (1, 6.12323300869917420000e-002) (2, -3.65797217579681800000e+001) (3, 4.25920322548524680000e+000) (4, 4.19072154644350620000e+001) (5, 2.02917403186004200000e+000) (6, 5.92534336603234810000e+001) (7, 4.27915913753806440000e+000) (8, 1.88475470325595250000e+001) (9, 1.90238383631380010000e+000) (10, 3.97421130363376670000e-001) (11, 4.49144647449586290000e+000) (12, 1.21863484347107430000e+001) (13, 6.56060604636456900000e+000) (14, 1.39255793637014630000e+001) (15, 5.64603602704604320000e+000) (16, 6.29866894168444350000e+001) (17, -2.03878833863277990000e+000) (18, 5.14005284460970130000e+001) (19, -1.73833100655409640000e+000) (0, 4.17014989412488430000e+001) (1, 4.12926988189515050000e+000) (2, 1.07095582176297340000e+002) (3, 1.96921221767157030000e+001) (4, 6.73443474488371830000e+001) (5, -7.01754663805722330000e+000) (6, -6.72512886365555290000e+001) (7, 7.85167349063842930000e+000) (8, 1.70052673009943900000e+002) (9, 5.34511710040796120000e-001) (10, 1.39979654385067050000e+002) (11, -1.11971783588275970000e+000) (12, 9.63035172335026030000e+001) (13, -2.73489983915523280000e+000) (14, 6.46358394477748130000e+001) (15, -7.71268859443255380000e+000) (16, 2.46303967713412020000e+002) (17, 1.11024785014001730000e+001) (18, 1.49211332288858530000e+002) (19, 9.00844224491891410000e+000) (0, -6.10105323425568140000e+002) (1, -1.96105401576223980000e+002) (2, 1.11552684579885930000e+002) (3, 2.47789902496790180000e+000) (4, -5.00680768727202580000e+002) (5, -6.65870219818036730000e+001) (6, 3.14961045386104710000e+001) (7, 9.43711473580935100000e-001) (8, -4.27906427380763930000e+001) (9, -1.61323895350552290000e+000) (10, -1.38017400781728780000e+002) (11, 1.90355699075553620000e+002) (12, 1.50000000000000000000e+003) (13, 1.20414274495534830000e+002) (14, 7.89378948847971740000e+002) (15, -1.55202529773116570000e+001) (16, 1.27061037015004880000e+003) (17, -5.45412035527030030000e+001) (18, 1.82948032892655130000e+001) (19, 2.69282723061587340000e+000) (0, 7.70664052707523980000e+001) (1, 5.01785314213293530000e+000) (2, -9.40294933512599300000e+001) (3, 6.04703597248858320000e+000) (4, 1.97731080803125620000e+002) (5, 1.05209492180990780000e+001) (6, -5.59149616986825960000e+001) (7, 1.95923361265168810000e+000) (8, 3.71345637295627430000e+001) (9, 2.91737542226212150000e+000) (10, 7.85062753725406000000e+001) (11, -6.45051429179040170000e+000) (12, -1.28112203559109730000e+002) (13, 9.13503778027042610000e-002) (14, 2.38175036383006140000e+001) (15, 1.13916454313991760000e+001) (16, 6.62740458764981070000e+001) (17, 1.05200359205816120000e+000) (18, 3.39113765148824770000e+001) (19, -1.04670943911575760000e+000) (20, -1.52613432048165350000e+000) (21, 6.27020919715718110000e-002) (22, 1.54302664989800480000e+000) (23, -1.04760417214487120000e-001) (24, 2.58394626497088600000e-002) (25, 6.98501251715583170000e-003) (20, 1.93315257949543050000e+000) (21, 1.85150945994599650000e+000) (22, -1.87675226714733800000e+000) (23, -1.86531406261628190000e+000) (24, -1.78535486173719880000e+000) (25, 1.83862171466186000000e+000) (20, -1.71521962360084370000e-002) (21, -1.66066369306793880000e+000) (22, 6.11971080382387590000e-003) (23, 1.71780807579622130000e+000) (24, 1.70258880100257030000e+000) (25, 1.63638408515557270000e+000) 

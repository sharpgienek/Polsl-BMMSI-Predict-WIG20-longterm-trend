FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.11822493045770630000e+001) (1, 2.35925706991993030000e-001) (2, 4.03313602351858550000e+001) (3, -7.18210929017613960000e-001) (4, 8.79279317242660060000e+000) (5, 2.78647558890015560000e+000) (6, -1.17135414569727350000e+002) (7, -3.26585746416090170000e-001) (8, -7.77770754229536290000e+001) (9, 1.03262760501384300000e+001) (10, 9.15698803923047960000e+001) (11, -1.37743678894776630000e+000) (12, 1.57819089894286740000e+001) (13, 1.89713748687104870000e+000) (14, 2.95204611494591160000e+001) (15, 3.56958497857674260000e+000) (16, 2.46248177997395780000e+001) (17, 1.13369070157125320000e+000) (18, -6.47007230738380770000e+001) (19, -4.50953628739448580000e+000) (0, -5.62105113645944150000e+000) (1, 3.54499814991264320000e-001) (2, -8.92272895573516140000e+000) (3, -1.60991976460919290000e+000) (4, -3.74893222065268010000e+001) (5, -1.70075044687443430000e+000) (6, 3.20830187100863280000e+001) (7, 1.16942385312240260000e+000) (8, 2.01938713321641710000e+001) (9, -9.07851537416857760000e-001) (10, -4.60733146076308980000e+001) (11, 1.04869444463330620000e+000) (12, 1.96023014990599160000e+001) (13, -5.44441549776973410000e+000) (14, 2.08137304957209640000e+001) (15, 1.80730044323437600000e+000) (16, -1.33210330639107720000e+001) (17, -1.87151364924680900000e+000) (18, -6.52036412292914310000e+000) (19, -5.33232149037344260000e+000) (0, 2.12858653378798080000e+000) (1, 1.22889505556544390000e+000) (2, -1.51524115290978670000e+001) (3, -9.34386182758733530000e-001) (4, 3.40100888032351370000e+000) (5, 6.43505352432045100000e+000) (6, -1.73580793931225060000e+002) (7, 8.96440657534394700000e+000) (8, -1.25151759167531220000e+001) (9, -8.16054348605638750000e-001) (10, 1.74677190512724320000e+001) (11, 2.37481270160502380000e+000) (12, -1.11236394359916390000e+002) (13, -1.96190753952095600000e+000) (14, 2.65168335680036100000e+000) (15, -9.35601995798687080000e-001) (16, 3.64802005567339410000e+001) (17, -2.49513199642473450000e+000) (18, -1.79931673778243670000e+001) (19, -1.72234641607826580000e+000) (0, 4.50963794096179740000e+001) (1, -7.12671921219007580000e+000) (2, 2.92000511113750970000e+002) (3, 1.18841328611267510000e+001) (4, 1.34884307889107960000e+002) (5, -6.87121787418112720000e+000) (6, 6.61640032510816950000e+001) (7, 3.47596256090057890000e+000) (8, 3.99296999783754390000e+001) (9, -4.42331275626587760000e+000) (10, -1.55459161892837870000e+002) (11, -4.29203994250734130000e-001) (12, 1.30226045512963500000e+001) (13, -2.78008467737147310000e+000) (14, 9.55764743573698040000e+001) (15, -3.18343196621191990000e+001) (16, 4.61774590267963700000e+001) (17, -1.59912339953397780000e+001) (18, -2.54599202280046430000e+002) (19, -3.62863158915668740000e+000) (0, 8.12939081415665190000e+001) (1, 5.82896293564605590000e-001) (2, -4.35709323357849740000e+001) (3, -1.12379302631436580000e+000) (4, -1.65343025398868870000e+001) (5, -9.40762841349410020000e-001) (6, 1.98406398295145920000e+002) (7, -4.69337461972395520000e+000) (8, 3.30493090863975780000e+001) (9, 2.77620836067642250000e+000) (10, 5.59760437849876740000e+001) (11, -3.60101345426805610000e-001) (12, 5.16236941903936990000e+001) (13, 1.24774378984643960000e+000) (14, 5.08179899461417680000e+000) (15, 1.89937991854802530000e+000) (16, -2.25387759793776180000e+001) (17, 4.17156975274365040000e+000) (18, 2.38325882775315700000e+001) (19, 2.70791996265315580000e+000) (0, 2.79852308913310990000e+001) (1, 6.28968073093514880000e-001) (2, -1.90782853021534640000e+001) (3, -1.11037990912190640000e+000) (4, -6.26998107378863740000e+001) (5, 2.43864511663734880000e-002) (6, -3.53434460157015240000e+001) (7, 1.27878629486275060000e+000) (8, -7.04378571179472780000e+000) (9, 1.34734069452136730000e+000) (10, 2.19071476521620130000e+000) (11, 5.17287054352378980000e-001) (12, 2.55823746348013860000e+001) (13, -2.86617971376223450000e+000) (14, 4.69582262611051460000e+001) (15, 2.31586100396841800000e+000) (16, 2.64641897906428520000e+001) (17, -6.79182746995318440000e-001) (18, -5.73745861150963600000e+000) (19, -3.85958497102672690000e+000) (20, -1.64023974174363670000e+000) (21, -1.83711208540845930000e+000) (22, -1.72608135782439140000e+000) (23, -1.22768335110454330000e+000) (24, -1.40239773078426120000e+000) (25, 1.82921427101654180000e+000) (26, -3.14969102916944700000e-002) (20, -4.07487333753835320000e-002) (21, -1.51010474562843890000e-001) (22, 2.07914497306906390000e+000) (23, 1.89645656143438710000e+000) (24, 2.14435569931692930000e+000) (25, 6.37070902347074560000e-002) (26, 1.74412546587974140000e+000) (20, 1.67030706212696560000e+000) (21, 1.94916537740411440000e+000) (22, 4.83062173485345260000e-003) (23, -3.43822365539508730000e-001) (24, -3.28831949978125200000e-001) (25, -1.91496394852111360000e+000) (26, 1.63235431255726900000e+000) 

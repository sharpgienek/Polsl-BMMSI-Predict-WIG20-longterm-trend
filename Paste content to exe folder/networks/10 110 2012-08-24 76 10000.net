FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.13895893481164990000e+002) (1, 9.75991355915334150000e+000) (2, 3.74244838039488120000e+002) (3, 4.50771459666557920000e+001) (4, 1.13665897604980710000e+003) (5, 4.40229103544003590000e+001) (6, 6.29622677503104670000e+001) (7, -5.23981435481595610000e+000) (8, -2.89197215330842820000e+002) (9, 3.09089014924788440000e+001) (10, 2.95630517013237690000e+002) (11, 1.02716795783753930000e+001) (12, 6.03862571417307320000e+002) (13, 6.85445467842485100000e+000) (14, 5.45684315121778130000e+002) (15, 1.99736333287772720000e+001) (16, 3.25670005732490680000e+001) (17, 7.15981781975425860000e+000) (18, -2.02917883952318590000e+002) (19, -8.65242440308169210000e-001) (0, 4.98755710817112000000e+001) (1, 1.82402185115379220000e+000) (2, 6.10561637919983440000e+001) (3, 1.16026995777106250000e+001) (4, -6.76960678920407590000e+000) (5, 9.70065906396131330000e-001) (6, -2.45360382128074730000e+001) (7, -1.15797674248475560000e+000) (8, -5.52342231893787530000e+001) (9, 5.26338185965073360000e+000) (10, -4.80057406288708960000e+001) (11, 4.49281315137367440000e+000) (12, 3.99440960825999200000e+001) (13, 4.25582848012861780000e-001) (14, 7.11373955894593880000e+001) (15, 1.27787530859417740000e+000) (16, 3.54008738377290370000e+001) (17, 5.19007949790367800000e-001) (18, 7.56929473896500870000e+001) (19, -1.27118660649125220000e+001) (0, 7.02319939461575130000e+002) (1, 3.62862425589750220000e+002) (2, 4.59043222915321960000e+002) (3, -1.01865365717686290000e+002) (4, 1.50000000000000000000e+003) (5, -2.67552268475507350000e+000) (6, 1.50000000000000000000e+003) (7, -2.48901011442972620000e+001) (8, 9.46967100027497280000e+002) (9, 3.79593545474674270000e+001) (10, 1.36436800737830840000e+003) (11, 2.42604297141561070000e+001) (12, -2.22036129454961180000e+001) (13, -4.83635194264458830000e+001) (14, 6.39322039982826710000e+002) (15, 5.78358593215613010000e+001) (16, -1.27182856324191740000e+003) (17, -5.17630494802319950000e+000) (18, 1.50000000000000000000e+003) (19, 1.05102700618291550000e+002) (0, 3.63726669197299730000e+001) (1, 1.04802612860604930000e+001) (2, -1.18533974981515140000e+002) (3, -8.36017935209438790000e+000) (4, 9.78277530648644240000e+001) (5, 1.74391163696050370000e-001) (6, 4.61616868038175990000e+002) (7, 8.63481313973084500000e+000) (8, -1.98889432052817850000e+002) (9, -3.05034074426290660000e-001) (10, -1.16330877887776840000e+002) (11, -1.30196789337743080000e+000) (12, 2.09660686204214040000e+002) (13, -2.12680424138093040000e+001) (14, 1.17589568570529480000e+002) (15, 1.03651126453891000000e+001) (16, 7.57564586468091220000e+001) (17, -2.78636995421203440000e+000) (18, 3.38094759381350570000e+002) (19, 1.25937856925096820000e+001) (0, -3.41404073585226940000e+001) (1, -1.53152917408141810000e+000) (2, -6.32053894087018970000e+000) (3, 6.50555599060110730000e-001) (4, -1.58817608493010470000e+001) (5, -1.04504980637315090000e+001) (6, 1.92239343410001100000e+001) (7, 5.76536980121477920000e-001) (8, 3.63331993213590470000e+001) (9, 4.94159269933327090000e-001) (10, -3.40267674807650810000e+001) (11, 6.67314291608821540000e+000) (12, -9.84362748496407110000e+001) (13, -3.30397305964844230000e-001) (14, -3.40076372394929860000e+001) (15, -7.61071055200631810000e+000) (16, -2.30472470032692020000e+001) (17, -2.38789775506556530000e+000) (18, 9.92114587961021850000e+000) (19, -2.28793987908336230000e+000) (0, 6.35561153192021210000e+001) (1, 3.82249185226564770000e+000) (2, -1.53074175783539740000e+002) (3, -1.18136803330726640000e+001) (4, -4.92705248074802000000e+002) (5, -8.63108058272982670000e+001) (6, -1.25565018610543750000e+002) (7, -2.67823856950902920000e+000) (8, 1.54216781558534390000e+002) (9, -7.96452560854783350000e+000) (10, -2.84412948630447720000e+002) (11, 2.65492696741848810000e+001) (12, -9.03801995096108270000e+002) (13, -6.52194112008091910000e+001) (14, 3.96090295580315970000e+002) (15, -1.24658593738908690000e+001) (16, 5.08849679963154240000e+002) (17, -3.34120833272499100000e+001) (18, 6.77562952871879960000e+001) (19, 1.33819354439401130000e+001) (20, -1.83119647660798820000e+000) (21, 1.74221765843414600000e+000) (22, 5.29193069476790230000e-001) (23, -5.80211696008363640000e-001) (24, -1.85018797247625270000e+000) (25, 1.18378020476257710000e-001) (26, 1.69184004224715070000e+000) (20, 2.12404739247892180000e+000) (21, -2.31997718755263800000e+000) (22, -5.87440491189115190000e-002) (23, 2.25540566524472610000e+000) (24, 4.35827572436321020000e+000) (25, -2.17970724433797390000e+000) (26, -1.31045557547371600000e-001) (20, 4.83690313708249400000e-002) (21, -4.39909831318796020000e-002) (22, -2.88381206977245340000e-001) (23, -1.25897144334564000000e+000) (24, -1.50189709292984390000e+000) (25, 1.40362093690690220000e+000) (26, 1.40043628963682740000e+000) 

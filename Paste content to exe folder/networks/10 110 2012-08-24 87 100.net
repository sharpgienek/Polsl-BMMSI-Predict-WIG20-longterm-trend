FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.38781820039188550000e+000) (1, 1.85142169931652820000e+000) (2, -4.16090898388163450000e+001) (3, 4.67756155765083500000e-001) (4, 2.37760024270377810000e+001) (5, -6.88459119626629310000e-001) (6, -5.36655209360184940000e+000) (7, -5.45380669314335260000e-001) (8, 2.06918390806098570000e+000) (9, 1.07060259099005920000e+000) (10, 4.76778560144869990000e+001) (11, 1.16331775102888810000e+000) (12, 2.47028431205279480000e+001) (13, 6.60011822164411900000e-001) (14, 1.61423206054632580000e+000) (15, 7.54839861617645360000e+000) (16, 1.22246038321082960000e+000) (17, 1.88891602829345470000e+000) (18, 2.18392203011682500000e+001) (19, 1.75107309602459390000e+000) (0, 1.06246953570001170000e+001) (1, 1.80381875468905770000e-001) (2, -1.22205779804826480000e+000) (3, 4.82260947645667070000e-001) (4, 1.86822099331887590000e+001) (5, 6.76171106574751430000e-001) (6, 1.48994604216809370000e+001) (7, 1.08872613909733630000e-001) (8, 2.22459581797718190000e-001) (9, -2.48653692081860940000e-001) (10, 6.42828841333232790000e+001) (11, 2.65000206544057450000e+000) (12, -6.32357983133885430000e+000) (13, -1.14786365304020570000e-001) (14, -1.12995459683663600000e+000) (15, -1.58874933027529420000e+000) (16, 2.05298109001905050000e+001) (17, -1.25636732437660910000e+000) (18, -3.48330687658262470000e-001) (19, -1.81685456709331560000e+000) (0, 1.09194567571986700000e+001) (1, 2.58022464010193090000e-002) (2, -2.17478118976449550000e+000) (3, -1.66539736578205030000e-001) (4, 4.34231548444659850000e+000) (5, -1.80347904146736040000e-001) (6, 1.17577561539531210000e+001) (7, -2.06892992055927790000e-001) (8, -6.67670664950593800000e-001) (9, 4.34787917344770070000e-001) (10, 4.29242981134323640000e+000) (11, -1.74517589786385760000e-001) (12, 3.73371300560616120000e+000) (13, 1.95322868729714300000e-001) (14, -1.65149814848454830000e+000) (15, 1.08138320447589640000e+000) (16, 1.01587175056190770000e+001) (17, 4.67787398815499630000e-001) (18, 8.85706382822528230000e+000) (19, 2.19591638182544870000e-001) (0, -4.36196561712405820000e+000) (1, 9.18977193896070160000e-002) (2, 8.50855620098163180000e+000) (3, 5.55260927104958700000e-002) (4, -2.48806547065935210000e+000) (5, 4.19145706079340600000e-001) (6, 2.37121182165284990000e+000) (7, -3.29339946474582030000e-001) (8, -2.83507661864878950000e+000) (9, -8.69365271251687640000e-002) (10, 4.37918090813311070000e-001) (11, 5.42843621172725780000e-001) (12, 9.60845835413712550000e-002) (13, -1.15440309682115850000e-001) (14, 2.97478900358996600000e-001) (15, -2.67106100363402990000e-001) (16, 1.18591700595499780000e+001) (17, 1.43934444755060290000e-001) (18, 6.42461761154319520000e+000) (19, -5.64614639154675800000e-001) (0, 2.92394289839298410000e+001) (1, 3.99953009205548270000e-001) (2, 6.64932215890848880000e+000) (3, 4.30852884460697250000e-001) (4, 1.74251093691542420000e+001) (5, 1.15995733235478780000e+000) (6, -5.37905057686401380000e+000) (7, -5.57686148867928440000e-001) (8, -2.72304326118857420000e+001) (9, 1.88790156360454380000e+000) (10, 8.21011096474490660000e-001) (11, -3.44401467337928040000e-001) (12, -2.43395563727863620000e+000) (13, 3.58500051171875060000e-001) (14, 9.17126142896210620000e+000) (15, 3.59481018992989210000e+000) (16, 1.79100131821246580000e+001) (17, 6.32204503654292590000e-001) (18, -7.57865196670038000000e+000) (19, -2.90418421309495130000e-001) (0, -5.50098371757098010000e+000) (1, 1.96876978245995730000e-001) (2, 1.24732746666980440000e+001) (3, -1.48922287177819080000e+000) (4, -1.44795399815750850000e+001) (5, -4.97564982154881540000e-001) (6, 8.52242721519722050000e+000) (7, -8.48119683851173870000e-001) (8, 8.58961423380277540000e+000) (9, -4.95864601658137010000e-001) (10, -2.99234776081596790000e+001) (11, -2.22532836487898710000e-001) (12, -4.10789461144496390000e+000) (13, 3.68600153618815260000e-001) (14, -6.38617115045447110000e+000) (15, 2.36959477501441330000e-001) (16, 2.58603762805323980000e+000) (17, 1.55373333958259760000e+000) (18, 1.45874305238933030000e+001) (19, 1.45094372964906500000e+000) (0, 3.84454690066914680000e-001) (1, -1.83508025362739340000e+000) (2, 1.51108040184837980000e+001) (3, -2.16320912883307330000e+000) (4, -1.05444008510143020000e+001) (5, -1.29343806757353550000e+000) (6, 2.53235846794152160000e+001) (7, -9.93736719422362750000e-001) (8, -1.60545034950103140000e-001) (9, -5.85875178956605900000e-001) (10, 3.98639756820734050000e-001) (11, -5.93917317188253580000e-001) (12, 1.37211110692619890000e+001) (13, 2.91036730878944440000e-001) (14, -5.83206036508760460000e-001) (15, -1.23955757517983740000e-001) (16, 2.59326797359849550000e+001) (17, 2.55856247885517140000e-001) (18, 1.22080895648851230000e+000) (19, -5.52202673396258390000e-001) (20, 4.51937690064778800000e-001) (21, -1.46012994504485700000e+000) (22, 1.34703435021361660000e+000) (23, 1.55092672381372430000e+000) (24, -1.52322677390832720000e+000) (25, -1.34638007338541080000e+000) (26, -3.69948003995712480000e-001) (27, 5.89748687917654450000e-001) (20, -1.64318595315614700000e+000) (21, 1.85704620048811030000e+000) (22, 1.42743853679730060000e+000) (23, -1.22390813469037310000e+000) (24, 1.05480745913181550000e-001) (25, 1.11786319296052230000e+000) (26, -9.09824712914588220000e-001) (27, 1.19914194662337240000e+000) (20, 8.50580437032866120000e-001) (21, -2.45862880175220400000e-001) (22, -2.44068238017456940000e+000) (23, -2.41575103671256230000e-001) (24, 1.15339901168877930000e+000) (25, 2.07763993148750270000e-001) (26, 1.39232972512195600000e+000) (27, 1.06203164156655380000e+000) 

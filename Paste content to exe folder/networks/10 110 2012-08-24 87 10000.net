FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.27869458710350730000e+001) (1, 1.02070233387205840000e+000) (2, 1.29461105396865950000e+002) (3, 2.86856600934597730000e-002) (4, 2.46915103467463610000e+000) (5, 1.24749562442654340000e+000) (6, -4.46788972744502360000e+001) (7, 3.69742305997486250000e+000) (8, -6.25717413340590700000e+001) (9, -6.70724834481961270000e+000) (10, 2.17506432567149180000e+002) (11, -7.58835041929135530000e-001) (12, 9.03724834680842410000e+001) (13, -1.38688169534878350000e+000) (14, 4.07522355215774820000e+000) (15, 2.73026740084834520000e-001) (16, 1.56800139031141980000e+002) (17, -5.52006637526394870000e+000) (18, 1.48527253590103820000e+001) (19, 6.05295732822623210000e+000) (0, 1.27221448735170040000e+002) (1, -2.40017293256543420000e-001) (2, -4.36654120623459510000e+001) (3, 4.07396269306867610000e+000) (4, -1.65683555354523830000e+001) (5, -1.35163108196656690000e+000) (6, 3.71755345962190940000e+001) (7, -6.17597351024831150000e-001) (8, 4.91668961995018140000e+001) (9, 1.25481548120716060000e+000) (10, -4.07856533002094540000e+001) (11, -4.41149653852845610000e+000) (12, 5.69687166878754000000e+001) (13, 1.51108340060633740000e+001) (14, 1.25724314133377820000e+002) (15, 7.78932727154268980000e+000) (16, -6.58430908806998620000e+001) (17, 9.22569877972125950000e+000) (18, 7.85598039363990490000e+001) (19, -6.00753238026698800000e+000) (0, 2.22741549563067310000e+001) (1, 7.64791297517626760000e-001) (2, -6.85192752479869220000e-001) (3, -1.99477125325022420000e+000) (4, 1.48132353388210230000e+001) (5, -1.28849053026006200000e+000) (6, -1.23719565564045180000e+001) (7, -1.83996401880983120000e+000) (8, -1.56488384947199660000e+001) (9, -2.97274585939819010000e+000) (10, 4.77018765045851510000e+001) (11, 7.50674634108029810000e-001) (12, -4.20958070462766120000e+001) (13, 3.42810771528639520000e+000) (14, -8.35421531607434820000e+001) (15, -4.16142141026677330000e+000) (16, -1.06642015718134410000e+001) (17, 1.26998003171812090000e+000) (18, 6.83837478996058620000e-001) (19, -1.39356028072776870000e+000) (0, -1.32623570677276380000e+002) (1, -1.25846563086233110000e+001) (2, 3.65148993289122360000e+002) (3, -1.87551839140093290000e+001) (4, 3.24757946592633000000e+002) (5, -1.60744882090544260000e+001) (6, -4.29506841473060280000e+001) (7, -7.32806977407326080000e+000) (8, -1.85245004013731150000e+002) (9, -3.93767536557497520000e+000) (10, -1.08354527104574130000e+002) (11, -4.66107600033475220000e+000) (12, -6.21016979720058300000e+001) (13, 7.21870998919559440000e+000) (14, 3.26007150677054430000e+002) (15, 2.19910660360028000000e+000) (16, 2.56162490541015550000e+001) (17, -8.85048347148831920000e+000) (18, -4.80181726246211300000e+001) (19, 1.98641917102671960000e+000) (0, 1.11872137970917680000e+002) (1, 1.42250163445752610000e+000) (2, -8.86420899804816430000e+001) (3, 9.71010133395618700000e+000) (4, -1.28346447222872740000e+002) (5, 1.41860012588772340000e+001) (6, -2.74912021859530500000e+001) (7, 2.10277020669100480000e+000) (8, -1.51609818875548910000e+002) (9, 1.20205780273347480000e+001) (10, -7.15856625088024430000e+001) (11, -6.07706084177059310000e+000) (12, -6.92656223412492120000e+001) (13, 2.15362572979522500000e+000) (14, -5.50250255877793890000e+001) (15, 3.73652145982907700000e+001) (16, -1.68348313121516810000e+002) (17, 2.04504076466442180000e+000) (18, -7.66533249882072310000e+001) (19, 6.91437527329347200000e+000) (0, 3.62384700089924510000e+001) (1, 1.52115247388464400000e+000) (2, 3.23761460097560840000e+001) (3, 2.17993548451337830000e+000) (4, 1.91330284825201890000e+001) (5, 9.31066189237310300000e+000) (6, 7.39046519296012430000e+001) (7, 3.04347882849432060000e+000) (8, -7.12692687307382190000e+001) (9, 4.20395698967979390000e+000) (10, -3.43484294466075040000e+001) (11, -4.61386983908684380000e+000) (12, -8.21666291725441230000e+000) (13, 2.91432029082432060000e+000) (14, 2.23578222434080690000e+001) (15, 7.97064573740421700000e+000) (16, -2.05233965985838300000e+001) (17, 3.73385278855619250000e+000) (18, 2.59059964488908610000e+001) (19, -2.64991176696261430000e-001) (0, -2.90316406190299430000e+001) (1, -4.07830068735169750000e-001) (2, -6.69072903467075350000e+000) (3, -9.27474766630687400000e-001) (4, -4.04793895177188110000e+000) (5, 1.14567274360367580000e+000) (6, -1.07877744290781300000e+001) (7, 1.15464761844727380000e+000) (8, 2.59182939216861890000e+001) (9, -2.81607438970980560000e-001) (10, 1.85330016894196030000e+001) (11, -2.85170174289508080000e-001) (12, 2.61755125038001990000e+001) (13, -9.09806145863670680000e+000) (14, 3.33405475982044880000e+001) (15, -9.72349389543277210000e-001) (16, 6.57766037029465680000e-001) (17, -1.50779777969639260000e+000) (18, -8.21053488140942630000e+000) (19, 1.15713235906462250000e+000) (20, 1.94644921764754790000e+000) (21, 3.25805265316944050000e+000) (22, 5.88067961324576710000e-002) (23, -9.75834299521728950000e-002) (24, 1.74901622406870280000e+000) (25, -3.20254676744942970000e+000) (26, 1.45275262611190010000e+000) (27, 1.39860271230469090000e+000) (20, -1.50719396675126350000e+000) (21, -3.45283203148470500000e+000) (22, -2.19085354947977830000e+000) (23, -1.98946755481237330000e+000) (24, -5.80604461912353020000e+000) (25, 5.77061714850789280000e+000) (26, -2.16734768402539580000e+000) (27, -6.03221320776210420000e-004) (20, -2.81737441966652180000e-001) (21, -1.34204621810987520000e-001) (22, 1.59972281664221240000e+000) (23, 1.65978062250115930000e+000) (24, 2.89673477772163010000e+000) (25, -1.51454193744533770000e+000) (26, 2.46969230656407720000e-001) (27, 1.83572986146903690000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 4 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.30557740564563720000e+001) (1, 5.61103820454503910000e-001) (2, -4.61256004023709070000e+001) (3, -1.18756234816828270000e+000) (4, 4.59912561994947710000e+001) (5, -2.22016082025289090000e+001) (6, 1.87166728774271410000e+002) (7, -2.28752979787648100000e+000) (8, -1.53247282462068400000e+000) (9, -4.50835822086842430000e+000) (10, 9.69833342495688560000e+001) (11, 2.07370862681522410000e+000) (12, 1.01179913908515290000e+002) (13, -9.60298196336247910000e-001) (14, -1.13191993094742430000e+001) (15, -6.76060167177249840000e+000) (16, 5.18597771232304010000e+001) (17, -2.74488605902404670000e+000) (18, 2.13259533914810360000e+001) (19, 3.64055758137894260000e+000) (0, -3.85434493922862340000e+001) (1, 7.77392844372778580000e+000) (2, -7.14367325590667120000e+001) (3, 2.06793105324153360000e+001) (4, 7.63750907353814680000e+000) (5, 2.71216423696571820000e+000) (6, 1.48753266557064700000e+001) (7, 2.36293456551978660000e+000) (8, 1.51093691168599860000e+001) (9, 3.22718729028378840000e-001) (10, 1.75186137898909950000e+001) (11, -1.54970952798383400000e+000) (12, 8.30856307565212260000e+001) (13, 3.21563172528099540000e+000) (14, 8.65274524669531930000e+001) (15, -7.17722492956636930000e-001) (16, 2.42231898168820900000e+001) (17, 1.55412129924616570000e+000) (18, -3.33792633528395090000e+001) (19, -2.99311328212179810000e+000) (0, 1.65694170529976280000e+002) (1, -1.49920836610876410000e+001) (2, 1.73033437837956040000e+001) (3, -2.91664802967947560000e+001) (4, -1.41304659667210930000e+002) (5, 3.51582599635229750000e+000) (6, 2.41789041523613260000e+001) (7, 1.41386149326041080000e+000) (8, 8.47855008918923970000e+001) (9, 5.93401824728651040000e+000) (10, -4.18939434598555140000e+001) (11, 7.03417237987919640000e+000) (12, -1.63037077374299570000e+002) (13, -1.84437503625745790000e-001) (14, 1.64977690482125080000e+001) (15, 1.52806507083106400000e+001) (16, 9.94219837412445170000e+001) (17, 3.92297025105232540000e+000) (18, 1.77543913215691650000e+002) (19, 4.19351974801039070000e+000) (20, 2.14380518834262760000e-001) (21, 1.67714257175873560000e+000) (22, 1.63475167573929640000e+000) (23, 1.40212876424315290000e-001) (20, 7.38942897638476090000e-001) (21, -4.43084438979736430000e-001) (22, -2.71429211917417980000e-001) (23, 1.38203197673131810000e+000) (20, -8.10972262480410430000e-001) (21, -7.64226270107153940000e-001) (22, -8.62478009120113190000e-001) (23, 8.27599349019433550000e-001) 

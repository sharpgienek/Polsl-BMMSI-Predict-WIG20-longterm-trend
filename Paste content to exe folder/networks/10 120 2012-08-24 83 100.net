FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.07914963494440210000e+000) (1, -1.32797252796249190000e+000) (2, 1.04734152350123790000e+001) (3, -2.42178423450840220000e+000) (4, -9.95870676135279350000e+000) (5, 7.54150286206197870000e-002) (6, 8.25369123460114710000e-001) (7, -4.19636444802598430000e-001) (8, -9.04980781229307860000e-002) (9, -1.32790940615131750000e-001) (10, -7.16396466898040090000e+000) (11, -6.82227740533157270000e-001) (12, -1.47447836304818130000e+000) (13, -4.49644409949561510000e-001) (14, 6.47152295976122670000e-001) (15, 2.63462922345826630000e-001) (16, -7.17245224111584530000e-001) (17, 2.89530308792597950000e-001) (18, 1.64630532018432410000e+001) (19, 3.91257806690712810000e-001) (0, 1.67349333495940190000e+001) (1, -3.19698442185285810000e-001) (2, -4.37525644431044400000e+001) (3, 4.86701118337097590000e+000) (4, 2.89075625709846980000e+001) (5, 6.89508603685856980000e-001) (6, 4.57689635432810110000e+001) (7, 4.68740277638522770000e+000) (8, 2.13861072004435790000e+001) (9, -1.21950797029453440000e+000) (10, 1.56589995634893420000e+001) (11, 2.00067161594640640000e+000) (12, 1.88189639200773620000e+001) (13, -3.42786878306049370000e-001) (14, -9.44053274567536780000e+000) (15, 3.22258073965809680000e+000) (16, -8.36819272848958630000e-001) (17, -6.81712408161785910000e-001) (18, 1.78632797066112410000e+001) (19, 2.50314300419914150000e-001) (0, 5.32664537658266490000e-001) (1, 1.66549945280147060000e+000) (2, -1.70957969678600710000e+001) (3, 5.62974309569960420000e-001) (4, 6.80584385591409640000e+000) (5, -6.14923398346016500000e-001) (6, 4.68094953074026860000e+000) (7, 4.80024062083363600000e-002) (8, 5.66923591698491380000e-001) (9, 2.42621694415473370000e+000) (10, -3.09459194094291660000e+001) (11, 4.58715396117001460000e-001) (12, -2.01064796574190650000e+001) (13, 1.26560329305528770000e-001) (14, 3.63625308231627590000e-001) (15, -1.76891677760604770000e+000) (16, -8.41596611539094570000e+000) (17, 1.54742361476314950000e+000) (18, -9.03076085114441440000e+000) (19, 1.15740751754797430000e+000) (0, -1.41083499024151900000e+001) (1, 1.05063431882238030000e+000) (2, 1.37001962404156820000e+001) (3, 2.73646059102014140000e+000) (4, 3.15330360408914030000e+001) (5, -8.65172405353158870000e-001) (6, -4.63077188649460850000e-001) (7, 9.73190654022006720000e-002) (8, -1.05202335088643150000e+001) (9, -2.71763711444768910000e-001) (10, 1.32442858882134450000e+000) (11, 1.49205178113525560000e+000) (12, -3.53240652415167400000e+000) (13, 1.89853355123055560000e-003) (14, -4.16068455257927730000e+000) (15, -1.90237904622185260000e+000) (16, -1.94122652546192680000e+000) (17, -1.40589745861707120000e+000) (18, -3.60824473100988640000e+001) (19, 2.45025859293574460000e-001) (0, -3.26558249005893440000e+001) (1, 1.17924144583332250000e-001) (2, 2.89584877522492580000e+001) (3, -5.29356373621773010000e-001) (4, -1.84914505800422080000e+001) (5, 5.12592004176311460000e-001) (6, 1.95238178937620500000e+001) (7, -1.34224538596608460000e-001) (8, -9.78453949903711790000e+000) (9, 1.11428127498332770000e+000) (10, -9.37499354752938710000e+000) (11, 8.22041834911482470000e-002) (12, 2.85925519374088330000e-001) (13, -3.74454689068187460000e-001) (14, -1.04917079042695340000e+001) (15, -2.15300346246510040000e+000) (16, 5.81038762267245710000e+000) (17, -1.10903018270992900000e-002) (18, -1.90011957346376550000e+000) (19, 3.56373514916582420000e-001) (0, -1.69799741282383150000e+001) (1, -1.68462498313150740000e-001) (2, 2.90389723527549660000e+000) (3, 1.92459489039135920000e+000) (4, -6.06236923640252810000e+000) (5, 8.18414884715867430000e-001) (6, 1.97989627705507940000e+001) (7, 7.11655000246422920000e-001) (8, -6.95960610771417180000e+000) (9, -7.12873340270958830000e-001) (10, -1.81645736845100860000e+000) (11, 6.71731512480284070000e-001) (12, 6.01043389435463560000e+000) (13, -1.03770646997139470000e+000) (14, -2.66346853723511860000e+000) (15, 3.95984583116713640000e-001) (16, 1.02296120090293950000e+001) (17, -8.82503687904216740000e-001) (18, -1.25368853284690330000e+001) (19, 5.45532637696228840000e-001) (20, -1.46326732787126890000e+000) (21, 4.97291623798118090000e-001) (22, 5.13175665687724550000e-001) (23, -1.72739612580350330000e+000) (24, 3.56720759191709760000e-001) (25, 2.53500595532645590000e-001) (26, -1.08233776031292630000e-001) (20, 9.35706537991948140000e-001) (21, 1.12144937277011090000e+000) (22, -2.88997619408285560000e-001) (23, 1.45541796056646370000e+000) (24, 6.54205028101488060000e-001) (25, -1.40958016753045870000e+000) (26, 1.19627431339360250000e+000) (20, 6.34663270944736400000e-001) (21, -1.38434880600052530000e+000) (22, -3.42299964371551230000e-002) (23, 2.97994103827133870000e-001) (24, -9.55560934507763580000e-001) (25, 1.00578022694912380000e+000) (26, 1.17751014526262670000e+000) 

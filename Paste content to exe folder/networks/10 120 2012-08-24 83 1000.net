FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.76481862326707600000e+001) (1, -9.95981515343860040000e-001) (2, 6.77128381103519810000e+001) (3, 2.20079666066055600000e+000) (4, 4.40706565845297290000e+001) (5, -2.66788339791197430000e+000) (6, 4.72211845313479370000e+001) (7, 2.14197193629484560000e-002) (8, 5.85288560705909480000e+001) (9, -2.70285039439350560000e+000) (10, 6.90571473267027760000e+001) (11, 3.97893278612660020000e+000) (12, 6.07792106185730890000e+001) (13, -4.36920010638543130000e-001) (14, -2.61709103593753410000e+001) (15, -4.12374797708712480000e+000) (16, -4.82157489221866410000e+001) (17, -6.67966875426990960000e-001) (18, 5.90888277744744170000e+000) (19, 6.48807444865352690000e-001) (0, -1.75277783709658690000e+001) (1, -1.27464961714079230000e-001) (2, 2.74493224230455230000e+001) (3, 6.83992132004155980000e-001) (4, 6.83870587745818970000e+000) (5, -1.58654293495369720000e-001) (6, -1.62361031365551970000e+001) (7, 1.42992665551541110000e-001) (8, 5.21716505503723390000e+000) (9, -5.74896353884754690000e-001) (10, 1.06803049235118030000e+001) (11, 3.97528844133655660000e+000) (12, 5.44672633823656760000e+000) (13, -6.26082147294942270000e-001) (14, -9.89371062750337420000e+000) (15, -1.42762618860809340000e+000) (16, -1.68689136912663820000e+001) (17, -1.38034585244223210000e+000) (18, -1.35955689482705150000e+001) (19, 3.49122243412550380000e-001) (0, 7.21042733934770440000e+001) (1, -9.02832466217455720000e-001) (2, 8.46638827263520850000e+001) (3, 1.61796163759950270000e+000) (4, -5.69674575724406580000e+001) (5, 1.00033081253700050000e+000) (6, 1.68096888416590820000e+001) (7, 2.02307032789759770000e+000) (8, 5.97744510296627570000e+001) (9, 6.54933878823965900000e+000) (10, -1.10620491593766430000e+002) (11, -1.31721014746940440000e+001) (12, -3.17220045059822130000e+001) (13, 7.54852018060378490000e-001) (14, -7.27723199448746240000e+001) (15, -3.43960097751809490000e+000) (16, 4.38138338081882670000e+000) (17, 2.55835717083648410000e+000) (18, 1.00868186417590990000e+000) (19, -9.43444625931004130000e+000) (0, 1.50137124396432430000e+001) (1, 1.35872322250206870000e+000) (2, 7.80709054538025240000e+001) (3, 4.69379141305955280000e+000) (4, 1.23228799360229960000e+001) (5, -5.62908507261204960000e+000) (6, -7.97067193503765170000e+001) (7, -2.65242903777121670000e-001) (8, -9.47711482587571300000e+000) (9, -3.44785671722439010000e-001) (10, 2.30367478463626660000e+000) (11, 1.28962539678849520000e+000) (12, -2.69971143747595330000e+001) (13, -1.00805377822278340000e-001) (14, -1.41704669732622810000e+001) (15, -6.55015280398411990000e+000) (16, 3.15172261728394790000e+001) (17, -3.06403971599545420000e+000) (18, -4.58959806524619720000e+001) (19, 1.16912867511291840000e+000) (0, -1.72238160805737290000e+002) (1, 4.32858263167256310000e+000) (2, -1.74060362028697750000e+001) (3, 4.90463664901791670000e+000) (4, -1.99659842767839030000e+001) (5, 1.60876580551369380000e+001) (6, -1.95606002230636700000e+001) (7, 5.06253474203965510000e+001) (8, 4.52496668138734250000e+001) (9, 9.36742169917383020000e+000) (10, -4.72716547573889590000e+001) (11, 1.14447717256903410000e+001) (12, 6.76727277589942130000e+001) (13, -6.63622416385270090000e-001) (14, 3.42577080167922080000e+001) (15, 3.36897964225323410000e+000) (16, 7.46058771218290100000e+001) (17, -6.36777416451614810000e+000) (18, -1.47519529380898290000e+001) (19, 2.57693302766722840000e+000) (0, 4.42695452856858030000e+000) (1, -1.13447258782140170000e-001) (2, -1.43068526760062800000e+001) (3, -9.49798694202854790000e-001) (4, 9.23656048815945210000e-001) (5, 2.57220350462206760000e-001) (6, 1.25820346247412850000e+001) (7, -2.15223365126165740000e-001) (8, -6.57812702839840300000e+000) (9, -9.35367954904775120000e-002) (10, 1.08865066603339430000e+000) (11, -4.22843224177494150000e-001) (12, 1.50456415002287280000e+000) (13, -5.82131724848042810000e-002) (14, 1.03300643278394590000e+000) (15, 5.84774533014518650000e-001) (16, -8.16236915172149360000e-001) (17, 1.30001816854011020000e-001) (18, 3.10889998065174970000e+000) (19, 7.03317976713530910000e-001) (20, 4.20228837508861420000e-002) (21, -2.13176215598525510000e+000) (22, -1.33122430004298330000e+000) (23, -1.82091419454975840000e+000) (24, 6.77526375507153410000e-003) (25, -3.92692468019514210000e+000) (26, 8.54871178357529460000e-001) (20, 2.01137084069487400000e+000) (21, -6.14369813627084340000e-002) (22, 1.09222023482216810000e+000) (23, 1.81419546192032490000e+000) (24, 1.20019803701405330000e+000) (25, 4.17832413034075860000e+000) (26, 3.11715380127096490000e-001) (20, -2.52660482147373330000e+000) (21, 2.66414563487319930000e+000) (22, 2.08209215469906590000e-001) (23, 1.31076329589791350000e-001) (24, -1.63597619385103470000e+000) (25, -1.01165121756888860000e-002) (26, 1.76670843231891910000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.69893562760065240000e+000) (1, 1.57092186933015570000e+000) (2, -1.11083161933371370000e+001) (3, -6.92812577707438870000e-001) (4, 1.90134854083429480000e+001) (5, 1.09828643720868600000e+000) (6, -2.05173262748013660000e+001) (7, 9.39840573301971990000e-002) (8, -3.13380280514587150000e+000) (9, 8.17287054222586740000e-001) (10, 9.66827514007586860000e+000) (11, -1.24120135898122500000e-001) (12, 7.06164864066376020000e+000) (13, -5.20596097258958640000e-002) (14, -8.05246144184813770000e+000) (15, 6.47129999656760100000e-001) (16, -3.02371912876230980000e+001) (17, 6.13254643877916510000e-001) (18, -3.80168377562785540000e+000) (19, -1.85339772294109940000e+000) (0, 3.01725074716866250000e+001) (1, -6.57533677046426730000e-001) (2, -4.15749052625706880000e+001) (3, -2.28314852869231120000e-001) (4, -8.59305427649148610000e+001) (5, 1.22887127806038320000e+000) (6, 1.46599824574240590000e+001) (7, 2.68461181003336440000e-001) (8, 2.59054574089741260000e+001) (9, 7.39734048066379430000e-001) (10, -2.69047747829854520000e+001) (11, -2.60079116592909320000e+000) (12, -6.99525186880114450000e+000) (13, 3.47642055641252560000e-001) (14, 1.78414087710349950000e+001) (15, 4.06918205039408140000e+000) (16, 4.53320012491673840000e+001) (17, 5.05224622397744310000e+000) (18, 8.41890197634874400000e+000) (19, 2.52046071386795020000e-002) (0, 2.77654494553231550000e+000) (1, -3.02687371194284350000e-001) (2, -5.22982606294466290000e+000) (3, -4.76715228021222130000e-001) (4, 1.83084263356932340000e+001) (5, -8.35085520038531650000e-001) (6, 5.11795133224018670000e+001) (7, 3.28742457361702050000e-002) (8, -1.42015469056705010000e+001) (9, 1.43297395838856150000e-001) (10, -2.34697588624515770000e+001) (11, -2.65461913032172430000e-001) (12, -1.71106747896241160000e+000) (13, 9.75714537409982260000e-001) (14, 6.26399880997353530000e+000) (15, 2.39766857907845220000e+000) (16, 2.63818393811741170000e+001) (17, -7.09578297334622410000e-001) (18, 4.29030806638943750000e+000) (19, 3.00162820237199760000e+000) (0, -2.80281846336912430000e+001) (1, -1.52690520182950550000e+000) (2, -5.87516268431530260000e+001) (3, 3.08680752460098460000e-001) (4, -1.88048557880543470000e+001) (5, 2.29485813548438250000e-001) (6, 7.76358577045622140000e+000) (7, 3.36562065317686490000e+000) (8, -7.53412969168394220000e+000) (9, 1.03219832428591810000e+000) (10, 3.97338836161223840000e+001) (11, -1.78567837893004680000e+000) (12, 2.61526016283469290000e+001) (13, 2.26887497684143740000e+000) (14, -8.87611530561702720000e+000) (15, 1.69505935648367860000e-001) (16, 1.84197733564670620000e+000) (17, 3.96491610409008380000e+000) (18, 1.33285670286028810000e+001) (19, 1.24859554112612890000e+000) (0, 1.75281241103977730000e+001) (1, 2.68281189973453630000e-001) (2, -2.84481415443907220000e+001) (3, -7.90590454942675790000e+000) (4, -3.13930639047872620000e+001) (5, 9.30836865642904580000e-001) (6, -7.95052038953786000000e+001) (7, 1.59958308709761520000e-001) (8, -3.15335114567198220000e+001) (9, 2.44488216603981150000e+000) (10, 2.33780366104046460000e+001) (11, -6.24665254362860000000e+000) (12, 2.36836129268882690000e+001) (13, 1.12330107511774440000e+000) (14, -7.23528487570767000000e+000) (15, 7.99177762775788740000e+000) (16, -3.37104376592334210000e+001) (17, 2.63910942229774960000e+000) (18, -1.92747988012355730000e+001) (19, -1.90839074227348890000e+000) (0, -3.21619807484788040000e+001) (1, 4.42274114717467980000e+000) (2, -7.91339538905257310000e+001) (3, 2.85805368956487050000e+000) (4, -1.78096024076175040000e+001) (5, 3.07576767442971600000e+000) (6, -1.25869127687446570000e+001) (7, -4.92361447395957690000e-002) (8, -2.72115386375345310000e+001) (9, 8.39274797969984390000e-001) (10, -5.59723147254538700000e+001) (11, -2.15832440856880630000e+000) (12, 9.82441762529444950000e+000) (13, -4.70234002959029780000e-001) (14, 3.90528315185692860000e+000) (15, 2.93663948237999730000e+000) (16, -1.29766420340895230000e+000) (17, 4.27690349635568800000e+000) (18, 1.69271583289042590000e+000) (19, -5.82618927587168700000e-002) (0, 4.30771077155799700000e+001) (1, 2.27789763704543360000e+000) (2, 5.66638502140612490000e+001) (3, 5.53424344303727670000e-001) (4, 1.43297477992952920000e+001) (5, -3.62280809280702110000e-003) (6, 3.06031565853034910000e+001) (7, -2.97050856195520920000e+000) (8, -1.01763256527755910000e+000) (9, -1.74866849551763930000e+000) (10, -5.15185608091140350000e+001) (11, -1.46919365733638820000e+000) (12, -1.38688759676519810000e+001) (13, -2.11753375929092020000e+000) (14, 3.63674599695218320000e+001) (15, 3.74043914945131340000e+000) (16, 1.95748623636442220000e+001) (17, -1.26186821203874680000e+000) (18, -4.62465469597070610000e+001) (19, 2.08799269179334730000e+000) (20, -4.19482522680440890000e-001) (21, 1.10442104509334400000e+000) (22, 1.93800470443874300000e+000) (23, -1.72153999976224740000e+000) (24, -4.32618730265585670000e-002) (25, 1.26491817710452990000e+000) (26, -2.20497827976981190000e+000) (27, -5.47932745629303830000e-001) (20, 2.92785567757080180000e+000) (21, 1.75949967001105710000e-001) (22, 3.83660711211353420000e-001) (23, 2.26802187077912130000e+000) (24, -2.33545405864997410000e+000) (25, -2.47844635793012240000e+000) (26, 1.89961442330425560000e+000) (27, 1.65160660127357510000e+000) (20, -2.18155519276919390000e+000) (21, -1.06663299990668390000e+000) (22, -1.93538209854967570000e+000) (23, -1.65872052912047900000e-001) (24, 1.97518073525760300000e+000) (25, 8.51759439136205660000e-001) (26, 3.22346866588584970000e-001) (27, 1.69636430448314420000e+000) 

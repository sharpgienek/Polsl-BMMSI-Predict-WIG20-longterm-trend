FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.74057386026443340000e+001) (1, 2.43305661285063750000e+000) (2, -7.04771346623662820000e+001) (3, 1.32639849234494860000e+000) (4, 1.80040745316471520000e+000) (5, -5.07447307801439610000e+000) (6, 8.70023771646605580000e+001) (7, 8.44963817386320310000e-001) (8, 1.62106336243476290000e+001) (9, -2.65394908297194390000e+000) (10, -7.22810872676399360000e+000) (11, 6.37251679492848040000e+000) (12, -5.49050671888333500000e+000) (13, 4.03160225189094050000e+000) (14, -6.48146963529031550000e+001) (15, 1.78242192445320740000e+001) (16, -1.98647040983044500000e+001) (17, -2.27742147366149080000e+000) (18, 5.53837615479844200000e+001) (19, 2.28502389265982360000e+000) (0, 2.83249342550611520000e+002) (1, 1.19614776337839890000e+001) (2, 1.66811077651823130000e+002) (3, 5.14742988818055380000e+001) (4, -4.48926245338457690000e+001) (5, 9.00158571675806480000e-001) (6, -7.22849266107202300000e+000) (7, -7.05397380807289660000e+001) (8, 2.01644802761600000000e+002) (9, 2.46234746361357640000e+001) (10, -3.87269010659853900000e+002) (11, 1.46697326942067200000e+001) (12, -5.37611826366309510000e+002) (13, 2.29439316221508570000e+000) (14, -3.45424499816715750000e+002) (15, 4.80270197892949380000e+000) (16, -3.86973039130436750000e+002) (17, 3.48588959263790430000e+000) (18, 3.54876983631621240000e+001) (19, -5.38023914183368670000e+001) (0, 4.15948541230958210000e+001) (1, -4.35926325670369650000e-001) (2, -1.15870879726481870000e+002) (3, -1.58195706461719680000e+000) (4, -6.92003547122482400000e+000) (5, 5.59608680629453130000e-001) (6, 8.42248203051718600000e+001) (7, -1.51818535322099460000e+000) (8, -1.73219218929971350000e+001) (9, 5.20384788420111710000e-001) (10, 5.46645167656650910000e+001) (11, -3.53628849791660520000e+000) (12, 1.31996219019962260000e+001) (13, 3.12209696303398500000e+000) (14, -2.31669031242575510000e+001) (15, 5.06444056147345110000e-001) (16, 9.65879747483176490000e+000) (17, 8.94553018034850030000e+000) (18, 2.12776967186832020000e+001) (19, 5.07597198437652610000e+000) (0, 6.44143183797804570000e+002) (1, 2.74320287950543680000e+001) (2, 4.42046041453012180000e+001) (3, -1.87758523254904080000e+001) (4, 7.55266036088507060000e+001) (5, 4.32556848250591490000e+002) (6, 1.50000000000000000000e+003) (7, 1.27719823496813940000e+001) (8, -4.04426276109015250000e+002) (9, 6.05829932176362010000e+000) (10, 5.82290948869739170000e+002) (11, -1.12149348528709890000e+002) (12, 1.17740919548043980000e+003) (13, 4.14174083435259700000e+001) (14, -3.96774206568323170000e+002) (15, 1.99285533536856060000e+002) (16, -2.74939252688398990000e+002) (17, 1.25552329687282740000e+002) (18, 1.42871582327244910000e+003) (19, 6.00980945733574940000e+000) (0, -4.01340328757524030000e+001) (1, 6.71364821981111250000e+000) (2, -2.19832940875578020000e+001) (3, -2.93483311901193570000e+000) (4, 3.14956941549231470000e+001) (5, 7.80541751734334180000e+000) (6, 3.52834365711513060000e+001) (7, 1.11736262738632380000e+001) (8, 3.07233816257784940000e+001) (9, 1.33777705957841690000e+000) (10, 3.40106843238903950000e+001) (11, 4.35932448802930750000e-001) (12, 6.65192972032722540000e+000) (13, -2.92162712727902200000e+000) (14, -4.65809142362237910000e+001) (15, 3.02721520236789940000e-001) (16, -3.40728315556372080000e+001) (17, 1.04802477749081800000e+000) (18, -5.37742396797446030000e+001) (19, 1.95730760585034380000e+000) (0, -2.84304791455685400000e+001) (1, -1.69689946298209080000e+000) (2, -3.07575365925254300000e+001) (3, -4.98011464381415880000e+000) (4, -9.16060633826717350000e+001) (5, -3.83934818540991070000e+000) (6, -1.43265772654413300000e+001) (7, 2.49184717238014340000e+000) (8, 5.78447506024412520000e+001) (9, -1.97441743439993940000e+000) (10, 6.17569493602628940000e+000) (11, -1.53880011445647390000e-001) (12, 1.60180163721919770000e+000) (13, -5.65747052679426600000e-001) (14, -1.85654784075691980000e+000) (15, -1.67021429359260140000e+000) (16, 5.55563727594718150000e+000) (17, -1.95300417158595340000e+000) (18, 3.22688064074697820000e+001) (19, 1.25335303976240220000e+000) (0, 1.56405147835636230000e+002) (1, 3.70921365189302820000e+001) (2, -3.50007275600256610000e+002) (3, 2.48628990654986950000e+001) (4, 3.31006624837688010000e+001) (5, -1.46667633578113850000e+000) (6, -6.89208619977683380000e+002) (7, 7.27953870831900000000e-001) (8, 1.04078775539403810000e+002) (9, 1.89334266927672380000e+001) (10, 8.14182580032575290000e+002) (11, -4.69277579298021850000e+000) (12, 3.14237258433319370000e+001) (13, 2.16792902806315710000e+000) (14, -7.89090734948506590000e+001) (15, -7.99331044162251650000e+000) (16, -1.21063781118078860000e+002) (17, 8.42066615936994790000e+001) (18, -3.12862303359709130000e+002) (19, -8.34074082213873960000e+000) (20, 7.02119014546308680000e-002) (21, 1.02348508543194370000e+000) (22, -1.00106940233230290000e-001) (23, 1.16694548956149260000e+000) (24, -3.57757648985636940000e-001) (25, 1.79421478415696980000e+000) (26, 9.39053596638012240000e-001) (27, 1.03554175723740900000e+000) (20, 1.53794758707390920000e+000) (21, 1.91892256915004140000e-001) (22, 1.71762453210726870000e+000) (23, -2.62463093770700030000e+000) (24, 2.72717159745371470000e+000) (25, -1.60197658394266230000e+000) (26, -1.11096725896419610000e+000) (27, -5.12211252310293410000e-001) (20, -1.30559447847038010000e+000) (21, -1.45753237831318060000e+000) (22, -1.25741372766703230000e+000) (23, 1.07019754285266270000e+000) (24, -2.03989275358415020000e+000) (25, -2.87346984038832520000e-001) (26, 6.14621603852613180000e-002) (27, 2.11172319376065860000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.14312849063632350000e+000) (1, -9.79733239403541070000e-001) (2, -1.53383095208225060000e+001) (3, 1.03003227518941600000e+000) (4, 6.51687784273488830000e+001) (5, 1.87000112472943070000e-001) (6, 3.04322872245853410000e+001) (7, -3.13660676449466050000e-001) (8, -1.58630004780864450000e+001) (9, -1.22071010613473870000e+000) (10, -3.78899528070954620000e+000) (11, 1.35578599905701560000e+000) (12, 1.58438902917766260000e+001) (13, -2.05379238787115350000e+000) (14, -1.75979122308604620000e+001) (15, 2.20929394710278300000e+000) (16, 3.27240221947875160000e+001) (17, -8.73269818611523310000e-001) (18, -4.44359281079195370000e+001) (19, 3.42034147391755900000e+000) (0, -3.75017853591835570000e+001) (1, 5.85299503802362690000e+000) (2, 7.99185223439706950000e+000) (3, 1.91152767766288870000e+000) (4, -2.33903350126123610000e+001) (5, 1.00642314804805120000e+000) (6, -1.28735860197955320000e+001) (7, 1.67265658528442330000e+000) (8, 8.71840053706887020000e+000) (9, 4.44686400776254940000e+000) (10, -8.99470984271893030000e+001) (11, 9.50727416237925670000e-001) (12, -1.23336596875410400000e+001) (13, -4.44295970976890440000e-001) (14, -1.69731320776610990000e+001) (15, 7.04636374221822240000e-001) (16, 4.07069786984101610000e+001) (17, 9.01058458769687710000e-001) (18, -2.04426111254837930000e+001) (19, 3.50167994055357660000e+000) (0, -5.76294907540311900000e+002) (1, -1.22246428662694680000e+001) (2, 3.99198420375525250000e+002) (3, -3.25146681435785910000e+000) (4, 3.59082319316207250000e+002) (5, 1.29068909365889680000e+002) (6, -1.50000000000000000000e+003) (7, 2.18038867197294870000e+001) (8, -1.28790879519332980000e+002) (9, 3.07402303559625350000e+001) (10, -7.82288621224201510000e+002) (11, 1.45848143115648930000e+000) (12, 4.44847639500647630000e+002) (13, 1.64261125167092010000e+000) (14, 1.91173920930522060000e+002) (15, 6.65805786057018170000e+001) (16, 3.69398808631315550000e+002) (17, 7.84540064703657340000e+000) (18, 1.25992991645612830000e+002) (19, 3.10336518595392160000e+001) (0, -2.25311291521807530000e+002) (1, -4.57218371482793490000e+001) (2, -7.92578762294439460000e+002) (3, 3.45768992017316990000e+001) (4, 8.63969338593412320000e+002) (5, -8.68808419450621020000e+000) (6, -3.74866597528313550000e+002) (7, -2.99986591139701630000e+001) (8, 2.31633413259798660000e+002) (9, -2.27137390092598960000e+002) (10, 1.49846035153836810000e+003) (11, -9.13364598986940730000e+000) (12, 4.49733475777526000000e+002) (13, -7.12712265462069470000e+001) (14, 2.90610872398666120000e+002) (15, 5.72011956255872710000e+000) (16, -8.96973045642134930000e+002) (17, -7.74467724534662520000e+001) (18, 4.12523376474025330000e+002) (19, 6.04317088898514360000e+001) (0, 1.22417487352358180000e+002) (1, 8.46932719067007870000e+000) (2, -1.23085081030838580000e+002) (3, 2.26524461351127610000e+001) (4, 1.05967407597121240000e+002) (5, -1.02915431613725650000e+000) (6, -1.27468843825588490000e+002) (7, 2.87236589557584620000e+000) (8, -3.41952596064326220000e+001) (9, 5.83271932421234500000e+000) (10, -3.13841986438085140000e+001) (11, 3.88086884166497410000e+000) (12, -1.73517863973943040000e+002) (13, 3.61627011319912100000e-001) (14, 1.32816514167254920000e+002) (15, -3.62609020410899370000e+000) (16, -1.36107762727506470000e+002) (17, -4.07101050172110850000e+000) (18, 1.08291734297985530000e+000) (19, 2.03933979120203860000e+000) (0, -3.43007746885363760000e+002) (1, 2.06623731087792000000e+000) (2, -5.42264296041558850000e+002) (3, 2.88293832483955440000e+001) (4, 5.29113039078202060000e+002) (5, -1.23390175952578800000e+001) (6, 5.95114103637049540000e+002) (7, 4.82714106201179670000e+000) (8, -2.12816709872403180000e+002) (9, -1.03568065210691670000e+001) (10, -2.88531030224594130000e+002) (11, 1.23903998462680660000e+001) (12, 5.26346285161156860000e+002) (13, 2.49664531368390640000e+000) (14, -9.63243526302847210000e+001) (15, 4.33073079431155320000e+001) (16, 5.17579507519548430000e+002) (17, -2.87978867174207180000e+000) (18, -1.44033453567232130000e+002) (19, 5.61478405150353340000e+001) (0, 1.01238037858254850000e+000) (1, 1.73768727077505760000e-001) (2, -6.23442480287427610000e+000) (3, 5.36036512923823150000e-001) (4, -6.00185944907824980000e+000) (5, -3.24779281719521700000e-001) (6, -1.04282043528584610000e+000) (7, 5.89805247952000580000e-002) (8, -4.95745550579117960000e-001) (9, 4.59447623433516180000e-002) (10, -1.57675074141581970000e+000) (11, 8.32100886434895550000e-002) (12, -6.06727417520351860000e-001) (13, -3.44640852954312660000e-003) (14, 8.99885249965478700000e-001) (15, -1.85954851108852240000e-001) (16, -3.25458530092860700000e+000) (17, -2.49632240990018990000e-001) (18, 1.81909814284616430000e+000) (19, 8.61217533247051470000e-002) (20, -1.65047373110337210000e+000) (21, 2.61901076029932330000e+000) (22, 9.35184448814036230000e-002) (23, 1.34658121512727180000e+000) (24, 2.72573931199099060000e-001) (25, 1.61023688664722990000e+000) (26, -1.31954808695311860000e+000) (27, -1.33607012418415390000e+000) (20, 1.04915253822078220000e+000) (21, -2.42285914424434390000e+000) (22, -1.81039154359771800000e+000) (23, -1.62717024440006890000e+000) (24, 1.75876600636098290000e+000) (25, 1.39382890864082790000e-001) (26, -3.27084322629291210000e+000) (27, 2.44982679547924140000e+000) (20, 3.28692433988681530000e-001) (21, -3.01105615378097820000e-001) (22, 1.40040109335782080000e+000) (23, 3.10355691065756170000e-001) (24, -1.62593926663840290000e+000) (25, -1.59304643636760090000e+000) (26, 3.60718402586452000000e+000) (27, 1.77750489563699790000e+000) 

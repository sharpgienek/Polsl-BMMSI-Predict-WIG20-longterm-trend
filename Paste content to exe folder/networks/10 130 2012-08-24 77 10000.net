FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.15100105638132580000e+000) (1, 1.35255679902198400000e+000) (2, -2.26486244228705000000e+000) (3, -8.25448135295464350000e-001) (4, -3.30211043555509460000e+001) (5, 2.75502423437066350000e+000) (6, 2.88965399403354620000e+001) (7, 1.07175566700268310000e+000) (8, 3.12361579999183260000e+001) (9, 2.38911014066677960000e+000) (10, 2.92310904966941050000e+000) (11, 1.16456233645918330000e-001) (12, -1.33006113788848610000e+001) (13, -2.30715914056784840000e+000) (14, -1.01730935512424410000e+002) (15, 4.30373387485632270000e+000) (16, 4.50002940561999620000e+001) (17, 6.52751233359568680000e+000) (18, 1.37210651381974300000e+001) (19, 6.73473646419188390000e-001) (0, 1.50000000000000000000e+003) (1, 2.48991936619524430000e+000) (2, -1.50000000000000000000e+003) (3, 7.40984809279435240000e+002) (4, 1.50000000000000000000e+003) (5, 8.60369199202430370000e+001) (6, -6.55049055174481400000e+002) (7, 1.59880163015175160000e+002) (8, -5.21483137086437750000e+002) (9, 8.49366585460471130000e+001) (10, 1.41656740280201570000e+003) (11, 1.37330700051968880000e+002) (12, -1.50000000000000000000e+003) (13, 2.53967487102812560000e+002) (14, 1.50000000000000000000e+003) (15, 4.17647417017774440000e+002) (16, 1.50000000000000000000e+003) (17, -9.10886487094758910000e+001) (18, -8.35474793086028060000e+002) (19, 1.10862260076574030000e+002) (0, 7.68964038062901520000e+001) (1, -2.05138574586799120000e+000) (2, 4.81347299104666670000e+001) (3, 4.20584482928440820000e+000) (4, 1.26002141046909400000e+002) (5, -4.33886859518102130000e-001) (6, 8.87393211936606860000e+001) (7, -6.28724661316976460000e-001) (8, -4.00815950982448470000e+001) (9, 3.95334116829368160000e-002) (10, -1.27845536221389950000e+001) (11, 7.42884698815322150000e-001) (12, -8.87292218824900660000e+000) (13, 2.21230158269450830000e+000) (14, 1.46131023746801900000e+002) (15, 2.15394790316353110000e+000) (16, 6.61225265905413410000e+001) (17, -3.90294369266069290000e+000) (18, -4.40941379141068810000e+001) (19, 4.92575657303619610000e+000) (0, -1.50910968146053900000e+002) (1, -1.72011172214434850000e+000) (2, -2.93802317104795290000e+002) (3, 2.69658775345769360000e+001) (4, 2.33872873343192450000e+002) (5, 9.76553743610381100000e+000) (6, -2.01803105202405130000e+002) (7, 3.51239127148039780000e+001) (8, -4.62735135718942100000e+002) (9, 1.17134515988406510000e+001) (10, -4.15530146536411450000e+002) (11, 1.84225590761323270000e+001) (12, -2.07328409303605780000e+002) (13, 1.91110903606535490000e+001) (14, 3.65172902927513350000e+002) (15, 7.44386483343287520000e+000) (16, -1.80379954906580080000e+002) (17, 4.09286126308754740000e+000) (18, -9.93145048504501740000e+000) (19, -1.73488754387010110000e+001) (0, 6.92478717835337870000e+002) (1, 5.85862464161831560000e+000) (2, -2.38628383853469420000e+002) (3, 2.24458764768083370000e+001) (4, -2.65681103730419860000e+002) (5, 2.00375730107091670000e+002) (6, -3.97022548511808110000e+002) (7, 3.62805730551640760000e+001) (8, 3.96808857114329850000e+001) (9, 1.14123152526061250000e+002) (10, 1.50212023159191090000e+002) (11, 6.82028724411164550000e+001) (12, 5.57740775251887270000e+002) (13, 1.27466475294192240000e+001) (14, 4.78971403841687960000e+002) (15, 8.00845966229030920000e+001) (16, 6.80991486301390520000e+002) (17, 3.53023450154307810000e+001) (18, 1.55082822069575460000e+002) (19, -2.67180071262917270000e+001) (20, 3.90720959209035880000e-001) (21, 1.49706168218190830000e+000) (22, -1.33910020215959660000e+000) (23, 1.33365905707819120000e-001) (24, -3.83042788195950500000e-001) (25, 2.20236035228615820000e-001) (20, 1.04562947032836020000e+000) (21, -1.07104076035690390000e+000) (22, 1.05130405344851850000e+000) (23, 9.77832421797753870000e-001) (24, -1.07998579609445080000e+000) (25, 9.60088407803229680000e-001) (20, -1.95548052099564700000e+000) (21, -1.42570250490903520000e-001) (22, -1.97700229356011540000e-002) (23, -1.62724985616494980000e+000) (24, 1.93166378796802300000e+000) (25, 1.72999083033159180000e+000) 

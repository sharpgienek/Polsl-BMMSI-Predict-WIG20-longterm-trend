FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.81087893094203970000e+000) (1, 4.22151352695736790000e+001) (2, -1.29998744291921040000e+002) (3, 1.68293916873615710000e+001) (4, 4.78900442027946100000e+002) (5, -1.34013315437323180000e+000) (6, 1.52845822574027700000e+000) (7, -1.04165552401709840000e+000) (8, -1.52764069800941230000e+002) (9, 2.57407394405271470000e+001) (10, -1.62958376681482490000e+002) (11, 1.50679605555488150000e+001) (12, -6.55197643390982020000e+001) (13, 9.89286311944237260000e+000) (14, 1.48978934234543590000e+001) (15, 1.13456138884570650000e+001) (16, -1.39063949937112030000e+002) (17, 8.35445279373397480000e+000) (18, 2.17677801058268640000e+002) (19, 6.28729834401829460000e+000) (0, 1.59178922116315960000e+001) (1, -9.86282089877072110000e-001) (2, -4.69005658781012170000e+000) (3, 4.28903894181032750000e-001) (4, -2.39315249010654010000e+001) (5, -1.36784003353886130000e+001) (6, 4.17016132345593320000e+001) (7, 2.46399176605451280000e+000) (8, 6.78991635266107210000e+001) (9, -3.12863873050012890000e+000) (10, -1.93787343612818540000e+001) (11, -6.61325609388642270000e-001) (12, 3.16923241177832470000e+001) (13, -1.98681235512021080000e+000) (14, 1.52882094580519540000e+001) (15, -2.71712451575759130000e-001) (16, 1.29560771402682050000e+001) (17, 3.40240340343012370000e-001) (18, 2.40936334365064440000e+001) (19, -5.43826439829879680000e+000) (0, 5.04249958448295810000e+001) (1, 1.89991003454673930000e-001) (2, -2.15802459176745530000e+001) (3, -1.38713595989417850000e-001) (4, 1.17721618800691630000e+001) (5, -1.57138913101709980000e+000) (6, -1.38935198528663300000e+000) (7, 3.83331126539953440000e-001) (8, -1.86264779594054560000e+001) (9, -2.19325544038626610000e-001) (10, 2.77569417096720940000e+000) (11, -7.49119651412724850000e-001) (12, -3.00645454076508760000e+000) (13, -2.61585589991771010000e-001) (14, -1.28397605213329590000e+000) (15, 1.47903799871262900000e-001) (16, 1.57587233406917400000e+000) (17, 4.35759056097801020000e-001) (18, -1.26425192038392320000e+001) (19, 2.22440735195057690000e+000) (0, -2.04430836234161930000e+001) (1, -1.88982226918211120000e+000) (2, 4.27089128436382380000e+001) (3, -5.61713594912911060000e+000) (4, 5.57351489560414230000e+000) (5, 2.97134996460410950000e+000) (6, 5.60984016233122200000e+001) (7, -1.71582763821868920000e+000) (8, 1.83793873995791530000e-001) (9, -9.67874511221688330000e-001) (10, 2.68098306190599410000e+001) (11, -5.64140692716383100000e+000) (12, -9.73397045856662120000e+001) (13, -3.02534962522935440000e-001) (14, -2.16663805568538950000e+001) (15, -1.95703792018131950000e+000) (16, 4.56037999097286000000e+001) (17, 3.92320266865034790000e-001) (18, 1.95279254672466360000e+001) (19, -1.49749658713898310000e+000) (0, 2.43937946900305820000e+001) (1, 1.07896194082983300000e+000) (2, -1.20300617967944970000e+001) (3, 1.86802558055871050000e+000) (4, -3.05087433297148610000e+001) (5, -1.24972429999664260000e+001) (6, 6.97981115957001490000e+001) (7, 2.27604403605624350000e+000) (8, 4.24625819453616700000e+001) (9, -4.30036325933124460000e-001) (10, -8.08582326713225830000e+001) (11, 3.72414231030031310000e+000) (12, -6.54536269568662550000e+000) (13, -4.44563993403376050000e-001) (14, 1.28944410657340660000e+001) (15, -1.79510482833220110000e+000) (16, 3.70917815227886080000e+001) (17, -1.20037259412170180000e-001) (18, 5.53285977555095130000e+001) (19, -4.15157067382119040000e+000) (0, -7.40197450058178390000e+001) (1, -3.49790569980055030000e-001) (2, 4.47508685009768710000e+001) (3, 1.48368995759093010000e+000) (4, -3.48898255366437300000e+000) (5, 1.39838078137853210000e+000) (6, -3.98010722375181350000e+001) (7, -1.40237953343393420000e-001) (8, 1.27705352317953210000e+000) (9, -9.50738573504782970000e-002) (10, -1.11460477523820440000e+001) (11, 1.63048960957802950000e+000) (12, 3.79102670945594650000e+001) (13, 5.78224381990758320000e-001) (14, 3.60829463743115750000e+001) (15, 2.97465046875478030000e-001) (16, 6.53306687469233530000e+000) (17, -1.47351964571715750000e+000) (18, 1.15885138797820450000e+001) (19, -2.58343963108734310000e+000) (20, 1.88331854719955730000e-001) (21, 1.46719504788776310000e+000) (22, -2.69725158447965360000e+000) (23, -1.24353552944448080000e+000) (24, -1.01862619592644710000e+000) (25, -2.20793866649252110000e+000) (26, 1.21964167124477440000e+000) (20, -2.10684469557461720000e+000) (21, -1.98608641598754380000e+000) (22, -2.41936541708152010000e-002) (23, -3.15507151864063580000e-001) (24, 1.71245236761044440000e+000) (25, -2.73788798785848720000e-001) (26, 1.92406186900079090000e+000) (20, 1.21531697759885500000e+000) (21, 6.93828344906123880000e-002) (22, 2.40106123571914720000e+000) (23, 1.58039937957441360000e+000) (24, -1.26284630488634970000e-001) (25, 2.15366872796421530000e+000) (26, 1.18191288636315530000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.63174487978631320000e-001) (1, -1.81740233871432920000e+000) (2, 8.18986498859650850000e+001) (3, -3.41164958787418100000e+000) (4, -4.15764052590104280000e+001) (5, 1.75767960740608140000e+000) (6, -8.74394987663830530000e+001) (7, 2.74215323963176220000e-001) (8, 2.01136846094337290000e+001) (9, -2.93815916362496130000e+000) (10, -5.87036848696390760000e+001) (11, -3.72238445392182940000e+000) (12, 7.20913480371948050000e+001) (13, -3.59188589444791750000e+000) (14, 2.25707070431413750000e+001) (15, 1.19138723956379920000e+000) (16, -5.82031834499023050000e+001) (17, 1.32162378110312240000e+000) (18, -8.30517981975451390000e+000) (19, 4.55199630109577400000e+000) (0, -1.38512792333369130000e+003) (1, -2.61602331863955330000e+002) (2, -2.97284810040895710000e+002) (3, 1.15085483206006630000e+002) (4, 9.87896081811795400000e+002) (5, -6.26225064712560310000e+001) (6, -1.50000000000000000000e+003) (7, 4.61576613486912630000e+000) (8, -5.86343407731372740000e+002) (9, -1.18495517611097840000e+002) (10, -1.49975574081174020000e+003) (11, 1.30225716420667340000e+002) (12, -1.50000000000000000000e+003) (13, 1.20932289888939520000e+002) (14, 1.44432185632805230000e+003) (15, 3.02772268244393000000e+001) (16, 1.50000000000000000000e+003) (17, -1.38519869881692360000e+002) (18, -1.48900174832481160000e+002) (19, -1.90860944850828050000e+002) (0, -6.32821595477540550000e+001) (1, 1.24987829345641580000e+001) (2, 5.10596572643866860000e+001) (3, 6.53417880659036140000e+000) (4, 1.60690378719943110000e+001) (5, 5.81471754059847080000e+000) (6, -2.57682412319889490000e+001) (7, 4.68180892562908820000e+000) (8, 1.12305598753879450000e+002) (9, -1.15009561723996320000e+000) (10, -7.79055772089772490000e+001) (11, 3.78820413349448960000e+000) (12, 3.36308327702205220000e+001) (13, 3.35322842447143540000e+000) (14, 5.07277519217843110000e+001) (15, 6.36864911503644930000e+000) (16, -3.19942143663280330000e+000) (17, 1.02832496961094150000e+001) (18, -5.50630449280304080000e+001) (19, 4.49843314793763760000e+000) (0, -6.14593432622866230000e+001) (1, 7.90942058307294630000e+000) (2, -1.28279545071801270000e+002) (3, 6.32494949182239100000e+000) (4, -6.65234699633449960000e+002) (5, 8.37324610278349160000e+001) (6, -6.22444480419256480000e+002) (7, 7.10004615004967030000e-001) (8, 1.64220780530970810000e+002) (9, 7.87800444373531670000e+000) (10, -7.33233019313169390000e+002) (11, -2.70994482409367390000e+000) (12, -1.54094025479829950000e+002) (13, -1.29669592607863430000e+001) (14, 4.22730559932509640000e+001) (15, 9.19947130156121950000e+000) (16, -1.30889922329368460000e+002) (17, -1.89265408181850430000e+000) (18, 1.36709974415079700000e+002) (19, 3.21303950450970750000e+001) (0, -4.74509589389108560000e+002) (1, -7.73786326708263310000e-001) (2, -7.74885067076838370000e+002) (3, 2.13849578971027510000e+001) (4, 8.35736485260628680000e+002) (5, 3.88361179082281540000e+001) (6, -9.68341153194718800000e+002) (7, 1.15014997742011770000e+001) (8, -1.55047620149480170000e+002) (9, 1.50603737844041290000e+001) (10, 9.62234222514424690000e+002) (11, 2.05114616345992120000e+002) (12, 1.50000000000000000000e+003) (13, 2.04862848572362000000e+001) (14, 6.73316834886116230000e+002) (15, 2.69499561441282590000e+002) (16, -1.50000000000000000000e+003) (17, 6.36027906507643980000e+001) (18, 5.68627126156009240000e+002) (19, 1.77194826742674650000e+002) (0, -9.49661188049686980000e+002) (1, 7.94000651849192000000e+001) (2, 3.58638148019596630000e+001) (3, -6.26808439678345410000e+000) (4, 1.37558473841117320000e+002) (5, -8.46236143332564520000e+000) (6, 2.67862886344971340000e+002) (7, -9.21788042596434210000e+000) (8, -1.18017602399501830000e+003) (9, 5.06919539616958160000e+001) (10, -5.22433142643849580000e+002) (11, -8.25646832566689430000e+000) (12, -1.01492588858918510000e+003) (13, 2.18536651481717070000e+001) (14, -6.82375234556457710000e+002) (15, -1.99275301533569770000e+002) (16, 1.50000000000000000000e+003) (17, 2.38906254418431700000e+001) (18, -1.13568825093446870000e+003) (19, -8.74085138711890440000e+001) (0, -5.71377587519922690000e+000) (1, 3.68406707391831480000e+000) (2, 5.55881877652240280000e+001) (3, 8.01556977343044990000e-001) (4, -1.45636025840062650000e+001) (5, 1.02385791536033040000e+000) (6, -8.70759170346185410000e+001) (7, 9.24572383859722740000e-001) (8, 9.91648065167504280000e+000) (9, 1.16848897713966400000e+000) (10, 2.13534163446032430000e+001) (11, -6.08476565293812400000e+000) (12, 2.42182734778199060000e+001) (13, -9.09567157664011170000e-002) (14, -4.92556877962851300000e+001) (15, -2.82436768409120240000e+000) (16, -4.42688931953631480000e+001) (17, 6.45488529956614520000e+000) (18, -1.58087665354936360000e+001) (19, 5.62240799716280710000e-001) (20, -1.80140949493542470000e+000) (21, 1.62284413463354090000e-001) (22, 4.51416016239762010000e-002) (23, 1.74158379483928650000e+000) (24, 1.31970059473896320000e-004) (25, -1.80050928926538600000e+000) (26, 1.94834778825467090000e+000) (27, -1.22818259489514520000e-002) (20, 7.16256522126264840000e-002) (21, -1.80958733529681530000e+000) (22, 1.84912156888130900000e+000) (23, -1.83566902722625570000e+000) (24, -1.88915581420779200000e+000) (25, 6.88923134498909680000e-002) (26, -1.84764226752816630000e+000) (27, 1.83711236721662190000e+000) (20, 1.17255450935995920000e+000) (21, 1.11790363927618410000e+000) (22, -1.29788503185222240000e+000) (23, 1.21706846331161630000e-001) (24, 1.38224917528695880000e+000) (25, 1.27641689236587430000e+000) (26, -7.25417143471712710000e-002) (27, 1.16644172092557970000e+000) 

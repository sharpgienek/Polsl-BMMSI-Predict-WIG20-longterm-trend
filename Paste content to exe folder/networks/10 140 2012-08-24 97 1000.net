FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.87344432542913130000e+000) (1, 5.86979732430814230000e+000) (2, 5.82250876359217670000e+001) (3, 4.89900806550674970000e-001) (4, 2.44893054647881390000e+001) (5, -1.96838814507617600000e+000) (6, 1.26125746911069940000e+001) (7, 3.32368772174106080000e-002) (8, 1.26220320908940100000e+001) (9, 1.68917324656074270000e+000) (10, -1.87813408720190860000e+001) (11, 1.15841395607108950000e+000) (12, 3.25128258465422040000e+000) (13, 2.83664370179531480000e+000) (14, -8.57751516525711290000e+000) (15, -9.80111197204915130000e-001) (16, -5.19225744234305110000e+001) (17, 1.72280953188906260000e+000) (18, 2.88445691168941850000e+001) (19, 2.28828117304209670000e+000) (0, -2.01454077319415570000e+001) (1, -6.70543238359391360000e-002) (2, 2.93831112199899880000e+001) (3, 7.51371077446764010000e-001) (4, 1.47695789788905520000e+000) (5, 1.96923342990345280000e+000) (6, -7.09711888480190960000e+001) (7, 1.11840006412905590000e+000) (8, -2.13841107126978190000e+001) (9, -1.68960295383687810000e-001) (10, -2.96635596000390440000e+001) (11, -8.26179609989555970000e-001) (12, -3.91323123774065920000e+001) (13, -1.40283385201672450000e+000) (14, 8.74736369067113630000e+000) (15, -4.15222134817448120000e+000) (16, -2.09509716208217290000e+001) (17, 1.30523272054693610000e+000) (18, 3.99590892239744330000e+000) (19, -3.36057755804801630000e-001) (0, -7.98086549852761640000e+001) (1, -1.35201542328292250000e+000) (2, -1.30616683970353710000e+002) (3, 6.23127008487247740000e+000) (4, 2.17198379456393130000e+001) (5, -2.07417176481277750000e+001) (6, 9.91788582328096880000e+001) (7, 1.57451360649474570000e-001) (8, 3.78602406928861730000e+001) (9, 2.89484254741503390000e+000) (10, -7.86884716837658690000e+001) (11, 1.13760326041877490000e+001) (12, -1.11303172934431150000e+002) (13, 1.57647949695404850000e-001) (14, 2.87818559439374080000e+001) (15, -8.77906473776622140000e+000) (16, 4.01178866687356080000e+001) (17, -4.13623269953615580000e+000) (18, 5.62478631416571600000e-002) (19, 3.57394145277051380000e-001) (0, -2.30757109191982120000e+001) (1, 8.45069259300003230000e-002) (2, -3.33107353102967800000e+000) (3, 3.89144131476522310000e+000) (4, 4.39494871354981740000e+001) (5, 1.56567963414883500000e+000) (6, 1.50904795753157090000e+000) (7, 7.98750904991528450000e-001) (8, -3.08343373433615750000e+000) (9, 2.41831242200910970000e+000) (10, 1.82430006597024350000e+001) (11, 3.38916021739673280000e-001) (12, -1.04330704168700730000e+001) (13, -1.33346554617823740000e+000) (14, 3.04768938215268780000e+000) (15, -3.45087039224993790000e-001) (16, 1.44211650032239460000e+001) (17, -1.89889164244750330000e-002) (18, -4.06966342571284480000e+000) (19, -1.57481850494048080000e+000) (0, 1.75293310722856290000e+001) (1, 1.00191298442546680000e+000) (2, -2.56991295797205450000e+000) (3, 3.13244973500723610000e-001) (4, 3.83790904078417800000e+001) (5, 2.94637625529471410000e+000) (6, 6.72735697492021390000e+001) (7, 2.07085319353198710000e-001) (8, -2.77055408443731040000e+001) (9, 5.34625085792764580000e+000) (10, -1.52607663168718940000e+001) (11, 6.45640292483473380000e-002) (12, -1.50243965432858510000e+001) (13, 1.20560116170031480000e+000) (14, 1.64246371575476220000e+001) (15, 4.74126967914580360000e+000) (16, 3.00612009305370760000e+001) (17, 1.15521233320476200000e-001) (18, 1.06633689838782360000e+000) (19, 4.25738984977953090000e-001) (0, 8.42235044316802970000e+001) (1, 2.02154545634123470000e+000) (2, 6.76695302379017820000e+001) (3, -5.83481869632958180000e+000) (4, 1.51819022677454840000e+001) (5, 4.77535543603297000000e+000) (6, 3.87220024647339760000e+001) (7, 7.75079725914252120000e-001) (8, 2.70991249252234030000e+001) (9, 4.33689149718049950000e-001) (10, 3.30418272575312320000e+001) (11, -2.46478773996894460000e+000) (12, 4.56563167595831700000e+001) (13, 4.65641017848845930000e-001) (14, 5.35735306840653680000e+001) (15, 2.97171685444244770000e-001) (16, -2.62183687761382520000e+001) (17, 3.82450250635263120000e+000) (18, 3.50406381828203730000e+001) (19, -5.62278405258105350000e+000) (20, 2.23346288384455120000e+000) (21, -2.47932282221088010000e+000) (22, -7.68586561390394270000e-001) (23, 3.04726826377999900000e+000) (24, -2.68367818685188730000e+000) (25, 1.88282630997187140000e+000) (26, 1.84222108812927840000e+000) (20, -1.63359870954314900000e+000) (21, 9.81899282150490380000e-001) (22, 1.33276470793704950000e+000) (23, -1.54801702317534450000e+000) (24, 1.10552957531786890000e+000) (25, -2.24593967219539090000e-001) (26, 1.21499067707024900000e+000) (20, 2.42048753759418620000e-002) (21, 6.41128417524233880000e-001) (22, -6.96233276448404600000e-001) (23, -5.28967838423525900000e-001) (24, 5.77255954109652140000e-001) (25, -1.00384363755247910000e+000) (26, -7.94749622602953720000e-003) 

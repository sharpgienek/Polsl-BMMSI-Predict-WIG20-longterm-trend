FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.73723868868463710000e+002) (1, -1.48844017520886960000e+000) (2, 3.19209463049330820000e+001) (3, -2.99469770228412090000e-001) (4, -7.43649026378918020000e+001) (5, -3.83751673675403750000e-001) (6, 2.70739025240488790000e+001) (7, 3.40528717901943500000e-001) (8, 2.36466149990176470000e+001) (9, 4.73386122039579680000e+000) (10, -6.69342632019238780000e+000) (11, -2.33954669559394720000e+000) (12, 1.51328703075454030000e+002) (13, -3.04451336141393800000e-001) (14, 6.48598699592876070000e+001) (15, 8.19638498466884970000e-001) (16, 9.47376900393009790000e+000) (17, 4.02476332024236520000e+000) (18, 3.85861836591961590000e+001) (19, 6.44379343202410660000e+000) (0, -1.25282688252108140000e+001) (1, -9.21506142751350010000e-001) (2, 1.15341957213872420000e+001) (3, -4.28893407826250610000e+000) (4, -1.24332765857262490000e+001) (5, -1.34266778664069970000e+000) (6, -6.83932249096987730000e+001) (7, -6.00617383018259070000e-001) (8, -4.43722405094314920000e+001) (9, -1.95075368654596740000e+000) (10, -3.30120582356955200000e+001) (11, -4.77022952615669470000e+000) (12, 2.80545111721861460000e+001) (13, -4.00347654322182280000e-001) (14, -1.13694473354099090000e+001) (15, 3.95685450703714900000e+000) (16, 9.27786614486904960000e+000) (17, 5.45102255060849060000e-002) (18, 2.25321201274296180000e+001) (19, 1.39855025574092200000e+000) (0, -1.17514265477320120000e+002) (1, -1.31362336018664010000e+000) (2, 3.75855187540238280000e+000) (3, 2.35809010250463210000e+000) (4, 3.48709156299754430000e+001) (5, -9.52876798378755050000e-001) (6, 6.07507141007474230000e+001) (7, -9.88563648624843030000e-001) (8, -4.90538389454125150000e+001) (9, -1.46519506700262830000e+001) (10, 3.78406488686091150000e+001) (11, 4.07459869423649590000e-001) (12, 8.11545055427677230000e+001) (13, -1.79445820323804090000e+000) (14, -2.13489180736584490000e+001) (15, 8.17018863674479870000e+000) (16, 1.34009538717416010000e+001) (17, -1.69026763091860420000e+000) (18, -3.02959035866571290000e+001) (19, 1.03624009350299610000e+000) (0, 1.28161779210646290000e+001) (1, 8.80252164584889530000e-001) (2, 1.41130546970508110000e+000) (3, 8.91059738748488960000e+000) (4, 2.21584011858228860000e+001) (5, 6.47061757668660590000e+000) (6, 6.47265721326579780000e+001) (7, 5.77938788022070660000e-001) (8, 2.47970438901316790000e+001) (9, 2.05781853066150640000e+000) (10, 1.36220907068810220000e+002) (11, 6.69927829935345390000e-001) (12, 7.43914352469649880000e+001) (13, -3.82929275707334440000e-002) (14, 9.10046817570660660000e+001) (15, 2.45039066518245360000e+000) (16, 1.46000036675607440000e+001) (17, 1.06239053754944250000e+000) (18, -6.99311455072435560000e+001) (19, 6.41099641340642630000e+000) (0, -4.99774350198535940000e+001) (1, -3.28911291357177140000e+000) (2, 5.06885937317015590000e+001) (3, 5.35873449960652430000e+000) (4, 6.01674049147944600000e+000) (5, 2.37712799749928560000e+000) (6, 9.31555331361303020000e+000) (7, -6.43126222916573400000e-001) (8, -1.20449950449870990000e+001) (9, -3.08346002355168910000e+000) (10, -1.56028799589142240000e+001) (11, 4.20951202560434190000e+000) (12, 4.35078588705600830000e+000) (13, -2.36846710517101890000e+000) (14, 5.18944887989592020000e+001) (15, -1.31881833630030050000e+000) (16, 3.70622519511248570000e+001) (17, 8.09282600820360520000e-001) (18, -4.73977167096216550000e+001) (19, 6.80146617231095970000e+000) (0, -1.60979638348498320000e+001) (1, -1.04910891385496190000e+000) (2, 3.01808420495617610000e+001) (3, 2.32887152893718370000e+000) (4, -4.15644990032374220000e+001) (5, 7.21748889244079760000e-001) (6, -3.26188331598651970000e+001) (7, 1.42422890088806910000e+000) (8, 8.53277951402620690000e+001) (9, 1.00158860166804540000e+001) (10, -5.98947486529746410000e+001) (11, 1.33674842065934230000e+000) (12, 1.16694108269838770000e+000) (13, 1.30328997056036230000e-001) (14, -3.84038450272960500000e+001) (15, -7.38086101366870030000e+000) (16, -4.45480572277536030000e+001) (17, 3.06193255807876110000e+000) (18, 3.45199557972574520000e+001) (19, 1.67052892217224590000e+000) (20, 2.23520357274514800000e-002) (21, -6.94906097199245180000e-002) (22, 2.00228242771024820000e+000) (23, 1.86332625280503980000e+000) (24, -1.84007037773928790000e+000) (25, 1.86964111869161890000e+000) (26, 8.52034169311584180000e-002) (20, 9.91447559100245730000e-001) (21, -1.22611794177306250000e+000) (22, -9.93038196970584600000e-001) (23, -1.96440804777696080000e+000) (24, 9.28920581896230500000e-001) (25, -2.01463141345729070000e+000) (26, 1.93889805078232640000e+000) (20, -7.70209728383306590000e-001) (21, 1.16308812183834640000e+000) (22, -3.26673151536569950000e-001) (23, 5.41135694255864050000e-001) (24, 4.29171513479655490000e-001) (25, 6.22204554540728650000e-001) (26, 4.08985876337270900000e-001) 

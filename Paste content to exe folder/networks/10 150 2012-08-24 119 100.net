FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.26626826835627940000e+001) (1, 7.30741068217142240000e-001) (2, -5.64244950477581410000e+000) (3, 3.77848241012563820000e+000) (4, 3.19492054847070830000e+001) (5, 1.51134158473449550000e-001) (6, 1.58879743958865150000e+000) (7, 3.59059896943979160000e-001) (8, 2.78683947928464890000e+000) (9, 5.27969273848285180000e-001) (10, 1.34801109160286930000e+001) (11, 3.57632712347676800000e-001) (12, 7.06008869525148960000e+000) (13, 9.35320229159744220000e-001) (14, 1.87055488425849430000e+001) (15, 4.27710786086440420000e-001) (16, -8.09117914273512100000e-001) (17, 1.58964259022635970000e-001) (18, 2.29119270961665220000e+000) (19, -3.51742132302529930000e-001) (0, 3.45197670732504060000e+001) (1, -7.38767293621169660000e-001) (2, -1.26300798924291180000e+001) (3, 8.87751511458160780000e-001) (4, 4.93933215807018480000e+000) (5, -3.79325001605487030000e+000) (6, 4.05940999711016560000e+001) (7, 8.75582887758687870000e-001) (8, 3.43821454497648200000e+001) (9, -8.68718594769720350000e-001) (10, 5.90607466501177070000e+001) (11, 3.65429194958853180000e-001) (12, 3.69879897033689040000e+000) (13, -2.75861576819578680000e-001) (14, -1.52004748552258470000e+000) (15, 1.82727673387648700000e+000) (16, -4.10672197593287440000e+001) (17, -1.38635091267171860000e+000) (18, 2.98322238926670470000e+000) (19, 1.95886812579566390000e-002) (0, -7.49703994577252500000e+001) (1, -2.69487782177803730000e-001) (2, 8.10544971016452640000e+000) (3, 1.98001013776169100000e+000) (4, -2.37132599875127750000e+001) (5, 2.93384957959580640000e+000) (6, 1.08470738081143400000e+001) (7, 6.93166103828718350000e-001) (8, 9.07067199258369960000e+000) (9, 6.77039480339794160000e-002) (10, 6.04766074624423670000e+000) (11, 1.46367386404539590000e+000) (12, 1.13716825943984880000e+001) (13, 4.12353888909658570000e-001) (14, 2.31797317653576120000e+001) (15, 1.91656313910199050000e-001) (16, 8.33200932216649900000e+000) (17, -1.11220700924837310000e+000) (18, -1.09647349787597610000e+001) (19, 1.19995557424784400000e+000) (0, -6.74690592869225900000e+000) (1, -3.48496538830772810000e-001) (2, 2.46693301425427560000e+000) (3, 1.66923762384446690000e-002) (4, -7.02263335502468160000e+000) (5, 9.19846019088222280000e-001) (6, 5.21128303759571310000e+000) (7, -1.74252658138890650000e-001) (8, -6.23025081621877530000e-001) (9, -1.50608659452541590000e-001) (10, 4.43160989231956290000e-001) (11, -1.30393488437356180000e-001) (12, 7.85891993650228130000e+000) (13, -6.82226731042445270000e-002) (14, -1.32105260542252580000e+000) (15, 3.04946437243203580000e-001) (16, 5.70941832810067580000e+000) (17, -1.17332490938536360000e-002) (18, -7.10437232393891780000e-001) (19, 4.08487037991169030000e-001) (0, -2.07653978512646160000e+001) (1, -2.95458251326064230000e+000) (2, 1.60865290431620980000e+001) (3, 1.50928897275115360000e+000) (4, 2.06721328430799780000e+000) (5, -1.58245664337043790000e+000) (6, 4.30371591865172660000e+000) (7, -1.39585172342059250000e-001) (8, 3.88260131021038380000e+000) (9, -8.72081759337541280000e-001) (10, 2.90044698677830360000e+000) (11, -9.20830523502852220000e-001) (12, 1.53934352931182780000e+001) (13, 5.76409750855271910000e-001) (14, -5.69871804231985580000e-001) (15, 1.89000286550082340000e+000) (16, -1.36957233243263250000e+000) (17, -5.72314507175961110000e-001) (18, -1.31339384060288400000e+001) (19, -6.79529040679406620000e-002) (0, -1.21379569185050910000e+000) (1, 6.07700319481477070000e-001) (2, -2.43445312611972000000e-001) (3, -1.31493212727329280000e-001) (4, -1.03289499958217700000e+001) (5, -1.99883837754499760000e+000) (6, -4.31924074300080400000e-001) (7, -2.01263107853827060000e-001) (8, 1.77849887749306750000e+001) (9, -6.86208088674519770000e-001) (10, -2.41178145478381050000e+001) (11, -4.26084215471610860000e+000) (12, 2.78725332891767120000e+001) (13, 1.01234468696665040000e+000) (14, -3.18342921476278630000e+001) (15, 1.11796573752993900000e+000) (16, 7.09703219733904550000e+001) (17, 4.41505331766339730000e+000) (18, 2.09966263645271240000e+001) (19, -1.85053420776702340000e-001) (0, 1.32630356409318160000e+001) (1, 1.24351363850581740000e+000) (2, 8.64061967200495220000e+000) (3, 1.11707984697331630000e+000) (4, 1.00757785942629030000e+000) (5, -7.69160188557584590000e+000) (6, 1.71064301764805780000e+000) (7, 5.23692210159096840000e+000) (8, -4.49505880326048770000e+001) (9, -7.23426315964914910000e-001) (10, -2.63230902564775880000e+001) (11, 9.02304500087834690000e-001) (12, -7.81320249470089130000e+000) (13, -6.32476736100531230000e-001) (14, -2.21113813485185880000e+001) (15, -3.74774716223344310000e+000) (16, 1.63413959186407110000e+001) (17, -1.01960621268695830000e+000) (18, -6.37391603789578200000e+000) (19, -1.15715899337801020000e+000) (20, 1.21420873261268620000e+000) (21, 1.58666968195253920000e+000) (22, 3.54962654331437640000e-001) (23, 1.00091810735544470000e+000) (24, -1.40818271370821500000e+000) (25, 1.22886497859488510000e+000) (26, -3.02180173436750080000e-001) (27, 2.88759009081144820000e-001) (20, 4.02552475890345260000e-001) (21, -7.56582622094746140000e-001) (22, -1.36265885073785720000e+000) (23, 1.80583319237337210000e+000) (24, 2.35374347124713280000e-001) (25, -1.09695787419369230000e+000) (26, 1.17626743659610210000e+000) (27, 1.15558422396847620000e+000) (20, -1.20297418151870890000e+000) (21, -5.28721021920357640000e-001) (22, 9.01050292498251420000e-001) (23, -2.13261658434689890000e+000) (24, 7.47691133603230030000e-001) (25, 8.62397070552425730000e-002) (26, -6.89913373887519830000e-001) (27, 7.80569315472602000000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.52384079491756810000e+001) (1, -2.20278524533851880000e+000) (2, 2.48520881781041610000e+001) (3, 4.16263039477471970000e-002) (4, 3.78754932098525860000e+001) (5, -1.29825924485537230000e+000) (6, -2.17371376093452360000e+001) (7, 1.02045998610851290000e+000) (8, -2.31622076727429910000e+001) (9, -5.86005001302677960000e-001) (10, -2.71177165212571400000e+001) (11, -2.74007219686272730000e-001) (12, -2.06055984312763170000e+001) (13, 3.56160376645456690000e-001) (14, 1.81886206179549280000e+001) (15, -1.57980566515904750000e+000) (16, 3.96635201697187730000e+000) (17, -4.04939708468783910000e-001) (18, 6.38079807213357770000e-001) (19, 5.18163585257874870000e-001) (0, 3.20230247081034420000e+001) (1, 8.61929555651006400000e+000) (2, -8.96809768462878910000e+001) (3, 4.30996668217746050000e+001) (4, 3.83914686172274060000e+002) (5, 4.01139978453151700000e+000) (6, -6.09571387048516160000e+001) (7, 3.60109575513156390000e+000) (8, 4.94440351078426160000e+001) (9, 3.64456750941495770000e+000) (10, 5.16382793391041960000e+000) (11, 7.34509965043277810000e+000) (12, -1.38461952408671890000e+002) (13, 7.61402234234356180000e+000) (14, 2.26988881620801830000e+002) (15, 3.08812109534025140000e+000) (16, -7.60319483822414380000e+001) (17, 2.46741650875975750000e+000) (18, -1.39286988580633920000e+001) (19, -1.78492602857534250000e+000) (0, 1.10106079349455030000e+001) (1, 1.92489290459373240000e+000) (2, -2.76682051416644010000e+000) (3, 1.32820009810543740000e+000) (4, -4.59658686330177280000e+001) (5, 2.64537464216941130000e+001) (6, 9.40631343397694760000e+000) (7, -1.91350695246490550000e+000) (8, 1.11585782345994740000e+002) (9, 1.70228947570562710000e+000) (10, 3.48632641451602510000e+001) (11, 6.57612963550059490000e-001) (12, -2.96441951337048160000e+001) (13, 5.13308978507975850000e-001) (14, -2.94835202879401240000e+001) (15, 8.65409510629964450000e+000) (16, -7.77143864628852440000e+001) (17, 1.81299222497872780000e+000) (18, -2.15525097748154590000e+001) (19, -4.59775638522609900000e-002) (0, 2.37539741856914830000e+001) (1, -1.94696807827820030000e-001) (2, -4.12341674720776580000e+001) (3, 4.09492660821185870000e+000) (4, -2.24543117502427020000e+001) (5, 1.97018413828660230000e+000) (6, 1.03585305052547890000e+002) (7, 1.83463579749978760000e+000) (8, 3.77913523571449800000e+001) (9, 2.14995755136727770000e+000) (10, 7.57302833805118640000e+001) (11, 1.15234594253103430000e+000) (12, -1.21655837179906620000e+001) (13, 6.59712384817161880000e-001) (14, -1.24876249485126910000e+001) (15, 6.66220246398359750000e-001) (16, 2.52184549184049930000e+000) (17, 7.56262192971554060000e-002) (18, -2.09207110005378960000e+001) (19, -1.54606777738155120000e+000) (0, -3.01940938883544310000e+001) (1, 2.02137790703480250000e+001) (2, -1.87084711541767600000e+001) (3, 7.53593714002287830000e+000) (4, 6.81226416352790240000e+001) (5, -2.09125167737324510000e-001) (6, -6.00441882379183410000e+001) (7, 1.85833618084011910000e+000) (8, -4.68391195613363820000e+000) (9, 8.22281835219007640000e+000) (10, -1.08007287806691410000e+002) (11, 3.40038667600296830000e-001) (12, -5.09208431896069840000e+001) (13, 1.52150824607878570000e+000) (14, -2.55083586633163040000e+001) (15, 9.33054767953288790000e+000) (16, 8.85518648687170900000e+000) (17, 5.63276379730697310000e+000) (18, 6.21408311740021230000e+001) (19, 5.92231306060226780000e-001) (0, -1.53547411797637000000e+001) (1, 4.52705197650611540000e-003) (2, 1.26789694119030950000e+001) (3, -7.13726278351108910000e-001) (4, 1.96967383573549740000e+001) (5, -1.43884194859518120000e-001) (6, -3.08440168634588120000e+000) (7, -3.54818228015424060000e-001) (8, -3.08763557518515970000e-001) (9, -7.43133277736430510000e-002) (10, -9.10844497502116650000e+000) (11, -4.26212561958297320000e-001) (12, 7.31468548735751780000e+000) (13, -3.96245279739745940000e-001) (14, 3.32617733236172650000e+000) (15, 7.11204518180795640000e-002) (16, 1.48737927901030220000e+000) (17, -3.87396731267002080000e-002) (18, 1.23630209266705600000e+001) (19, -2.80424279837704960000e-001) (0, -4.48675644808744280000e+001) (1, 1.60012888508101380000e+000) (2, 2.59976146984586800000e+001) (3, -7.23126923725328390000e-001) (4, 8.04043583230490810000e+001) (5, 6.66514640520565530000e-001) (6, 4.32204125195774860000e+001) (7, -1.25987067719730560000e+000) (8, 6.93967352462902770000e+001) (9, 5.44643793228707460000e+000) (10, 5.04735111922377800000e+001) (11, -6.13675826851132870000e-001) (12, -1.29094784550697700000e+001) (13, -1.40608863683555650000e+000) (14, -1.73248944173333400000e+001) (15, 4.83445173545573330000e+000) (16, -2.53845125729894470000e+001) (17, 4.92889296360594810000e-001) (18, 8.07604712572124230000e+000) (19, 1.13745789503435190000e+000) (20, -1.13183559955973870000e+000) (21, 5.38865274187010020000e-001) (22, -8.17028337435780070000e-002) (23, 2.07421786094635200000e+000) (24, 1.14713862685693500000e+000) (25, 3.37562651357333450000e+000) (26, -1.52043079572601410000e+000) (27, 1.04451625178168460000e+000) (20, -5.38339755611695110000e-001) (21, 4.91527505285191510000e-001) (22, -8.27904976396209410000e-001) (23, -8.97375376447958950000e-001) (24, -2.26376700475040590000e+000) (25, -1.62386215895650120000e+000) (26, 8.43640603865061790000e-001) (27, 1.86869467691946660000e+000) (20, 1.32993078323547340000e+000) (21, -9.57075996141261930000e-001) (22, 8.76475722709095240000e-001) (23, -7.77278226513880230000e-001) (24, 3.22583895697375560000e-001) (25, -1.20008311764495980000e+000) (26, 3.17159345330712550000e-001) (27, 5.35055534338901630000e-001) 

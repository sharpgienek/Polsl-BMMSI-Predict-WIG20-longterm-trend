FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.45727698956925610000e+000) (1, 2.53789277204459100000e-001) (2, -2.40246102569267710000e+001) (3, -1.04800875449185470000e-001) (4, 1.18686742195479000000e+001) (5, 1.00008901416620000000e+000) (6, 1.55581867534503960000e+001) (7, 5.12475852575769330000e-001) (8, 1.85200340501002000000e+001) (9, 5.80369141243530340000e-001) (10, 1.56374106172950980000e+001) (11, 9.19014214321517640000e-001) (12, 4.72740413843329940000e+000) (13, 6.03115208905329990000e-001) (14, 1.00485757222481040000e+001) (15, 1.22962072722741290000e+000) (16, 2.91981697870847120000e+001) (17, -1.37402386751840050000e-001) (18, 2.49516602651181880000e-002) (19, 2.02099523882104480000e+000) (0, 1.78484305775977990000e+001) (1, 1.56029229526504500000e+001) (2, -2.68410079335725450000e+001) (3, 5.77045607999160830000e-001) (4, 1.99541353897093670000e+002) (5, -1.54910184322598510000e+000) (6, 1.01486612294476880000e+002) (7, -2.10477726155084040000e+000) (8, -7.78803680264103950000e+001) (9, -8.69476750055931550000e+000) (10, -9.20378556330969250000e+001) (11, -2.03709961562870380000e+001) (12, 1.89393332097700440000e+002) (13, -2.60269881897035220000e+000) (14, 1.68985655714381550000e+002) (15, 4.01391485160800140000e-001) (16, 3.17165892319455340000e+002) (17, 1.20438072317226100000e+001) (18, 1.03098266304049970000e+002) (19, 3.83775185798294110000e+000) (0, 1.81180673838354810000e+000) (1, 1.16980825575478230000e-001) (2, -3.21336344065057130000e+001) (3, -6.69835643851185330000e-001) (4, 3.91417026546826600000e+000) (5, 3.14582214688377050000e-001) (6, 2.34327743367036130000e+001) (7, 5.73347421578844440000e-001) (8, 1.88774554608844160000e+001) (9, 8.26769282223132510000e-001) (10, 1.02049117223650450000e+001) (11, 1.19690945541360930000e+000) (12, 6.46105644832188730000e+000) (13, 1.34244512665023020000e+000) (14, 3.27608734296559720000e+000) (15, 1.80734363912216580000e+000) (16, 3.01315726974921280000e+001) (17, -3.75248946216047430000e-001) (18, 9.85713545674260240000e+000) (19, -4.71739875487625300000e-001) (0, 1.09397783916836930000e+002) (1, 3.09373493013257170000e-001) (2, -4.05283017372714620000e+001) (3, -5.56439563151452980000e+000) (4, -1.05624419551670120000e+002) (5, -1.31348822343074080000e+001) (6, 1.74418104320534500000e+002) (7, 7.91567251988019120000e+000) (8, -4.33800157980326520000e+001) (9, -7.80149525566397010000e+000) (10, -8.29317131610887230000e+001) (11, -6.98380013265986130000e+000) (12, 1.02339722853414810000e+002) (13, 5.28235994510555780000e+000) (14, 1.86702261813458850000e+001) (15, 4.35135099302182930000e+000) (16, 5.46726010495272160000e+001) (17, 1.56351011054442110000e+000) (18, 1.53714600246231720000e+001) (19, 1.47395161641527620000e+000) (0, -1.77560027841136990000e+002) (1, -2.62829566491192730000e+000) (2, -5.19234766380138610000e+000) (3, 2.90433276373375280000e+000) (4, -4.14746840901299900000e+001) (5, 1.41761404869185870000e+001) (6, 1.86600813339355570000e+002) (7, 4.02650800055289970000e+000) (8, 1.49528805393477680000e+002) (9, -1.81520158935725040000e+000) (10, -2.99781178975407270000e+001) (11, 3.32615577254606220000e+000) (12, 2.70587344672738510000e+001) (13, -1.95116103286800160000e+000) (14, -6.76192521378415560000e+001) (15, 2.47665060740508650000e+000) (16, 1.13642156938511010000e+002) (17, 1.13772576868432760000e+000) (18, 6.01971344815465130000e+001) (19, 1.95768643699732650000e+001) (0, 6.99660663968417680000e+002) (1, 3.03157015589953110000e+001) (2, 2.41737992916140120000e+002) (3, 1.62005228290205570000e+001) (4, 4.06757807573744230000e+002) (5, -2.39148605297030270000e+001) (6, 1.50000000000000000000e+003) (7, 1.15325826371687910000e+002) (8, 1.50000000000000000000e+003) (9, -5.53445263325233090000e+001) (10, 2.16142959110163930000e+002) (11, -8.29599581207300360000e+001) (12, -3.90295926497948240000e+002) (13, 1.12751949214634020000e+001) (14, 7.12802450011702720000e+002) (15, 8.76654247949893060000e+000) (16, 4.44911828103597200000e+002) (17, 9.60083913751653030000e+001) (18, -3.67026295523358270000e+002) (19, 5.40597206163952680000e+001) (0, 9.07723337615078240000e+001) (1, -2.07880163603218510000e+001) (2, 6.80634350433126660000e+002) (3, 1.36924838094028600000e+001) (4, 4.05064341965428350000e+002) (5, 5.25126579975306810000e+001) (6, 1.29157085288644000000e+003) (7, 3.29373583956699750000e+001) (8, -7.47637292167638350000e+001) (9, 1.01508470015485200000e+001) (10, 7.11887628309484850000e+002) (11, 1.21304877379637170000e+001) (12, -1.43211421240043170000e+002) (13, 1.91028086039336530000e+001) (14, 8.32558214664531420000e+001) (15, 2.64218867723608010000e+000) (16, -1.50000000000000000000e+003) (17, 5.48173978163322670000e+000) (18, -1.50000000000000000000e+003) (19, 4.10155499115672060000e+001) (20, -6.28135788463930210000e+000) (21, 1.84771583141538320000e+000) (22, 4.14519435774927470000e+000) (23, -1.81747491508796340000e+000) (24, 2.36918160485553080000e+000) (25, 3.60461073315650930000e-004) (26, 1.97015785560487040000e+000) (27, 1.71901793567741220000e+000) (20, 9.52836076882255800000e-001) (21, -1.19097544836080130000e+000) (22, -2.56164796545720270000e-001) (23, -5.74334465689296660000e-002) (24, -3.34119295740909280000e+000) (25, 1.19027930740575120000e+000) (26, -1.13996546442778810000e+000) (27, 3.74141704895958950000e+000) (20, 3.09964227667399060000e+000) (21, -7.95117599106511390000e-002) (22, -2.41540666171607740000e+000) (23, 1.32142299048499680000e+000) (24, 6.53271079216905860000e-001) (25, -1.25082435290988680000e+000) (26, -1.64974325028595880000e-001) (27, -1.26804648266468440000e+000) 

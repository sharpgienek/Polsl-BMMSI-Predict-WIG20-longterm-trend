FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.88971043072992830000e+001) (1, -1.58056563093696640000e-001) (2, 1.39130717316369330000e+001) (3, 5.67498590284683520000e-001) (4, -6.78415468919620320000e+000) (5, 1.02089453348170520000e+001) (6, -4.25258743154369940000e+001) (7, 9.83746255443229240000e-001) (8, 4.43529241354240330000e+001) (9, -3.95864537627416360000e-001) (10, -2.98817019221783560000e+000) (11, -2.78497256341757190000e+000) (12, 1.91740152759914860000e+001) (13, 3.81133805050481830000e-001) (14, -4.01923833539620570000e+001) (15, 3.94757203445769230000e+000) (16, -4.49466185253933260000e+001) (17, 1.42220351765350950000e+000) (18, 2.49045945469719070000e+001) (19, 2.03339293781079620000e+000) (0, 1.85092015659896740000e+001) (1, 2.04634715315852810000e-001) (2, -6.86223145507387680000e+000) (3, 1.37019170712408020000e-001) (4, -1.43645120685141720000e+001) (5, -3.48851021600498700000e+000) (6, -6.50364046487360790000e+000) (7, -1.88694083858661710000e-001) (8, -1.91833472315050990000e+001) (9, 6.61496963721493470000e-002) (10, 1.30636132123023160000e+001) (11, 7.96035342251748820000e-002) (12, -1.05116027207312060000e+001) (13, -7.31497893810455710000e-001) (14, 6.61186613113875680000e+000) (15, -1.87654930856152920000e+000) (16, 1.13262586856820490000e+001) (17, -6.45273164248814870000e-001) (18, -6.49824033839098280000e+000) (19, -1.14201316094643010000e+000) (0, 1.56351073217112170000e+000) (1, -3.46239001841484870000e-002) (2, 7.96231079124952280000e-001) (3, 2.44414899445124960000e-001) (4, -2.74506264081083500000e+000) (5, 1.69570695030498430000e-001) (6, -2.93565175505448470000e+000) (7, 7.44111144850668340000e-002) (8, 2.90726018759469180000e-001) (9, -5.19065150158946940000e-001) (10, 1.46030550236697160000e+001) (11, -6.58391498626195730000e-002) (12, 1.12363059416547050000e+000) (13, -4.49520242265456840000e-001) (14, -3.72570502707050500000e+000) (15, -1.73458798579462420000e-001) (16, -4.56603523550701060000e+000) (17, -2.01878331472355340000e-001) (18, -2.82384378371148870000e+000) (19, -5.66754644787062390000e-001) (0, -6.84277788869499940000e+001) (1, 2.07299419708383150000e+000) (2, 1.01001877487151840000e+002) (3, -6.08992258309053900000e-001) (4, -4.21761070518775940000e+001) (5, -2.06362376070730710000e+000) (6, -5.68149108009301290000e+001) (7, -2.24539668566980100000e-002) (8, -5.00717991637326070000e+001) (9, 2.00092512216619340000e+001) (10, -3.87559958961461920000e+002) (11, 6.95137643100499970000e-001) (12, -6.31145147250346950000e+001) (13, 1.08555992889871860000e+000) (14, 7.12188617389486750000e+001) (15, -1.25367668722009430000e+001) (16, 9.94358976104293500000e+001) (17, -7.60825304993702160000e-001) (18, -4.41683582449216200000e+001) (19, -7.88939582982871370000e+000) (0, -5.20240792848697070000e+001) (1, 5.30405468270053680000e+000) (2, -1.20641453430490330000e+001) (3, 1.02944465978407540000e+001) (4, -7.14706666506229030000e+001) (5, 7.10834076270760650000e+000) (6, -7.17727878602463410000e+000) (7, 2.60573832313355380000e+000) (8, 6.30985069011727550000e+001) (9, 2.77914328862575570000e+000) (10, 2.39237815751831030000e+001) (11, 1.61088629847211460000e+000) (12, 5.89948990970056290000e+001) (13, -1.63468054270512650000e+000) (14, -8.31321816381218600000e-001) (15, -2.88112575735578340000e+000) (16, -1.48102362117558770000e+001) (17, -4.33867797279967670000e-002) (18, -3.26662781045940860000e+000) (19, 1.23595847960417910000e+000) (20, 2.86490617195913130000e+000) (21, 3.66030928895798540000e+000) (22, -5.41883722823657980000e+000) (23, -1.94153850773691740000e+000) (24, 1.47653997098435920000e+000) (25, -1.26978194522629770000e+000) (20, -2.17129496614981400000e+000) (21, -2.42484979306090900000e+000) (22, 2.10359401122048870000e+000) (23, 5.19835734428494960000e-001) (24, -3.93927935936227320000e-001) (25, 1.54527799369751160000e+000) (20, -8.33781811176009520000e-002) (21, -4.18609947806515390000e-001) (22, 1.56779424487545120000e+000) (23, 7.69918534175828670000e-001) (24, -6.36488399365019000000e-001) (25, 1.39886899353578560000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.90402113885747260000e+001) (1, 1.03924408893400470000e+000) (2, 5.49326509208539270000e+000) (3, 5.31408773524478930000e+000) (4, -1.96815151670432470000e+002) (5, 2.41731506367090430000e+001) (6, -1.62713844638183860000e+001) (7, 6.92268283868787120000e+000) (8, 1.16595708625390560000e+002) (9, -3.57662701011182090000e+000) (10, -3.05989750868463120000e+000) (11, -8.89624939349609000000e+000) (12, 1.16441420641171020000e+002) (13, -8.89623671330680770000e-001) (14, 6.93187570912059670000e+001) (15, 1.09406196956706550000e+001) (16, 6.57875046660874400000e+000) (17, 5.64959574503966080000e+000) (18, -1.29042187393339580000e+001) (19, 1.45194657847994320000e+000) (0, 9.97248884726490270000e+001) (1, 2.86655608713234140000e+001) (2, -1.48346098658112400000e+003) (3, 1.01000970806743080000e+001) (4, -8.40341103615723340000e+002) (5, 1.58802660210171000000e+001) (6, 4.09646981986011610000e+002) (7, 2.42452145303371330000e+001) (8, 8.26847520459007570000e+002) (9, 3.12569752108982210000e+000) (10, 1.53222454851594590000e+002) (11, 3.60800999837487740000e+001) (12, 6.19505161352713800000e+002) (13, -2.23094781311516590000e+000) (14, -1.05055489657655410000e+002) (15, 2.03917736569881660000e+000) (16, -5.06992584487465360000e+002) (17, 1.57832121924710030000e+001) (18, 1.91764057977090000000e+002) (19, 4.73307536906952680000e+001) (0, -6.52480829956529500000e+001) (1, -1.61710972622091970000e-001) (2, 2.18455628474809450000e+001) (3, -6.92223324137717990000e+000) (4, 9.54623300202973370000e+000) (5, 1.16958698811818280000e+000) (6, -1.78647777775244910000e+001) (7, -7.28442523524423710000e+000) (8, 2.18131011296452580000e+001) (9, -2.61635356323877800000e+000) (10, -1.06168005262353410000e+001) (11, -2.54284473554226900000e+000) (12, -1.24436244618395440000e+001) (13, -2.22908356279896270000e+000) (14, 3.10038949381323230000e+001) (15, 4.10964794218804560000e+000) (16, 2.74836352454953000000e+001) (17, -4.49602307830720750000e-001) (18, -2.32173113901320000000e+001) (19, 5.67399049091937520000e+000) (0, 4.71309994092848540000e+001) (1, -4.37573780215165190000e-001) (2, 8.86811257466131340000e+001) (3, 1.80683992445376950000e-001) (4, -5.96201419958859890000e+000) (5, 8.21486266107873340000e-001) (6, 7.75293143919047760000e+001) (7, -2.68096082607057080000e-001) (8, 1.29950354527129530000e+000) (9, -2.61172013193509580000e+000) (10, 5.34282399907805900000e+001) (11, -1.28337154803990130000e+000) (12, 4.69244399842342260000e+001) (13, 3.74969994778304010000e-001) (14, 1.34061751293581230000e+001) (15, 3.92119981488799320000e+000) (16, 3.37616950916281200000e+001) (17, -2.97131141718908860000e+000) (18, -4.74359408758854000000e+001) (19, -3.98839958343933440000e+000) (0, 5.66631983207486640000e+000) (1, -2.58727423433327890000e-001) (2, -1.57701172507365590000e+001) (3, 6.96509198533205590000e-001) (4, -1.61480975488755260000e+001) (5, -6.06511381242202180000e-002) (6, -8.90096346705764140000e+000) (7, 1.13766567174254680000e+000) (8, -2.21216993286677030000e+000) (9, 1.47198709432915330000e-001) (10, -7.58519900169063810000e+000) (11, 2.07910122407685750000e-001) (12, 2.01026086958418080000e+000) (13, 1.47212079431083500000e-001) (14, -3.05792947688105340000e+000) (15, -2.62724271789780310000e-001) (16, -1.13058025651638020000e+001) (17, 7.64347475088904440000e-001) (18, -1.87331621447449480000e+000) (19, 3.29133342178887510000e-001) (20, 1.64513281078266930000e+000) (21, 1.08248563727390070000e+000) (22, -2.07216812653186370000e+000) (23, -2.13359408367949620000e+000) (24, -4.46393602111511000000e+000) (25, 6.32560276328983260000e-001) (20, -1.10833248220157280000e+000) (21, 3.38365439439110020000e-001) (22, 6.62924117541660140000e-001) (23, 1.56414849614541460000e+000) (24, 2.21620901072910610000e+000) (25, 7.72206183068306680000e-001) (20, -1.13049798955715510000e-001) (21, -1.59232519731312340000e+000) (22, 7.21593151690273380000e-001) (23, 5.66072588382016540000e-002) (24, 1.10947561692193440000e+000) (25, 1.48123029460767050000e+000) 

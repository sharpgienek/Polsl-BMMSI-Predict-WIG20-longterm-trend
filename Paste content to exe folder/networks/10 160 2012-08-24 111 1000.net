FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.29351685456475350000e+000) (1, -6.22787699755627420000e-001) (2, -7.66132246034081130000e+001) (3, -7.77242966270985880000e-001) (4, 3.75285155709968240000e+001) (5, -3.35479953551859670000e-001) (6, -5.18233536949645490000e+000) (7, 2.00224223756956790000e+000) (8, 8.70132843210950390000e+000) (9, 6.64091872671646750000e+000) (10, 6.72253696353793660000e+001) (11, -2.53114267284227510000e-002) (12, -4.16723989747088340000e+001) (13, 9.21703138768375290000e-001) (14, 3.25024949630307130000e+001) (15, 1.24101887403180790000e+001) (16, 2.16897533100564800000e+002) (17, 5.36350639664429000000e+000) (18, 2.40803391275549540000e+001) (19, 1.19916267474672260000e+000) (0, 1.14615550767047390000e+001) (1, -4.06486228270285910000e+000) (2, 5.62888603609599300000e+001) (3, -1.26893152883807300000e+001) (4, -1.77115927456839610000e+002) (5, -9.85970363700933920000e+000) (6, 1.24977072281755950000e+002) (7, -5.02925055148789200000e+000) (8, -5.58342970134026030000e+000) (9, -4.43675083841853370000e+000) (10, -4.49305270216604880000e+001) (11, -3.41070111451307590000e+000) (12, 3.87196217229025170000e+001) (13, -2.44521871515731570000e+000) (14, -1.79738846233327730000e+002) (15, 1.38092753787016350000e+000) (16, 2.75587709771902600000e+001) (17, 1.25465322413168370000e+000) (18, -2.89937718450453550000e+001) (19, -4.75332792361281160000e+000) (0, -3.59278838940568190000e+001) (1, 5.26837765508752500000e-001) (2, 3.07650086389189320000e+001) (3, 1.29749484225903600000e+000) (4, -2.02821513583241750000e+001) (5, 1.29411927124979780000e+000) (6, -6.01346589065424770000e+001) (7, -8.39909055014241620000e-001) (8, -4.92092784673131510000e+000) (9, -2.18352613236486850000e+000) (10, -2.65921243540891150000e+001) (11, -5.05923921936497160000e-001) (12, 1.18135585446539540000e+001) (13, -9.76002155473269790000e-002) (14, 8.01548270785730030000e+000) (15, -4.87476903332124590000e+000) (16, -8.67028767134026310000e+001) (17, -3.62965854545385990000e+000) (18, -2.39133525883580380000e+001) (19, -2.16600706261173310000e-001) (0, 9.20485213792059460000e-003) (1, 4.04825762475027330000e+000) (2, -9.72324618688729810000e+000) (3, 5.46373298225657500000e+000) (4, 3.04571902180941160000e+001) (5, 3.44004295350960510000e+000) (6, 1.88835246128657990000e+001) (7, 6.25213338114431030000e-001) (8, 2.08270077792252550000e+001) (9, 1.42979010595891400000e+000) (10, 5.06854664066164200000e+001) (11, 4.88959585474501580000e-001) (12, -7.12104543040927760000e+000) (13, 2.47615545110589830000e+000) (14, 9.06244717351554670000e+001) (15, -1.17607209408899990000e+000) (16, 2.40490300513467940000e+001) (17, 4.58680996664693090000e-001) (18, 1.10469404563026450000e+001) (19, -1.08086784576635670000e+000) (0, -4.71226987820481020000e+000) (1, 2.25351191781687500000e+000) (2, -5.40871981193421550000e+001) (3, 1.24213030358472740000e+001) (4, -1.43649228369500610000e+002) (5, -1.16824289175164810000e-002) (6, -2.92157219913556500000e+001) (7, 7.86123163865334010000e+000) (8, 1.71241258925214130000e+001) (9, -2.49681045034738910000e+000) (10, -1.10288983142444780000e+002) (11, -7.67970563841882230000e-001) (12, -6.12970339540737540000e+001) (13, -3.72731093232961550000e-001) (14, -1.08590489028675360000e+000) (15, -3.99148577634086070000e-001) (16, 9.09963389015057660000e+001) (17, 3.39148657734589200000e+000) (18, 6.88294442500668710000e+001) (19, -1.39799143948283970000e-001) (0, -3.77673347466940610000e+001) (1, -1.14183077877686160000e+000) (2, 2.39334993393286270000e+001) (3, 9.38908828546824780000e-001) (4, -3.35535703147969290000e+001) (5, -1.98087563272191680000e+000) (6, -4.38058376620780620000e+001) (7, 1.58092194779305490000e+000) (8, 4.34331171022625500000e+001) (9, -3.62997620638902510000e+000) (10, -1.24388814118500830000e+002) (11, -2.19000222760883380000e+000) (12, -1.63724021884245130000e+001) (13, -1.18142474843899530000e+000) (14, -2.04497830594621450000e+001) (15, 2.12471502318662720000e-002) (16, 2.04858889845358870000e+001) (17, 6.16762566765587270000e-001) (18, 4.73990272387482040000e+001) (19, 6.66316095954336830000e-001) (20, -1.51259664138169800000e+000) (21, 1.45255910047954990000e-001) (22, -1.82559915457706450000e+000) (23, 1.96777424377830770000e+000) (24, -1.66062596242547960000e+000) (25, 1.82369275012503440000e+000) (26, 1.53172250499188230000e+000) (20, -5.79163566267932750000e-001) (21, -1.28062189379976780000e+000) (22, -3.78427467417918330000e-001) (23, -1.32069754532832760000e+000) (24, 1.34750572304684790000e+000) (25, -1.44737845146509740000e+000) (26, 2.75897182620856620000e-003) (20, 2.19457823908777700000e+000) (21, 1.50277075398628220000e+000) (22, 2.23821502728371910000e+000) (23, -1.33491069987273340000e-001) (24, 7.49237976283147200000e-002) (25, -1.67543483378204340000e-002) (26, 1.52066833633131850000e+000) 

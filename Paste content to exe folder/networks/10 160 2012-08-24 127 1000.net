FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.23571329440894060000e+002) (1, 2.31802502175849460000e+000) (2, -1.09820864904066040000e+002) (3, 6.58467833375166120000e+000) (4, -1.10039448579873410000e+002) (5, 4.00929470780293060000e+000) (6, 5.63592183001400140000e+001) (7, 2.87049855394820460000e+000) (8, -1.94791452229087660000e+001) (9, 1.19699032068053460000e+000) (10, -8.59577441815580380000e+000) (11, -3.19098222613933520000e+000) (12, 2.01700893283557790000e+001) (13, 8.89760389376413310000e+000) (14, 1.15544430191554110000e+002) (15, -3.44304235375291200000e-001) (16, -4.72598206580520410000e+000) (17, 5.07502392320560820000e-001) (18, -8.39014087067788240000e+001) (19, -2.09920613941706110000e+000) (0, 2.68748804739872930000e+001) (1, 2.05379656020046130000e+000) (2, -1.08418907102153510000e+001) (3, -2.12474213505218760000e+000) (4, 2.98067234188266960000e+001) (5, 8.59841362475187940000e-001) (6, -3.12304747481026330000e+001) (7, 7.71645644403943230000e-002) (8, 9.38599663373562270000e+000) (9, 8.46316103212956690000e-001) (10, 2.00904475819584820000e+001) (11, -3.37787581021308720000e-002) (12, -5.37569352927968820000e+001) (13, -2.16113305351491950000e-001) (14, 9.52791564797967010000e+000) (15, -9.91942866033496570000e-001) (16, -5.00122254775771150000e+000) (17, -8.89467744505005760000e-001) (18, -2.67112596779461140000e+001) (19, 5.35693805305002210000e-001) (0, 2.14878117582404680000e+001) (1, -2.99744002891964150000e+000) (2, 1.15925539549456640000e+001) (3, 3.95153341587159800000e+000) (4, 9.68774818279234180000e+001) (5, -3.06331971085654150000e+000) (6, 1.60506010665488300000e+002) (7, 3.70712938012351370000e+000) (8, 3.29964579156222160000e+001) (9, -1.28151813246023490000e+000) (10, 2.45781780036435760000e+001) (11, 5.32210699643424690000e+000) (12, 2.56903501084513160000e+001) (13, -9.67351162190122070000e-001) (14, -2.78920636499693660000e+001) (15, 1.20386597043791130000e+000) (16, 2.66056888476466500000e+001) (17, -7.14590248259410640000e-001) (18, 7.54437103327685890000e+001) (19, 8.11024701327157200000e-001) (0, 5.22144914669181730000e+002) (1, -2.81888951009761610000e+000) (2, -6.26841887474611780000e+002) (3, 2.20179217136661090000e+001) (4, 1.93599124384041520000e+001) (5, 3.55602359680189930000e+001) (6, -7.78702743556081710000e+002) (7, 2.57524433571714790000e+001) (8, 7.72493838923951440000e+001) (9, -4.31749334934650620000e+000) (10, 9.90905873122484950000e+000) (11, 2.61827715664416870000e+002) (12, -5.89610400799502090000e+001) (13, -1.18749679209744700000e+001) (14, -1.10582596052256480000e+002) (15, 3.63145533219512330000e+000) (16, -3.40620043216515710000e+001) (17, 3.41723361520771930000e-001) (18, 6.52557314322903630000e+000) (19, 1.20305371301251560000e+000) (0, 9.08949653122513720000e+000) (1, -1.53590977958253220000e-001) (2, -2.32019975857741880000e+000) (3, 6.43103755689263810000e-001) (4, -2.68670734185673440000e+001) (5, -2.68650978178512250000e-001) (6, -8.69941484257523530000e+000) (7, 1.88961332094960770000e-001) (8, 6.00545346723663620000e+000) (9, 7.80970333460703250000e-006) (10, -2.01357810705699940000e+001) (11, -1.32732633625999250000e+000) (12, 1.34074184776687070000e+000) (13, 3.92409189960911260000e-002) (14, 4.66468281455344870000e+000) (15, 7.79254726337949450000e-001) (16, 7.58028277063297210000e+000) (17, 5.44112254494746870000e-001) (18, 1.09185052321613650000e+001) (19, 3.56745522528598980000e-001) (0, 3.09964561229061220000e+000) (1, 4.78145354537112320000e-001) (2, -2.06693583573324040000e+000) (3, 3.46202605146631680000e+000) (4, 2.82027531671717040000e+001) (5, 1.77486071515801600000e+000) (6, 9.58941913524244710000e+001) (7, 1.34398743842088650000e+000) (8, -4.25910294724491130000e+000) (9, 1.06696193778179560000e+000) (10, 2.33209483238846000000e+001) (11, 7.74877504769110440000e-001) (12, 2.12461227762134040000e+001) (13, 1.79929123721490500000e+000) (14, 1.13819435382345040000e+001) (15, -8.77204459247932110000e-001) (16, -6.01849050799196220000e+000) (17, -5.96771444918015520000e-002) (18, 3.85939415933615090000e+000) (19, -1.08194682723699810000e+000) (0, 1.07277820364609030000e+001) (1, -3.21081893136152490000e-001) (2, 4.87693258905494530000e+001) (3, -2.39098786281766480000e+000) (4, 1.19906348724314270000e+002) (5, -3.59643434939943860000e+000) (6, 5.47920007861825700000e+001) (7, 2.99448598988277580000e-001) (8, 3.00849887789319150000e+001) (9, -5.32292232482479030000e-001) (10, 3.12866889012105570000e+001) (11, -7.62149104604862630000e-001) (12, -9.40345841278315360000e+001) (13, 5.29406395092319130000e-001) (14, -1.46780170915319880000e+001) (15, -1.80430329009551780000e+000) (16, -9.39107970407330230000e+000) (17, -1.56645142371619660000e+000) (18, -2.25576773856252540000e+001) (19, 2.84223997245998430000e+000) (20, -1.42359433648912970000e+000) (21, 1.90509147277610260000e+000) (22, -3.35447561863279730000e-001) (23, 9.64204403598729500000e-001) (24, 2.08847257613388180000e+000) (25, 2.75546430338692170000e+000) (26, -6.49824566697882130000e-001) (27, 1.91969981086719950000e-001) (20, 1.41702391955524280000e+000) (21, -6.12658442618229990000e-001) (22, 1.56728354589850730000e+000) (23, -1.51956915499777280000e+000) (24, -2.04460206793980430000e+000) (25, -1.91495541361836800000e+000) (26, -3.95417007331881560000e-001) (27, 1.48618398332812580000e+000) (20, -3.31208919409960030000e-002) (21, -8.16487148622500600000e-001) (22, -8.76462979002124660000e-001) (23, 4.31615024664105670000e-001) (24, 8.89706764844456070000e-002) (25, -5.09432229152416700000e-001) (26, 6.79439332640880860000e-001) (27, 7.15819895291584850000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.49999921316744940000e+003) (1, -5.17613820854622200000e+000) (2, -1.50000000000000000000e+003) (3, 1.64665076732606400000e+001) (4, -1.50000000000000000000e+003) (5, -1.38378122955746820000e+002) (6, -1.37339250956471780000e+003) (7, 2.97716344515450190000e+001) (8, 1.50000000000000000000e+003) (9, 1.64359717656760790000e+001) (10, 1.30398491782031190000e+002) (11, -9.81623800574215720000e+001) (12, 1.41835904586835770000e+003) (13, -9.64522879273701650000e+001) (14, 1.38322862859652010000e+003) (15, 6.00899456539963740000e+001) (16, 1.37435553875992790000e+003) (17, 5.84323106690504660000e+001) (18, -1.47715946527962050000e+001) (19, 5.62056597420224760000e+001) (0, -2.88290351573946530000e+001) (1, 3.63758979186954920000e+000) (2, -3.95249515392933180000e+002) (3, 1.44429078727009800000e+002) (4, -1.50000000000000000000e+003) (5, -3.39011381632174120000e+000) (6, -1.83371226370090970000e+002) (7, 4.78253233163667770000e+001) (8, 1.27571359949577550000e+003) (9, -2.73821641599211710000e+001) (10, -1.31872655228497750000e+003) (11, 5.29577999663173390000e+001) (12, -2.75652799295736490000e+002) (13, 2.36877827767184580000e+000) (14, 3.87768246116694630000e+002) (15, -1.07296626296505180000e-002) (16, 5.28737661431341530000e+000) (17, 5.60766915715565250000e+000) (18, 4.70878855769991620000e+002) (19, 4.74784172586795210000e+001) (0, 9.71241713269881760000e+000) (1, 3.99253326758980730000e-001) (2, 9.09818787654075400000e+000) (3, -7.75809924233130840000e+000) (4, -2.57148485035158250000e+001) (5, 1.27765061950357040000e+000) (6, -1.96837623223052770000e+001) (7, -2.58349462231038850000e+000) (8, -9.87042779551036060000e+001) (9, -9.73619560685232980000e-002) (10, -1.43706566775030410000e+002) (11, 4.65191508445957510000e+000) (12, -1.87737620709162660000e+001) (13, 3.07171014178768020000e+000) (14, -1.60069964567699570000e+002) (15, 1.94662034754286670000e+000) (16, -5.51930668594764530000e+001) (17, -4.13107524698047070000e-001) (18, -4.03523787749453650000e+001) (19, 5.05024724493414620000e-001) (0, -3.95521185286658030000e+000) (1, 1.01629066205886340000e+001) (2, -6.80235411876639520000e+001) (3, 5.62748543457056630000e+000) (4, -5.96012555089133760000e+001) (5, 5.06089469522699250000e-002) (6, -4.32837926872072670000e+001) (7, 1.19514601079665210000e+000) (8, -4.80282917138480980000e+001) (9, 5.84877277326766890000e+000) (10, -1.31576394215108370000e+002) (11, -1.95114070821582860000e-001) (12, -2.33221546748759680000e+000) (13, 1.23250759927207530000e+000) (14, 1.22426303545208020000e+001) (15, 7.76769754961322970000e+000) (16, 1.46011969376621950000e+002) (17, 8.03336828308561230000e-001) (18, 7.10058822049009140000e+001) (19, 4.24260321879268880000e+000) (0, -4.25164804303750050000e+001) (1, 9.58565950069893800000e+000) (2, -1.63045101389526390000e+002) (3, 1.72259592530355550000e+001) (4, 8.10969969131894290000e+001) (5, 9.02602294632348290000e+000) (6, -6.06966486828393950000e+001) (7, 5.76545422846952070000e+000) (8, -6.35405032756456920000e+000) (9, 2.59346624601691690000e+000) (10, 3.52968139788355020000e+001) (11, 4.13098830342575860000e+000) (12, -1.70093654440375640000e+002) (13, 1.21685915556287410000e+000) (14, -3.03373495968124840000e+001) (15, -2.74919049646083210000e-001) (16, -6.86497013079641240000e+000) (17, -2.46298160368969170000e+000) (18, -3.30448083807001960000e+001) (19, 2.68632316314459440000e-001) (0, 6.93543747768035470000e+002) (1, 1.77211676033563780000e+001) (2, -3.00793241040270860000e+002) (3, 8.77768054218734050000e+001) (4, 1.50000000000000000000e+003) (5, -2.14662455314294470000e+001) (6, -1.50000000000000000000e+003) (7, 3.29950041892292060000e+001) (8, -2.95651209454344950000e+002) (9, 8.24606230927364830000e+001) (10, -6.32372744065368480000e+001) (11, -2.28290984843801010000e+001) (12, 6.06954056009044510000e+001) (13, -1.16103935415970700000e+000) (14, 6.47689716672777310000e+002) (15, 7.52342566396829540000e+001) (16, 1.50000000000000000000e+003) (17, -4.85015119285986970000e+000) (18, -3.66383100169913800000e+002) (19, -1.80244332494982840000e+001) (0, 5.97710372275149560000e+000) (1, 1.37358819204545670000e+001) (2, -6.48058671703740570000e+001) (3, 5.94569962562554990000e+000) (4, -1.15528772310000730000e+002) (5, 9.76146765828121020000e-002) (6, -9.67696521421835240000e+000) (7, 1.21570663421996590000e+001) (8, -1.35928269966284640000e+003) (9, -3.07194889357404350000e+000) (10, 7.55815010293281830000e+002) (11, -2.44317949935029830000e+001) (12, -2.38255119610713990000e+002) (13, 1.66745932385621000000e+001) (14, -1.50860883342279060000e+001) (15, -1.40199391874070060000e+001) (16, 2.59411597219214020000e+001) (17, -7.33687955539934820000e-001) (18, -3.69169533993381190000e+001) (19, 1.31597763365884240000e+001) (20, -3.94151270980159090000e-002) (21, -1.79996533109173230000e+000) (22, -1.90163247056286470000e+000) (23, 1.86701345947715300000e+000) (24, -1.04689738590010980000e-001) (25, -1.81202933960366260000e+000) (26, -1.86159778379259300000e+000) (27, 1.83211766823550490000e+000) (20, 1.61019918985756250000e+000) (21, 1.60364694715902560000e+000) (22, 1.68071011110944420000e+000) (23, -1.66177488699648630000e+000) (24, 1.80096780521147700000e+000) (25, 5.21103613193935470000e-002) (26, 1.64172146933277820000e+000) (27, -1.80381741211038890000e-001) (20, -1.50245656867879830000e+000) (21, -1.60016136433752960000e-004) (22, -4.30759131746943500000e-002) (23, 5.80199913065280460000e-002) (24, -1.53410239463448010000e+000) (25, 1.46853184915929220000e+000) (26, 1.38394480094744620000e-002) (27, 1.49161293884076400000e+000) 

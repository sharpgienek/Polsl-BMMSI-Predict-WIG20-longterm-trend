FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.19350635648812470000e+001) (1, -2.77564527142252080000e+000) (2, 1.65460322646802460000e+001) (3, 5.53259279393854440000e-001) (4, 9.75166566479241830000e-001) (5, 3.66641875729541720000e+000) (6, 3.22160676798305020000e+002) (7, 1.63641410701967910000e+001) (8, 1.38331617194515100000e+002) (9, 2.19511611397286280000e+000) (10, -4.48750103551628360000e+001) (11, 5.13844714315950140000e+000) (12, 5.20564510161430360000e+001) (13, -2.48938094185424540000e+000) (14, 7.79286497207931600000e+001) (15, 7.90551352311757770000e+000) (16, 2.82711367609442410000e+001) (17, -8.56414217648269860000e-001) (18, -5.75266324023889130000e+001) (19, 3.68706718858875160000e+000) (0, -9.35481690579534730000e+001) (1, -1.30611003179269660000e+000) (2, 3.75310652635555040000e+001) (3, 3.16399684006007440000e+000) (4, -3.06119339003077730000e+000) (5, -2.19002112453824080000e+000) (6, -1.69536437675654010000e+002) (7, -1.40962658903646890000e+001) (8, -6.50188230452395430000e+001) (9, -1.34988465483566710000e+000) (10, -3.91320864908097830000e+001) (11, 5.03345200811514790000e-001) (12, -2.89669477378975100000e+001) (13, 1.69644878863508100000e+000) (14, -5.98305901999212470000e+001) (15, -3.11214324306309460000e+000) (16, -8.58841470377721950000e+001) (17, -5.75148283051303370000e+000) (18, -1.13627098781169400000e+001) (19, -1.48555436614266070000e+000) (0, 6.89402278147589410000e+001) (1, -7.79878919388755420000e+000) (2, 7.49951808619139090000e+001) (3, -8.76268110568365800000e+000) (4, 4.40170408604745230000e+001) (5, 5.01097126246187630000e-001) (6, 8.16769328622341820000e+000) (7, 9.85400428136463800000e+000) (8, -9.61045183048310320000e+001) (9, -6.42046499724660080000e+000) (10, 1.83001637542735780000e+002) (11, -1.58298110774439140000e+000) (12, 6.49693755420836680000e+001) (13, -1.16910446980184110000e+000) (14, -2.08178062349770760000e+002) (15, 3.84508822701547760000e+000) (16, 5.80981979281794960000e-001) (17, 3.68492307731392370000e+000) (18, 8.62522873880281510000e+001) (19, 6.66379025736651530000e+000) (0, 3.99643531294881310000e+001) (1, -1.47686220166564870000e+000) (2, 6.82190066749594950000e+000) (3, 8.22032619026428210000e-001) (4, -9.29602435305831420000e+000) (5, 1.63340895354902020000e+000) (6, 7.05556536881393160000e+001) (7, 3.24931869853920220000e+000) (8, 3.84567753302080750000e+001) (9, -6.94581147512007280000e-001) (10, 5.22021146163392230000e+001) (11, 1.46827364750086040000e+000) (12, 2.87711275173366770000e+001) (13, -4.69629806122439790000e-002) (14, -2.32853519195036360000e+001) (15, 4.83875553681637540000e-001) (16, -2.24191477303187310000e+001) (17, -7.42300306661598070000e-001) (18, 1.20966816405692300000e+001) (19, -5.04866154498998240000e-002) (0, 6.26948463818107090000e+000) (1, -2.00706857584782980000e+001) (2, 2.00355912650714430000e+002) (3, 1.20590554187420550000e+001) (4, -1.36214117823293350000e+002) (5, 4.34987256734362760000e+000) (6, 8.99309504673039020000e+001) (7, -3.49148751252818580000e-001) (8, 1.21308242531457030000e+002) (9, -1.53177106863874090000e+000) (10, -5.60701970605161220000e+001) (11, 1.87221002648995490000e+001) (12, 5.94569332059191570000e+001) (13, 3.61874309447804740000e-001) (14, 4.71118137538519480000e+001) (15, -2.22709572293594920000e+000) (16, -2.49485781891274460000e+002) (17, -2.30565945674798910000e+001) (18, -1.49802269114178670000e+002) (19, -1.40064019716172710000e+000) (20, 6.46084659338086450000e-001) (21, 8.54476241242118070000e-001) (22, -6.62710487321322650000e-001) (23, 1.51813688679202890000e+000) (24, -1.51613884853619640000e+000) (25, 6.14110096408697070000e-001) (20, -1.56707530664902640000e+000) (21, -1.79997729564903610000e+000) (22, -1.40964915364239080000e-001) (23, -1.22757195722121750000e-001) (24, 1.51050722049402710000e+000) (25, 1.58455879231048220000e+000) (20, 6.60808120898812690000e-001) (21, 5.61659622158424690000e-001) (22, 6.97338960902908920000e-001) (23, -1.12435806696512830000e+000) (24, 2.18347766594283540000e-001) (25, 4.96632951232012730000e-001) 

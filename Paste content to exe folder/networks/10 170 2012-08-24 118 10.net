FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.03138174224353400000e-001) (1, 3.71793607439844100000e-002) (2, -3.11206424151027770000e+000) (3, 2.53899123177163900000e-001) (4, -9.36087539069404560000e-001) (5, 6.19224776668098050000e-003) (6, 3.16729495522390450000e+000) (7, 3.70664198393049480000e-001) (8, 3.12734744486301520000e+000) (9, -8.77713766803610850000e-002) (10, 3.13839480830888370000e+000) (11, 3.99394730813967310000e-001) (12, 3.17113406660923670000e+000) (13, 3.78905228555524940000e-001) (14, 1.18518941385554230000e+000) (15, 2.26885091059228580000e-001) (16, -3.11334597981062710000e+000) (17, 2.38615919824426400000e-001) (18, 3.20082767056733090000e+000) (19, 1.31641591127721340000e-001) (0, 5.14916017975317390000e-001) (1, 2.19544166860941300000e-001) (2, 3.06042849855334520000e+000) (3, -1.92756798037278160000e-001) (4, 3.20911624490959020000e+000) (5, 2.46266858165664460000e-001) (6, -3.10713260081179050000e+000) (7, -5.89168222615656270000e-001) (8, -1.18718613791700860000e+000) (9, 8.59965140530545430000e-002) (10, -1.22787217367952770000e+000) (11, 6.11870365123174610000e-001) (12, -1.18000840343505200000e+000) (13, 5.29546145146448270000e-001) (14, -1.46096143379052020000e-001) (15, -2.84771230572199000000e-001) (16, -5.70341922582886300000e-001) (17, 1.05531783259860120000e-001) (18, -3.05531985589909550000e+000) (19, 3.60228175252923110000e-001) (0, -1.65409236072910160000e+000) (1, -1.90188832532064840000e-001) (2, 6.08550052573698100000e-001) (3, -1.67648548993063470000e-001) (4, -1.44870139459480440000e+000) (5, 4.04533865280927790000e-003) (6, -5.46977664422231720000e-001) (7, -9.16871963163506530000e-002) (8, 4.23633105020356840000e-001) (9, -1.88357128479498730000e-001) (10, 5.42083471877294890000e-001) (11, -2.65719839516939560000e-001) (12, 4.01251512889970130000e-001) (13, -4.47827870747864730000e-002) (14, 3.67314211598135100000e-001) (15, -1.99191518213090310000e-001) (16, 4.19666385530105050000e-001) (17, 1.30668875695896970000e-001) (18, -1.47240160742221900000e-001) (19, 5.34538750030651500000e-003) (0, 1.25487703357033190000e-001) (1, 2.64529954284514370000e-001) (2, 9.85917441235217850000e-003) (3, 2.92575608999302180000e-001) (4, 2.07493097894744680000e-001) (5, 7.41632397016140920000e-002) (6, 3.68684539123174890000e-001) (7, 2.78729565763192520000e-001) (8, 7.21275837001013050000e-002) (9, 3.55302089349896100000e-001) (10, 3.66865691439821950000e-001) (11, 2.21823654820015930000e-001) (12, 6.81276710460309460000e-001) (13, 1.62255282029912710000e-001) (14, 1.44647046426348820000e-001) (15, 2.32071457707095090000e-001) (16, 2.16425001799662680000e-001) (17, 1.14867586011281110000e-001) (18, 4.51698456375803640000e-001) (19, 6.11128691138695500000e-001) (0, 9.78722821971387050000e-001) (1, 2.14462814866580860000e-001) (2, -3.19048831494451250000e+000) (3, 2.93686448859604990000e-001) (4, 5.53852981376192770000e-002) (5, 4.62179784866447120000e-001) (6, 9.42348713328247320000e-001) (7, 4.76052203606691090000e-002) (8, 2.98658681680171290000e-001) (9, 1.13931807509177170000e-001) (10, 1.83019849732523140000e-001) (11, 6.58900908647432000000e-001) (12, 4.05763397097567920000e-001) (13, 5.17392188032925970000e-001) (14, 4.78114472394432940000e-001) (15, 2.33316574913148780000e-001) (16, -5.82041403477972840000e-001) (17, 1.46471590388467380000e-001) (18, 5.35505830671505810000e-001) (19, 6.05507353164306040000e-001) (0, 3.95139010053995040000e-001) (1, 1.58403087573100010000e-001) (2, -1.72150720338683560000e-001) (3, 9.83060894522442410000e-002) (4, 1.00254452948631530000e+000) (5, -4.90482464532229490000e-002) (6, 1.64522619897442740000e-001) (7, 3.52069557122315970000e-001) (8, 2.44842846508241060000e-001) (9, -1.53838606637163010000e-001) (10, 6.99133424821284600000e-001) (11, 2.30070160645756350000e-002) (12, -1.06967976545551010000e-001) (13, 4.68338474035377040000e-001) (14, 3.69108484182586400000e-001) (15, -1.50756331200608520000e-001) (16, 4.07742725382788800000e-002) (17, 2.54919264866407920000e-001) (18, 4.85754496098356690000e-001) (19, -2.66835177506730860000e-001) (20, -4.33556830052147440000e-002) (21, -3.39533817988068750000e-001) (22, 2.41840309771304720000e-001) (23, 5.95503690905864860000e-001) (24, 4.18893651408933480000e-001) (25, 1.72768454340392120000e-001) (26, 4.73837499883910610000e-001) (20, -1.20420035655025880000e-001) (21, 2.09839108416307820000e-001) (22, 2.01590933976993010000e-001) (23, 1.22477047648221260000e-001) (24, 4.56497411734898160000e-001) (25, -1.24678183741577770000e-001) (26, 3.87509373597521300000e-001) (20, -4.00664912271338550000e-001) (21, 9.29522904614822900000e-002) (22, 4.62795620201707340000e-001) (23, 2.78561936915482200000e-001) (24, 2.26663742782763860000e-001) (25, -1.55639143773368100000e-001) (26, 2.62570725739694590000e-001) 

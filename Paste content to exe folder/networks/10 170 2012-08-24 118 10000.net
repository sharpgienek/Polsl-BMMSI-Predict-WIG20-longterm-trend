FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.96345745510650490000e+002) (1, -4.06953644349140620000e+001) (2, 1.27980396035782610000e+003) (3, 1.52866987112853750000e+001) (4, 2.71760369693270890000e+002) (5, 2.54868163825931720000e+001) (6, 1.50000000000000000000e+003) (7, 1.78864093096217330000e+001) (8, 3.35896524808509070000e+002) (9, -9.75021100630138310000e+001) (10, -1.36098151251599970000e+002) (11, 2.50129781161032530000e+000) (12, 1.16124976700337490000e+003) (13, -2.95117712566767170000e+001) (14, 2.95390100153835420000e+002) (15, 8.52017908165993630000e+000) (16, -6.43761589439661070000e+002) (17, -1.89285080022923000000e+001) (18, -4.77657400025906610000e+002) (19, 5.53928625608383100000e+001) (0, -1.05190276764665920000e+002) (1, 6.21040697010633650000e+000) (2, -2.51676081651207850000e+002) (3, 2.88124280702066970000e+000) (4, -1.86372301236944150000e+001) (5, -1.94163175225268600000e+000) (6, -2.78042314984333000000e+001) (7, 1.84220671286199340000e+000) (8, 3.16378462033831520000e+001) (9, 9.92344267860706530000e+000) (10, -4.46471024539667740000e+001) (11, -1.27872794676245900000e-001) (12, -1.50369065983578570000e+002) (13, 1.53765948958595340000e+000) (14, 1.75018165761323170000e+001) (15, 1.70707388457011610000e+000) (16, 1.06242200603171770000e+002) (17, 6.75369572547065910000e+000) (18, -1.61604767934211960000e+001) (19, -5.75905435476683270000e-001) (0, 1.55368683696590890000e+002) (1, 1.51835474807005110000e+001) (2, -2.53380278058735460000e+002) (3, 1.74923051805748850000e+001) (4, 1.51522731990959190000e+002) (5, 2.19043592750633830000e+000) (6, 2.46737934721646550000e+002) (7, 3.19382407318294300000e+000) (8, -1.22571355298718900000e+001) (9, 1.70751725338235940000e+001) (10, -1.56522978934567050000e+002) (11, 2.79344563076690200000e+001) (12, 9.81738128626559790000e+001) (13, 1.95559775080585220000e+001) (14, 1.78714639448179820000e+001) (15, 6.94591917475628410000e+000) (16, -2.48754957315861630000e+001) (17, 1.35406241220719070000e+000) (18, 1.19478444682532620000e+001) (19, -1.23594466300286680000e+001) (0, -1.50000000000000000000e+003) (1, -2.44340292470949160000e+001) (2, -5.82561176134358670000e+002) (3, -1.63588466582764230000e+001) (4, -5.68627151007401950000e+002) (5, 9.57243098224925500000e+000) (6, 1.50000000000000000000e+003) (7, 2.62276394486355890000e+001) (8, -1.50000000000000000000e+003) (9, 9.25882231029574320000e+000) (10, -1.01628832658191630000e+003) (11, 1.52338714776710230000e+001) (12, -8.64523601225689480000e+001) (13, 1.39567633777141270000e+001) (14, -1.86395162821624890000e+002) (15, -9.21224815143482660000e+001) (16, -1.50000000000000000000e+003) (17, -1.84990248392780610000e+001) (18, -1.50000000000000000000e+003) (19, -5.27199716849154940000e+000) (0, 1.05452749014048880000e+002) (1, 7.76808610863483120000e+000) (2, 9.18033693205617570000e+001) (3, 4.04084310555261350000e+000) (4, 8.17958147202673020000e+001) (5, 4.84419125028914530000e+000) (6, -9.55175129298689280000e+001) (7, 2.90450265067469360000e+000) (8, 2.97072594928157170000e+002) (9, -5.52532283285607570000e+000) (10, 3.36606646675777090000e+002) (11, -7.14652982283052830000e+000) (12, 2.09311186030820640000e+002) (13, -8.89582216725096590000e+000) (14, 1.57766091652854440000e+002) (15, 2.49791049646166270000e-001) (16, 1.58600001386929310000e+002) (17, 3.15967398836784240000e+000) (18, 3.16163986160295390000e+002) (19, -4.20704611233944760000e-001) (0, 6.40870304810950070000e+002) (1, -6.94356247407683020000e+000) (2, -1.17206896767574200000e+003) (3, 1.29302842941896980000e+002) (4, -1.50000000000000000000e+003) (5, -3.88165013556910240000e+001) (6, 1.16213644217112800000e+003) (7, 7.50251431002964180000e+001) (8, -8.91600202588758460000e+001) (9, -1.22068664021588390000e+001) (10, -1.50000000000000000000e+003) (11, 1.63453394265196720000e+002) (12, -9.96831384544598450000e+002) (13, 1.17352217654515790000e+001) (14, -5.53710034232711560000e+002) (15, 2.39533729170645340000e+001) (16, -4.73214783680343910000e+001) (17, -1.11193855688700620000e+001) (18, -7.28191100623008420000e+002) (19, 4.48850433621284280000e+001) (20, 1.82863473456397770000e+000) (21, 1.67346965354487030000e+000) (22, 8.93600765771281450000e-001) (23, 2.38222005726250380000e-001) (24, 6.75944172687559940000e-002) (25, -1.03723572671772240000e+000) (26, 3.71575516380325040000e-001) (20, -1.38919901233893150000e+000) (21, -1.17850615249985410000e+000) (22, 2.00102599074588470000e-001) (23, 1.11530776572401690000e+000) (24, 1.23690765103965550000e+000) (25, 1.26859203195499280000e+000) (26, 9.65078561355705360000e-001) (20, -6.02433600400106330000e-003) (21, -2.82110536450451420000e-002) (22, -1.17460875275670330000e+000) (23, -1.39557176706321550000e+000) (24, -1.34193563183086660000e+000) (25, -1.14542973870421170000e-001) (26, 1.25585572790149190000e+000) 

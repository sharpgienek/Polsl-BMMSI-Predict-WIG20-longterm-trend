FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.64300575489588570000e+001) (1, 5.07286197429780540000e+001) (2, 1.50000000000000000000e+003) (3, 4.23700641819176660000e+000) (4, 3.52259441352821110000e+002) (5, 1.10524417845242640000e+002) (6, -5.35821311132746700000e+002) (7, 3.16777235052952120000e+001) (8, -6.13532198790720500000e+001) (9, 3.96075294755796250000e+001) (10, -2.28854097239035670000e+002) (11, -6.94070074438962510000e+000) (12, 2.54505663235081410000e+002) (13, 3.05763573370184040000e+001) (14, 3.78698317650081550000e+002) (15, 1.14781576150936000000e+002) (16, 7.12646474299342800000e+002) (17, -1.61546250328060290000e+000) (18, -1.02889671716045700000e+002) (19, 8.39183921508468270000e+001) (0, 1.50000000000000000000e+003) (1, 2.46966752714586480000e+002) (2, -1.50000000000000000000e+003) (3, -1.23317283678036220000e+001) (4, 1.50000000000000000000e+003) (5, 1.91714157475593790000e+001) (6, 8.87425080239843400000e+002) (7, 2.90389113433006080000e+001) (8, 1.43516966165104490000e+003) (9, 1.02407854911556000000e+001) (10, 4.53187438978390930000e+000) (11, 1.65152602472069710000e+001) (12, -7.06075801983997620000e+002) (13, -3.88035834429741300000e+000) (14, -6.02341597740355840000e+002) (15, -5.84235143593953910000e+001) (16, 5.10540689647405090000e+001) (17, 1.09927776350527340000e+002) (18, -9.11103680066808580000e+002) (19, -6.98111744188349000000e+000) (0, -1.44383300763846190000e+002) (1, 1.93432158414938820000e+000) (2, 1.04770292781682800000e+002) (3, 3.58285118497066210000e+000) (4, -1.74362123962404340000e+000) (5, 1.08934834321132690000e+001) (6, 1.16078410035195560000e+002) (7, 1.78068787986925110000e+000) (8, 5.76695845915689130000e+001) (9, -9.94534964937622500000e-001) (10, 1.97318337486418150000e+001) (11, -1.04336538086421320000e+000) (12, -1.72279024043041460000e+001) (13, 1.88841394860152770000e+000) (14, 9.58160822932937180000e+001) (15, 4.15375589008680100000e-001) (16, -1.08315508535444740000e+001) (17, -1.52586048530829530000e+000) (18, -6.66076137294189440000e+001) (19, 7.47911219163963190000e+000) (0, -4.95710861183563340000e+002) (1, 2.92204245270260540000e+001) (2, -1.50000000000000000000e+003) (3, 3.26880066597051380000e+001) (4, -6.66010092249193430000e+000) (5, -6.55160724097539490000e+000) (6, 9.07134437538621650000e+001) (7, -4.56342302427275650000e+000) (8, -1.26329491540316740000e+002) (9, 5.97524535902409410000e+000) (10, -2.00387270499850640000e+002) (11, 1.62847727591954800000e+001) (12, 2.06784408432316980000e+002) (13, 1.25058041340088480000e+001) (14, 1.68291495637915660000e+002) (15, 8.29586045472483490000e+000) (16, 4.81690928323920730000e+002) (17, 1.56769299328068450000e+001) (18, -1.46909866108236770000e+002) (19, -9.63587592659943580000e+000) (0, 2.61894563947703380000e+002) (1, -7.97998583003328580000e+000) (2, 1.88081787933731110000e+002) (3, -4.82456243947112280000e+001) (4, -1.04045359070521430000e+003) (5, 9.16528303017791050000e+000) (6, 2.48473714214163860000e+002) (7, -1.69453844401899260000e+001) (8, -7.66741684825311490000e+002) (9, 2.29780596458259300000e+001) (10, -1.17365282206334270000e+003) (11, -1.18103815843374860000e+001) (12, 7.40025950434465810000e+002) (13, 4.79023380617919440000e+001) (14, 1.04126039907549220000e+003) (15, 5.98810049312639240000e+001) (16, 1.50000000000000000000e+003) (17, -3.24883319279254450000e+000) (18, 1.21169576860201870000e+003) (19, -6.36314765143174820000e+000) (0, -8.56521485093398920000e+000) (1, 6.13158304073030090000e+000) (2, -1.07526114516682800000e+002) (3, 1.20673163310744190000e+001) (4, -9.71664864320449480000e+001) (5, 1.42756893671053530000e+000) (6, 5.25047572889996060000e+001) (7, 9.49505018362714060000e-001) (8, 3.89473924631405310000e+001) (9, -2.71200725088774730000e+000) (10, 5.35186916412426830000e+001) (11, 4.67124554672651370000e+000) (12, -1.74270937316113720000e+001) (13, 1.28235796897710990000e+000) (14, 1.24513721503581520000e+001) (15, -5.83188685822122820000e+000) (16, 1.34451375432108120000e+001) (17, 1.70597538787025260000e+000) (18, -1.11008634742128310000e+002) (19, -4.27978141333805340000e+000) (0, 1.71701772968733000000e+002) (1, 1.00527819980722390000e+001) (2, 2.76854913676994440000e+002) (3, 1.52624574903835520000e+000) (4, -5.16042085056485920000e+002) (5, -5.73702686319820910000e+000) (6, -2.78014685269854950000e+001) (7, -3.14915097040075200000e+001) (8, -2.56290995593170920000e+002) (9, -2.25816067899097280000e+001) (10, -2.90311677094316170000e+002) (11, -7.60788029974426560000e+000) (12, 6.50045620955945940000e+001) (13, 7.43371048075900640000e+000) (14, 5.88394703852527310000e+001) (15, -7.37057713778366170000e+000) (16, 2.57735962737153160000e+002) (17, -2.82505726623442140000e-001) (18, -8.92461563415449110000e-002) (19, 1.49939266015786130000e+001) (20, -2.26977979071750770000e+000) (21, 1.97192709575634970000e+000) (22, 2.03996939130355370000e+000) (23, 3.30989946450791700000e-002) (24, 1.97610509015872650000e+000) (25, 4.98809993500416190000e-003) (26, -2.00227769745567130000e+000) (27, 2.17564862252556250000e+000) (20, 1.18276861692569590000e+000) (21, -5.96653390795493400000e-001) (22, -1.28012370978868620000e+000) (23, -6.72410468165454910000e-001) (24, 3.57059771425062360000e-002) (25, 1.12980335244548450000e+000) (26, 2.32656639858723620000e-001) (27, 4.35872584641702590000e-001) (20, 3.18290492106530040000e-001) (21, -5.66692594731135870000e-001) (22, -1.27747433548302670000e-001) (23, 5.71577964573006250000e-001) (24, -1.18169697737348290000e+000) (25, -9.96318986652421020000e-001) (26, 1.00297595750069530000e+000) (27, 5.83973464402170020000e-001) 

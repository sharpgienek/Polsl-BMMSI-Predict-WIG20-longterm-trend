FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 4 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.39262784308049500000e+002) (1, 1.01361123621929740000e+002) (2, 1.22951592127975960000e+001) (3, -1.24838059025307300000e+001) (4, 1.17924185728379170000e+001) (5, 5.26908036835527670000e+000) (6, -1.50000000000000000000e+003) (7, 1.96418720639171410000e+001) (8, 1.10836692101331000000e+003) (9, 3.16828957909950930000e+002) (10, -1.50000000000000000000e+003) (11, 5.16260489842976330000e+001) (12, 1.03572692364643580000e+003) (13, -4.31804288899456030000e+001) (14, -9.33962355373095760000e+002) (15, -8.68852599535610470000e+001) (16, -1.50000000000000000000e+003) (17, 6.24987368476484020000e+001) (18, 1.50000000000000000000e+003) (19, 1.97760346300259360000e+002) (0, -3.38286081691430300000e+002) (1, 1.67649285800975600000e+001) (2, -5.27076669920271000000e+002) (3, 5.26867891516305630000e+001) (4, -1.10198804475639250000e+002) (5, 2.97514916098096760000e+001) (6, 1.50000000000000000000e+003) (7, 3.47891260446197070000e+001) (8, 3.73509548436676880000e+002) (9, -5.69912180405364590000e+001) (10, 1.50000000000000000000e+003) (11, 2.04343475798540130000e+001) (12, 5.74167284998491940000e+002) (13, 7.81841608489085900000e+001) (14, 1.11553431850677290000e+003) (15, 1.17108342636496130000e+001) (16, 4.12779703069539610000e+002) (17, 1.72563894776063990000e-001) (18, 4.07904019143871180000e+001) (19, -4.56128208968312590000e+001) (0, 2.18135580276706560000e+001) (1, 4.48011790400532120000e+000) (2, -1.19803884733860670000e+002) (3, 6.90244976125848190000e+000) (4, -7.01477520630939320000e+001) (5, 2.85129685719963220000e+000) (6, 1.77316562259142330000e+002) (7, 3.77209729674752390000e+000) (8, 1.42160775917042320000e+002) (9, -8.72967381530635800000e-001) (10, 1.19675428172017670000e+001) (11, 3.93996485464883640000e+000) (12, 1.06373677123752760000e+001) (13, 5.16020852462923050000e-002) (14, -1.35298504518476740000e+001) (15, -5.02993754430897330000e+000) (16, -2.08080952170204480000e+001) (17, -2.33748722820930900000e-001) (18, 5.82399745565898360000e+001) (19, -6.09939605993769400000e-001) (20, 1.34481983611403870000e+000) (21, 1.39774002728186870000e+000) (22, -3.47927364506664890000e-001) (23, 3.45635642364480860000e-001) (20, -1.18103316341722690000e+000) (21, -1.25474669713193720000e+000) (22, 1.13434393378630820000e+000) (23, 1.39600840551667550000e+000) (20, -9.68154558549455710000e-003) (21, -5.16335091308772480000e-002) (22, -5.07100195508404570000e-001) (23, 6.27813956377564650000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.16457414097793170000e+001) (1, -3.73291341608521120000e-001) (2, 1.61382907527371790000e+000) (3, -1.54188298990796420000e+000) (4, 1.68002715873103760000e+000) (5, -1.18896528971913540000e+000) (6, -2.83456974352146000000e+001) (7, -7.70439597229518820000e-001) (8, -5.54976055955792800000e+000) (9, 2.83954858092824520000e-002) (10, -3.90752073095062400000e+001) (11, -5.78294111722987720000e-001) (12, -1.15190586066426950000e+001) (13, -3.48789226758221440000e-001) (14, -6.32173267850018750000e+000) (15, 6.34046480239211510000e-001) (16, 4.70536554144846250000e+000) (17, 4.40328480303230130000e-001) (18, 1.52969829235260890000e+001) (19, 8.60947768600901610000e-001) (0, -8.21845319518035920000e+000) (1, -7.96233065580850670000e+000) (2, 3.05315784228205220000e+000) (3, 2.56087494307341230000e+000) (4, 3.76444280451170730000e-001) (5, -2.31611303071894400000e-001) (6, 2.07501248620308130000e+001) (7, 3.85787145959314130000e-001) (8, 2.44298159083821960000e+001) (9, -2.15006251793251080000e+000) (10, -5.04840230958789600000e+000) (11, -6.87898133272288660000e-001) (12, 2.58032107459164770000e+001) (13, 2.67266438309945810000e+000) (14, -1.23792549324794760000e+001) (15, 5.76723618502789860000e-001) (16, -1.63199332371626800000e+001) (17, 2.15201407064195130000e-001) (18, 1.31308139285002800000e+000) (19, -1.50611314391375790000e-001) (0, -1.45004216373023700000e+001) (1, -8.98254495472376010000e-001) (2, 3.54794813904437090000e+001) (3, -2.54412124320811060000e+000) (4, 2.03600476907479560000e+000) (5, -9.10663057353004010000e-001) (6, -1.27245135871448980000e+001) (7, -1.91965349821123590000e+000) (8, -2.89799545106981750000e+001) (9, -5.50523179050372850000e-001) (10, 6.54596323151647040000e-002) (11, -2.53882562701702150000e+000) (12, 2.90190991630257750000e+001) (13, -3.19585401525394830000e-001) (14, -1.05387053640951100000e+001) (15, -2.71906518164322210000e-001) (16, 1.53791607408462670000e+001) (17, 3.76140547916851920000e-001) (18, 1.38529810476266700000e+001) (19, -8.57882849681820410000e-002) (0, -1.76954058020572620000e+000) (1, 7.59965869375823330000e-001) (2, 5.90635297173434730000e+000) (3, 4.02279482640479410000e-001) (4, 1.36428883562510510000e+001) (5, 7.40280627061651870000e-001) (6, 6.44907101907884920000e-001) (7, 9.09073024761172940000e-002) (8, -7.45064535067005810000e+000) (9, -3.48452285448708820000e-001) (10, 3.44149937176644510000e+001) (11, 3.55661656773796300000e-001) (12, -8.72914675730800390000e-001) (13, -6.35621071054701450000e-001) (14, 3.93786670045386610000e+000) (15, -1.06932719952656610000e+000) (16, -7.69347243451917070000e+000) (17, -8.24270907587690280000e-001) (18, -1.76641383975969720000e+001) (19, -1.98698601286520250000e-001) (0, 4.83853311827484140000e+000) (1, -4.25580783894305430000e-001) (2, 1.35091406829495960000e+001) (3, -1.16552015266848330000e+000) (4, -3.26928748349511120000e+001) (5, 2.21124507232673710000e-001) (6, 2.13891880868290230000e+001) (7, -1.04657187230059510000e-001) (8, -7.95746886666624050000e+000) (9, 3.15509813083797350000e+000) (10, 1.33423529518675150000e+001) (11, 2.05264144873748100000e-002) (12, 1.92335751647475380000e+001) (13, 8.99322970637456810000e-001) (14, -3.76033486956318750000e+000) (15, -5.60271215640350650000e-001) (16, 1.97037892955020690000e+001) (17, 1.65195109636211590000e-001) (18, 1.32692579686126900000e+001) (19, -8.16959763849520400000e-001) (20, -1.99156900145552430000e+000) (21, -9.02979203357858080000e-001) (22, -1.22395490026108180000e-002) (23, -2.14215548655185420000e+000) (24, -6.29932071833770530000e-001) (25, 4.51401517897486780000e-001) (20, 1.19695821620753500000e+000) (21, 4.86204177318087570000e-001) (22, -1.18859304023752870000e+000) (23, 1.11603995565559670000e+000) (24, 8.38525256619062410000e-001) (25, 4.55925160604428340000e-001) (20, 4.53107022903018020000e-001) (21, 2.46548597904640370000e-001) (22, 1.15028118613483390000e+000) (23, 6.05884637579134910000e-001) (24, -2.85544653052077770000e-001) (25, 1.26645776866939410000e+000) 

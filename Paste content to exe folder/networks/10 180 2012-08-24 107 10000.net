FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.50000000000000000000e+003) (1, -3.22665526203500410000e+002) (2, 1.50000000000000000000e+003) (3, 2.77938827320791400000e+002) (4, -1.50000000000000000000e+003) (5, 9.57558190857050140000e+001) (6, 1.50000000000000000000e+003) (7, -1.50000000000000000000e+003) (8, -1.50000000000000000000e+003) (9, -5.02494358373222780000e+002) (10, 1.50000000000000000000e+003) (11, 4.38198459846728890000e+002) (12, -1.50000000000000000000e+003) (13, -1.27422945634291590000e+001) (14, -9.19925925396175190000e+001) (15, -4.42945196725617690000e+001) (16, 3.70379291282407790000e+002) (17, -3.77639124208174960000e+002) (18, -1.50000000000000000000e+003) (19, 7.18261326979502570000e+001) (0, 1.21572762573709130000e+002) (1, 1.08375186466172660000e+001) (2, -1.63355606641459020000e+002) (3, 1.17979697139296280000e+001) (4, 8.07171670167352460000e+001) (5, 2.12693748535433440000e+000) (6, 4.97516945568863370000e+000) (7, 4.94563192471479950000e+000) (8, -1.83967255495767940000e+002) (9, 1.02232124080344860000e+001) (10, 9.82721258998637240000e+001) (11, 2.33780176963207890000e+001) (12, 1.88515129003235050000e+002) (13, 8.81570473529390600000e+000) (14, 1.15622756202206440000e+001) (15, 1.38065147309874510000e+000) (16, -6.63012825776026490000e+001) (17, -5.54010491794861280000e-001) (18, -3.55865502298915180000e+000) (19, -1.74304641780105630000e+001) (0, -1.42785328574587880000e+002) (1, -4.52267341259851200000e+000) (2, 4.66644167425702680000e+001) (3, -1.46802521611567570000e+001) (4, 1.50978658512302600000e+001) (5, -2.72442950441241740000e+000) (6, -2.54305299999228620000e+002) (7, 1.11450979636706800000e+000) (8, -1.88287038209087290000e+001) (9, 3.19136309950605450000e+000) (10, -2.38364963199985970000e+002) (11, -3.54729735744032750000e+000) (12, -1.64147856258203800000e+002) (13, 1.22767699974276880000e+000) (14, 8.27098850336313800000e+001) (15, 6.05203896389110870000e+000) (16, 4.74378086370656080000e+001) (17, -1.44419587181512460000e-001) (18, 1.92541542037808140000e+001) (19, 3.53578052674124520000e+000) (0, 4.01854111328234400000e+001) (1, 2.87025095742275480000e+000) (2, 2.66787461402990580000e+001) (3, -6.39829622157229160000e-002) (4, 5.63382656282947850000e+001) (5, -2.02373995567348610000e+000) (6, 8.61911432061513240000e+001) (7, 3.52842263725134320000e+000) (8, 1.81623578134975720000e+001) (9, -2.84031506463769680000e-001) (10, 5.20750718053259760000e+001) (11, -5.63119671133123400000e+000) (12, 6.19523535150522520000e+001) (13, -2.69776678204722710000e+000) (14, 1.03784909693953120000e+001) (15, -1.04217154465095140000e+000) (16, 2.94807969316007930000e+001) (17, 2.80148313106353440000e+000) (18, 2.71505391225318780000e+001) (19, 2.68382496522520330000e+000) (0, -4.88373851504871670000e+000) (1, -2.90637307796489000000e-001) (2, -6.88493860889844990000e-001) (3, -1.08936409303743560000e-001) (4, -9.48183186586186720000e+000) (5, 7.36738067263159930000e-001) (6, -2.72690984286042020000e+000) (7, 7.14922542997572990000e-003) (8, 7.58847471442413380000e+000) (9, -1.10288119363693980000e-001) (10, -6.24577349613395950000e+000) (11, -1.76914461326442150000e-002) (12, -5.06807738444175460000e+000) (13, 1.07851260571758080000e-002) (14, 1.28357886413351910000e+000) (15, 1.92471909157560350000e-001) (16, -2.14766383794870060000e-001) (17, -4.46329107467692000000e-002) (18, 4.59910392216489150000e-003) (19, 2.59641076747031570000e-001) (20, 3.87673596836793250000e-001) (21, 1.37472766038637340000e+000) (22, 1.63166652981656500000e-001) (23, 1.63434909751958510000e+000) (24, 3.08206484434362290000e+000) (25, 9.44612853999386990000e-002) (20, -7.33502146809618120000e-001) (21, -6.47521707640731800000e-001) (22, -7.53892377807415360000e-001) (23, -1.12497580517304140000e+000) (24, -1.22731746128309420000e+000) (25, 1.15637904825428460000e+000) (20, 3.19033565971836570000e-001) (21, -5.75711300783616430000e-001) (22, 5.34765691611192140000e-001) (23, -3.60739305575638380000e-001) (24, -1.37705799939083700000e+000) (25, 9.27782052970163470000e-001) 

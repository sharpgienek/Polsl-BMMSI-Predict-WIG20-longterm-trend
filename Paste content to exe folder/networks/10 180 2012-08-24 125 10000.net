FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.81500504578329610000e+001) (1, 1.26707071281369550000e+001) (2, 1.98570684220043830000e+002) (3, 3.62960414433822290000e+001) (4, 3.74252095357614730000e+002) (5, 1.33838625665106330000e+001) (6, -5.45922131994333310000e+002) (7, -1.12648566805131690000e+001) (8, -3.27609164575317210000e+001) (9, -2.06636468514294940000e+001) (10, 4.12046924322066450000e+002) (11, -2.34966546945483610000e+001) (12, 4.38592999844414010000e+002) (13, -3.22172801269833610000e+001) (14, -6.17275460782770510000e+001) (15, -2.46128291101378030000e+001) (16, -6.01920239828050630000e+002) (17, 7.83227778665145460000e+000) (18, -1.33134275818253850000e+002) (19, 3.77151889246681340000e+001) (0, -1.47522657267303800000e+002) (1, -9.82993015546336760000e+000) (2, 3.30902954979873870000e+002) (3, -1.98893018345544450000e+001) (4, 1.63191400416105520000e+002) (5, -1.80770883508905340000e+001) (6, 8.60159752771393470000e+001) (7, -2.69681863496788840000e+000) (8, 9.62731213498028920000e+001) (9, -5.87528388837084400000e+000) (10, -3.91750148048939120000e+001) (11, -1.20011763307961220000e+001) (12, 2.29798765400303840000e+002) (13, 2.74833188156642150000e+000) (14, 7.64415522888307780000e+001) (15, 1.30729042858328060000e+001) (16, 3.48531044889624440000e+001) (17, 2.79852061097226910000e+000) (18, -1.11251948796499620000e+002) (19, 1.06543861399823340000e-001) (0, -3.64206784477022950000e+002) (1, -2.95029100183517560000e+001) (2, 6.58857856766809620000e+002) (3, 7.40417903724689450000e+000) (4, 2.93086959219771020000e+002) (5, -1.16279552990083350000e+001) (6, 2.66970562970082940000e+002) (7, 8.03950675804337860000e+000) (8, 2.37009816493902080000e+001) (9, -7.80257020598569400000e+001) (10, -4.21232846360153190000e+002) (11, -4.75852609206367280000e+001) (12, 1.50000000000000000000e+003) (13, -2.80741341640371650000e+001) (14, 7.10360672557874410000e+002) (15, -1.70918415603028430000e+001) (16, 6.75723247403827830000e+002) (17, 7.85469784089031630000e+000) (18, 3.74382735837993100000e+002) (19, 3.89994870683476050000e+001) (0, -6.76717448712142300000e+001) (1, 2.58791654259818090000e+000) (2, -4.08975593843889840000e+001) (3, 3.81495476621509470000e+000) (4, 5.02359457494702750000e+001) (5, -5.67729385023084120000e-001) (6, -6.92887574043745360000e+001) (7, -4.42401689542580690000e-001) (8, 2.67656677239623840000e+001) (9, 4.02857771828680720000e+000) (10, 5.76844261456143950000e+001) (11, 1.89554006991019300000e+000) (12, 2.22852009557494700000e+001) (13, 4.49824044476890560000e-001) (14, -3.47372104498552330000e+001) (15, 2.32856926886115410000e+000) (16, -8.27008420925154830000e+000) (17, 6.74363639071277100000e+000) (18, 4.91690009072369350000e+001) (19, 5.27444222694705720000e+000) (0, 9.65937810135782510000e+001) (1, 1.27400536941876210000e+001) (2, -1.14009909187171890000e+002) (3, 1.17182155793164730000e+001) (4, 3.09688720777994770000e+002) (5, -3.08514748667481980000e+001) (6, 8.79686752118494950000e+002) (7, 9.17494479655376340000e+000) (8, 1.50000000000000000000e+003) (9, -3.46049991035035450000e+001) (10, 1.50000000000000000000e+003) (11, -3.31453347972510600000e+001) (12, 1.47509183387944770000e+003) (13, 1.29979055525998820000e+001) (14, 2.77958451050940820000e+002) (15, 5.94449509693532220000e+001) (16, -5.62430728352701980000e+002) (17, 1.43723159019794250000e+002) (18, -6.95839018092675930000e+002) (19, 7.04690359321018460000e+001) (0, 5.91602593992219430000e+001) (1, 6.47319591308578170000e+000) (2, -1.28432969071137990000e+002) (3, 6.98799689052961080000e+000) (4, 3.80776160297038760000e+001) (5, 6.22462672947769760000e+000) (6, 5.51072981448372620000e+000) (7, 4.85759371183781980000e-001) (8, -4.30412214500074630000e+001) (9, 3.59621731956599030000e+000) (10, 1.27346333847800580000e+002) (11, 3.07853064290153310000e+000) (12, -6.42306174245737940000e+001) (13, 6.84337514179264720000e-002) (14, -5.24939929865891630000e+001) (15, 2.26058467743928390000e+000) (16, -2.19768746711188130000e+002) (17, -1.18166581718756300000e-001) (18, -3.57484580171569700000e+001) (19, -9.07613510521986240000e-001) (20, -1.80078944698015690000e+000) (21, -6.31774192482274790000e-002) (22, 1.83987810959840800000e+000) (23, 2.14935067445864330000e+000) (24, -1.18819779913739820000e-001) (25, 1.84597384961944670000e+000) (26, -2.47178004375944920000e-001) (20, 6.41788814912735150000e-002) (21, -1.16536938010641470000e+000) (22, -1.26229083131193050000e+000) (23, -1.44895193032584180000e+000) (24, 1.22626214958604220000e+000) (25, -1.21084791296044520000e+000) (26, 1.38398732338530710000e+000) (20, 1.16773385637239600000e+000) (21, 1.09613586057657340000e+000) (22, -9.69442880867741330000e-002) (23, -1.98944345353934820000e-002) (24, -1.04779403180851150000e+000) (25, -2.35523759441208600000e-001) (26, 1.30091014812703200000e+000) 

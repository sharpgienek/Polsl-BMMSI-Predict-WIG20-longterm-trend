FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.92383691001063310000e+002) (1, -4.22819787377528370000e+001) (2, 8.07360117849732660000e+002) (3, -4.40510541387967930000e+001) (4, 2.43937809723866310000e+002) (5, 2.93955895018775660000e+001) (6, -8.79160865785042200000e+001) (7, 3.39582514472196170000e+001) (8, 9.91851777383310150000e+002) (9, -7.40762845536084740000e+001) (10, 1.94032751467626210000e+002) (11, -5.18285223475453800000e+001) (12, -3.03837327459144970000e+001) (13, -7.03963516488788630000e+001) (14, -6.50198929627333200000e+002) (15, -4.35638024247859960000e+000) (16, -8.54044717761301650000e+001) (17, -3.70414847166673220000e-001) (18, -6.98085842408108710000e+000) (19, 2.81880318750319350000e+001) (0, -2.54816234664156840000e+002) (1, -4.73930683206981480000e+000) (2, 2.42911653413122790000e+002) (3, -4.59981800122408640000e-001) (4, 2.22683349986547110000e+002) (5, -8.17390793864998660000e-002) (6, -1.35740888933938650000e+000) (7, 5.75075425679550280000e+000) (8, 1.01479053790658210000e+002) (9, 1.58816325335736510000e+000) (10, -3.59548762946132290000e+002) (11, -9.49333024693839180000e+000) (12, 1.44847518238040690000e+002) (13, 2.51047664854753270000e+000) (14, -2.80983692598218870000e+001) (15, 1.13470521832814910000e+001) (16, -6.88272427115856690000e+001) (17, 9.71658756444640300000e+000) (18, 6.07018010893959000000e+001) (19, -3.26800367052158480000e-001) (0, 5.29184755582714160000e+002) (1, 7.79174729661893930000e+001) (2, 9.72291268826700620000e+002) (3, 1.37102720839931640000e+002) (4, 8.68494653159915400000e+002) (5, 4.40663449015153010000e+001) (6, -3.61077835562608070000e+002) (7, -9.74501076902446780000e+000) (8, -6.68384142714329980000e+002) (9, -9.32688169627249760000e+000) (10, -5.50648168526376030000e+002) (11, -1.06901884415795560000e+002) (12, 4.64357688313590870000e+002) (13, -1.90888999787331740000e+001) (14, -1.50000000000000000000e+003) (15, 4.90568689770068110000e+000) (16, -3.43987557253103380000e+002) (17, -3.69035178529405950000e+001) (18, -9.71873679577474970000e+001) (19, -7.78069085024392280000e+001) (0, -2.85835191031322210000e+002) (1, -6.20900391463424980000e+001) (2, 5.72142685533507840000e+001) (3, -5.76136866176851110000e+001) (4, 1.20787837842590620000e+003) (5, 1.93078781470226770000e+001) (6, 1.31756127952628780000e+003) (7, 1.42037401621299320000e+002) (8, 4.20373404354058380000e+002) (9, 2.89853370761434800000e+001) (10, -4.68343667433838960000e+002) (11, 1.80053173341725920000e+001) (12, 6.18322181525888250000e+002) (13, 2.51677947624613160000e+001) (14, 1.50000000000000000000e+003) (15, 2.32020638853505400000e+001) (16, -2.16440682457102300000e+002) (17, 6.75876619513513360000e+001) (18, 2.03138674087112520000e+002) (19, -1.21594594723955660000e+001) (0, -5.30725775587017310000e+001) (1, -1.02558257419703640000e+000) (2, 8.59072238304812250000e+000) (3, 3.07721237323837070000e+000) (4, -2.20737928401511990000e+001) (5, 6.48167752951130540000e+000) (6, 4.20271415707037330000e+001) (7, 2.22452538624961130000e+000) (8, -2.41362004050299430000e+001) (9, 1.53290233651212360000e-001) (10, 3.99809256979488620000e+001) (11, -8.45150161630556870000e+000) (12, -4.64535159872959440000e+001) (13, -2.18070329444672020000e+000) (14, -4.86957925572773310000e+000) (15, 2.00392694033346920000e+000) (16, 7.23203753477695840000e+001) (17, 5.97723519906764450000e-002) (18, 3.67009088772177920000e+001) (19, 4.47283379522161530000e+000) (0, 4.64887141382316490000e+002) (1, -7.02066777168387690000e+001) (2, -2.26418647852086710000e+002) (3, 5.14164899286955050000e+001) (4, -3.87932009378973020000e+002) (5, -4.87080520571274820000e+001) (6, 7.25748895852198760000e+002) (7, -1.50213326970793590000e+001) (8, -5.65002168945354130000e+002) (9, 1.23820880877146780000e+001) (10, 1.15054713463314690000e+003) (11, -2.23564345706381540000e+001) (12, -9.44430696683468110000e+002) (13, 2.36137159978310720000e+001) (14, -2.62773927326795100000e+002) (15, 3.71959987026356910000e+001) (16, -7.24503059853610410000e+001) (17, -3.81692624281810780000e+001) (18, 1.97221584128148580000e+002) (19, -4.08915562565373850000e+001) (0, -8.49110843488511900000e+001) (1, 3.76088090482710010000e+000) (2, -6.57996814377908200000e+000) (3, -2.14249725872211630000e+000) (4, -2.12255261466369620000e+001) (5, -1.60769366374526230000e+000) (6, -2.83758201132620970000e+002) (7, -8.67466862702396920000e+000) (8, -9.70909039901352600000e+001) (9, 8.68205233630923610000e-001) (10, -4.98569703788793960000e+001) (11, -8.03080237813446170000e-001) (12, 1.26860367500592370000e+001) (13, -7.95692297942015680000e-001) (14, 7.20242240693072800000e+001) (15, -1.83970095900350320000e+000) (16, 5.08277259192894770000e+001) (17, 6.58713941622574910000e-001) (18, -4.11190737914472000000e+001) (19, 3.48027308553852780000e+000) (20, -1.29911711953633340000e+000) (21, 9.29770684128304100000e-001) (22, -7.61651932491454350000e-001) (23, -6.72411836733341480000e-001) (24, 6.61675921718879010000e-001) (25, -1.43602503394340380000e+000) (26, -1.36837950677711230000e+000) (27, -1.96354345566476570000e-001) (20, 2.19234366601404020000e-002) (21, -1.54261754332308110000e+000) (22, 1.69022726645395240000e+000) (23, 1.61439671191676570000e+000) (24, -1.87354302172215190000e-001) (25, 7.59852096160402650000e-003) (26, -1.06840170050025930000e-001) (27, 1.71362388396780860000e+000) (20, 1.36688974788282280000e+000) (21, 2.98179916540036500000e-001) (22, -5.31921152773794040000e-001) (23, -5.10121390970784570000e-001) (24, -4.19477692313146690000e-001) (25, 1.37781240670074110000e+000) (26, 1.43090927693374790000e+000) (27, 1.40386151341988800000e+000) 

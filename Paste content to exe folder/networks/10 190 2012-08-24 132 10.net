FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.30691473925957810000e-001) (1, -2.46613868258073470000e-002) (2, -1.03837264960027160000e+000) (3, 5.62428981524347280000e-001) (4, 1.01632560368619060000e-001) (5, 4.79906309285254070000e-001) (6, -1.90709360393363840000e-001) (7, 4.61636571967727620000e-001) (8, 6.74697120518515940000e-001) (9, 3.71632793059428650000e-001) (10, 2.24244776854279270000e-001) (11, 8.95138275394084080000e-001) (12, 6.31905371833994200000e-001) (13, 3.58339335830090700000e-001) (14, -3.19876782925042900000e-002) (15, 6.30949621381141080000e-002) (16, -1.03048668104961430000e+000) (17, 5.43669346643063660000e-002) (18, 2.41706935317610700000e-001) (19, 9.40092692393981740000e-002) (0, -3.08828494428093860000e+000) (1, 2.40007832747999830000e-001) (2, 2.82273004472289560000e+000) (3, 3.23130503611112760000e-002) (4, 3.03251712118430830000e+000) (5, -1.36310657042445550000e-001) (6, -3.05208499256964230000e+000) (7, 1.20641375891176030000e-001) (8, -1.16463975086229120000e+000) (9, 4.03520186390880440000e-001) (10, 2.97449476016975190000e-001) (11, -1.13533247057580630000e+000) (12, -2.33741912973080000000e-001) (13, -4.65706654708404330000e-002) (14, -4.31729047539410330000e-001) (15, 1.85950990246203980000e-001) (16, 1.05819291998786150000e+000) (17, 2.15966789277461050000e-001) (18, -4.15441405161081690000e-001) (19, 3.72644037705883950000e-001) (0, -9.91302336398869440000e-001) (1, -3.68714986834162370000e-001) (2, 3.14914920300038670000e+000) (3, -1.18041862157723590000e+000) (4, 6.08449919247125330000e-001) (5, -1.03224471982145840000e+000) (6, -1.17598008306252530000e+000) (7, -7.88217148508846720000e-001) (8, -1.15595444799849510000e+000) (9, -5.33097387882778270000e-001) (10, -8.59662800528181450000e-002) (11, -7.19412215842948340000e-001) (12, -1.31437119840596360000e+000) (13, -5.29545141736095680000e-001) (14, 3.67218787566073070000e-001) (15, -1.62308464013587090000e-001) (16, 6.84326019519342690000e-001) (17, -2.03346302988748530000e-001) (18, -5.17316604020575600000e-002) (19, 1.82720234238098080000e-001) (0, -3.81821034798504930000e-001) (1, -2.40305796770834830000e-002) (2, 8.98613688227110910000e-002) (3, 1.89905671717908060000e-001) (4, -1.28938950858058240000e+000) (5, 2.29107907531560300000e-001) (6, 5.83135013132484610000e-001) (7, 3.28353498271563900000e-001) (8, 5.57469729546917090000e-001) (9, -4.07193740261066190000e-002) (10, 5.83904056112694250000e-001) (11, -3.54929821916365880000e-002) (12, 6.70479591158794850000e-001) (13, 6.67442550824098870000e-003) (14, 8.11603807856453590000e-002) (15, 2.84727463869390520000e-001) (16, 3.93707270441625570000e-001) (17, 1.40017287724697880000e-001) (18, 5.63774661281492890000e-001) (19, -3.66314773296008010000e-003) (0, 4.00355967817295970000e-002) (1, 1.34933209488231340000e-001) (2, 1.42127648726475450000e+000) (3, 1.48873538137466590000e-003) (4, 1.16788803715794790000e+000) (5, 1.45840866011397050000e-002) (6, -9.11407315677090770000e-001) (7, -3.80665511105865500000e-001) (8, -9.36480558238211190000e-001) (9, 1.45071149092423410000e-001) (10, -1.07707087075570310000e-002) (11, 4.09479644849879910000e-002) (12, -1.05285018887850380000e+000) (13, -4.98906599154879810000e-002) (14, 1.60745165424007100000e-001) (15, 7.20914116768156250000e-002) (16, 1.06649270348457660000e+000) (17, 1.01034283201848010000e-001) (18, -3.14041507201086300000e+000) (19, 1.27451499549333070000e-002) (0, -1.93824725196298680000e-001) (1, 9.99494894311069170000e-002) (2, -1.65751032953003330000e+000) (3, 3.29663846140861920000e-001) (4, -3.93057607231567910000e-001) (5, 1.38031834797620380000e-001) (6, 3.03563135346048230000e-001) (7, 2.18083791232643040000e-001) (8, 5.30455568988124740000e-001) (9, 1.93958531561473080000e-001) (10, 4.42836071209675770000e-001) (11, 1.17786530018249110000e-001) (12, 5.91759280839121220000e-001) (13, 9.85079718963412580000e-003) (14, 1.63472946394219140000e-001) (15, 1.62694359424154890000e-001) (16, -2.74810542883867470000e-001) (17, 3.81618174569331100000e-002) (18, 5.31139162748311080000e-001) (19, -9.35068990717362740000e-002) (20, 6.70881808215000990000e-001) (21, 2.11250363083636930000e-001) (22, 1.01591075530396190000e-001) (23, 3.65990768602948550000e-001) (24, -2.17308580290915820000e-001) (25, 1.29561548511887110000e-001) (26, 6.36720430752831800000e-001) (20, 4.81472998044563390000e-001) (21, -1.84758109199799490000e-001) (22, 1.67443962719262370000e-001) (23, -4.91421601464640590000e-001) (24, -1.55012533563683330000e-001) (25, -8.12659823372100240000e-002) (26, 7.11300625446926520000e-001) (20, 3.43497269087929940000e-001) (21, 3.45358040040646350000e-001) (22, 6.68663228441989780000e-001) (23, -2.40299288540002650000e-001) (24, 2.10000195065739910000e-001) (25, -4.48474414850556060000e-001) (26, 7.87768785562833030000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.43668610168686730000e+000) (1, 3.11074247891699020000e-001) (2, -6.33695660521110060000e+000) (3, -6.59797491949855490000e-001) (4, -4.69266972475046910000e+001) (5, 7.37439352328514320000e-001) (6, -7.31558602801435230000e+000) (7, 7.35965046664085460000e-001) (8, 3.77385894714811200000e+001) (9, 4.27578087476429610000e-001) (10, 6.07720979065254910000e-002) (11, 4.50025422655589260000e-001) (12, 4.03646004837593470000e+001) (13, -3.17847118190471360000e-002) (14, 1.54451038360269150000e+001) (15, -1.23802098188921880000e-001) (16, -1.89393301151690070000e+001) (17, 1.02892902177260530000e+000) (18, 2.65282036847029280000e-001) (19, 5.49522687555375030000e-001) (0, -2.43183621898641600000e+001) (1, 2.29806341160429020000e+000) (2, -2.89278242589401380000e+001) (3, 1.43683618207299620000e+000) (4, 1.90969097734920970000e+001) (5, 1.05005884039486050000e+000) (6, 3.23537038244913120000e+001) (7, 1.04605051033957670000e+000) (8, -7.75000826358485550000e+000) (9, 9.53475298726748080000e-001) (10, 1.15112590831398500000e+001) (11, 1.10178411879491870000e+000) (12, -1.31448949133362910000e+001) (13, 2.72692732797270190000e-001) (14, -1.34213518441588460000e-001) (15, -3.06049811159548100000e-001) (16, 1.98897232396381940000e+001) (17, 2.97857861604847620000e-001) (18, -1.50189631883216880000e+000) (19, -1.45809414419565430000e+000) (0, -1.64932160722317710000e+001) (1, 3.67151726030022220000e-002) (2, 2.05099591502480920000e+000) (3, 7.64704294713493440000e-001) (4, -2.21777575112794790000e+000) (5, 6.01878259380915210000e-001) (6, 6.79516756087796740000e+000) (7, 1.15297906219338620000e+000) (8, 7.61677220482534700000e+000) (9, -5.85606022745871700000e-001) (10, -8.39999232649625150000e+000) (11, 5.05298149749108580000e-001) (12, 7.45057823842265950000e+000) (13, 3.43929330135587660000e-002) (14, -1.49353000756673970000e+000) (15, -4.87860259951711890000e-001) (16, -8.15978708223365420000e+000) (17, 9.99120689807763810000e-001) (18, 2.59789699960157880000e+001) (19, 1.13116294269257580000e+000) (0, -1.81382631521172400000e+001) (1, 3.89820737298832600000e-001) (2, 2.98591430285671280000e+000) (3, -4.20569899365630740000e+000) (4, -1.29551693020304220000e+001) (5, -1.49872186902975390000e+000) (6, -4.99970996604943210000e+001) (7, -3.86348094534481050000e+000) (8, -4.93951889641041570000e+001) (9, 1.57324397981351870000e+000) (10, -2.79677604463556410000e+001) (11, -1.50724124355070450000e+000) (12, -4.79517459028872040000e+000) (13, -1.82361193092960420000e+000) (14, 1.76550268547124000000e+001) (15, -4.12401480496962790000e-001) (16, 7.23089391927963110000e+000) (17, -4.34498204039519550000e-001) (18, -6.36510337076735620000e+001) (19, -2.89879064279977140000e-002) (0, -5.68070912889805510000e+000) (1, 1.68028933307617970000e+000) (2, -1.90142174784930770000e+001) (3, 5.20225743574090210000e-002) (4, -1.16653122107931130000e+000) (5, 1.19176781306892530000e+000) (6, 1.33772751681838020000e+001) (7, 1.67717386493834790000e+000) (8, -2.31707125809439970000e-001) (9, 1.08324356257724790000e+000) (10, 1.93253443617418020000e+001) (11, -3.00862299817535760000e-001) (12, 6.37901952169688700000e-001) (13, 6.43578339731386230000e-001) (14, -3.58990032834329040000e+000) (15, 2.77918924145312940000e-001) (16, 6.01558427639923910000e+000) (17, 2.17062094422460300000e-001) (18, 2.22743358148404930000e-001) (19, 4.45495371746487120000e-001) (0, 9.11016626690284430000e+000) (1, -1.21256537459673820000e+000) (2, 6.08629836890163210000e+000) (3, -7.91140883265433300000e-001) (4, -2.22163892538799390000e+001) (5, -4.48794163879874530000e-001) (6, -7.66445272478976400000e+000) (7, 1.39641695045063660000e-001) (8, 2.82896073005355790000e+001) (9, -8.66313911756107720000e-001) (10, -1.18349103268200030000e+001) (11, -1.58200833097923770000e+000) (12, 1.69540683510403060000e+001) (13, 4.17634701225936380000e-001) (14, -1.60839832408337350000e+001) (15, 1.09424509873790730000e+000) (16, -2.87779547511052020000e+001) (17, 4.35412468971233200000e-001) (18, 2.74160521194285530000e+001) (19, 1.67081609434145760000e+000) (20, 4.58694313282653140000e-001) (21, 1.90810888716815660000e+000) (22, -8.01826574361221840000e-001) (23, -1.79338792548147750000e-001) (24, -1.13280696758577440000e+000) (25, 1.23075970397853070000e+000) (26, 9.49701976052984790000e-001) (20, 5.70883942915645040000e-001) (21, -1.37859896526738450000e+000) (22, -5.53051217200827060000e-001) (23, -1.08690908099440240000e+000) (24, 9.21911607290024640000e-001) (25, -1.46839036599913530000e+000) (26, 7.09761350565427770000e-001) (20, -8.79770575559436830000e-001) (21, -5.77746845434972680000e-001) (22, 1.42024743557165900000e+000) (23, 1.26260839877129370000e+000) (24, 2.76845555107382350000e-001) (25, 1.96817840700599540000e-001) (26, 5.88946498219660940000e-001) 

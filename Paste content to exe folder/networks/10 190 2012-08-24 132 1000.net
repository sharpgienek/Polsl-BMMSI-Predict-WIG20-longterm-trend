FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.00804584171133630000e+001) (1, -3.21723646973398230000e-001) (2, -3.51098116366532840000e+001) (3, -3.21679586301689650000e+000) (4, -1.06206209143120790000e+002) (5, -9.09289150316549280000e-002) (6, 1.71875693587885540000e+002) (7, 1.48005345207247350000e+000) (8, 4.37622889886774540000e+001) (9, 3.69130764894025050000e+000) (10, 6.71414408538015110000e+000) (11, 4.28852332919009260000e+000) (12, 7.32232871999235170000e+000) (13, 6.24372966621937930000e+000) (14, -5.34741733323963510000e+000) (15, 5.10399234842200510000e-001) (16, -1.14730076025961610000e+000) (17, -1.74687562200782380000e-001) (18, -3.68538537339184770000e+001) (19, 1.83905238516417820000e+000) (0, 1.14371472144635790000e+001) (1, -2.22658687838932550000e+000) (2, 7.17744493136197690000e+001) (3, 5.16929570299365700000e-001) (4, -7.93796773746294800000e+000) (5, -2.37424839471977730000e-001) (6, 1.90411600049460560000e+002) (7, 1.52429219044210720000e+000) (8, 2.35164634407429710000e+001) (9, -1.97589240670377860000e+000) (10, 5.17279780146472050000e+000) (11, 4.40106621789793430000e-001) (12, 4.85539723015467500000e+001) (13, 1.71498955122017030000e+000) (14, -2.82580153864334990000e+001) (15, 2.09320361426501120000e-001) (16, -1.21559102923203340000e+001) (17, -4.26320757695896780000e-001) (18, -2.43508979312588990000e+001) (19, 1.58947256030401010000e+000) (0, 5.14576511156887760000e+000) (1, 3.07513403244241260000e-001) (2, 6.12186404060813860000e+000) (3, -6.84613429386444480000e-002) (4, -2.04075993786491560000e+001) (5, 5.26709152682843570000e-001) (6, 3.22277887450972220000e+001) (7, 9.64483536562647380000e-002) (8, 1.73594595246455320000e-001) (9, 1.79549888492928990000e-001) (10, 1.45793128383846820000e+000) (11, 7.27312896723394830000e-001) (12, 4.42478748207405910000e+000) (13, 1.17487590776485670000e+000) (14, 5.92309889373432520000e+000) (15, -7.81337370861547860000e-001) (16, -1.67859569428643740000e+001) (17, -3.39527638421233290000e-001) (18, -1.98903221184708270000e+001) (19, 1.44995278049838540000e+000) (0, -1.21679147133553240000e+003) (1, -4.16895920783654290000e+001) (2, 3.60946305322560830000e+001) (3, -3.01031114187889610000e+002) (4, 1.50000000000000000000e+003) (5, 1.31477287918336230000e+001) (6, 1.38786564287070980000e+001) (7, 1.00048896520759630000e+001) (8, 9.14602378756723770000e+000) (9, 1.00096413626248520000e+002) (10, -5.69273074300476200000e+002) (11, -5.21909253313357770000e+001) (12, 8.44836671829938720000e+002) (13, -1.22837532622261910000e+000) (14, 3.83003887582473060000e+002) (15, 9.33437512866211700000e+001) (16, 9.28453484274703440000e+002) (17, -9.78886000489490730000e+000) (18, -4.39752244598288510000e+001) (19, 4.29732972789715430000e+001) (0, -4.85189634269990220000e+001) (1, 4.04092866514591090000e+000) (2, -1.59430494566585250000e+002) (3, 1.93352269498249750000e+000) (4, -3.23515186922353680000e+000) (5, -1.31486007940982260000e+000) (6, -4.08168139272777640000e+001) (7, 2.81296426379170180000e-001) (8, 1.21039182537852490000e+001) (9, 1.21643232232269870000e+000) (10, -1.56783634663572080000e+001) (11, 7.53828500241048860000e-002) (12, -2.33500916040577380000e+001) (13, -3.78062101563126700000e-001) (14, 2.59935280050321720000e+001) (15, 4.91028372880150050000e-001) (16, 4.15827418383681430000e+001) (17, 2.05681750600225930000e+000) (18, 8.14587393140280370000e+001) (19, -4.86594929952070100000e-001) (0, -1.00178125836780140000e+002) (1, -9.16192168823119780000e+000) (2, 3.18535858410611180000e+001) (3, -1.35463129977020740000e+001) (4, -4.70865050363554830000e+001) (5, -1.57362260396114060000e+001) (6, 6.32204453185231470000e+001) (7, -9.66240716266744570000e+000) (8, -5.72128324012332570000e+001) (9, -7.18016158290766880000e+000) (10, -1.31760007256649460000e+002) (11, -3.91181228055515360000e+000) (12, 5.04397785856344090000e-001) (13, 2.89941673140795650000e-004) (14, -4.66543486639812170000e+001) (15, 1.27099602514620270000e+000) (16, 8.26849035405380730000e+001) (17, 9.73014062998580950000e-001) (18, -4.22654381389449000000e+000) (19, -1.40617435861191510000e+000) (20, -4.17457653966777030000e-001) (21, 1.37962667096098700000e+000) (22, 2.92962920152458010000e-001) (23, 6.48958680302879510000e-001) (24, 1.30044512060756690000e+000) (25, -5.66179588547428560000e-001) (26, 5.36007942800460140000e-002) (20, 1.76310773066669730000e+000) (21, -7.69664818754927320000e-001) (22, -1.83503508039181610000e+000) (23, -7.52566245948188770000e-001) (24, -1.24688135080807090000e+000) (25, -8.16330688236373780000e-001) (26, 6.74570245442871590000e-001) (20, -1.26643384987051430000e+000) (21, -3.29678042796331730000e-001) (22, 1.51491440681510680000e+000) (23, 1.55799780475402850000e-001) (24, 5.15467234757760390000e-002) (25, 1.64281162139127420000e+000) (26, 1.86139278306762020000e+000) 

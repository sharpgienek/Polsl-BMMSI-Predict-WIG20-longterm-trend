FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.13877878820999110000e-001) (1, 1.50432091371404510000e-001) (2, 1.98188276622476560000e+001) (3, -4.91956555899432270000e-001) (4, 2.10700367277818400000e+001) (5, 7.07996187720219990000e-001) (6, -1.13716180721363590000e+001) (7, 1.80982770092524970000e+000) (8, -1.18287911691695520000e+001) (9, 1.53132086900386240000e-001) (10, -2.25694207982592720000e+000) (11, -1.80229675683739040000e-001) (12, -1.87044175019715590000e+001) (13, -1.28837644540457590000e+000) (14, 1.58524515971184610000e-001) (15, -1.33832539072425360000e+000) (16, -2.80640544684408260000e+001) (17, -5.15122605393464770000e-001) (18, 3.07234006427676660000e+000) (19, -1.36926593646142350000e-001) (0, 1.89243582385645450000e+000) (1, 8.10113000090710970000e-001) (2, -3.40933603509850800000e+001) (3, 6.42142694685771010000e-001) (4, 6.33372047473247330000e+001) (5, 8.50814952525682400000e-001) (6, -3.44560914003677500000e-001) (7, -7.30761254562704440000e-002) (8, 1.30706356644501540000e+000) (9, 2.86034784986030240000e-001) (10, 3.88627885343056610000e+000) (11, 5.59773527536987840000e-001) (12, -1.27426413997251590000e+001) (13, -2.24374972139979450000e-001) (14, -7.32049490486690240000e+000) (15, -3.06952800601107190000e-001) (16, -1.11946300730452620000e+001) (17, 6.62250963688975400000e-001) (18, 2.22560310755830880000e+001) (19, 7.65525722764504480000e-001) (0, 3.92033405743332740000e+000) (1, -2.22636328453284100000e-001) (2, -2.61805194677455260000e+001) (3, -1.42069075166972470000e+000) (4, 2.00695943501834580000e+001) (5, 1.04917702167465720000e+000) (6, 2.32424747697186760000e+001) (7, -3.21079585544928130000e+000) (8, 9.02582704215510390000e+000) (9, -5.39578653722541430000e-001) (10, 9.21686849015119590000e+000) (11, 8.69845529118569380000e-001) (12, 4.58256657491374400000e-001) (13, 2.30548613402911370000e+000) (14, -1.02727709166186520000e+000) (15, -7.74556442407729920000e-001) (16, 1.41304598143828630000e+001) (17, 1.81449112162556860000e+000) (18, 7.10971296945838120000e+000) (19, 3.69929152554617990000e-002) (0, -2.04888983704698650000e+001) (1, 1.08825784239494470000e+000) (2, -3.39222629241378120000e+001) (3, 2.64390041245805920000e+000) (4, -2.39531061133405740000e+001) (5, 2.50857548736325460000e+000) (6, -3.70014687323149540000e+001) (7, 2.23083648531702930000e+000) (8, 5.47149289078852520000e+001) (9, 1.01596704329559740000e+000) (10, 7.92752506943894360000e+000) (11, 2.71499367443399200000e+000) (12, 1.01690351736812130000e+001) (13, 1.08860967519871000000e+000) (14, -2.86509671391053140000e+000) (15, 1.13843337415936520000e-001) (16, -3.42521267391558550000e+001) (17, 1.18036193622818310000e-001) (18, 8.47901293011211800000e+000) (19, 1.19615672608845420000e+000) (0, 2.54160057756491900000e+001) (1, -7.18816889868077040000e-002) (2, -1.75871355272825870000e+001) (3, 1.17532103235687120000e+000) (4, 1.39554005154430050000e+001) (5, -7.62927977809761850000e-001) (6, -1.97138226650798320000e+001) (7, -9.50879029079255140000e-001) (8, -1.65226211726092730000e+000) (9, -5.28140711783020240000e-001) (10, -9.25633067602593050000e+000) (11, -9.29588077494905020000e-001) (12, 9.40522589319284740000e+000) (13, -2.21211299742149180000e-001) (14, -5.38048069651642360000e+000) (15, 6.67836275522789240000e-001) (16, 1.85310715517914690000e+000) (17, 4.43978788900034890000e-001) (18, 1.66319563267909310000e+001) (19, 2.39421326724377940000e-001) (0, 3.79105098424279420000e+001) (1, 6.02426244485068650000e-001) (2, -1.81092776742978150000e+001) (3, -1.45493204334935040000e-001) (4, 2.08996384080797420000e+001) (5, 5.94026474768670650000e-001) (6, -1.87113246721944380000e+000) (7, 4.10583386110596800000e-001) (8, 8.93610912948888550000e+000) (9, -8.40790023526171050000e-001) (10, 4.71048299331775410000e+000) (11, -1.75032166363064890000e+000) (12, 1.32757259969206910000e+001) (13, 5.25155684744310740000e-001) (14, -9.87595874520561080000e-001) (15, 3.89484340782668860000e-001) (16, 3.48664519273629690000e+000) (17, 2.25341533759305520000e+000) (18, 3.71515755010472970000e+001) (19, -1.25416176012684040000e+000) (0, -6.96986217482888860000e+001) (1, -1.42881300341794860000e-001) (2, 1.70636578054417920000e+001) (3, 2.72555117436232620000e-001) (4, -1.15741524444589320000e+001) (5, 5.75987220872486440000e-001) (6, -6.93146469596513270000e+001) (7, 6.34695756515907480000e-001) (8, 2.16814408448957470000e+001) (9, -8.75211597168928380000e-001) (10, -8.16553519150781600000e+000) (11, -1.53357439748139470000e+000) (12, 1.32961026641214410000e+000) (13, 3.23029259840347970000e-001) (14, -1.15487030350356910000e+001) (15, 2.57296256411830350000e-001) (16, -4.80090569310070240000e+000) (17, 7.68295428091568370000e-001) (18, 1.49859425495208660000e+001) (19, -1.15986848572052480000e+000) (20, -1.72592720534819400000e+000) (21, 1.27135524625556710000e+000) (22, -1.24317144996120650000e+000) (23, 8.59161490847689390000e-002) (24, -1.98245276916867550000e+000) (25, 8.36525650208451150000e-001) (26, 2.66103528294107310000e-002) (27, 4.50370175900972060000e-002) (20, 1.20239340230644310000e+000) (21, -1.35027118170921740000e+000) (22, 7.70815141556061900000e-001) (23, 1.16688560641767620000e+000) (24, 9.81543947345741800000e-001) (25, 1.07176768151350900000e-001) (26, -6.77123096039252250000e-001) (27, 5.35743012070078350000e-001) (20, 4.17953539063394890000e-001) (21, 2.22030491327437850000e-001) (22, 3.34547693221324330000e-001) (23, -1.39601141451514080000e+000) (24, 7.31752280888189000000e-001) (25, -7.54073900493545170000e-001) (26, 6.65320166944304290000e-001) (27, 1.80300895448829370000e+000) 

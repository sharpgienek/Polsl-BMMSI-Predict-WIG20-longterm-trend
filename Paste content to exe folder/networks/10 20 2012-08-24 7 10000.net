FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 4 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.80507678373494900000e+001) (1, -1.12857568574404000000e-001) (2, -3.28233535703653740000e+000) (3, -7.92474511538568740000e-001) (4, 7.53056910848434930000e+000) (5, -6.93804276300558610000e+000) (6, -6.05398281370732150000e+001) (7, -8.54377307209486240000e-002) (8, 7.67660099085283100000e-001) (9, 3.54594330521509240000e-001) (10, -7.24008512671010040000e+001) (11, 2.23819746381145010000e+000) (12, 3.80598633936004570000e+000) (13, 8.73626794961728010000e-001) (14, -2.80876894393265030000e+001) (15, -1.30290286236380280000e+000) (16, 5.90825154055383720000e+000) (17, 2.99437662352613950000e+000) (18, 3.47471412132468270000e+001) (19, 3.02693792623445530000e-001) (0, 1.50000000000000000000e+003) (1, 2.05173958656910390000e+000) (2, -1.92690707251260580000e+000) (3, -2.02967313999532270000e+000) (4, 2.68980674024682740000e+002) (5, -8.03910835934946100000e+000) (6, 2.77995020716789050000e+001) (7, -8.03667960631759490000e-001) (8, -6.29476013316108490000e+002) (9, 2.89531949697259460000e+001) (10, 7.43786465899541160000e+001) (11, -2.89478629837432780000e-001) (12, -1.35468255224606420000e+001) (13, -3.53528036299096020000e+000) (14, -2.33285259120578620000e+002) (15, 1.89741055371899780000e+001) (16, 2.52659743153490920000e+002) (17, -3.80784766252494800000e+000) (18, -4.48380500590863280000e+001) (19, 6.44800573533464580000e+000) (0, -1.19268879650859690000e+001) (1, 8.33064393935552260000e-002) (2, 2.89260187256476840000e+000) (3, 2.19030543662828920000e-001) (4, -5.17306300665896760000e+000) (5, 4.37490496518760100000e-001) (6, 1.08136841344351940000e+001) (7, 3.87676209946191620000e-001) (8, 2.51124446458213720000e+000) (9, 4.56538238954693420000e-001) (10, 2.56457994716882040000e+000) (11, 1.03477709079380990000e+000) (12, 1.15486860101140620000e+001) (13, 2.18126878315270000000e-001) (14, -2.66937093514575170000e+000) (15, 1.78213290061865680000e-001) (16, -2.50295075897331380000e+000) (17, 1.25780198397745860000e+000) (18, 2.79171381985317420000e+001) (19, -2.20623871194668020000e+000) (20, 6.74950877662859390000e-004) (21, -3.41101551847661930000e+000) (22, -1.08871239085290930000e-002) (23, 3.40326354748745530000e+000) (20, -4.87765420753865530000e+000) (21, 3.41927342158894640000e+000) (22, 5.61520365734711470000e+000) (23, 2.41632035401580620000e+000) (20, 5.06195092511577100000e+000) (21, -1.20640180316739600000e+000) (22, -7.42423664662082050000e+000) (23, 1.17769693822277090000e+000) 

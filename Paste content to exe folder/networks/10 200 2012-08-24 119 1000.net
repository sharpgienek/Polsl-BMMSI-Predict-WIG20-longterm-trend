FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.48343575609911080000e+001) (1, 9.74470901133174360000e-001) (2, -4.17753485195776620000e+001) (3, 1.01401654833976500000e+000) (4, 5.93218628026773160000e-001) (5, 2.38267141073496140000e+000) (6, -3.44592599371952790000e+000) (7, 1.07425264444048300000e+000) (8, 2.33463216076694270000e+001) (9, 1.95871245844960990000e-001) (10, -1.02909764113962350000e+001) (11, 3.46145475264700690000e-001) (12, -2.13348929361163810000e+000) (13, 9.09585266656115640000e-002) (14, 2.16165919721873050000e+001) (15, 3.08290968941581530000e-001) (16, 2.64144435536179890000e+001) (17, 3.64512529393987210000e-001) (18, 1.53096125907815920000e+001) (19, 2.23313240941300340000e+000) (0, -2.16277093210058810000e+002) (1, 1.56718529747610540000e+001) (2, -1.19101584924666400000e+002) (3, 8.70111200001343300000e+000) (4, -1.86775966737999330000e+001) (5, 5.98770403735854200000e+000) (6, 7.94881525243425100000e+001) (7, 6.02628809716751230000e+000) (8, 2.75687643343309790000e+001) (9, 6.27809956213033260000e+000) (10, 2.26027742474036670000e+002) (11, 1.99856545845759470000e+001) (12, 5.68975685245443970000e+001) (13, 8.76813718119169080000e-001) (14, -1.07271810381671300000e+002) (15, -1.65354876541464810000e+000) (16, 1.36163191501862120000e+002) (17, -1.13204836624782450000e+000) (18, -3.93659092464346680000e+001) (19, -1.21727603396308110000e+001) (0, 2.34548770284348900000e+001) (1, -4.50983207119847500000e+000) (2, 1.30585163117723650000e+002) (3, -1.82806597237008590000e-001) (4, -3.17713312336498710000e+001) (5, -2.03132589734229540000e+000) (6, -6.28917229188091010000e+001) (7, -2.82547221970663400000e-001) (8, 6.17048495043600270000e+001) (9, 1.40017518806134070000e+000) (10, -4.54797567148909250000e+001) (11, -6.99548787554769190000e+000) (12, -8.32735921791586440000e+000) (13, -6.41131634889794740000e-001) (14, -1.82782300016815360000e+001) (15, 9.68341527210085220000e+000) (16, -4.30177489158674720000e+001) (17, 1.49750069049475830000e+000) (18, 2.77948903224712820000e+001) (19, 1.01859250796032550000e+001) (0, 5.09876081850719490000e+000) (1, 8.28978823447871170000e+000) (2, -2.28772911419907710000e+001) (3, 2.38302112161713250000e+001) (4, -1.24758841805321430000e+001) (5, 2.61161032038399980000e+001) (6, 8.40990726622309240000e+001) (7, 1.73463324896790920000e+001) (8, 2.75141868040031400000e+002) (9, 1.05907772471581950000e+001) (10, 1.59733366880406550000e+002) (11, 5.04053484865642170000e+000) (12, 8.74513785888977680000e+001) (13, 8.05003093369075610000e-001) (14, 1.02111046639221670000e+002) (15, -3.82365759526944600000e-002) (16, 8.08913649138220170000e+001) (17, 2.28253210026602550000e+000) (18, 8.06683596570110100000e+001) (19, 2.00006276293047320000e+000) (0, 2.16935214800098180000e+002) (1, -7.26379664928937530000e+000) (2, 6.46669327316661080000e+001) (3, -3.21211933616220690000e+000) (4, -1.20549528954752200000e-001) (5, -3.89199859810226780000e+000) (6, 7.51478431564733000000e+001) (7, -6.54189421701575010000e-001) (8, 5.21725511798893540000e+001) (9, 6.11093587237189210000e-001) (10, -1.83359337369745360000e+002) (11, -1.01007644167700640000e+001) (12, -2.50542069552019700000e+001) (13, 3.19402291936638560000e+000) (14, 4.34669699905618570000e+001) (15, 1.01436045771218310000e+001) (16, -1.02112876659441380000e+002) (17, 4.46199644238170560000e+000) (18, 5.54172221409392450000e+001) (19, 7.28614906834670960000e+000) (20, 1.50661735403188780000e-001) (21, 1.75247453155595620000e+000) (22, -2.52534226511782030000e-001) (23, 9.78577132070393570000e-002) (24, 1.87827953393373700000e+000) (25, 1.42129225305374560000e-001) (20, -1.57056978427114840000e+000) (21, -7.31136449417024050000e-001) (22, -6.50953565044259940000e-001) (23, 1.41495598193844210000e+000) (24, -2.45152329232552590000e-001) (25, 1.55554697199712070000e+000) (20, 1.75664318840271670000e+000) (21, -3.94105217151748180000e-001) (22, 9.55239925014855550000e-001) (23, -2.10540970367773990000e+000) (24, -1.00661518644629600000e+000) (25, 8.06846205897013500000e-001) 

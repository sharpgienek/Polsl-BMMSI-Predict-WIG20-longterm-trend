FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.28822154359244400000e+000) (1, -4.54694248070320740000e-002) (2, 8.59268941790014780000e-001) (3, -9.72491375842268610000e-002) (4, -7.06891517453352850000e-002) (5, -3.02060648307505420000e-002) (6, -1.28067002841296280000e+000) (7, 2.78521094886689110000e-002) (8, 2.19947197543365610000e-001) (9, 3.27769225503343890000e-002) (10, 7.95449128539865050000e-001) (11, -1.87050164312991430000e-001) (12, -1.91045643238078990000e-001) (13, -1.47007540728028800000e-001) (14, 3.93826021052335380000e-001) (15, -1.49778832161231720000e-001) (16, 9.01953040769229660000e-001) (17, -1.35246037472932790000e-001) (18, 1.96296252598352510000e-001) (19, 8.08892560042453330000e-003) (0, 3.09947879210398990000e+000) (1, 2.99342140791668540000e-002) (2, -3.05940310791306570000e+000) (3, 8.11786824839680450000e-001) (4, 3.22350546400405750000e-002) (5, 1.09991437164082250000e-001) (6, 3.07555301049746800000e+000) (7, 4.95997986568788020000e-002) (8, 1.41885606801253110000e+000) (9, -2.73943540077559170000e-003) (10, 1.32253820751099540000e-001) (11, 8.19064779559453230000e-001) (12, 1.36537095979366590000e+000) (13, 3.67654984291657940000e-001) (14, 5.68130094427563350000e-001) (15, -2.11711234601432350000e-001) (16, -1.35505650985282890000e+000) (17, -2.60251089435448830000e-001) (18, 2.08120646328501110000e+000) (19, 2.65051587043749760000e-001) (0, 1.96011881499628960000e+000) (1, 2.50339280244931850000e-001) (2, 3.05723025631818770000e+000) (3, -3.24469700168885520000e-002) (4, 3.12961379961034740000e-001) (5, 1.10051868344306400000e-001) (6, -5.65052244312090560000e-001) (7, -3.61180329988382980000e-002) (8, -4.41721577168294520000e-001) (9, 3.44784763585875010000e-001) (10, -5.00391208760428090000e-001) (11, 4.89983436967411090000e-002) (12, -6.03185461768269980000e-002) (13, 3.04013597450991490000e-001) (14, -2.67487156109873780000e-002) (15, 1.60717108285674760000e-001) (16, -4.99242589125650370000e-002) (17, 2.00668869348535030000e-001) (18, -1.52946308957352330000e+000) (19, 6.72769314809289250000e-001) (0, 1.32667467015454620000e+000) (1, 1.26660596165193820000e-001) (2, -3.18976810009003040000e+000) (3, 4.68069526542806370000e-001) (4, -9.18823087271969370000e-001) (5, 5.02986754002200390000e-001) (6, 1.13365952102290320000e+000) (7, 8.49300172700156340000e-001) (8, 1.07538315296701770000e+000) (9, 9.35254517595811020000e-002) (10, -6.24330739602661710000e-002) (11, 6.51920411779961740000e-001) (12, 1.13665024372371850000e+000) (13, 2.26027614402468490000e-001) (14, 8.24166846807766420000e-001) (15, 1.92656084860087670000e-001) (16, -3.04448611550328520000e+000) (17, 3.46980752648902660000e-001) (18, 3.02881628404249650000e-001) (19, 2.07814490809538790000e-001) (0, -9.08795010950664390000e-001) (1, 2.54093532190524800000e-002) (2, -1.10361923260377150000e+000) (3, 1.02933595127428100000e-001) (4, -9.66973722755094740000e-001) (5, 1.73775452564892190000e-001) (6, 1.07853256707644760000e+000) (7, 9.12672784406348800000e-001) (8, 1.20991074286226000000e+000) (9, 2.20758482068397650000e-001) (10, 1.12604233340939830000e+000) (11, 1.22184083695532730000e-001) (12, 5.83252766889589050000e-001) (13, 7.36672372694503890000e-002) (14, 3.74782839140803010000e-001) (15, 8.39801961975888520000e-001) (16, 3.15324466204578880000e+000) (17, 5.70966500009951750000e-001) (18, 1.06186996917190560000e+000) (19, -6.07537733347499280000e-001) (0, -1.00697914103671900000e+000) (1, 3.23068696480063700000e-001) (2, 4.70144792084631610000e-001) (3, 2.58657510288323570000e-001) (4, 1.69296080744452520000e-001) (5, -1.31569694390553990000e+000) (6, -3.09680545222040400000e+000) (7, 1.62704139717881970000e-001) (8, 4.13636583779937340000e-001) (9, -5.69034711796499170000e-002) (10, 7.44551331316665400000e-001) (11, -2.76586142279720780000e-001) (12, -8.15154245982849470000e-001) (13, 9.65787945046305410000e-002) (14, -7.06171370060779680000e-001) (15, 8.72200871557048120000e-002) (16, 1.51094979449393580000e+000) (17, 4.26649627877547010000e-001) (18, -3.22909781775386040000e-001) (19, 1.15799184648220320000e-001) (20, 3.70050587663689700000e-001) (21, 3.74848414605147730000e-001) (22, 3.32201094168321500000e-001) (23, -1.06177728709182590000e-003) (24, 8.01584310548973940000e-001) (25, -5.52643410359033030000e-002) (26, 4.13988204762044400000e-001) (20, 1.97397818680135730000e-001) (21, 5.78565972142731640000e-001) (22, 4.95712500209873400000e-001) (23, 9.26768257866624890000e-002) (24, 3.04392760311257420000e-002) (25, -1.87239219830059840000e-001) (26, 3.57644871199380540000e-001) (20, 4.46842295312798570000e-001) (21, -7.69538066175920880000e-002) (22, 4.13176437171823120000e-001) (23, -1.16005241379339580000e-001) (24, -1.13130513947588730000e-001) (25, 2.24146746580417590000e-002) (26, 4.94765720705715170000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.22235973939053720000e+002) (1, 1.11406363312663400000e+002) (2, -3.70374693047151420000e+002) (3, 2.48655321627255890000e+002) (4, 3.88959467204267700000e+002) (5, 2.33858072188873390000e+002) (6, -7.41900257099383110000e+002) (7, 1.61223649608363300000e+002) (8, 1.50000000000000000000e+003) (9, 1.10435817733517980000e+002) (10, 1.29777926029641800000e+003) (11, 1.32192195629408560000e+002) (12, 9.11374041267154890000e+002) (13, 9.23782971836786440000e+000) (14, 1.50000000000000000000e+003) (15, -2.70606163789384870000e+001) (16, 6.03439840620646560000e+001) (17, -2.97670523147757710000e+001) (18, 6.36852516642712090000e+002) (19, 2.25083334077921150000e+001) (0, 1.40580745755979000000e+001) (1, 6.88659286853350050000e+000) (2, 8.32350828210055480000e+001) (3, 2.77725930746972520000e+000) (4, 4.73292896977229920000e+001) (5, 1.64848460561892270000e+001) (6, -8.58526452578806670000e+001) (7, -1.56993673364338200000e+000) (8, -5.62945447316084180000e+001) (9, 9.52555535807285910000e+000) (10, 6.87340684197520490000e+001) (11, 7.27754123999266330000e+000) (12, 8.04871551512471940000e+001) (13, 5.95295891021530820000e+000) (14, 2.26197258734915680000e+001) (15, 8.92122588622782510000e+000) (16, -3.95769377056792420000e+001) (17, 2.65551339453728690000e+000) (18, 4.94290142790757440000e+001) (19, -6.43158564271367530000e+000) (0, 4.22494929977903150000e+002) (1, 1.26072355435474360000e+002) (2, 1.50000000000000000000e+003) (3, -1.13512508845603600000e+000) (4, 1.50000000000000000000e+003) (5, -1.14185229120303550000e+001) (6, -1.17771289898561560000e+002) (7, -9.28452132189362620000e+000) (8, -4.07786179151793530000e+002) (9, 8.63340444173501710000e+001) (10, 1.17205182837616230000e+003) (11, 1.47169964461177840000e+002) (12, 4.21300923980454400000e+002) (13, 8.57352657628875820000e+000) (14, -1.13229431977488870000e+003) (15, 1.59617334077598500000e+001) (16, -7.81525669633133700000e+002) (17, 2.74434375081616400000e+001) (18, 9.19527854316014550000e+002) (19, -1.93714534008739610000e+001) (0, -1.95140838739960780000e+001) (1, 3.99306136981668390000e+000) (2, 1.54876182883013770000e+002) (3, 2.33183154652731250000e+000) (4, 1.29219066299119960000e+002) (5, -7.67835373705096820000e+000) (6, -2.17863134595799860000e+002) (7, -2.70361836946287410000e+000) (8, -1.45839803652256820000e+002) (9, -4.40627429346734800000e+000) (10, -9.67349740589443460000e+001) (11, 1.30367942417947510000e+000) (12, -1.60603159260648820000e+002) (13, -1.30637855039849970000e+001) (14, -2.12884138408167490000e+000) (15, -2.31933305619097150000e+001) (16, -1.15882932293015430000e+002) (17, -8.22233456308290120000e+000) (18, -9.72607945337623510000e+001) (19, 1.38106024825547400000e+001) (0, -8.38828584753680840000e+002) (1, -1.02258560271212100000e+001) (2, -3.96327539532342480000e+002) (3, 2.52582774080534340000e+001) (4, 6.60374796993160540000e+002) (5, -4.38825742469472370000e-001) (6, -1.50000000000000000000e+003) (7, 8.86274314576254770000e+001) (8, 9.16720219457398460000e+002) (9, -1.88729517614973580000e+001) (10, 9.82326552220029270000e+002) (11, 1.18718169218229650000e+001) (12, 4.27437017181854860000e+002) (13, -8.85585304044713130000e+001) (14, 8.38051964320914980000e+002) (15, -7.17906705242261010000e+001) (16, -1.50000000000000000000e+003) (17, 8.45154860863805090000e+000) (18, -5.43730704236819860000e+002) (19, 1.82561630013391860000e+001) (0, -1.58567255895015810000e+001) (1, -5.59076680071519760000e+000) (2, -1.37709630800912810000e+002) (3, -2.53914619121416640000e+000) (4, 9.04266015004356840000e+000) (5, -1.26150003572207280000e+001) (6, 4.05082418936420560000e+000) (7, 6.28676835838129570000e+000) (8, 7.01406204402848200000e+001) (9, -4.69553477190998510000e+000) (10, 1.55448928427588900000e+002) (11, 1.30575267869610600000e+000) (12, 8.33687586478464200000e+001) (13, -3.54920217250688500000e+000) (14, -1.12288868487052850000e+002) (15, -7.54296065685985350000e+000) (16, -1.66939716308339370000e+002) (17, 3.15059989652296050000e+000) (18, -1.42169434828472630000e+001) (19, -2.99915830775435180000e+000) (20, 1.13406035825885200000e+000) (21, -1.41258402015945390000e+000) (22, 1.14319551402477160000e+000) (23, -1.14939433030892870000e+000) (24, 1.15148212640375030000e-001) (25, -4.12228749526586840000e-001) (26, 9.82068597406330210000e-002) (20, 1.20831312862998820000e-001) (21, 2.15159443149986050000e+000) (22, -1.48772504178150780000e+000) (23, 1.42554142641343940000e+000) (24, -1.39431056095774110000e+000) (25, 2.08356239524418860000e+000) (26, 1.33165656009262360000e+000) (20, -1.57775262374756250000e+000) (21, -3.81541968116858100000e-002) (22, -5.83137440363741280000e-003) (23, -3.75985885984277750000e-002) (24, 1.19908475001929200000e+000) (25, -1.21214596056977640000e+000) (26, 1.59691036738920930000e+000) 

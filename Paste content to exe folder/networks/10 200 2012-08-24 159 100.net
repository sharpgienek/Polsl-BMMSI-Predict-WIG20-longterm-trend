FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.23386454075223730000e+001) (1, 1.01034302037664100000e+000) (2, -1.16211050690484750000e+001) (3, 2.03874974713468630000e+000) (4, -3.43645437474845930000e+000) (5, 1.42340267463052660000e+000) (6, 2.53991075430773080000e+000) (7, 3.81931755599209390000e-001) (8, 1.81583294133932930000e+001) (9, 1.40022420133908980000e+000) (10, 1.22493166687669320000e-001) (11, 3.51968529655933130000e+000) (12, 1.61645411210165900000e+001) (13, 3.22018683494632360000e+000) (14, -7.40119921893776040000e+000) (15, 4.33411080518590510000e-001) (16, 1.15854491200095140000e+001) (17, -3.43427052169748060000e-001) (18, 1.59051677815657030000e+001) (19, -4.78417606174208200000e-002) (0, -2.16287927526270560000e+001) (1, 3.37777167133920480000e-001) (2, -1.65653202493859770000e+001) (3, 1.30531269238294390000e+000) (4, -3.10000513050044620000e+001) (5, 2.83720902045114910000e-001) (6, 7.52461289331843310000e-001) (7, -6.14288301572130930000e-004) (8, 6.26613558311858580000e+001) (9, 9.48560924642758290000e-002) (10, 2.01115816860470670000e+001) (11, -9.52692655170872950000e-002) (12, 1.91983585948540880000e+001) (13, 7.06796023699174820000e-001) (14, 1.67916884704251320000e+000) (15, 2.51479502084239570000e+000) (16, 5.77695545563508620000e+001) (17, 1.72191974592947020000e-001) (18, -1.71516874070081520000e+000) (19, 1.81448725113377700000e-001) (0, -2.27417734133877760000e+000) (1, 5.97211424147992780000e-001) (2, 2.79985959970995250000e+000) (3, 1.13740280778762710000e-001) (4, 1.43322008444529450000e+000) (5, 4.96211349030653890000e-001) (6, 4.86601992233189050000e+000) (7, 2.65521830382749570000e-001) (8, 9.80399986973969640000e+000) (9, 2.46454518743726230000e-001) (10, 2.41720264045296500000e+000) (11, 8.62498653584413410000e-002) (12, 4.53588128360288150000e+000) (13, 1.88442252879849730000e-001) (14, -1.81662233159735380000e+000) (15, 1.17032118088984190000e-001) (16, 9.04478855599224120000e+000) (17, 3.02245534447928620000e-001) (18, 7.09337328119537510000e+000) (19, 1.63236570752451280000e+000) (0, -6.25598336802718920000e-001) (1, -8.36578644057442200000e-001) (2, 5.82580563495476780000e+000) (3, 3.80567813608458160000e-002) (4, 1.15704330069369810000e-001) (5, -1.75957296857097630000e-001) (6, -9.37628272800704820000e+000) (7, 4.23417372813964940000e-002) (8, 2.89033801553448550000e+000) (9, -2.65177496245820150000e-001) (10, -1.66856800716033500000e+000) (11, 3.34125648955897190000e-001) (12, -6.25613719938279280000e+000) (13, 7.91915623163861600000e-002) (14, 3.69694787834952090000e+000) (15, 2.70693874379865080000e-001) (16, -2.92243525205403380000e+000) (17, -4.63523672759118100000e-001) (18, -3.78491005677407430000e+000) (19, 4.30516083341404010000e-001) (0, 8.69780061983587150000e-001) (1, -9.29365873343335200000e-001) (2, -2.65168703203105770000e+000) (3, 3.09186415697061470000e-002) (4, 1.06295188290000480000e+001) (5, -1.66963814366391210000e+000) (6, -3.44341391825752230000e+001) (7, 8.22234668901871470000e-001) (8, 1.55942856467521320000e+001) (9, 7.44712038547234450000e-001) (10, 3.04125464832598310000e+001) (11, 5.32402176305358470000e-001) (12, -7.10607410055176470000e+000) (13, -1.03935482050156010000e-001) (14, 2.35232885751995480000e+001) (15, 2.51192820002963830000e+000) (16, -1.66138241827392360000e+001) (17, -3.90946296862034250000e-001) (18, -1.66350090808605880000e+000) (19, -9.81241676497315640000e-001) (0, -1.15904550246988730000e+001) (1, 2.05694393464952840000e+000) (2, 4.89082686656287620000e+000) (3, -3.25979623929301630000e-001) (4, 4.41883372941089100000e+000) (5, -1.86544479736601660000e+000) (6, -7.22706992358305770000e+001) (7, -5.74994136732814080000e-001) (8, 1.54288995383898260000e+000) (9, 1.66897145678784460000e+000) (10, -6.90164659544460870000e+000) (11, -4.35788662517231920000e-001) (12, 3.88782201283200960000e-001) (13, -6.11089516199080850000e-002) (14, 1.86213082440692900000e+000) (15, 2.88210633112041490000e+000) (16, 1.42003591514093250000e+001) (17, 5.00248258142200200000e-001) (18, 1.26860171961960550000e+001) (19, 1.40460092503152110000e-001) (0, -1.97048417423888650000e+001) (1, 4.71102910557495760000e+000) (2, 1.26546164024573410000e+001) (3, 7.59140272349300150000e-002) (4, 2.58350559657406760000e+001) (5, -6.43945100380076130000e-001) (6, -2.90713669256860640000e+001) (7, -3.44853763192970510000e-001) (8, 9.00041064914344440000e-001) (9, 1.51064856823573000000e+000) (10, -3.90463336891812030000e+001) (11, -1.45747289965466380000e-001) (12, -1.52791348934844290000e+001) (13, 4.23895820913185280000e-001) (14, 3.39041525628474890000e+000) (15, 1.27768968993517750000e+000) (16, 1.65124844316377090000e+001) (17, 1.70958246273044120000e+000) (18, 4.40133445933188910000e+001) (19, 2.18731991143225320000e+000) (20, 2.31930985476329980000e-001) (21, 6.71602986699243230000e-001) (22, 3.26656537435628720000e-001) (23, -1.44521968559012760000e+000) (24, 1.21369915521262460000e+000) (25, -1.36677314218287240000e+000) (26, 9.29012256572262050000e-001) (27, 5.23422044530887300000e-002) (20, 7.25254258266734400000e-001) (21, -9.02315422332769400000e-001) (22, 1.06030826931252880000e+000) (23, 1.84777420615243770000e-001) (24, -2.59101445506612960000e-001) (25, 6.56777596804974830000e-001) (26, -1.34192722195206660000e+000) (27, 5.01005428379097670000e-001) (20, -1.08490133978985840000e+000) (21, 5.95618078493224610000e-002) (22, 4.09810180915733010000e-001) (23, 1.52479121401206140000e+000) (24, -8.18252153103605110000e-001) (25, 6.33224124385283970000e-001) (26, 3.09372101898429060000e-001) (27, 5.85417291708985270000e-001) 

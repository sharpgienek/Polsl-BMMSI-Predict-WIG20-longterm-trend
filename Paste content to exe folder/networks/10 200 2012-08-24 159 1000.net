FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.39916361276902420000e+001) (1, 5.31049145167096980000e+000) (2, -9.34390639962437750000e+001) (3, 8.63037247357111600000e+000) (4, -6.19921424333207010000e+001) (5, -2.04537009800680720000e+000) (6, 2.19295455804747520000e+001) (7, 2.54006186296053650000e+000) (8, 2.11885050198056150000e+002) (9, -3.47428777517436590000e+000) (10, -1.45316388759243610000e+002) (11, 6.21024959321203520000e+000) (12, -1.00705435143678610000e+002) (13, -5.53068620417942820000e+000) (14, 1.98140302856771700000e+001) (15, 6.75951280949327770000e-001) (16, -8.64087288982696440000e+001) (17, -8.59355087517223890000e-001) (18, -8.84535636675232870000e+000) (19, 1.33642213093905010000e+001) (0, 2.40828274563795160000e+002) (1, 1.17623847495007470000e+001) (2, 1.04935506803127440000e+002) (3, 2.05877127912799680000e+000) (4, -1.69935820374566190000e+002) (5, -7.66418207618043910000e+000) (6, -3.53746497299416260000e+002) (7, -1.68730096448757510000e+001) (8, 2.05573722486045170000e+002) (9, 4.27608188829111600000e+001) (10, -4.60042344143006740000e+002) (11, -8.99486491504256640000e-001) (12, -1.54713690102460190000e+002) (13, 2.72343536514352410000e+000) (14, 8.56521642670865190000e+001) (15, 9.43615844462653360000e+000) (16, -2.15185713532667340000e+002) (17, -5.57705850369526420000e+000) (18, -2.31124891078848610000e+002) (19, -4.56762762735219410000e+000) (0, 1.62731824908984280000e+001) (1, 3.39830484957949070000e+000) (2, 5.30747049441941950000e+001) (3, 1.68285397596266880000e+000) (4, 1.07456971530943720000e+002) (5, 1.89214133534751270000e+000) (6, -4.20157274970254310000e+001) (7, -6.71347557869493850000e-001) (8, -9.24752230831643090000e+001) (9, -1.85298741022793910000e+000) (10, 2.53018199293581720000e+002) (11, 4.73782023669798050000e-001) (12, 4.65204375057074200000e+001) (13, -3.88360416055917180000e+000) (14, 7.69967176831875830000e+001) (15, -3.41299938752133600000e+000) (16, -5.43176462331560190000e+001) (17, -2.20806568531957570000e+000) (18, -1.74972048611191040000e+002) (19, -5.70027674848090360000e-001) (0, -2.66695650864051960000e+001) (1, 7.37024793061579330000e+000) (2, 2.10737377562817040000e+002) (3, 5.81875828741824550000e+000) (4, 4.36735689733413320000e+000) (5, -2.86819154813440050000e+000) (6, 1.42356799585770570000e+002) (7, 5.79328590518054560000e+000) (8, 1.21226492551609970000e+002) (9, 1.11169214221216970000e+000) (10, 6.26523780302420760000e+001) (11, -1.24899681529833570000e+000) (12, -4.94318639089195600000e+001) (13, 3.49402175145082290000e+000) (14, 1.59303712108372310000e+002) (15, 1.46858056499384880000e+000) (16, 4.01569265516205500000e+001) (17, -1.47327821392945310000e-002) (18, -3.64450887770328150000e+001) (19, -6.73967960758982980000e+000) (0, -9.18447153954732300000e+001) (1, 5.87375883869759470000e-001) (2, 3.58964151872238800000e+001) (3, 9.50100491927689860000e-001) (4, -1.44598100374578510000e+002) (5, 2.94539930742696520000e-001) (6, -6.01412955463282370000e+001) (7, 4.43147340363398530000e+000) (8, 4.82384730954064410000e+001) (9, 1.32426512812161510000e+000) (10, -1.22023761097210450000e+002) (11, -3.34443916402721180000e+000) (12, -6.63658412414656030000e+001) (13, 1.07206347414569800000e+001) (14, -1.32317457017365030000e+002) (15, 1.34160144192151330000e-001) (16, 5.72662051872272150000e-001) (17, 1.82826578960470540000e+000) (18, 1.12176996758378850000e+002) (19, 4.81032491777473580000e+000) (0, -5.87962247384305030000e+001) (1, 3.18953228303045620000e+000) (2, -6.44687277722551360000e+001) (3, 3.08432814140584280000e+000) (4, -6.91775109866495650000e+001) (5, 4.44051932601681010000e+000) (6, -7.53199902457842260000e+001) (7, 1.83188352323934380000e+000) (8, 1.02063826591453140000e+002) (9, 2.89107561802032010000e-001) (10, -1.99412627238592250000e+001) (11, 1.41206689316301180000e+000) (12, 4.69069635053833610000e+000) (13, -1.48241383851227940000e+000) (14, -4.54690965735264430000e+001) (15, -5.67908776050135460000e-001) (16, -7.14751292416272150000e+001) (17, 2.41621754237318100000e-001) (18, 4.71473396723752550000e+000) (19, 5.08407245410090350000e+000) (0, 2.06300379063998780000e+002) (1, 2.81526620229161840000e+000) (2, 2.89553039332100610000e+001) (3, -1.24722009020262830000e+000) (4, 2.83103171758923580000e+001) (5, -1.74948048096696640000e+000) (6, 1.55650124751171750000e+002) (7, -3.96512712172460180000e+000) (8, -1.48674286332172880000e+000) (9, 9.18506451752669050000e+000) (10, 2.42689764397170040000e+001) (11, 1.75221273890933450000e+000) (12, 5.06906512891929640000e+001) (13, 8.15754447506766840000e+000) (14, 2.80545395035412850000e+001) (15, 4.35080138292431150000e+000) (16, 4.34865506569000860000e+001) (17, -2.24554670628395890000e+000) (18, -1.82442469830887750000e+001) (19, -1.13044534537818730000e+001) (20, -1.43290647166407630000e+000) (21, -2.78746854848426370000e-001) (22, -1.31436845915747850000e+000) (23, 1.20522940314253720000e+000) (24, -1.25141332907011680000e+000) (25, 1.63104726077666440000e+000) (26, 5.70486145064676360000e-002) (27, 1.25496068524444190000e+000) (20, 1.35094257053406560000e+000) (21, -1.06536032110267720000e+000) (22, 1.34272932686585580000e+000) (23, -1.18471775332746980000e+000) (24, 1.28585791051794440000e+000) (25, -5.61786115806998040000e-002) (26, 1.24213033319192310000e+000) (27, 2.87588937714536550000e-002) (20, -4.17607683236949770000e-002) (21, 1.35669632141239440000e+000) (22, -7.08873224463463240000e-002) (23, -1.35094036227131450000e-002) (24, -3.25520312705038880000e-003) (25, -1.45422454284132450000e+000) (26, -1.35840966479595470000e+000) (27, 1.37989247660983370000e+000) 

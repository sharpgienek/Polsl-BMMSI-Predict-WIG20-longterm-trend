FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.72524716328311530000e+001) (1, -3.92326932378590180000e-001) (2, 2.16414134050363400000e+000) (3, 2.19086362027201840000e+000) (4, -9.13259370466099440000e+000) (5, 1.20362982687929220000e-001) (6, 1.55598755362865140000e+001) (7, 1.74177571566008300000e-001) (8, 3.37032814559290060000e+000) (9, -4.86634297829776130000e-001) (10, 5.42165991599562960000e+001) (11, 8.97123569522637280000e-001) (12, -2.62455229880520290000e-003) (13, -7.82413089749655550000e+000) (14, -7.08264125654424600000e+000) (15, -5.23959551863126820000e-001) (16, 2.47784340900349420000e+001) (17, 1.80937789240567740000e+000) (18, 7.20607901539460020000e+001) (19, -8.94142068303516350000e+000) (0, 4.21046872116872580000e-001) (1, -7.30723380438892840000e-001) (2, -2.38272351683186830000e+000) (3, 9.00835567373731940000e-001) (4, 8.82085927348196460000e-001) (5, 1.74228064079563880000e+000) (6, 1.68081375774028740000e+001) (7, 4.63229843051701560000e-001) (8, -1.64237717625932760000e+000) (9, -1.18183775004622050000e+000) (10, 5.61901311368005010000e+000) (11, 9.53095022661163550000e-002) (12, 1.05699280840565430000e+000) (13, -1.66693681830336240000e+000) (14, -1.79463689994621590000e+001) (15, -1.25519648399531090000e+000) (16, 6.63251890754860620000e+000) (17, 3.01578040084325530000e-002) (18, 4.47586964830030990000e+001) (19, -1.81070940333403630000e+000) (0, -1.10031909702798100000e+001) (1, -4.87772900145454710000e-001) (2, -7.44225162884002310000e-001) (3, 1.07847789932497860000e-001) (4, 7.75965408911753850000e+000) (5, -1.24099264097397530000e+000) (6, -3.10182274835271700000e+001) (7, -4.15948642756017450000e-001) (8, 3.78992124275725000000e+001) (9, -3.02273313678008690000e+000) (10, -4.10447536360207810000e+000) (11, -2.40418550399849270000e-001) (12, 1.54262815185894950000e+000) (13, 1.07918302121279200000e+000) (14, -2.11031326763174000000e+000) (15, -4.21708389035768960000e-001) (16, 3.01987526218728420000e+000) (17, 9.05596374650786910000e-001) (18, -3.43552144193592070000e+001) (19, 1.52665169026654550000e+000) (0, 2.26036283478853260000e+001) (1, -5.25091958316159070000e-001) (2, -1.03202157603912350000e+001) (3, 1.88395321618804970000e+000) (4, 1.65974073152619040000e+001) (5, 1.75916922484191970000e+000) (6, -2.59197084963246340000e+000) (7, 2.66165553560139930000e-001) (8, 7.45263625683298630000e-001) (9, 1.29730169434879810000e+000) (10, -3.39939630585825600000e-001) (11, -6.56927584790762130000e-002) (12, 1.55804409012017280000e+001) (13, 9.37639885540447640000e-001) (14, 2.47839101833175410000e+000) (15, 4.42085176888782290000e-001) (16, 2.66058780858231450000e+000) (17, -2.52502808202994030000e-001) (18, -2.09636139874606930000e+001) (19, 1.80856537174417460000e-001) (0, -4.20429132230553560000e+000) (1, 1.35018594203943380000e-001) (2, 1.08508155205444560000e-001) (3, -2.23082078587638350000e+000) (4, 2.71875602154246750000e+001) (5, -3.18181372017822590000e-001) (6, -1.09971177398017750000e+001) (7, 5.05825446129926010000e-002) (8, -1.01706928730880290000e+001) (9, 1.30832735943329400000e+000) (10, 9.26531912128699540000e-002) (11, -1.43114757391848590000e-001) (12, 1.40239179621221630000e+000) (13, -1.05523215293102530000e+000) (14, 3.04376107269015150000e-001) (15, -1.59941843467909760000e+000) (16, -1.24854570259829840000e+000) (17, -2.73239168231627660000e+000) (18, 1.13190330026806110000e+001) (19, 6.06726131532442150000e-001) (20, 1.52861889729653380000e+000) (21, -3.23405117075704420000e-002) (22, -1.14493488100244620000e-002) (23, 1.17567930365183840000e-002) (24, -1.14334670350064070000e-002) (25, 1.48653074087589500000e+000) (20, -1.29208828661696050000e+000) (21, 2.13552439154764960000e+000) (22, -1.39356374597136970000e+000) (23, 1.12185029130357980000e-001) (24, -1.30761693977402340000e+000) (25, 7.65651741522989650000e-001) (20, 2.80338509369897240000e-001) (21, -2.79387429051859960000e+000) (22, 1.78010588705810700000e+000) (23, 1.01854723754824030000e+000) (24, 1.92909594932042920000e+000) (25, 1.72349413405097600000e+000) 

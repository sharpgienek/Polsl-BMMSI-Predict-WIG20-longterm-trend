FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.60124564117063710000e+000) (1, 5.06811643589592190000e-001) (2, 1.10202907470649570000e+001) (3, -1.41503206461333010000e+000) (4, 3.61479870039136970000e+000) (5, 8.91130753316291660000e-001) (6, -5.24830503355660500000e-001) (7, 2.03703680828801350000e+000) (8, 3.22017066971979840000e+001) (9, 2.85132866999385510000e+000) (10, -7.36986001837649680000e+000) (11, 5.45114004699800090000e-001) (12, -1.03077761481629630000e+001) (13, 1.65137418470130810000e+000) (14, 1.34573145864401720000e+000) (15, 4.34833401782856840000e-001) (16, -1.40548010692424740000e+001) (17, -2.88837209113286970000e-001) (18, -8.73605693303494490000e+000) (19, 1.39180613772612930000e+000) (0, 1.48249408532617770000e+001) (1, -1.12724136034227960000e-002) (2, -9.95235148246592160000e+000) (3, 1.73705259663428140000e+000) (4, 1.80673404876062830000e+000) (5, 2.19045199661302710000e+000) (6, -8.28198794905890520000e+000) (7, 6.53172079173693910000e-001) (8, -1.79691049023016160000e+001) (9, 9.99609017949527280000e-001) (10, -7.84181464512453810000e+000) (11, -4.21162058603781860000e-001) (12, 1.77786640806597340000e+001) (13, 3.40534822166167710000e+000) (14, 3.12306648668621990000e+001) (15, 4.34052585519705960000e-002) (16, 3.40942989336469320000e+000) (17, 2.87635506346769980000e+000) (18, 5.42763375773756350000e+000) (19, -3.02894785363499950000e-001) (0, 2.32891691039004840000e+001) (1, 5.75807933697095040000e-001) (2, 1.37531468667306420000e+001) (3, 3.37701100232349200000e-002) (4, -1.59680777671232080000e+000) (5, 1.83273219145929690000e+000) (6, 7.07472967857525960000e+000) (7, 6.66220586372736210000e-002) (8, 2.23212926535912190000e-002) (9, -8.10847204487556840000e-002) (10, -2.91155266998259780000e+001) (11, 3.98289527835287770000e-002) (12, 5.48631371174032450000e+000) (13, -2.06372595094187570000e-001) (14, -5.11620648460871190000e+001) (15, -3.45132420197009630000e-001) (16, 2.88422266525749200000e+000) (17, -3.47034094774722130000e+000) (18, -1.73429570141559390000e+001) (19, 4.01808013780331870000e-001) (0, 4.51113150576693270000e-001) (1, 2.52169842674165030000e-001) (2, 4.66877728197575000000e-001) (3, 4.40684552314532410000e+000) (4, -1.37300246605494750000e+001) (5, 2.15013061170802060000e+000) (6, 3.10554932080801860000e+001) (7, 8.71126109037353440000e-001) (8, 5.37489487798550990000e-001) (9, -2.57835323555199070000e+000) (10, 1.10591531887890080000e+001) (11, 1.97278304372669880000e-001) (12, 1.27984086020108740000e-001) (13, 4.28445090788796610000e-001) (14, 2.34286236591939880000e+001) (15, 2.84843695301600030000e+000) (16, -3.36934396940820770000e+000) (17, 6.85019248888840470000e-001) (18, -2.39106234706568910000e+001) (19, -4.09137825621976250000e+000) (0, 2.21295105030440980000e-001) (1, 4.18869503936050070000e+000) (2, -1.93552669966170540000e+001) (3, 1.20793693300733860000e+000) (4, 1.33522358278648670000e+001) (5, -8.30215354075432680000e-001) (6, -4.99437792481158120000e+000) (7, 1.91896748386292450000e-001) (8, -5.59882496831392910000e-001) (9, 1.45099303785817970000e+000) (10, -8.20552963004897880000e-001) (11, -2.08539938282647580000e-001) (12, 2.14672013705531790000e+000) (13, 1.16803561959396100000e+000) (14, 1.21241181789124330000e+001) (15, 1.25910265648596710000e+000) (16, 4.67965009831278070000e+000) (17, 5.85355682329471110000e-001) (18, -4.08148425005752990000e+000) (19, 9.72711780812085870000e-001) (0, 1.90323726840221760000e+000) (1, 1.30539620093378320000e+000) (2, 1.01937476013004140000e+001) (3, 4.28904265282070320000e-001) (4, -8.14975702189103930000e+000) (5, 1.13724622126912080000e+000) (6, 9.04133842637394380000e+000) (7, -4.88319160987839280000e-002) (8, 2.23313690047779010000e+000) (9, -2.49576235622818000000e-001) (10, 1.67030947609019130000e-001) (11, -6.53526662650724680000e-002) (12, 1.85923813491393530000e+000) (13, -1.96319099531888260000e+000) (14, -7.73002304361491180000e+000) (15, -8.89894781699469890000e-001) (16, 4.41202776454293840000e+000) (17, 3.35395250002705150000e-001) (18, 3.15030763434453820000e+001) (19, -1.03574943095113490000e-001) (0, -6.14392678163188850000e+000) (1, 4.37647189082580770000e-001) (2, 3.39841435463291150000e-001) (3, -5.12412140635089220000e-001) (4, 2.77070409351198810000e+001) (5, 2.81899102323948160000e-001) (6, 2.50337759338683310000e+001) (7, -6.49442206384042150000e-001) (8, 9.65341917223742070000e-001) (9, 2.26439605589198890000e+000) (10, 1.41176151589558060000e+001) (11, 3.40480181524592360000e-001) (12, 2.89028134493899860000e+000) (13, 8.95921089111287540000e-001) (14, -2.10604176339977480000e+000) (15, -6.46396077434686190000e-001) (16, 1.61364989694378740000e+001) (17, 4.57762862894577850000e-001) (18, 3.24958745857177720000e+001) (19, 2.47991846574027400000e-001) (20, 1.38091778015893430000e+000) (21, -7.44112048787281430000e-001) (22, -5.19436216293078350000e-001) (23, 9.33200402679967510000e-001) (24, -1.37527461472922900000e+000) (25, -1.88362141216568750000e-001) (26, 1.71302706264751840000e+000) (27, 2.74974420044472150000e-001) (20, 1.19431591699704030000e+000) (21, 3.56490514905019220000e+000) (22, 1.91057981552406940000e+000) (23, 2.17816173325880950000e+000) (24, -7.39649999892469270000e-001) (25, 3.06058244308636420000e+000) (26, -1.39507045567544230000e+000) (27, 6.97327944978300640000e-001) (20, 8.92752922720587480000e-001) (21, -1.49189240693571310000e+000) (22, 1.31481885165853860000e+000) (23, -2.99855877695366150000e+000) (24, 3.53027518601997900000e+000) (25, -4.25077110209916760000e+000) (26, 1.66197187946651480000e+000) (27, 1.36208975489504390000e+000) 

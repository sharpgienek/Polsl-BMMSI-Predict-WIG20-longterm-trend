FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.98067722272419920000e-001) (1, -2.39199877831595930000e-002) (2, -4.11538667477211200000e+000) (3, 4.06587774801239470000e+000) (4, 1.12646354308826860000e+000) (5, 3.11793110273748300000e+000) (6, -1.46570002602167970000e+001) (7, 5.12468369918458460000e-001) (8, -1.48255534394285980000e+000) (9, 6.72054784087597670000e-001) (10, -2.95327854243141900000e+000) (11, -1.56104192876115430000e-001) (12, 1.93536876884809810000e+001) (13, 3.77556600979507050000e-001) (14, -2.93270548977200400000e-001) (15, 2.81150933104397050000e+000) (16, -2.52456546878824390000e+001) (17, -1.66979370308208020000e+000) (18, -5.24561529251949000000e+001) (19, 3.71566972627138890000e-001) (0, -3.65527225444065440000e+000) (1, -3.63052482496273030000e-001) (2, -5.61476858134471120000e-001) (3, 2.43986582589003790000e+000) (4, -1.53599784649333500000e+001) (5, 1.14682524976735030000e+000) (6, 3.82367207394575590000e+000) (7, 1.11601838109224900000e+000) (8, 2.32332750508631360000e+000) (9, 8.49691508009125070000e-001) (10, -2.73378134856741730000e-001) (11, 3.73716641069722410000e-001) (12, 4.66205435594070020000e-001) (13, 4.61252436889803610000e-001) (14, 4.29984158842169060000e-001) (15, 2.71410206260814140000e+000) (16, -1.35428038847318710000e+001) (17, -4.03253304957521100000e-001) (18, -9.41344118707277210000e+000) (19, -2.54347138197049790000e-001) (0, 1.07284095065669480000e+001) (1, 2.31461413865364120000e+000) (2, -8.07660291879452070000e+000) (3, 7.73153863740005940000e-001) (4, -3.13358488710849880000e+001) (5, 2.51816522720039560000e+000) (6, -3.41210270798398550000e+001) (7, 3.12280138768487040000e+000) (8, 1.61569489854336790000e+001) (9, -1.43245925192797690000e+000) (10, 3.81559666842871680000e-001) (11, -1.41366512377958060000e-002) (12, 1.21533364125675880000e+001) (13, 1.07697806545944810000e-001) (14, 8.55057043394463870000e-001) (15, -1.84957556618656120000e-001) (16, -6.82672682657467700000e+000) (17, 1.13439983441438640000e-001) (18, 1.72560674065843360000e+001) (19, 1.33234650539498900000e+000) (0, -6.32707868386567360000e+000) (1, 3.97168953752964520000e-001) (2, -3.82823564869659520000e-001) (3, 1.09631229285167930000e+000) (4, -1.98865224737930530000e+000) (5, 6.15963876677870450000e-001) (6, 6.07637782590511720000e+001) (7, 1.47077082344691550000e-001) (8, 7.40736410669749270000e-001) (9, 1.22787179147849280000e-001) (10, 6.04025118562831320000e+000) (11, 3.00743467118326450000e-001) (12, 5.09291708868799550000e+000) (13, -6.83817332817226120000e-001) (14, 1.69699997715804400000e+001) (15, 5.55667474863746010000e-001) (16, 4.79310627941706150000e-001) (17, 7.10591553693697200000e-001) (18, 2.14264596893538660000e+001) (19, -2.23753304593860540000e+000) (0, 9.29704514629930760000e+000) (1, -7.67733053474992240000e-002) (2, 1.16779149883534220000e+001) (3, 2.50630264633070430000e+000) (4, 2.46757261312597230000e+000) (5, 7.85519640803246060000e+000) (6, -1.39256617170701520000e+001) (7, 7.75888677400550900000e-001) (8, 8.22296572212891760000e-001) (9, -1.45117045979698260000e+000) (10, -1.97730107106368460000e+001) (11, 3.76053717063299760000e-001) (12, 3.86284546982839890000e+000) (13, 3.06131850724117300000e+000) (14, -2.72235413120700120000e+001) (15, -1.39038588181452700000e-001) (16, 4.08893307182243360000e+001) (17, 7.19316834330577310000e+000) (18, 1.06386139046130430000e+001) (19, 1.69843360365842980000e+000) (0, 2.58498280390316640000e+000) (1, 4.70267857809632160000e+000) (2, 3.95365919344264860000e+000) (3, 1.36224655483673150000e+000) (4, 7.68674475924039240000e+000) (5, -2.23912415799179600000e+000) (6, -2.30472427658689720000e+000) (7, 2.52560578963760610000e-001) (8, 1.17938489192172140000e+000) (9, 2.92333424910885360000e+000) (10, -4.73060324385595980000e+000) (11, 1.68327687169468780000e-001) (12, -9.10409465214395030000e-001) (13, 1.67503485207694580000e+000) (14, 1.99052625526914030000e+000) (15, 1.40695290229366980000e+000) (16, -3.26833982620223740000e+000) (17, 1.11915595923440630000e+000) (18, -3.25858848363737600000e+000) (19, 9.26145801914636140000e-001) (0, 5.07795359661264030000e+001) (1, -1.49639086106636430000e-001) (2, -1.00672210428291290000e+000) (3, -1.05403740141851320000e-001) (4, -1.55745432712811190000e+001) (5, 6.22055976379837670000e-001) (6, 4.45176437384586520000e+001) (7, 1.19036312492646370000e+000) (8, 5.02797225132915030000e-001) (9, 6.14757995555112460000e-001) (10, -2.95437689809693040000e+001) (11, 1.62523738083425600000e+000) (12, 8.38765144227262030000e+000) (13, 3.91231613899090670000e-002) (14, 5.26599142174130110000e+000) (15, -5.88529829716008980000e-001) (16, -3.92924635818090850000e+000) (17, -7.83946002084624840000e-001) (18, -1.92081584509774180000e+001) (19, 1.55710789789502390000e+000) (20, -2.72962137887562410000e+000) (21, 2.80538974610657110000e+000) (22, -4.53793084046719530000e-001) (23, -5.09245820868980470000e-002) (24, -5.42395662130564160000e-002) (25, -2.78961194103365570000e-002) (26, 1.45469932445707020000e-001) (27, 2.38930906881744180000e-001) (20, 2.45916409954961780000e+000) (21, 5.22026211621551270000e-001) (22, 3.07161887782509750000e+000) (23, 2.81390844784586890000e+000) (24, 2.97305586699599770000e+000) (25, -2.22625330814605430000e+000) (26, 2.25189049488965810000e+000) (27, -8.27311182721316430000e-002) (20, -5.67693678938556490000e-001) (21, -1.31913543352572860000e+000) (22, -5.32001162418931920000e-001) (23, -6.77111740330918720000e+000) (24, -2.72250838080011630000e+000) (25, 3.90814997513677340000e+000) (26, 8.88515621181993010000e-001) (27, 1.41465555585272580000e+000) 

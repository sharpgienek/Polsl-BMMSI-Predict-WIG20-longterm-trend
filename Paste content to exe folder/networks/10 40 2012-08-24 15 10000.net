FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 4 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.20021351558314450000e+002) (1, -1.28940742886563830000e+000) (2, -9.42816509808984050000e+001) (3, -4.18620585965386120000e+000) (4, -1.76129403259258910000e+002) (5, 2.33239620897859010000e+000) (6, 8.17733218307658800000e+001) (7, 1.01242760613284140000e+001) (8, 5.19849812303320820000e+001) (9, 4.28577973238255510000e+001) (10, 1.93977549067245750000e+002) (11, 1.64796538850642400000e+000) (12, 8.68263288517218680000e+001) (13, 5.92460052646077880000e+000) (14, 1.45533214814751250000e+001) (15, 4.33974486572917330000e+000) (16, 1.60348778467627220000e+001) (17, -1.13896835914613060000e+001) (18, 2.78522740717730530000e+002) (19, 3.52827561175940920000e+000) (0, -5.78057339872780600000e+001) (1, -1.16327171097232400000e-001) (2, -5.50095749906027190000e+000) (3, -1.23342252249044670000e+000) (4, -1.41895284617863380000e+000) (5, -3.45982447110219360000e-002) (6, 3.07350937248225800000e+001) (7, 1.38377988292847350000e+000) (8, 4.59906001599043180000e+001) (9, 6.42820911350348820000e+000) (10, -2.14488566809624470000e+001) (11, 9.49056788477610770000e-002) (12, -1.57888836586074620000e+001) (13, 7.15408740818252010000e-001) (14, 1.69955366206394770000e+001) (15, 2.10535978805004470000e-002) (16, 9.51934777028704280000e+000) (17, -1.11720639263319450000e+000) (18, 4.88585681939437610000e+001) (19, -2.60554812485945590000e-001) (0, -1.09570710708012200000e+002) (1, 3.46481344597882130000e+000) (2, -1.74303471576646020000e+002) (3, 3.32539557368049630000e+000) (4, -1.37732504707605070000e+002) (5, -3.72555180252588690000e+000) (6, 8.86817605525943920000e+002) (7, 7.17145092003457480000e+000) (8, 8.20774960361552300000e+002) (9, 5.30844698463371290000e+001) (10, 1.50000000000000000000e+003) (11, 1.72912914524031360000e+001) (12, 4.85920141176615570000e+002) (13, 7.63842634897657290000e+000) (14, -3.65229488965682950000e+001) (15, 1.14107282316169490000e+000) (16, -5.01529366111477800000e+001) (17, 1.02284177356658710000e+000) (18, 8.02809898518448510000e+001) (19, -3.58501875908420620000e+001) (20, 7.01416687563421300000e-004) (21, -1.35240843055702780000e-002) (22, 3.32344746346760060000e+000) (23, 3.31244041560305110000e+000) (20, 4.40370149942485070000e+000) (21, -4.47506007510954530000e+000) (22, -1.66580189901507010000e-002) (23, -3.21350724361381610000e-002) (20, -6.18873259951226910000e+000) (21, 6.06075300064265310000e+000) (22, -2.54846605439238160000e+000) (23, 2.69526766672238380000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.81116341396770690000e+000) (1, 6.03211358059865050000e-002) (2, -1.32168037739807120000e+000) (3, 1.95329414211068140000e-002) (4, 1.98568099261928310000e+000) (5, 2.04974384884608280000e-001) (6, -4.66471296388541390000e+000) (7, -1.76341242286959550000e-001) (8, -4.73065062845640580000e+001) (9, 8.40960724062071900000e-001) (10, -4.58759535766451790000e+000) (11, -1.62216092546111080000e-001) (12, 3.76342277818745790000e+000) (13, 6.30732497855661880000e-001) (14, 3.69786486053520090000e+000) (15, 1.71548028807430650000e+000) (16, 2.22946644330168340000e-001) (17, 1.42798429023765630000e-001) (18, -4.05321756814516480000e+001) (19, 2.37487540126962470000e-001) (0, 1.01288919004312130000e+001) (1, -3.71545508625054030000e-001) (2, 2.06159693057836920000e+000) (3, 9.29375896913116170000e-001) (4, -1.17352250740672180000e+001) (5, -3.48460106741405310000e+000) (6, 1.06189594419981540000e+001) (7, 5.30130656828332380000e-001) (8, 4.86200015101550780000e+000) (9, -4.37543588875191340000e+000) (10, 1.35650298656940930000e+001) (11, -4.00058303086590680000e-001) (12, -1.13188653110129530000e+000) (13, -4.74918196408594450000e-001) (14, 2.61459879673185400000e-001) (15, -4.47539462098919130000e+000) (16, -7.74929632497922240000e-001) (17, -1.54071173394278140000e+000) (18, 7.44849445745014830000e+001) (19, -6.67217489652267240000e-001) (0, 1.78059797702749980000e+001) (1, -1.37642705627236820000e-001) (2, -1.52484415377806700000e+000) (3, -4.69842564834719030000e-001) (4, -7.08352998892185360000e-002) (5, 2.49271046308959040000e+000) (6, -1.19028031285143430000e+001) (7, 6.27830903668949340000e-001) (8, -4.26123568446959580000e+000) (9, 4.77575802637023430000e-001) (10, -5.07379241153479870000e+001) (11, 2.95044773520553640000e-001) (12, 1.88671987297628910000e+000) (13, 3.20117950530251940000e-001) (14, 2.57396088858232290000e-001) (15, -1.88339740707010120000e-001) (16, 9.94975069484532600000e+000) (17, 8.97611471891018860000e-003) (18, 5.17324294425464350000e+000) (19, -2.30752387097990650000e-001) (0, 9.75795842735455570000e+000) (1, -1.16700481733777380000e+000) (2, 4.21526290385144890000e+000) (3, 5.92687742937448410000e-001) (4, 8.97933603596701420000e+000) (5, 1.09879728265340830000e+000) (6, 1.05814200062897540000e+001) (7, 5.65288175473264930000e-001) (8, -1.05183870218099780000e+001) (9, -6.34172516756598800000e-001) (10, 1.26302759779705290000e+001) (11, -3.90949413044340000000e-001) (12, 1.47634448869054410000e-001) (13, -1.00898628161406090000e+000) (14, 2.78837873566523740000e+000) (15, -1.65483983337679440000e+000) (16, 9.91886391004210390000e+000) (17, 5.10328814588280610000e-002) (18, 7.04481618523855530000e+001) (19, -1.06231444357736350000e+000) (0, -1.38111219876147340000e+000) (1, -1.61022893895312070000e-001) (2, -5.10228591789238180000e+000) (3, -1.29382031177538150000e+000) (4, 5.16647940071977200000e+001) (5, -1.42861481015624590000e+000) (6, -8.38853185475993430000e+000) (7, 9.07943312046191940000e-001) (8, 1.19972963011250190000e+001) (9, -3.53875467028285540000e+000) (10, 1.08657086522933480000e+001) (11, 1.74645558265792380000e+000) (12, 4.34623294012963900000e-001) (13, 6.39810742744522510000e-002) (14, 2.14586565754218440000e+000) (15, -5.98662413416455990000e-001) (16, 5.12707462742279580000e+000) (17, 2.08997160980376990000e+000) (18, 2.80323271054004730000e+001) (19, -1.58449098008936830000e+000) (0, -1.10181249388071740000e+001) (1, 1.86305362574443740000e-001) (2, -9.44293260469255320000e-001) (3, -8.50969526009335290000e-001) (4, 1.39640838151681410000e+001) (5, 8.82443065368984870000e-001) (6, -5.46957446411050370000e-001) (7, -2.83122654258816160000e-001) (8, 6.04195416804996470000e+000) (9, 3.65770730129875150000e+000) (10, -2.42092524911826210000e+001) (11, 9.55973696764362140000e-002) (12, 3.17848133945478840000e-001) (13, 7.71505007823175440000e-001) (14, -8.94082256988344760000e-001) (15, -3.78346550694976690000e-001) (16, 1.52615857036560540000e+001) (17, -1.26466965760154080000e+000) (18, -2.60338514316756870000e+000) (19, 1.52993611109777860000e-001) (0, 1.63942597702629360000e+000) (1, -2.31813996630102770000e-001) (2, -1.32043911694825340000e+000) (3, 5.94186528087883640000e-001) (4, -1.36128406775465130000e+001) (5, 2.90528820325849260000e-001) (6, 1.41427860441437460000e+001) (7, 1.06082380534655750000e+000) (8, 2.05590825198519730000e+001) (9, 3.73015217736727020000e-001) (10, 2.28808614107408630000e+001) (11, 3.31882700171691190000e-001) (12, -7.71567426317469800000e+000) (13, 7.31376564555221290000e-002) (14, -2.20540523354556140000e+000) (15, 5.56659754796736020000e-001) (16, 5.43338768384951320000e-001) (17, 3.03248514980046460000e-001) (18, 2.23802555387864200000e+000) (19, -1.22224091523896620000e+000) (20, -9.70656817734904860000e-001) (21, -1.46904776818594730000e-001) (22, -1.56043448929401220000e-002) (23, -6.52792851788259850000e-001) (24, 2.97099675053434260000e-001) (25, 7.55620266815644090000e-001) (26, 1.44457893228360670000e+000) (27, 6.80632713621497350000e-001) (20, -4.64673069597160320000e-001) (21, 1.02449296949189610000e+000) (22, 4.68883892204452700000e-001) (23, 8.69143672696886750000e-001) (24, -1.72186371660254940000e+000) (25, -1.53431116447284070000e+000) (26, 4.23849327100360830000e-001) (27, 2.01106729541362530000e+000) (20, 1.53804548014349110000e+000) (21, -6.50550076496741240000e-001) (22, 7.25512931515317370000e-001) (23, -4.03916874303255120000e-001) (24, 1.30404035076200240000e+000) (25, 1.00805117951300540000e+000) (26, -2.31370400536626520000e+000) (27, 7.67697500392403030000e-001) 

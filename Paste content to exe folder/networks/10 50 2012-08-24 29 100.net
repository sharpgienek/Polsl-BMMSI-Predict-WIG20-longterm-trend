FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.39103922498244260000e+000) (1, -6.43966466335983870000e-001) (2, 3.74118698616727400000e+000) (3, 1.08583507385070450000e+000) (4, -2.37607556371878950000e+001) (5, 4.26208519648020200000e-001) (6, -1.74523178883424990000e+001) (7, 7.05170940221914950000e-001) (8, -3.68480025760294510000e+001) (9, -8.55095715882495940000e-002) (10, -2.50446104023391530000e+001) (11, -1.02680930156928950000e-001) (12, -5.30590680381522260000e+000) (13, 2.29469935361511470000e-001) (14, -9.85928346607627940000e+000) (15, -6.97963734958952590000e-001) (16, -1.32755642315378120000e+001) (17, 2.65208924061521090000e-002) (18, 1.21141112658883080000e+001) (19, 3.50044212596515520000e-001) (0, -1.18391973046450950000e+000) (1, -3.59261495065566650000e-001) (2, -2.87247790917140530000e-001) (3, 2.76023047245747840000e+000) (4, 4.51857287865016440000e-001) (5, 1.54516718894140670000e+000) (6, 3.32861474560511890000e+001) (7, 1.62032911906743290000e+000) (8, 1.37764495631161400000e+001) (9, 4.98382287816027610000e-001) (10, -6.88946007568591590000e+000) (11, 3.71940844748365970000e-001) (12, 2.23908598060964610000e+000) (13, 1.01455337719435240000e-001) (14, 5.06217634066665220000e+000) (15, -1.63327524975061230000e-001) (16, -2.92147743454320130000e+000) (17, 3.79713360310937610000e-001) (18, 2.46621984355025250000e+001) (19, 1.71544460935638990000e-001) (0, 1.64187803987918170000e+001) (1, 2.05661143643277140000e-001) (2, 9.56995809174336820000e+000) (3, -2.54799484545838510000e-001) (4, 4.54649025807913440000e+000) (5, 1.14985383816495010000e+000) (6, -1.93162498984572830000e+000) (7, 2.64780241129111920000e-001) (8, 3.71022432358606350000e+000) (9, 1.36037521193483530000e+000) (10, -5.88041269717212330000e+000) (11, 6.45242593153511960000e-001) (12, -1.85984095891121760000e+001) (13, 6.86820651366128690000e-001) (14, 1.10290240690301930000e+001) (15, 2.96797780023897980000e+000) (16, 2.03043482270717350000e+001) (17, -1.68924064784041180000e-001) (18, -5.50526001824724250000e+001) (19, 2.12422347979548310000e-001) (0, -6.27281118108739030000e+000) (1, 1.63024484288913030000e+000) (2, 2.52123688329487060000e-001) (3, 7.90450733035664600000e-001) (4, 1.67402455272409230000e+001) (5, -3.50763105812841050000e+000) (6, 1.06841617443513210000e-001) (7, -1.17997944604738450000e+000) (8, -8.47475919648734920000e-001) (9, -5.33115542306874410000e-001) (10, -1.10251678178040140000e+001) (11, 3.74426887694379210000e-001) (12, -8.34423459885036680000e+000) (13, 7.32255444820857360000e-002) (14, 1.26753111163896400000e+001) (15, 1.58920507635421740000e+000) (16, -1.59074987569726380000e+000) (17, 3.97375368815811870000e-001) (18, -9.77911297747157700000e+000) (19, 1.79788760110353080000e-001) (0, 1.28454295062869640000e+001) (1, 2.51796216743299830000e-001) (2, 8.61860551871149210000e+000) (3, 3.92903380582849060000e+000) (4, -3.24367462020557160000e+001) (5, -9.43433179696481330000e-001) (6, -8.06126231742348230000e+000) (7, 7.96486712045029880000e-002) (8, -5.74261687065950250000e-002) (9, -1.43617495552225520000e+000) (10, -2.56232526687146180000e+000) (11, 4.42834036146893540000e-001) (12, 3.50189108778168290000e+000) (13, -6.54970981261425720000e-001) (14, 6.81611249179766880000e+000) (15, 1.67555347819152330000e+000) (16, -6.44389911754416910000e+000) (17, 4.09422544850619850000e-001) (18, -1.45159336382376810000e+000) (19, 4.35660027846171420000e-001) (20, -1.61657672464395020000e+000) (21, 1.74791501830170760000e+000) (22, 1.16121827518493370000e-001) (23, 1.74294767472366080000e-001) (24, -8.89328713928218330000e-001) (25, 5.29272027299755200000e-001) (20, -6.11794630354165040000e-001) (21, -9.44572041439880490000e-001) (22, -1.77945856530768840000e+000) (23, -2.22044857442428170000e+000) (24, 2.49548605527012810000e+000) (25, 2.11727436153853650000e+000) (20, 2.32455495277449890000e+000) (21, -6.87684611217911690000e-001) (22, 1.72372720269842920000e+000) (23, 1.63332265885446630000e+000) (24, -2.03204663298213320000e+000) (25, 4.28175838185605560000e-001) 

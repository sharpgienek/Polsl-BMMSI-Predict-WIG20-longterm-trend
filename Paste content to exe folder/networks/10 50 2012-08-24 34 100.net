FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.56134160554636170000e+001) (1, -2.69866287882186580000e-001) (2, 1.17024725747414200000e+000) (3, -1.11877133636586760000e+000) (4, -2.11628279632497040000e+001) (5, 2.48278078196678830000e-002) (6, -3.66219666859970160000e+000) (7, -6.42648057596235890000e-001) (8, -1.01352080731623620000e+001) (9, -7.76545248023362330000e-001) (10, -1.53272177821872670000e+001) (11, -3.55298778185644700000e-001) (12, 8.77868473210230600000e+000) (13, 1.44317532799187050000e-001) (14, -1.73368942491612720000e+001) (15, 8.35931546943020850000e-001) (16, -1.01179526437204910000e+001) (17, -4.37526426370858980000e-001) (18, -1.42590729026433450000e+001) (19, 7.14103204868476450000e-001) (0, -5.85192796142924540000e+000) (1, 5.11110891900519280000e-001) (2, -1.93473342014042120000e+001) (3, 6.45110743790868630000e-001) (4, 5.58069902392011270000e+001) (5, -1.45594104666023050000e-003) (6, -1.42985276268991210000e+001) (7, -2.49780286254544930000e-001) (8, 2.37847470640582590000e+001) (9, 6.84598475011458760000e-001) (10, 1.49973539218595400000e+001) (11, -1.60026042421585720000e-001) (12, -1.54914223824441690000e+001) (13, 2.71470076016895270000e-001) (14, 1.35004368095445140000e+000) (15, 4.04877721114475970000e+000) (16, 2.02377985682912400000e+001) (17, 1.48100185920182840000e+000) (18, -1.01117632021749530000e-001) (19, 9.34326694395667180000e-001) (0, -2.27174003719273900000e+000) (1, -3.79742311892063260000e-001) (2, 4.44047409969837210000e-001) (3, -3.62636394860429150000e-001) (4, -3.25042239042632740000e-001) (5, 4.07211060321851230000e-002) (6, -2.22214660432780790000e-001) (7, 2.46065080305303730000e-002) (8, -9.58215943773376470000e+000) (9, -1.15219261569508810000e+000) (10, -5.09606229591918090000e+001) (11, -6.66568867487353780000e-002) (12, -4.23589629932000220000e-001) (13, 4.64501370040905800000e-001) (14, -7.20437472207378260000e+000) (15, -3.54516508492356410000e-003) (16, 1.16076229209691720000e+000) (17, 7.56613875656988900000e-001) (18, -1.07602887226711700000e+001) (19, 1.51776716632868510000e-001) (0, 3.10056881007051360000e+001) (1, -3.68093466009728140000e-001) (2, -6.28373895481535880000e-001) (3, 7.42394011027480820000e-001) (4, -3.77556114492692000000e+000) (5, 1.57760627475091720000e+000) (6, 3.27694650274245220000e+000) (7, 9.68291161715309270000e-001) (8, 3.11226504938687260000e+001) (9, 1.01269584807365960000e+000) (10, 4.76966607308130010000e+001) (11, -5.41693820227701410000e-001) (12, 2.26790701553773570000e+001) (13, 3.93356335374226560000e+000) (14, -2.11645748912361570000e-001) (15, 4.02537032309871370000e-001) (16, 4.56961163310804870000e+000) (17, 6.65172056423697900000e+000) (18, 5.39695201388237410000e+000) (19, -3.94086132161620750000e-001) (0, 4.82635161729777590000e+001) (1, -4.73501139641939460000e-002) (2, -3.03737336706671000000e+000) (3, 4.61206909262861060000e-001) (4, 2.89469683359900070000e+000) (5, -6.36979364039490510000e-001) (6, 3.92718804808165960000e-001) (7, 5.13236349931700970000e-001) (8, 9.79612762091054210000e+001) (9, -7.13649735243810570000e+000) (10, -8.06498835351816010000e+000) (11, 1.09678964811453490000e+000) (12, 4.28002092420500710000e+000) (13, -8.63198670132428570000e-001) (14, -6.07320346536557220000e+000) (15, 3.00531055603097830000e+000) (16, 6.56450665252510030000e+000) (17, -3.40900064946997670000e+000) (18, 5.50182571487093690000e+000) (19, 6.69714974672959600000e-001) (0, 1.35337816699396340000e+001) (1, 3.41365045026564060000e-001) (2, 1.72640551516999740000e+001) (3, 3.97895842898282480000e+000) (4, -2.53260473337330470000e+001) (5, -4.89663971840431480000e-001) (6, -2.16711542761988980000e+001) (7, 2.00544874513138680000e-001) (8, -4.54979551507530020000e+000) (9, -1.65464508705074650000e+000) (10, -2.45644721931152520000e+000) (11, 9.46209591355296140000e-001) (12, -5.70246788104023630000e-001) (13, -1.79590786055809170000e-001) (14, 2.60188971753843640000e+001) (15, 1.14018902622245920000e+000) (16, 5.52296327825130360000e+000) (17, 6.79868296552540860000e-002) (18, 3.11359112199760980000e+000) (19, 3.81582978495555390000e-001) (20, -1.66358832611701280000e+000) (21, 3.88067743549419250000e-001) (22, 1.69531167235449950000e-003) (23, -7.14129569978619460000e-002) (24, 1.42937226551884570000e+000) (25, -1.69214003490594140000e+000) (26, 1.12090664831800100000e+000) (20, 1.21059964823013750000e+000) (21, -1.63298283498145390000e+000) (22, -1.36294263720769560000e+000) (23, 1.43992221030022090000e+000) (24, 1.61886870518554720000e-001) (25, 1.17778916271071220000e+000) (26, 1.36599042093285910000e+000) (20, 6.38581451949526310000e-001) (21, 8.64406461329427110000e-001) (22, 1.64972765335884700000e+000) (23, -1.53373014770309890000e+000) (24, -1.75091763814417780000e+000) (25, 2.03553183859162790000e-002) (26, 1.04033793186427400000e+000) 

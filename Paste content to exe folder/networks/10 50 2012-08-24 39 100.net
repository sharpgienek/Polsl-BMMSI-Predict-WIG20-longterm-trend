FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.07773222723603920000e+001) (1, -9.76845598452427130000e-002) (2, 2.93610276557047360000e-001) (3, 1.05108066132441370000e+000) (4, 3.51185243489625380000e+001) (5, 8.55397538794719640000e-002) (6, -8.48993169179892430000e+000) (7, 7.96602943080524040000e-001) (8, -7.59150415941433290000e+000) (9, 7.09279261461597480000e-001) (10, 6.27651548142976970000e+000) (11, 1.87809205971620070000e-002) (12, 9.74894706000056010000e-001) (13, -1.48990360221672270000e+000) (14, -1.02679589239583110000e+000) (15, 1.34367669619575410000e-001) (16, -7.51653226582317120000e+000) (17, 1.57430300037974040000e-001) (18, 2.78972947668819660000e+001) (19, -8.36625019567459490000e-001) (0, 9.59545730116107780000e-001) (1, -7.12424063731748190000e-002) (2, -6.99403255167473040000e-001) (3, 2.02606305512767550000e+000) (4, 2.91502076389274210000e+000) (5, 1.15817070188693070000e+000) (6, 1.64538161472506740000e+001) (7, 7.21807798229602280000e-001) (8, 3.36897621934655400000e+001) (9, 1.05231710619510400000e+000) (10, -2.11778236609498110000e+000) (11, 1.71129244746981100000e-001) (12, 1.69057933596520660000e+000) (13, -3.92831003647310990000e-001) (14, 1.89360346438302880000e+000) (15, -4.09712418523608470000e-002) (16, 9.45311660393210750000e+000) (17, 4.36660257295758760000e-002) (18, 1.04311523478165410000e+001) (19, -4.31792253931345290000e-001) (0, -2.96421596835943550000e-001) (1, -1.73565913579181690000e-001) (2, 6.66985260636910750000e+000) (3, 1.99446300379188960000e+000) (4, 6.36551683000191030000e+000) (5, -1.91734164440938850000e-001) (6, -2.71937519220335030000e+001) (7, 4.92403435491492130000e-001) (8, -1.61144451417620950000e+000) (9, -8.31445939493450690000e-001) (10, -7.04481928766780400000e-001) (11, -1.87271704640123660000e-001) (12, 2.46225786488585060000e+000) (13, -1.03440304989479870000e+000) (14, 1.49289218255199450000e+001) (15, 1.11982665438715590000e-001) (16, 1.83535678267873620000e-001) (17, 5.21456267328451480000e-003) (18, -6.66118550019288060000e+000) (19, 3.74889872659720930000e-002) (0, 8.21999112609536200000e+000) (1, -1.11089906084790750000e+000) (2, -4.78482676062030600000e-002) (3, -4.37459805987577670000e-001) (4, 6.41961116363388570000e+000) (5, 1.03414968897333390000e-002) (6, -1.09810478478217080000e+001) (7, 4.43453801555841660000e+000) (8, -4.68208806901817520000e+001) (9, 2.36528982945391020000e+000) (10, -6.98339783728201360000e+000) (11, 9.38116099336546020000e-002) (12, 1.03304028962310120000e+001) (13, -3.25830051621688930000e-001) (14, 1.07030234925933550000e+001) (15, -6.00525504205543180000e-001) (16, -5.79473569399332260000e+000) (17, -5.45326275923250310000e+000) (18, -1.48586362381813760000e+001) (19, -1.55879792503851980000e-001) (0, -3.56651505234042250000e+000) (1, 4.81734098116991040000e+000) (2, -2.63267638730976530000e-001) (3, -1.45888476306852370000e-001) (4, 3.20254780982066410000e+001) (5, -1.18042512029063130000e+000) (6, 2.55572208205170100000e+001) (7, 7.59917976647895980000e-002) (8, 7.43383670424721750000e-001) (9, 6.02567228060827740000e-001) (10, -1.87770898974780210000e+001) (11, -1.32178845679352980000e-001) (12, -2.99987211554097010000e+001) (13, 1.15808135729894320000e+000) (14, 9.43623461654493670000e+000) (15, 7.55187553668954430000e+000) (16, 5.24573888056904640000e+000) (17, 2.36515800903429520000e+000) (18, -3.26782294913445380000e+001) (19, 9.61059232765891340000e-001) (0, -4.38704823766868390000e+000) (1, -2.35168606356897870000e-001) (2, 5.84700511302645550000e-001) (3, -6.14113709154357150000e-001) (4, 7.96558132209557000000e+000) (5, 1.30466991299595400000e+000) (6, -3.29145550139259680000e+000) (7, -1.24474651048372760000e+000) (8, -1.19034190954021620000e+001) (9, 6.35477100030744420000e-001) (10, -2.20232605560667700000e+001) (11, -1.80573674184344470000e-001) (12, -2.55621797407568340000e+000) (13, 2.49710958580937420000e-001) (14, -4.15221024047825530000e+000) (15, -2.04748979230207650000e+000) (16, 3.08704404286200820000e+001) (17, 2.50128304738897800000e-001) (18, -3.19499192410502640000e+001) (19, -6.68395283901388030000e-001) (0, 1.18248200170581370000e+001) (1, -7.68543738904665650000e-002) (2, 4.87115102625667620000e+000) (3, 6.67603115548433880000e-001) (4, -1.47046455931554710000e+001) (5, 7.36189715777978870000e-001) (6, -6.80897550897011250000e+000) (7, 1.01859035609908640000e-001) (8, -8.54594493770292730000e+000) (9, 3.66295701625736210000e-001) (10, -8.39035996069074200000e-001) (11, -1.57550770738094180000e-001) (12, 5.28513017047057510000e+000) (13, -2.76823275569548530000e-002) (14, 1.16327094774232230000e-001) (15, 1.14849107579584390000e-001) (16, 1.45855425232335970000e+000) (17, -3.72744880848066280000e-002) (18, 5.57773619079965770000e+000) (19, -7.89325923168829460000e-002) (20, 7.71962249670820940000e-001) (21, 1.81288065216101320000e+000) (22, -1.82053730250342280000e+000) (23, -6.41242134980451320000e-002) (24, 7.32441933711086710000e-002) (25, -2.73083547433769670000e-001) (26, -2.78190740742985600000e+000) (27, 8.05360933580010490000e-001) (20, -1.92941221309721220000e+000) (21, -3.75109985276188340000e-002) (22, 1.34431319561891450000e+000) (23, -8.45329530724161730000e-001) (24, -1.10048430576250000000e+000) (25, -1.76432282213608540000e+000) (26, 3.20950359984837740000e+000) (27, 9.46566368103004760000e-001) (20, 4.08613171264048890000e-001) (21, -1.59550929285672740000e+000) (22, 6.08160396046038780000e-001) (23, 1.47805073234040200000e+000) (24, 1.20743707207795930000e+000) (25, 2.44361265818156600000e+000) (26, 6.06785540832408540000e-002) (27, 1.39724629866241170000e+000) 

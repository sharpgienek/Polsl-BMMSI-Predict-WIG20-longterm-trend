FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.04671224075628810000e+000) (1, -1.21807505675194260000e-002) (2, 5.27780622894871330000e+000) (3, -5.18815601185764640000e-001) (4, 2.49859772027645290000e+000) (5, 9.27308297620829000000e-001) (6, -2.06592955038906040000e+001) (7, -2.56249476927042140000e-001) (8, -3.65002455608179230000e+001) (9, 1.34819229657647500000e+000) (10, -1.44847798879240770000e+001) (11, -8.22982511691664480000e-001) (12, -1.78507723547389400000e+001) (13, 4.84473114244952150000e-001) (14, 7.72346750265994240000e+000) (15, -1.64944621527295030000e+000) (16, 1.07238245426940020000e+001) (17, 1.15186385648902160000e-001) (18, -2.16016769267062830000e+001) (19, -5.75309064710913810000e-001) (0, 2.69273403514476060000e+000) (1, -5.21284566038438870000e-001) (2, -1.47805581021646120000e+001) (3, -4.33142358403601600000e-001) (4, 7.70172223166150080000e-001) (5, 3.59717934911994160000e-001) (6, -1.14878787986525430000e+001) (7, -4.36709891321680200000e-001) (8, 1.69708221547660470000e+001) (9, 6.12265334821061710000e-001) (10, -1.36899792953318020000e+000) (11, 5.77809497439083980000e-002) (12, 3.51831637736081060000e+000) (13, 1.10172298423612360000e-001) (14, -2.00573271623224760000e+001) (15, 2.72830845321559150000e+000) (16, 1.64630815554085360000e+001) (17, 1.49270402892933250000e+000) (18, 5.70367894280016860000e+000) (19, 6.07983712189788460000e-002) (0, 1.76159234996516180000e+000) (1, -1.50486106985567060000e+000) (2, -2.97830442339590950000e+000) (3, -1.17419759719026920000e+000) (4, -3.15686535033324030000e+001) (5, 2.80763801745106890000e+000) (6, 3.16596298072400770000e+000) (7, 2.32684002167888200000e-001) (8, 9.61403875300278980000e+000) (9, 9.43445666023994600000e-001) (10, 7.68479406225161730000e+000) (11, -7.49310730638512280000e-001) (12, -1.25444723308368330000e+000) (13, -1.65425040192121200000e-001) (14, -5.58029816774908840000e+001) (15, 2.13355247500967730000e+000) (16, 2.85465232907538360000e+001) (17, 6.07921931674725080000e+000) (18, 1.47593551740077530000e+001) (19, 4.86029819038203030000e-001) (0, -1.73404642965691450000e+000) (1, 3.66198874985950330000e-001) (2, 1.41014442394757630000e+001) (3, 1.28144571249983020000e+000) (4, 8.67603254346965610000e+000) (5, 1.97734010216702030000e+000) (6, 2.67614085259573540000e+001) (7, 1.60611657664115830000e+000) (8, 1.68363499285479610000e+001) (9, 1.61865650723163350000e+000) (10, -3.45362021289533950000e+000) (11, 6.27998143793344070000e-001) (12, 4.36105957795917120000e+000) (13, -7.81272402924714230000e-002) (14, 1.38554983161505290000e+001) (15, -1.59551979541092970000e+000) (16, -2.18730988851318430000e+000) (17, 2.53768852136095900000e-001) (18, 2.63416781472097090000e+001) (19, -8.32179748836537780000e-001) (0, 1.80087710484326670000e+001) (1, -3.92025173322460940000e+000) (2, 1.51470334495130000000e+001) (3, 2.14441541804022020000e+000) (4, -1.49634067709675180000e+001) (5, -6.39895516274165630000e-001) (6, -1.46414084319469570000e+001) (7, 1.00780877375326900000e+000) (8, -7.56115538960833280000e-001) (9, -5.06995227418036040000e-001) (10, -1.59239079059281820000e+001) (11, -1.99901794397944310000e-001) (12, 3.13068970134172100000e+001) (13, -9.78384097438640850000e-001) (14, 5.91473525967940890000e+000) (15, -2.92686438371004380000e-002) (16, -4.79006185086545420000e+000) (17, -1.62798114752707680000e-003) (18, 1.45307189483497600000e+001) (19, -1.72620588534459360000e+000) (0, 6.72941672172792100000e+001) (1, 5.41217512606254060000e-001) (2, -3.16234046074822640000e-001) (3, 5.70150990246994200000e+000) (4, -6.86777914803922410000e+000) (5, -2.33512783668800280000e+000) (6, -1.84940482620032680000e+001) (7, -3.28653054317166960000e-001) (8, 7.91754565220195690000e+000) (9, 8.83279388562912770000e-001) (10, 2.80416906425513800000e+001) (11, 2.30070478831698690000e+000) (12, -2.41787254017593650000e+001) (13, 2.13934335481759370000e+000) (14, 2.58971844148945680000e+001) (15, 3.36548131546667940000e+000) (16, -8.26552243369771070000e-001) (17, 4.15420928586148870000e-001) (18, -5.89612090075232190000e-002) (19, 7.22020497397292350000e-001) (0, 8.93759128479872440000e+000) (1, 5.66316928184001480000e-001) (2, 3.97837585761936770000e+001) (3, 3.95296619471578850000e-001) (4, -2.05291544675780170000e+001) (5, 3.56607949204465280000e+000) (6, 3.99912860854989290000e+000) (7, 2.15493624508898670000e-001) (8, 2.65157052548767070000e+001) (9, 1.05504288337491570000e+000) (10, -1.69493789292527270000e+001) (11, 4.76868452761468920000e+000) (12, 2.37417862593450390000e+000) (13, 1.58661879202184550000e+000) (14, -4.40466909646855950000e+000) (15, 8.04710049009549010000e-001) (16, -1.42545326743539270000e+001) (17, 3.46432087486173990000e-001) (18, -1.27875148571349990000e+001) (19, 1.84399447148883940000e+000) (20, -7.23757673449472950000e-001) (21, 1.26186765130746110000e+000) (22, 1.14406387887158080000e-001) (23, 1.67370846670041760000e+000) (24, -1.44957823460353820000e+000) (25, 2.00611452885983920000e-001) (26, -1.64870093089939120000e+000) (27, 8.48211251530106130000e-001) (20, -2.57751609834150970000e+000) (21, -3.96840947054489530000e+000) (22, 3.13081710416016490000e+000) (23, -1.17944764796964360000e+000) (24, 8.29810924171475510000e-001) (25, 1.84501472987789070000e+000) (26, 5.43855857636149960000e-001) (27, 7.54118131795648350000e-001) (20, 3.65506947060369660000e+000) (21, 2.94198543537483510000e+000) (22, -2.93085562424311030000e+000) (23, -9.55721277454373630000e-001) (24, 1.21718426292087600000e+000) (25, -2.08849275186816770000e+000) (26, 1.21063360096690830000e+000) (27, 3.06242387558881380000e+000) 

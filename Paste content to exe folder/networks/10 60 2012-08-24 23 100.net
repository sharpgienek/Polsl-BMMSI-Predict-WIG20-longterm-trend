FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 4 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (4, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.79033415985091150000e+001) (1, 8.51526859799938280000e-002) (2, 5.83803727261057780000e-001) (3, -6.34782343412825250000e-001) (4, -1.56085003124576310000e+001) (5, 4.22044861589749910000e-001) (6, -7.44902248964490980000e+000) (7, -1.31927836958250430000e+000) (8, -9.08413061201178210000e+001) (9, 3.76593852734364850000e-001) (10, -2.35566867020806010000e+001) (11, -6.37409823486854150000e-002) (12, 3.91182799677831530000e+001) (13, 1.71673326510599390000e+000) (14, -3.74724405744627590000e+001) (15, -8.52891881124044900000e-002) (16, -2.21203964212663640000e+001) (17, -1.42725654283096390000e-002) (18, -3.25307936977572960000e+001) (19, 4.07233280057545510000e+000) (0, 1.03465196982500340000e+001) (1, 5.40311419144920420000e-001) (2, -1.13960751566475850000e+001) (3, 1.08564627352734110000e+000) (4, -2.27457007198850400000e+001) (5, -1.48516600165128130000e-001) (6, -1.52219842084299690000e+001) (7, 4.39087567136268790000e-001) (8, -9.60115971787313070000e+000) (9, -8.28822770026840460000e-001) (10, 2.25574637463373160000e+001) (11, 1.70936170907776370000e+000) (12, 5.74455272434816070000e+000) (13, 4.12182685666449560000e-001) (14, 7.93173824771474900000e+001) (15, 9.77204957736629300000e-001) (16, 3.85031313592433300000e+000) (17, -1.83469313227381720000e-001) (18, 2.16239560714990090000e+001) (19, 2.08337700211499800000e+000) (0, 1.32392751058931810000e+001) (1, 3.99670237403649320000e-001) (2, 1.61114682790002380000e+000) (3, 3.92237256225586310000e-001) (4, 1.14603056885128600000e+000) (5, 1.68566040927578850000e-001) (6, 9.81353722624890070000e+000) (7, -4.48161341556797380000e-001) (8, 1.42281910654311140000e+001) (9, 3.60302079618787350000e-001) (10, -4.27292588811240570000e+000) (11, 6.80599816829524220000e-002) (12, 1.08382400817745680000e+001) (13, 1.51924999917640150000e+000) (14, -1.89087072256257860000e+001) (15, 1.38158239482823960000e-001) (16, 1.30080367987129540000e+001) (17, 7.03976346374131870000e-001) (18, -4.37681685586904920000e+000) (19, 1.12904048253403430000e+000) (20, -1.26830402712061190000e+000) (21, 2.96006083464143980000e-001) (22, 7.73210820915609550000e-001) (23, 7.46816448466904200000e-001) (20, 5.75991431349728300000e-001) (21, 9.75387531725749100000e-001) (22, 1.42904059985716700000e-001) (23, 5.00161796058629720000e-002) (20, 5.83916515661168760000e-001) (21, -1.76982330386708190000e+000) (22, -1.08034642072348210000e+000) (23, 2.02312722808398910000e+000) 

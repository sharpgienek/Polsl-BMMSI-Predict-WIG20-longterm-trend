FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.26559537301644580000e+000) (1, -3.20292472241184000000e+000) (2, -9.29282591956863870000e+000) (3, -1.08922805113972810000e+000) (4, -1.19528982253189980000e+002) (5, 3.99249615478478680000e+000) (6, -1.51175662623174510000e+001) (7, 3.90554358053529740000e+000) (8, 3.04147200361589970000e+001) (9, -2.88253448099359980000e+000) (10, 4.32930879409883720000e+001) (11, 9.78974847978541400000e-001) (12, 1.77221648249362110000e+001) (13, 1.72993043386327710000e-001) (14, 3.15103412085154840000e+000) (15, -8.08804889691321920000e-001) (16, 1.99016113321245200000e+000) (17, -1.31176018284449360000e-001) (18, -1.22262364655114570000e+001) (19, -4.12478483494963080000e-001) (0, 7.89078086352852780000e+001) (1, 8.65059059437321750000e-001) (2, -3.36029179272561650000e+001) (3, 5.25903568971688770000e-001) (4, -3.01974119293571840000e+001) (5, 2.66163337192210320000e+001) (6, -9.29784383115234620000e+001) (7, 2.64748917824840290000e+000) (8, -1.64125230041506650000e+002) (9, 3.22677090819741470000e+000) (10, 1.48955172341383320000e+001) (11, 1.08587850912903380000e+001) (12, -2.85608930935154070000e+001) (13, 1.19435673765657850000e+000) (14, 1.70074374171587690000e+002) (15, -3.27155589635860360000e+000) (16, 2.20884055730777150000e+001) (17, 4.40783801144047780000e+000) (18, -1.62201549907236310000e+002) (19, 1.55078572194943320000e+001) (0, -9.93879896354933480000e+000) (1, 3.99257254991043310000e-001) (2, 9.31165685954235210000e-001) (3, 1.77559092489606630000e-001) (4, 1.74965177710720500000e+001) (5, -4.11670777327905300000e-001) (6, 8.57258257814136830000e+000) (7, -9.22074622943542670000e-002) (8, 1.58153050511494960000e+001) (9, 6.50472428549830450000e-001) (10, 7.81377616853367220000e+000) (11, 8.08215405458010410000e-001) (12, -3.42168007459172460000e+000) (13, 6.86262228939246280000e-003) (14, 1.38782928217872660000e+001) (15, -1.19528572042957260000e-001) (16, 1.37809020321834530000e+001) (17, 4.93885408892949860000e-002) (18, 1.10068795516357340000e+001) (19, -4.25330003902176350000e-001) (0, 6.74793832714847590000e+000) (1, -5.38623190243741200000e-002) (2, 1.02363730141529760000e+001) (3, 3.91760078029106730000e-001) (4, -6.68398543286225700000e+000) (5, 6.18430689568567060000e-001) (6, -2.33099105781881450000e+001) (7, -5.18340332236705060000e-001) (8, -8.56861630153539090000e+000) (9, 1.12838894697352510000e+000) (10, 1.70109404078115390000e+001) (11, 4.92656701187876140000e+000) (12, 2.04625158714820770000e+000) (13, -1.56866378137640070000e-003) (14, 1.39486320893051980000e+001) (15, -3.14565366474859640000e+000) (16, -1.24901297258168050000e+000) (17, -5.30546198631006160000e-001) (18, -2.19658071749428210000e+001) (19, -1.63169031135663660000e+000) (0, 4.61786214371867420000e+001) (1, 8.42339061037438270000e-001) (2, -4.11803804096371540000e+000) (3, 2.63311309691247790000e+000) (4, -4.89664869963359310000e+001) (5, 6.70586673818922340000e-001) (6, 7.20654125324531240000e+001) (7, 1.16754209851785970000e+000) (8, 2.13684706199670440000e+002) (9, 2.89454061572207740000e+000) (10, 3.11258915710146370000e+002) (11, 1.97951672166563090000e-001) (12, 1.13240557221659690000e+002) (13, -3.43527447477357470000e-001) (14, 7.51836793658537630000e+001) (15, 3.54404554899567790000e+000) (16, 6.06603226433315830000e+001) (17, 4.84618252712551430000e-001) (18, 5.93797596579287370000e+001) (19, 3.03367839630269390000e+000) (20, 1.80317792636358830000e+000) (21, -6.89188180138101820000e-002) (22, 3.78088679283237860000e+000) (23, -2.17070067280292720000e+000) (24, -7.92170395450356720000e-001) (25, 6.07626615699754850000e-001) (20, -1.13022305661437630000e+000) (21, -1.70567203546668080000e+000) (22, -5.58305792328645190000e+000) (23, 3.47967529071900610000e+000) (24, 2.29862896125887190000e+000) (25, 2.82693930729516250000e+000) (20, -3.81753489420116000000e-001) (21, 7.60099232026810290000e-001) (22, 5.41400268832922140000e-001) (23, -5.51405873778867410000e-001) (24, -1.91882112397696860000e+000) (25, 1.21694739337309050000e+000) 

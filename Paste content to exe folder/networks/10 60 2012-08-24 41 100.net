FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.76121601928336520000e+000) (1, 2.84096233508980810000e+000) (2, 1.29857379751851560000e+000) (3, -2.00976992002884960000e-001) (4, 3.92727530792883210000e+000) (5, 2.53973421117953140000e+000) (6, 1.34278567049301630000e+000) (7, 9.74579524382425900000e-001) (8, -1.25123593229845080000e+000) (9, 9.01066140439721000000e-001) (10, 7.41538943062688820000e+001) (11, 4.94601007609090870000e-001) (12, -1.30702868231701630000e+000) (13, -9.27150916261374610000e-002) (14, 1.89019537555523950000e+001) (15, 1.16196833228683840000e-002) (16, 2.19354072670157340000e+001) (17, 1.15581552359219030000e-001) (18, 1.58487909384197200000e+001) (19, 1.72354228734874760000e+000) (0, -1.80605509266409890000e+001) (1, -6.05794338920731650000e-001) (2, -2.64752768350539860000e+001) (3, -4.13537281185456960000e+000) (4, 3.02235221146030850000e+001) (5, 2.62097847638782240000e-002) (6, 9.19274542366229500000e+000) (7, 2.90901563865899710000e-001) (8, -7.74146900707387450000e-001) (9, 9.27451387328929460000e-002) (10, 1.59339035565711370000e+001) (11, 3.90790295338656000000e-001) (12, -3.07430459436216050000e+000) (13, -6.21146594559562450000e-001) (14, 5.13785125244160220000e+000) (15, 5.67555358490741790000e-001) (16, 2.35732651614866760000e-001) (17, 6.48230445126590560000e-001) (18, 5.26183426077807680000e+001) (19, 2.06339400436523430000e-001) (0, -1.03677986677612760000e+001) (1, 3.20424971339642650000e-001) (2, -4.14646596533590590000e-001) (3, -1.50737141006532300000e+000) (4, 3.48916781833197550000e+001) (5, -4.96110767910692640000e-001) (6, 1.02782127296898530000e+001) (7, -2.00953660870605340000e-001) (8, 6.61163787352880480000e+000) (9, 3.92869387661205770000e-001) (10, -1.08426303248084580000e+000) (11, -3.35959825020143390000e+000) (12, 1.97043801136634010000e+001) (13, -4.54896442558532510000e-001) (14, -2.75658335980788610000e+001) (15, -1.18020247877934130000e+000) (16, 3.71922546893387510000e+000) (17, -3.28892334438261320000e-001) (18, -1.50336857255761900000e+001) (19, -3.50605792249750750000e-001) (0, 6.75612032961736330000e-001) (1, 5.45514248589751170000e-001) (2, 1.78123979860896520000e+000) (3, 2.45195038810026890000e+000) (4, 4.29319995662805540000e+000) (5, 5.20458548074336340000e-001) (6, -4.00960562967808800000e+000) (7, 3.33215248399373960000e-002) (8, -2.75697358644004530000e+000) (9, 2.76222589978736610000e-001) (10, -1.19386276130342530000e+001) (11, -3.64960823556128630000e-001) (12, -9.24902989577115700000e+000) (13, 3.80719629653738790000e-001) (14, 1.29717179481164710000e+001) (15, 7.01257132241684960000e-001) (16, 1.24997797391703780000e+001) (17, 2.92557397709053480000e-001) (18, -2.79062907568401430000e+001) (19, 9.67178999359437850000e-001) (0, 4.10262185713895280000e+000) (1, -6.02339620532368340000e-001) (2, -5.24738387098763950000e+000) (3, -3.80119893904022370000e+000) (4, 2.41287612892273950000e+001) (5, -9.21129503937926810000e-001) (6, -1.53043824912832550000e+000) (7, -1.29558886416168670000e-001) (8, -2.57808293886516400000e+001) (9, 2.92809479468408570000e-001) (10, -1.66444727220093540000e+001) (11, -3.39004958836240660000e-001) (12, -1.30281589010112150000e+001) (13, -3.34250278543741620000e-001) (14, -7.77508577931522900000e+000) (15, -4.55096126628837470000e-001) (16, -3.86807475651712810000e+000) (17, -2.31419651142468150000e-001) (18, 3.03737542812266930000e+000) (19, 9.09691619502538180000e-001) (0, -8.88444808576096530000e+000) (1, -1.95295238626746250000e-001) (2, 1.05175964524601560000e+001) (3, 3.14416527283646220000e-001) (4, 1.72362433276436280000e+000) (5, 3.88903268893355750000e-001) (6, 3.37064154898757500000e+000) (7, -6.39312162272367560000e-002) (8, -5.28347575061748830000e+000) (9, 2.23259856023126980000e-001) (10, -2.41219424639531970000e+000) (11, 1.29809951980881170000e+000) (12, -2.70305078067925100000e+001) (13, 1.06841087059129740000e-001) (14, -1.01603976849266750000e+001) (15, -1.99727168070772290000e-002) (16, 2.62961080280090750000e+000) (17, -6.77816028701113460000e-001) (18, -5.49663935819300780000e+000) (19, -1.55615288942029640000e-001) (20, 5.99507880431708770000e-001) (21, 1.34456350545571570000e+000) (22, 1.41787509540144700000e+000) (23, -1.83241547084288800000e-001) (24, -1.82756219835034340000e+000) (25, -2.82539438384598190000e-002) (26, 5.89478538111249280000e-001) (20, 1.30948474432438890000e+000) (21, -1.86294333037256870000e+000) (22, -2.37810250819242920000e+000) (23, -7.48991393905302780000e-001) (24, 5.15749179106816280000e-001) (25, -2.13963980035635170000e+000) (26, 4.35225876516980300000e-001) (20, -1.84208700639224390000e+000) (21, 6.03888477614512250000e-001) (22, 6.84421345450517690000e-001) (23, 1.29201474026280170000e+000) (24, 1.55006162955818040000e+000) (25, 1.95386979196376980000e+000) (26, 1.46539033359451310000e+000) 

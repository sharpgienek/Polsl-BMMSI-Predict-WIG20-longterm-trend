FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.66599964506441120000e-001) (1, -2.52364721469100990000e-001) (2, 9.53441576939280820000e+000) (3, 9.96119823919227460000e-002) (4, 5.09935091715308000000e+000) (5, 4.53375368955778620000e-001) (6, 9.60929105141308780000e+000) (7, 3.04253375765631720000e-001) (8, 1.22795360274405110000e+001) (9, -4.63090486272833330000e-001) (10, 1.18495082290940770000e+001) (11, 2.70555730959183280000e-001) (12, 7.69024468278044090000e+000) (13, 1.76515091491436960000e-001) (14, 3.98262360774197430000e+000) (15, 5.72175311386358910000e-001) (16, 5.04326436412319710000e+000) (17, -3.37164351241259100000e-001) (18, 1.21029555477328690000e+001) (19, -2.61072703047857400000e-001) (0, -1.75822287147254810000e-001) (1, -3.67967217806305200000e-001) (2, -1.36425594428538130000e+001) (3, -2.18425751812987730000e+000) (4, 5.68490643914947640000e+001) (5, -8.33514909033263450000e-002) (6, -1.49013793157116830000e+000) (7, 3.38141037870247980000e+000) (8, -1.08616066797381650000e+002) (9, -2.95730825977042640000e-001) (10, 1.74271124913200240000e+001) (11, 4.65136174268344950000e+000) (12, 1.96278419261410590000e+001) (13, -1.26778681017500680000e+001) (14, 3.60273553284422520000e+000) (15, -1.41775250414097530000e+000) (16, 4.20389840406406280000e+001) (17, 8.80334632913615360000e-001) (18, 1.58108635301500530000e+002) (19, 5.59550032682792350000e-001) (0, -1.10926995453560160000e+001) (1, 1.13869540532146820000e+000) (2, -2.76103872714264000000e+000) (3, 1.87717822474158560000e+000) (4, 1.80028538334782700000e+001) (5, -6.93263736988791620000e-001) (6, 1.12593811070923260000e+001) (7, -4.86107671828530040000e-001) (8, 2.34868004831499310000e+001) (9, 2.77223782749400140000e+000) (10, 1.41314646643909380000e+001) (11, 3.65262385252963670000e-001) (12, 8.59598557301771930000e+000) (13, -5.06155242283099490000e-001) (14, -2.10184599294221910000e+000) (15, -1.78634176056463390000e+000) (16, 6.75012101988852550000e+000) (17, 1.21080970826058890000e+000) (18, 6.64419808327800700000e+000) (19, -7.72880818578608330000e-002) (0, 2.32056584005861350000e+001) (1, 1.68713338437041350000e+000) (2, 1.55985786564478100000e+000) (3, -1.94666969416380380000e+000) (4, 1.22711428530244950000e+001) (5, -1.43411039447390690000e+000) (6, 3.11039181206917800000e+001) (7, 1.20716751534794130000e+000) (8, -5.29507420446458990000e+001) (9, 5.23876659197377470000e-001) (10, -1.33065613881700000000e+000) (11, 9.56805624872154870000e-002) (12, 9.99986305682480570000e+000) (13, -1.73858074691215590000e+000) (14, 1.87955364324818710000e+001) (15, -2.58521543769506370000e-001) (16, 1.55287666794667580000e+001) (17, 5.45532545660892780000e+000) (18, -1.26521581332840980000e+001) (19, 5.71349889017197120000e+000) (0, -1.79921844134429030000e+001) (1, 1.52837982104464140000e-001) (2, -5.47886707838890800000e+000) (3, -7.89023287577424900000e-001) (4, 6.87518567077408700000e+001) (5, -3.35038545819861790000e+000) (6, -4.64848030565790040000e+001) (7, -3.51850022617907540000e-001) (8, 4.09501452277022440000e+001) (9, 8.61884798290201370000e-001) (10, -1.28775190467715460000e+001) (11, -4.21909924412289340000e+000) (12, 1.35843292630839390000e+001) (13, 2.24453097070654200000e+000) (14, -1.13238456111328420000e+001) (15, 5.58489345186894500000e+000) (16, 5.90801828157129310000e+001) (17, -8.82404465230173660000e-002) (18, -8.11918892884443860000e+001) (19, -5.65961916013477450000e-001) (0, 3.10707256921023680000e+000) (1, 7.78354211166582540000e-001) (2, 8.97824982831522610000e+000) (3, 1.75778859844191620000e+000) (4, -7.27494483608551960000e+000) (5, 8.08226348936068150000e-001) (6, 1.19912755425405740000e+001) (7, 1.39322830729547960000e+000) (8, -1.03528072936025360000e+001) (9, -6.44376819433560290000e-002) (10, 3.01923373695311420000e+001) (11, 1.22053332589108040000e+000) (12, 4.81843655494403150000e+001) (13, -1.55790880785921040000e-001) (14, -4.79128167494868360000e+001) (15, 2.92669259484379960000e+000) (16, -2.17411228350749820000e+001) (17, 1.06669721476929900000e+000) (18, 7.37043820080501890000e+001) (19, 7.81936859157453530000e-002) (20, 6.10437406393636280000e+000) (21, -3.16891372884789750000e-001) (22, 3.06129065030666330000e+000) (23, 1.03573785311597690000e+000) (24, 1.19802772381584120000e+000) (25, -7.67874840169927460000e-001) (26, 4.66266344525337190000e-002) (20, -5.80790504117941440000e+000) (21, -1.86243031132736700000e+000) (22, -2.94368324766435930000e+000) (23, 1.00963659479249260000e+000) (24, -3.25951164320557480000e+000) (25, 2.71226411687503880000e+000) (26, -1.17770172570190500000e-001) (20, 7.82397179142410720000e-002) (21, 2.55076483114613110000e+000) (22, 3.77913631214744710000e-002) (23, -2.11931722791941770000e+000) (24, 2.10747450552856460000e+000) (25, -3.04157595117318950000e+000) (26, 4.61532870767065260000e+000) 

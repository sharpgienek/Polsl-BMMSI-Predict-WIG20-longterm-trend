FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -9.24779804571762830000e+000) (1, 3.57713243935287200000e-001) (2, 1.86255149912280470000e+000) (3, 3.08753837674497930000e-001) (4, 3.42490342438209710000e+000) (5, 5.50269513025990340000e-002) (6, -9.64935741992475650000e+000) (7, 4.63947771876970230000e-001) (8, -1.27070213917270140000e+000) (9, -4.33533207589554770000e-001) (10, 5.04550737064121700000e+000) (11, 2.23641296124369970000e-002) (12, -3.31484660908383160000e+000) (13, -8.34060876597518040000e-001) (14, 1.16171624486976310000e+001) (15, -4.61354581050118950000e-001) (16, -1.74183566443672400000e+001) (17, 7.79044586978975270000e-001) (18, -2.57872138332224310000e+001) (19, 1.44144738844585310000e-001) (0, 1.07095970513363920000e+001) (1, 9.71706980860747140000e-001) (2, 1.41134758910660140000e+000) (3, 4.34420508657058280000e-001) (4, 8.07793768934303100000e+000) (5, 3.97890463769719590000e-001) (6, 1.86774117509434560000e+000) (7, 2.63339101777705310000e-001) (8, 1.63774727925299570000e+001) (9, -1.22878972420115340000e+000) (10, 1.93136221899518860000e+001) (11, -3.04913955487769170000e-001) (12, 1.90018575552162620000e+001) (13, 2.12088213941765070000e-002) (14, 6.13937497264533840000e-001) (15, 3.05300502242477960000e+000) (16, 6.71510205452326760000e+000) (17, -7.55433734366600770000e-001) (18, 1.49690988702785170000e+001) (19, -4.78358793643115070000e-001) (0, -2.47212453892265390000e+001) (1, -1.35199548615559650000e+000) (2, 1.51784450549440280000e+001) (3, 1.31957760829368300000e+000) (4, 2.68350674845066450000e+001) (5, 9.54389906301964960000e-001) (6, 1.55683518275111020000e+000) (7, 1.77723915991755450000e+000) (8, 1.68865703197036120000e+001) (9, -5.52943808514982660000e+000) (10, 2.82462486209008500000e+001) (11, 9.20948892391339260000e-001) (12, -1.70070068268051710000e+000) (13, -2.83840964602988910000e+000) (14, 2.10957452084777800000e+001) (15, -9.44519926806082990000e-001) (16, 3.54219854674155070000e+000) (17, -3.37551213804523580000e-001) (18, -3.10916123365521490000e+001) (19, -1.39884815319584570000e+000) (0, 1.04699178991969490000e+002) (1, -1.82478252257240820000e-001) (2, 1.15846931948907450000e+001) (3, 6.64302384092239960000e-001) (4, 2.21970262162603480000e+001) (5, -2.97387739820404030000e+000) (6, -3.33423974021833970000e+000) (7, -7.32376870208721780000e-001) (8, 8.22355932972469890000e+000) (9, -1.63313861262891820000e+000) (10, -5.97729213781564680000e+001) (11, -3.28438622143221970000e+000) (12, -4.12203216957144040000e+001) (13, 1.47745932027899900000e+000) (14, -1.83309188982957830000e+002) (15, 2.82098350727954460000e+001) (16, -9.94272218818369850000e+001) (17, 1.03069935432467050000e+000) (18, -1.56407299998330590000e+001) (19, -9.46089755109428420000e-002) (0, 1.58000545230142320000e+001) (1, 1.33800212741791990000e+000) (2, 2.23391809627491920000e+000) (3, 1.31701232762856280000e+000) (4, 8.27992955368887440000e-003) (5, 8.77863945321739610000e-001) (6, -2.66897932449154710000e+001) (7, -3.91791953190230080000e-001) (8, -1.33364055605871970000e+001) (9, 7.06168718544851190000e-001) (10, -1.19581558923720320000e+001) (11, 3.19534422050093080000e-001) (12, 3.60311111714518190000e+001) (13, -1.16259811827017790000e-001) (14, 4.64141525013005120000e+000) (15, 9.03346634336540800000e-002) (16, 4.90479412480551690000e+000) (17, -4.27465440647978150000e-001) (18, 8.87763887450330100000e+000) (19, -3.48151180211207060000e-001) (0, 8.10748222375210470000e+001) (1, 2.02878147325063640000e+000) (2, -4.59312005750612400000e+001) (3, 1.30147332076488170000e+001) (4, -1.06274350433464480000e+002) (5, 2.44505281055601880000e+000) (6, 7.46701837734489120000e+001) (7, 4.26552864933771310000e-001) (8, 9.57130825446449190000e+001) (9, -4.43075671574239550000e-001) (10, 8.86444839680285310000e+000) (11, 1.14457924902953970000e+000) (12, 6.66074478325041640000e+001) (13, 1.04338279740775740000e+000) (14, 4.61281070445316240000e-001) (15, 3.76969451183771900000e-001) (16, -3.65549350647756700000e+001) (17, 8.29060415169000820000e+000) (18, -8.45736777760549780000e+001) (19, 3.11939490008231070000e+000) (0, -2.45755165797087650000e+001) (1, 1.56379386142549740000e+000) (2, -4.74223982870584370000e-001) (3, 6.53134098388521660000e-001) (4, 4.02352082477462500000e+001) (5, -7.24534430764577570000e-001) (6, 1.06298558434891780000e+001) (7, 7.82333487706482620000e-002) (8, 1.35810440920159830000e+001) (9, 2.00389842654206650000e+000) (10, 4.10872660439110950000e+000) (11, 4.84860411009602200000e-001) (12, -2.15196754102430440000e+000) (13, -1.48279658680503750000e-001) (14, 1.61792585451214310000e+001) (15, -1.17318799896699040000e+000) (16, -3.19894663294185120000e+000) (17, 1.87961944736991730000e+000) (18, -2.36487565325205380000e+000) (19, -2.18876749962231550000e-001) (20, -4.14372561429958710000e+000) (21, 1.03599217542304970000e+000) (22, 2.73128331467550560000e+000) (23, 5.35786171345081890000e-001) (24, -1.34139739166186020000e+000) (25, 6.75171632939608730000e-003) (26, 3.86861930459700920000e+000) (27, 2.21432731108163150000e+000) (20, 1.30526999115219640000e-001) (21, 1.72395805996555930000e+000) (22, -1.95311955947086950000e+000) (23, -2.04453954263030500000e+000) (24, -6.15267373449091550000e-001) (25, 1.18016341669276240000e+000) (26, -4.53238059605668600000e-001) (27, 3.04098766503826110000e-001) (20, 2.21791701255254030000e+000) (21, -2.87588293838201240000e+000) (22, 3.78993540110358240000e-001) (23, 1.72370246386532200000e+000) (24, 1.45478133594847560000e+000) (25, -1.59701968163162380000e+000) (26, -1.88533786713755850000e+000) (27, 1.98565396619376330000e+000) 

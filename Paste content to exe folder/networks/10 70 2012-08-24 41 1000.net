FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.00194643355504940000e+002) (1, 3.62836490403692870000e-001) (2, 1.11412295552752400000e+001) (3, -1.48925408294197790000e+001) (4, 3.37355500453858920000e+001) (5, -2.07893769913907180000e+000) (6, 5.28822394510725790000e+001) (7, 6.74313139044829700000e-001) (8, 7.74075157322656790000e+000) (9, 7.55861107791795050000e-001) (10, 4.27706993324447990000e+001) (11, 3.31129648902273570000e+000) (12, -9.02833246334813030000e+000) (13, 8.42908698498486260000e-001) (14, 3.42663227279094910000e+000) (15, -1.83027816782735540000e+000) (16, 2.60359326662312430000e+001) (17, -1.83013063252157140000e+000) (18, 3.08700761930428660000e+001) (19, -6.16878819314914840000e+000) (0, 4.07911261592686980000e+000) (1, 8.43762597081968320000e-001) (2, -1.74916134562272060000e+001) (3, 4.55768541527260940000e+000) (4, 2.80093447017615420000e+001) (5, 1.75211462456781490000e-001) (6, 5.22811772130289260000e+001) (7, 5.68034096882990670000e-001) (8, 2.93085156980970890000e+001) (9, 1.32603295679055840000e+000) (10, 5.04519251567025290000e+001) (11, 1.32028857103931020000e+000) (12, 3.79336369454248870000e-001) (13, 1.03516699450452360000e-001) (14, 1.90802663302658400000e+001) (15, -1.39501578549777320000e+000) (16, 1.22272921002369090000e+001) (17, -2.75144037843016610000e-001) (18, 2.42573739060888370000e+000) (19, -8.00740508155312390000e-001) (0, -1.44703417698043940000e+001) (1, -3.13951844488728760000e-001) (2, 1.32780272620737530000e+001) (3, 1.28714729402514890000e+000) (4, -1.03605171013312930000e+001) (5, 8.48024654705772370000e-001) (6, -2.15746185723350800000e+001) (7, 5.57319286026898150000e-002) (8, -1.64868118772879520000e+001) (9, -1.16569441256036010000e+000) (10, -7.35871914384427760000e+000) (11, 8.40680244778878700000e-001) (12, -7.88897849726232230000e-001) (13, -9.85652381250361360000e-001) (14, 1.38888089762598770000e+001) (15, 1.41995198175178470000e-001) (16, 1.09709235860117290000e+001) (17, -1.50691682385094920000e+000) (18, -1.29928715636431030000e+001) (19, 9.97804929442229200000e-001) (0, 3.20232578075642560000e+001) (1, 1.75765668832070160000e-002) (2, 7.27759522691217780000e+000) (3, 1.00796565407426650000e+000) (4, 1.83486995729537910000e+000) (5, 1.22450914249489310000e+000) (6, -4.02042522785236050000e+000) (7, -8.18822403069362210000e-002) (8, -3.40402279549509500000e+001) (9, -2.62123955096779880000e-001) (10, 4.36095093144810950000e+001) (11, 2.00331382507549090000e+000) (12, 3.42518691257003790000e-001) (13, -7.84137976086666240000e-002) (14, 1.54437089474501030000e+001) (15, -2.20226092466814240000e+000) (16, -6.60127710417309020000e+000) (17, -1.71654994364348480000e+000) (18, -1.33532977164148350000e+001) (19, -4.35351343626509240000e-001) (0, 6.34019400086160760000e-001) (1, -1.11606826851961790000e-001) (2, -3.22480575466148570000e+000) (3, 1.72646065710106070000e-001) (4, -3.29598640790081410000e+000) (5, 9.38842335577068370000e-002) (6, -3.09736079709475920000e+000) (7, 4.56677018091873610000e-002) (8, -4.94000308453286600000e+000) (9, 3.04570016289830490000e-001) (10, -3.89692924662337290000e+000) (11, -2.82077788012126160000e-002) (12, -6.10260479960949360000e+000) (13, 1.11179329599304420000e-001) (14, -1.39915630092246500000e+000) (15, -2.77407882623396160000e-001) (16, -3.15902848291852490000e+000) (17, 1.34216387812432110000e-001) (18, -4.55727687386998600000e+000) (19, -8.74162798370229370000e-001) (20, 5.33834748159790370000e-001) (21, 2.26247253771801170000e+000) (22, 6.26021645397157430000e-001) (23, -2.42778474411170550000e+000) (24, -6.74406286217568260000e-001) (25, 6.23101129221948560000e-002) (20, -2.22860926175534680000e+000) (21, -2.10248667448338810000e+000) (22, -4.86980590538346810000e+000) (23, 5.66696947025133560000e+000) (24, -6.95621092806801670000e+000) (25, 1.47398367570211520000e-001) (20, 1.19242092592334110000e+000) (21, -9.39779507661202000000e-001) (22, 2.45515250175186010000e+000) (23, -1.77144485878202020000e+000) (24, 6.92709566487691570000e+000) (25, 3.04409940534065490000e+000) 

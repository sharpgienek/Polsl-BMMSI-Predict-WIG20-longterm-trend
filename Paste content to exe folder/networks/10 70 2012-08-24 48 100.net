FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.35842328311481350000e+000) (1, 1.13413422890608500000e+000) (2, -7.04692286088340580000e+000) (3, 8.58146477848161920000e-002) (4, -1.82347065380607560000e+001) (5, 1.70925861992965760000e+000) (6, -4.19358108798361330000e+001) (7, 1.10998895881396950000e+000) (8, -1.91032056696986320000e+001) (9, 7.05370423469736800000e-002) (10, 7.07349586619824590000e+000) (11, 9.20649428138928360000e-001) (12, -1.37783852901184440000e+000) (13, -2.71181821738504910000e-002) (14, 1.48625609864130760000e+000) (15, 9.85762941972467170000e-001) (16, -3.37184365508064900000e+000) (17, 2.07014804382170850000e-002) (18, -3.52946121462000710000e+000) (19, 6.20254882098749790000e-001) (0, -6.50293867390942810000e+000) (1, -2.88010628510752760000e-001) (2, 1.00086925341690100000e+000) (3, -3.30855940946704900000e+000) (4, 2.69054162566031430000e+001) (5, -9.75773611893348100000e-001) (6, 6.57337465988156010000e-001) (7, 2.12667442186982610000e-001) (8, 1.87722832328503570000e+000) (9, 7.10989204948470950000e-001) (10, -1.13475917499499700000e+000) (11, -2.29350741394854430000e+000) (12, -2.43780526586389960000e-001) (13, 7.29951916187715160000e-001) (14, 8.86843751762076240000e+000) (15, 5.77294713303514140000e+000) (16, -1.04878535807470620000e+000) (17, 8.79838713654540800000e-001) (18, -8.45594207494930040000e+000) (19, -2.21022638689040650000e-001) (0, -2.43292666762199690000e+001) (1, -3.52616696660483670000e-001) (2, -6.93590682719301820000e+000) (3, -2.55451938802094990000e-001) (4, 8.18882574395049720000e+000) (5, 2.97292036729451200000e-001) (6, -2.46650031370872200000e+000) (7, 1.23147201971058110000e+000) (8, 1.61113337968556680000e+001) (9, 3.21493952546460020000e-001) (10, -2.35691996468741430000e+001) (11, 3.54611706694014650000e-001) (12, -4.87790834625067050000e+000) (13, 3.26929434517161780000e-001) (14, 1.61733841414712740000e+001) (15, 5.24535863002373980000e-001) (16, 2.69637667895551690000e+001) (17, 2.11858427102465520000e-002) (18, 3.72205048320890870000e+000) (19, 1.65986573031920350000e+000) (0, 7.01448408405367370000e+000) (1, -4.40230268766580330000e-001) (2, -9.18038404903127490000e-001) (3, 1.32014587297966080000e-002) (4, -1.43150268811316850000e+001) (5, 4.97333939312185540000e-002) (6, -1.04150604413979120000e+001) (7, 1.29077088380700140000e-001) (8, -2.00999593510974070000e+001) (9, 2.10394146355395800000e-001) (10, -2.05830504694773600000e+001) (11, -2.64563834824452000000e-001) (12, -3.71202499929391650000e+000) (13, 1.90329852541714200000e-001) (14, -1.27659946542452810000e+001) (15, 2.00401838763274890000e-001) (16, -1.26786064856113270000e+001) (17, -1.31643459258915820000e-001) (18, -1.03772992442561060000e+001) (19, 7.35541983707741260000e-001) (0, -9.48118639216133370000e+000) (1, 4.87879114532333740000e-001) (2, -1.18842083681657540000e+000) (3, 3.11315896649164750000e+000) (4, -1.08297579565564350000e+001) (5, 4.09711313896505720000e-001) (6, 1.44597602150020110000e+000) (7, 2.67690309987599970000e+000) (8, 2.70823340641639800000e+001) (9, -4.11264205395998670000e-001) (10, 2.11727868893310890000e+001) (11, -5.82540363519722160000e-001) (12, 6.21426264265278320000e+000) (13, 1.81560806170295820000e+000) (14, 1.53416300796797960000e+001) (15, 8.94296914255868210000e-001) (16, -1.02733244680393070000e+001) (17, 2.68632685306974710000e-001) (18, 5.54481095744051890000e+000) (19, 3.10988507174302100000e-001) (0, -1.03216626282750710000e+001) (1, 3.51407323725028030000e-001) (2, 3.56743681178334660000e+000) (3, 7.02058681438180180000e-001) (4, 8.75065085626563710000e-001) (5, -1.15710607782663940000e-001) (6, -5.08187775766017060000e+000) (7, -1.39920599303320430000e-001) (8, -1.05858314417663160000e+000) (9, -1.22491418697277710000e-001) (10, -1.06617496465294050000e+001) (11, -2.08641353144505050000e-001) (12, -2.20260127478817300000e+001) (13, -3.93654341628749820000e-002) (14, -7.75435894198553920000e+000) (15, -1.07991092859007390000e+000) (16, -1.79163953828075220000e+001) (17, 1.12511086248176670000e-002) (18, -2.97582253839050740000e-001) (19, -5.98911815755258090000e-001) (20, -1.27700678569280850000e+000) (21, 4.02104056926464340000e-001) (22, 2.55596702572476080000e-001) (23, -2.42998352465877470000e+000) (24, 5.58557836699718810000e-001) (25, -1.54584961590419590000e+000) (26, 1.12675975346705700000e+000) (20, 1.65650613915856290000e+000) (21, -1.49470536186949120000e+000) (22, -1.78079019106408600000e+000) (23, 1.82102813870715590000e+000) (24, 7.08886329803131490000e-001) (25, -7.53286056209984680000e-001) (26, 4.02726900354425150000e-001) (20, -2.45872387426894490000e-002) (21, 9.95349547186230480000e-001) (22, 1.59270734584907610000e+000) (23, 1.12076371166660940000e+000) (24, -1.39291629920289070000e+000) (25, 2.29765444135255370000e+000) (26, 7.36607002013516700000e-001) 

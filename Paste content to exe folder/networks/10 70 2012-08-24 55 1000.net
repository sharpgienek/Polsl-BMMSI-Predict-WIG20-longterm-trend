FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.48573673656233750000e+000) (1, 1.81111708607459040000e-002) (2, 2.22771872642275110000e+000) (3, 1.16971086246329210000e+000) (4, -3.72677120372573820000e+001) (5, 2.56050799278445720000e+000) (6, -3.27594815929262980000e+000) (7, -3.29405632341904340000e-001) (8, -3.61782870073623360000e+001) (9, 4.20770692062545530000e-001) (10, -7.86663727334099240000e+000) (11, 2.71563424983056570000e+000) (12, -2.12096694589664200000e+001) (13, 2.19855617161514690000e+000) (14, 3.12409591218727110000e+000) (15, 5.74559789911390560000e-001) (16, -6.48673386727036410000e+000) (17, 1.03443498516934820000e+000) (18, 7.04657948237592270000e+000) (19, 4.36059354370161250000e-001) (0, 1.61550740008484940000e+001) (1, 3.82112285679763190000e+000) (2, 6.83605863263650890000e+000) (3, 3.41932963740173460000e-001) (4, -1.14025698209479000000e+001) (5, 6.75869044586229100000e-001) (6, -5.12757494562976180000e+001) (7, 2.48293171639021800000e+000) (8, -4.04478410730335900000e+000) (9, 1.84166548260954690000e+000) (10, 1.75010170039729860000e+001) (11, -1.50846721315051830000e+000) (12, 4.23242042558574170000e+001) (13, -2.26622669686778270000e+000) (14, 1.95504278381257710000e+001) (15, 3.09995040397123560000e-001) (16, 1.92481783160437060000e+001) (17, 4.76013623082047640000e-001) (18, 5.51793912971911100000e+001) (19, -3.27802990113263880000e+000) (0, 3.00900597850049780000e+001) (1, -3.58939305856066600000e-003) (2, -1.12432705316820220000e+001) (3, -2.97054465637383200000e+000) (4, 1.12912560781076100000e+001) (5, 8.83707884489668080000e-001) (6, -1.97687567289680680000e+001) (7, 4.93525108783914150000e-001) (8, 2.69027838677664270000e+001) (9, 7.23489224457979320000e+000) (10, 3.87985894424155480000e+001) (11, 4.00673084001941060000e+000) (12, 8.55203357264656270000e-002) (13, 9.79669225555371840000e-001) (14, 4.40038297767870430000e+001) (15, 3.69706173148912760000e+000) (16, 4.46633009799963790000e+001) (17, -4.23585645171161150000e-001) (18, -2.04335802188987510000e+001) (19, 3.29183314528216970000e-001) (0, -2.47751019855097070000e+001) (1, 2.86963394199581910000e-002) (2, 7.58370312236815610000e-001) (3, -4.48117050468439080000e-001) (4, -2.47976515188309770000e+000) (5, -9.20043346897007730000e-001) (6, 7.19690883893068460000e-001) (7, -9.44174027029950240000e-001) (8, 6.74578703119393940000e-001) (9, -1.96553198163571280000e-001) (10, 1.00734081964315030000e+001) (11, 7.23498628724140500000e-001) (12, 3.28381662327576020000e+000) (13, 4.92222323345173570000e-001) (14, -1.91525375656164200000e+001) (15, -1.15065647117847500000e+000) (16, 3.42306393399914640000e+000) (17, 1.99906986528554930000e-001) (18, 1.75413875351970070000e+001) (19, -3.62930442113881760000e-001) (0, -3.75906096775204760000e+001) (1, 1.56410478286498120000e+000) (2, 1.47064648076736460000e+001) (3, 7.73955530771415430000e-001) (4, 3.99036251166610260000e+001) (5, 1.16256068537298020000e+000) (6, -6.30771345418101870000e+000) (7, 1.09327709751342940000e-002) (8, -1.51405794140294600000e+000) (9, -6.47221882102542830000e-001) (10, 9.78189449067056670000e+000) (11, -1.18199388691839810000e+000) (12, -2.70217998643254620000e+001) (13, -8.00585100726296070000e-001) (14, -1.65354453443944640000e+001) (15, -4.11137280606533210000e+000) (16, 7.70299298339824020000e-001) (17, -8.91154577292355250000e-001) (18, 4.31019254446951120000e+001) (19, -2.76863476414864930000e+000) (0, 2.90401239287734720000e+001) (1, 2.41281315133231770000e+000) (2, 1.41365718905993390000e+000) (3, 5.11483097145990830000e-001) (4, -3.46978173260832180000e+000) (5, 1.60395218598800860000e+000) (6, 1.27132141885001670000e+001) (7, 2.77630940913920490000e-001) (8, 1.88323568708419270000e+001) (9, 6.99940363856365820000e-001) (10, 4.95228879231805340000e+001) (11, 4.20883010966766280000e-001) (12, 8.11278947881011800000e+000) (13, 1.64081252779181650000e-001) (14, 2.59469930775841070000e+001) (15, 6.08160845659150850000e-001) (16, 4.12358524652226510000e+000) (17, 9.59598003323448860000e-002) (18, 5.21239296849527630000e+000) (19, -7.95039138249758690000e-001) (0, -2.14728350702658060000e+001) (1, 5.02868483284212410000e-001) (2, -2.44932490814098210000e-001) (3, 4.27315939766488020000e-001) (4, 2.53987713161625590000e+001) (5, -4.12719438020712590000e-001) (6, 1.39071783280294010000e+001) (7, 6.79157371162686490000e-001) (8, 1.13615976249623870000e+001) (9, -2.97633554026035750000e-001) (10, -1.51931536175827520000e+001) (11, -3.32763967965821060000e+000) (12, 3.21543920611202910000e+001) (13, -1.17468138819600150000e-001) (14, -1.23150676406254650000e+001) (15, 3.10185751121948480000e+000) (16, -1.45545644833973590000e+001) (17, 1.52360706520946910000e+000) (18, 4.68284111961836750000e+000) (19, 1.32248939940266180000e-001) (20, -2.18133182957689580000e+000) (21, -1.68863380911181070000e+000) (22, -7.04946310133693240000e-001) (23, 2.87964358759572200000e+000) (24, -1.41794554269752360000e+000) (25, 2.82949009943436860000e+000) (26, 2.19324009992787830000e+000) (27, 6.29306521685566560000e-001) (20, 1.74812199335930370000e+000) (21, 2.22856427648016140000e+000) (22, -1.93599156544410110000e+000) (23, -2.60483753673429770000e+000) (24, -7.68935845514042040000e-001) (25, -6.89344649896939000000e-001) (26, -3.01640217792813250000e+000) (27, 1.69468357412967620000e+000) (20, 9.13628546851992930000e-002) (21, -7.71883332722344660000e-001) (22, 2.50966352641347300000e+000) (23, 1.47992931756345590000e-002) (24, 2.13503320010514350000e+000) (25, -1.91387231326764380000e+000) (26, 8.02817617977430010000e-001) (27, 1.34508988410771520000e+000) 

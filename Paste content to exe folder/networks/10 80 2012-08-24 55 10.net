FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.73590836063560950000e-001) (1, -5.27268103368269900000e-001) (2, -6.10925184569851230000e-001) (3, -6.48988853635346970000e-001) (4, 5.02807747784605350000e-001) (5, 7.36489113626788370000e-001) (6, -2.87614379771289840000e-001) (7, 1.02322029656457780000e+000) (8, 1.06130844572603820000e+000) (9, -1.48374442809421940000e+000) (10, 6.82425105702699760000e-002) (11, 2.52056715995627620000e-001) (12, 7.84357007027787210000e-002) (13, -3.35924802413691990000e-001) (14, -3.60953114565673690000e-001) (15, -4.50168492844396200000e-001) (16, 1.45107385099001980000e+000) (17, 1.31554073118644310000e-001) (18, 4.04298919592491040000e-001) (19, -2.09949405217080100000e+000) (0, 3.05826785398989910000e+000) (1, -1.12086539012291330000e-001) (2, -6.40674640786611630000e-001) (3, 3.56069401106018090000e-001) (4, -1.21102036678779120000e+000) (5, 2.48600899014058550000e-003) (6, 8.74731360676095030000e-001) (7, 1.49523304479351550000e-001) (8, -3.02885501175473860000e+000) (9, -3.10902947975559010000e-001) (10, 1.85619175330155390000e+000) (11, 5.39294489557723860000e-001) (12, -4.67231084050723000000e-001) (13, 5.47694837200316180000e-002) (14, 1.28440782382159610000e+000) (15, -1.45991842562260670000e-001) (16, -1.87860996590397840000e-001) (17, -1.45570671507398830000e-001) (18, 3.21197269026465460000e+000) (19, 9.31005318147087310000e-002) (0, 5.10653586686291350000e-001) (1, 4.14707285068324600000e-001) (2, 8.08014553097216040000e-002) (3, 3.05981002083733360000e-001) (4, 1.83009878311737370000e-001) (5, 3.95637355287393740000e-001) (6, -6.95432236200448780000e-002) (7, 7.87630249906202900000e-001) (8, -7.52733298489362880000e-001) (9, 8.84796780803860790000e-002) (10, 2.62874603487338710000e-001) (11, 4.96763476767557500000e-001) (12, -1.22640122639198390000e+000) (13, -2.73589466926189570000e-002) (14, 1.14365707976562850000e+000) (15, 4.66123301459482940000e-001) (16, -5.29159081934208130000e-001) (17, -1.02750495552443750000e-001) (18, 1.03431259571439370000e+000) (19, 4.96653087070662190000e-001) (0, 6.93428739335770870000e-001) (1, -4.78596397207304710000e-002) (2, -3.12890994488629830000e+000) (3, -3.38471384032255210000e-002) (4, 1.08962922318560170000e-001) (5, -3.35468953668289630000e-002) (6, -1.86838583204465670000e-001) (7, -4.17640099021142630000e-002) (8, -3.20471561007839070000e+000) (9, -5.95943750898127230000e-001) (10, 3.19366214311680620000e+000) (11, 6.52018854015175150000e-002) (12, 6.10866368545256110000e-001) (13, -1.52567517108203270000e-001) (14, 1.37656088671678130000e+000) (15, -2.82179725273933730000e-003) (16, -3.14988162488630060000e+000) (17, -3.79981407053734400000e-002) (18, 8.66975848321363870000e-001) (19, -8.91316129919807880000e-002) (0, 6.62401371735520270000e-001) (1, 4.42316677329253170000e-001) (2, -3.21422488756383990000e+000) (3, 6.04643049946777420000e-001) (4, -3.09183108691190520000e+000) (5, 3.02611221506937140000e-001) (6, 9.19128333993911470000e-001) (7, 7.10658850501029950000e-001) (8, 8.36336748857920980000e-001) (9, -4.89011334687037700000e-002) (10, 3.16479251378036520000e+000) (11, 3.06545474586804090000e-001) (12, -6.04169676535610710000e-001) (13, -1.57624122792661500000e-001) (14, 5.93421270931754560000e-001) (15, 2.82612085105719390000e-001) (16, -5.99190432117423790000e-002) (17, -1.14137594040720390000e-001) (18, 3.13448245473496010000e+000) (19, 3.22205591555083600000e-001) (0, 7.71327981333427950000e-001) (1, 4.15611739942486960000e-001) (2, -3.10828616528210500000e+000) (3, 3.23401880635409700000e-001) (4, -5.76295981458388780000e-001) (5, 2.63298476780506610000e-001) (6, 1.91418735963450580000e+000) (7, 3.73073795890653310000e-001) (8, 3.17197635177803770000e+000) (9, 3.64363559322110950000e-001) (10, 1.83819858897093490000e+000) (11, 3.00462783974922930000e-001) (12, 5.48395088494177400000e-003) (13, 3.18788393727372080000e-002) (14, 1.62562075739472980000e-001) (15, 3.23735517870299580000e-001) (16, 1.89484609567774440000e-001) (17, 2.12852919388184240000e-001) (18, 3.05741336178966620000e+000) (19, 3.62132735239337700000e-001) (20, 4.13869321033622230000e-001) (21, -2.31553989703632470000e-001) (22, -1.71492302753036230000e-001) (23, -9.79511932015277730000e-002) (24, 3.98914577073136490000e-001) (25, 4.20732589628168560000e-001) (26, 3.11076826275420380000e-001) (20, -9.30473429926530070000e-002) (21, 9.12943258996074420000e-001) (22, -1.06166374045229040000e-001) (23, -2.11018268220079940000e-002) (24, 3.57671065250978640000e-001) (25, 3.77391524529211380000e-001) (26, 4.65143826106904190000e-001) (20, -2.45726907299925220000e-001) (21, -3.79463278009949390000e-001) (22, -3.58129029675684000000e-001) (23, -1.54600469245559540000e-001) (24, -5.32505346858331170000e-001) (25, 2.24747658021207940000e-002) (26, 1.02783667451610340000e+000) 

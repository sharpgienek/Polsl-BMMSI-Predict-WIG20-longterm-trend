FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.45537334777962400000e+000) (1, 1.19202660909189380000e-002) (2, 3.18436427144895080000e+000) (3, -3.74636544486503130000e-001) (4, 1.04172689967208910000e+001) (5, -4.37217208351341550000e-003) (6, 1.20989439099914370000e+001) (7, -1.48415481820211890000e-001) (8, 1.51229015605369150000e+001) (9, 1.71657416264850650000e-001) (10, 8.57646670976710370000e+000) (11, 5.67110888833704320000e-002) (12, 5.17354351217115750000e+000) (13, 5.99510583625149640000e-002) (14, 8.74361886294073010000e+000) (15, 5.98555423983392120000e-001) (16, 8.47052088349095200000e+000) (17, 1.02212729583478570000e-001) (18, 4.22838307486699880000e+000) (19, -5.71490239462992930000e-001) (0, 1.41386420252130130000e+001) (1, 2.67705633203216390000e+000) (2, 1.70123870716488700000e+001) (3, -5.72765740207113130000e-001) (4, 4.43660450394407930000e+000) (5, 1.73959796162704450000e+000) (6, 3.69125693898302960000e+000) (7, 7.49955816367032460000e-001) (8, 2.63187826279568850000e+001) (9, 9.16620773154367070000e-001) (10, 2.89793300481399680000e+001) (11, 1.19346487801426160000e-001) (12, 1.90956752220964320000e+001) (13, -6.34195430194564150000e-001) (14, -3.19816244190273440000e+001) (15, 1.37976090128576970000e+000) (16, 4.01854183800105180000e+001) (17, -8.86118527104468920000e-001) (18, 4.75080958386257850000e+001) (19, -1.24026872546343010000e+000) (0, -2.86150203253258050000e+001) (1, 2.18641923542210880000e-001) (2, 9.76967951444651210000e-001) (3, -4.47286930279970800000e-001) (4, 1.29004676426756110000e+001) (5, 5.04419743705469690000e-002) (6, -2.31280493786989360000e+000) (7, 1.84136786295826190000e-001) (8, 2.20911703595121590000e+001) (9, 1.11931307786042630000e+000) (10, -2.04296041998231000000e+001) (11, -7.90786976326826180000e-002) (12, -3.75394245557166030000e+000) (13, 3.37363650229922040000e-001) (14, -2.53598534210011770000e+000) (15, 2.65049694164329440000e+000) (16, 1.37419401877673110000e+001) (17, 8.14432215725930390000e-001) (18, -2.97613371160667340000e+001) (19, -4.30616640434131390000e-001) (0, -9.64697929685356840000e-001) (1, 2.20317497791560680000e-001) (2, 4.66242749433796710000e+000) (3, -5.75134375463251770000e+000) (4, -6.83394606534473680000e+000) (5, -5.61855031469726260000e-001) (6, 2.43069913202136290000e+000) (7, -2.24406962961138930000e+000) (8, 9.12918908765802330000e+000) (9, 2.44225295300549980000e-001) (10, -4.87634523513620800000e+000) (11, -2.97812208816918170000e-001) (12, -1.49448587402838500000e+001) (13, -1.49285132067725420000e-001) (14, 8.60911444026151250000e+000) (15, 1.22543678542331700000e-001) (16, 1.05836596562860710000e+000) (17, 5.28933370875017350000e-001) (18, -1.92588200613377010000e+001) (19, -1.76178504915893620000e-001) (0, -2.45189947486447050000e+001) (1, -5.49004110666956760000e-001) (2, -1.62047406931563710000e+001) (3, 2.63134950605152350000e+000) (4, 1.83510314720232940000e+001) (5, -1.58633815031320440000e+000) (6, 1.34135489157208060000e+001) (7, -2.59248689414900560000e-002) (8, 3.73566869725603610000e+001) (9, -6.95035117406673090000e-002) (10, 1.85676163412840300000e+000) (11, 2.24791878848646510000e-003) (12, 4.62575517878890000000e+000) (13, 3.43505064666972450000e-001) (14, 1.12780518832851320000e+001) (15, 2.10261657808582260000e+000) (16, -2.43989470369570650000e+001) (17, 5.28339659611988590000e-001) (18, -4.26483595467027000000e+001) (19, 1.22849728504990470000e+000) (0, -2.58479850796057730000e+000) (1, 2.13281442051659380000e+000) (2, -8.93139738899460060000e+000) (3, -7.08138518896289540000e-001) (4, 9.55638952822332580000e+000) (5, -6.14284210938407130000e-001) (6, 1.66889860687605170000e+001) (7, -7.95128558892647770000e-003) (8, -6.42259807553240770000e+000) (9, -2.07679450161481140000e-002) (10, 1.02399387898328950000e+001) (11, 1.88034133780851100000e-001) (12, 1.46202385143302700000e+000) (13, -8.13835998774357640000e-002) (14, 3.66105534915664110000e-001) (15, -1.09423633491172080000e+000) (16, 4.76091301895126760000e+000) (17, 1.07235490015835650000e+000) (18, -2.08550254312684340000e+001) (19, 5.71790256387947000000e-001) (20, 2.37945809296587460000e+000) (21, -2.55908944654106850000e-001) (22, 2.30882435518086400000e-001) (23, -1.20672462067354250000e+000) (24, -4.71679023513345510000e-001) (25, 9.09132044451633760000e-001) (26, 5.91720651749798490000e-001) (20, -2.30692658262328500000e+000) (21, 1.89446205912219080000e+000) (22, -2.41689577220110510000e+000) (23, 1.43413685962002120000e+000) (24, 2.04684705719595250000e+000) (25, -7.82486823482030250000e-001) (26, 8.98808112090282000000e-001) (20, -9.47859126764286410000e-001) (21, -1.28101404668341610000e+000) (22, 1.75972589566138100000e+000) (23, 3.02145086960800450000e-001) (24, -1.19728670845623490000e+000) (25, -5.87693595590590760000e-001) (26, 1.14723115097206100000e+000) 

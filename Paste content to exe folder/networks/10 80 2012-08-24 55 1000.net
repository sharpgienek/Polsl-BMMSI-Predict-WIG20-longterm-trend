FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.04598106897014950000e+001) (1, -9.38611423894570860000e-001) (2, 2.43657520220624340000e+001) (3, 4.81500617731705550000e-001) (4, -6.35703267557236100000e+000) (5, 1.69648771296744270000e+000) (6, -5.05535961947682540000e+001) (7, 9.79133588851634260000e-001) (8, -4.13533946371673690000e+001) (9, -7.18736143568371010000e-001) (10, 1.83203750968506330000e+001) (11, -4.68056177710654280000e-001) (12, -3.03265830412264540000e+000) (13, 1.22138486768058610000e-001) (14, 2.71221583875593940000e+000) (15, 1.21154928790521250000e+000) (16, -3.17542537024131870000e+001) (17, -1.10736054015091700000e+000) (18, -9.65197707822300010000e+000) (19, -1.53315414910340910000e+000) (0, 2.58459098816423440000e+000) (1, 5.90838987425711390000e-001) (2, 2.04101306210074930000e+001) (3, 1.84349941212130930000e+000) (4, 2.28206653322339650000e+001) (5, -2.98944168764583470000e+000) (6, -2.18831066740628800000e+001) (7, -1.26868339873594200000e+000) (8, 3.94290688559102020000e+001) (9, 1.12826736227782540000e+000) (10, -1.73432129292928250000e+001) (11, 4.38965628837170390000e-001) (12, 1.87901784677580320000e+001) (13, 4.32378863563291290000e+000) (14, 2.26335787277996620000e+001) (15, 7.03787180842799560000e-001) (16, 2.59738862321847250000e+001) (17, 3.68411510288661460000e+000) (18, 5.99814056347825140000e-001) (19, 1.11781946715559480000e+000) (0, 3.23736543888859530000e+000) (1, 1.05969352616216150000e+001) (2, -6.48376448327151710000e+001) (3, 2.28819380668916180000e+002) (4, 7.80805560428120430000e+002) (5, 4.69312824834851310000e+000) (6, 3.35063494050536260000e-001) (7, 3.77330308330468470000e+001) (8, 1.30449025734221260000e+001) (9, -1.33836086017216440000e+001) (10, 3.03642808640151180000e+001) (11, 1.37617492740984630000e+000) (12, 8.94600634231791790000e+001) (13, 8.37800289060970730000e+000) (14, 1.92081204750217470000e+002) (15, 3.04538672747649700000e+000) (16, 3.10858207369367220000e+002) (17, -4.04193255365167300000e+000) (18, 9.42403859632866220000e+002) (19, -3.72329663435912340000e-001) (0, -1.39519047371040940000e+001) (1, -4.03857929444654100000e-001) (2, 2.33108767680048890000e+001) (3, -1.00649321057946710000e+000) (4, 6.65235016507697740000e+001) (5, 3.37015982861110620000e-001) (6, 2.87285781174037600000e+001) (7, 7.86592773936762750000e-001) (8, 5.99005089399088960000e+001) (9, -2.03470826406757330000e+000) (10, 7.10741771169017510000e+001) (11, 1.29308242361592600000e+000) (12, 8.47591775729446440000e+000) (13, 3.82109617245889150000e-001) (14, 1.46043656637101780000e+001) (15, 4.25525848530873850000e+000) (16, -3.88011261939240480000e+001) (17, -8.86442834143144180000e-001) (18, -2.15547118920814600000e+000) (19, -7.83555192818432890000e-001) (0, -2.03852502858983090000e+000) (1, 1.88812430689709990000e+000) (2, -1.12003566452657710000e+001) (3, 1.61325957928194450000e-002) (4, 1.57868975550801170000e+001) (5, 3.17916701552754050000e-002) (6, -1.13257483885060560000e+000) (7, -5.96430300086613130000e-001) (8, 1.53586141936403410000e+000) (9, 6.63200113741499900000e-001) (10, -2.21771352063814970000e+000) (11, 1.82073993956335830000e+000) (12, 3.82488915187338340000e+000) (13, 1.00979054844756670000e+000) (14, 2.93698223193000130000e+001) (15, 2.63047839385507490000e+000) (16, 1.07423334244476740000e+001) (17, 8.78525616471877880000e-001) (18, -6.25984597478944660000e+001) (19, -4.23276300961929590000e-001) (0, 1.12998565669641310000e+001) (1, 1.26825067415683820000e+000) (2, -1.78627265285154420000e+001) (3, 4.54537742158373260000e+000) (4, 2.61560156590118600000e+001) (5, -1.36304688966997280000e+000) (6, -8.51054475431718240000e+000) (7, -1.05277742888950380000e-001) (8, 4.36338573429710230000e+000) (9, -1.38494808355778080000e+000) (10, -3.28920743364429380000e+001) (11, 3.51503180897930930000e+000) (12, -4.62141150399328850000e+001) (13, -1.13093504977046070000e+000) (14, 2.39860998292787640000e+001) (15, -3.22512869828939540000e+000) (16, 1.80732086668088460000e+001) (17, -2.02729426018778060000e+000) (18, -2.42582814207299010000e+001) (19, 5.86769099780918080000e-002) (20, -2.15594240726816590000e+000) (21, -3.92714236944572360000e-001) (22, 7.61603842290334510000e-001) (23, 1.52251512630066200000e+000) (24, 4.59664185162335760000e-001) (25, -5.71669586283592770000e-001) (26, -3.66273445269116090000e-001) (20, 1.31668880271245350000e+000) (21, 1.73555648114200300000e+000) (22, -1.46482896234092700000e+000) (23, 4.48217820578331040000e-001) (24, -2.79287778682492590000e+000) (25, 1.61641728094443130000e+000) (26, 2.57941118412978950000e+000) (20, 8.71713984934453960000e-001) (21, -1.58534859346474180000e+000) (22, 7.92080035537700460000e-001) (23, -2.06500714893678610000e+000) (24, 2.79312670014780990000e+000) (25, -1.14943399970977040000e+000) (26, 6.97878085395030710000e-001) 

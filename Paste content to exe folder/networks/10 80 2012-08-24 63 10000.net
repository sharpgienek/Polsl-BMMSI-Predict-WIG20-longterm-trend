FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.33052463433129300000e+001) (1, 1.67907189336386880000e-001) (2, 5.98276783563448830000e+001) (3, 1.83058943006827260000e+000) (4, 5.07473589340680750000e+001) (5, 1.45743945944889500000e+001) (6, 5.62427317066056440000e+000) (7, 5.50953320985304250000e-001) (8, 4.02351803639698460000e+001) (9, 1.03124801688554830000e+001) (10, -3.06434222162634700000e+001) (11, -4.71600842121764900000e-001) (12, -3.55687087812911220000e+001) (13, 2.28908572109401960000e+000) (14, 6.00618752505359980000e+001) (15, 6.68948544649113330000e+000) (16, 1.26271036100846050000e+002) (17, 4.62355298835239960000e-001) (18, 3.29380683859305990000e+001) (19, 2.24475453278739940000e-001) (0, 1.50000000000000000000e+003) (1, 3.32873273282685320000e+002) (2, 4.75564309656425170000e+002) (3, 1.15267484841128130000e+001) (4, 1.68710220656826810000e+002) (5, 3.20668906520967030000e+002) (6, 1.97292234964889900000e+002) (7, 3.29934679400913130000e+002) (8, -1.22945284103638070000e+003) (9, 2.84000470133583460000e+001) (10, 1.44903740332470080000e+003) (11, -1.36660843625847830000e+001) (12, -8.54072123249546280000e+002) (13, 7.27614101084024440000e+001) (14, -5.95722159818849490000e+002) (15, 8.01542561284194650000e+000) (16, -5.76852514163847160000e+001) (17, 3.28751855438065150000e+002) (18, -1.50000000000000000000e+003) (19, 9.00661457682827520000e+001) (0, -1.12446095291155030000e+002) (1, 1.12799393188444850000e+000) (2, 3.82923636662322050000e+001) (3, -1.36676727290054560000e+000) (4, 5.37248799341291700000e+001) (5, 2.07982057166575180000e+000) (6, 5.85895816896689400000e+001) (7, 2.31494011401085410000e+000) (8, 1.35193901923430900000e+002) (9, 3.07731742955684020000e+000) (10, -1.24225888326407290000e+002) (11, -1.48012002247949370000e+000) (12, -7.37343803104463120000e+001) (13, 4.78002322416879810000e+000) (14, -1.17102941269633850000e+002) (15, 1.52604031331245030000e+000) (16, 5.06778611742681660000e+001) (17, 3.39890699425883500000e+000) (18, 2.56868536437314820000e+001) (19, -2.83155380930596840000e+000) (0, 1.71610562236056910000e+001) (1, -4.58942374241177030000e+000) (2, -1.26959703069969120000e+001) (3, 1.33568841696611980000e+000) (4, -2.21659577384071550000e+001) (5, 6.91314586137647400000e-001) (6, 7.10434903825963190000e+000) (7, -3.90330213217560620000e-001) (8, 7.02340892843924680000e+001) (9, -8.79138705623887180000e-001) (10, 1.45600784734495170000e+001) (11, 2.79974109677473660000e-001) (12, -8.46018698668746440000e+000) (13, -5.69354063961096020000e+000) (14, 8.73923560453256130000e+001) (15, 1.53423933260815650000e+000) (16, 1.30408989371272640000e+002) (17, -1.81886891753503390000e+000) (18, 6.15788836554727460000e-002) (19, -2.03720514703106660000e+000) (0, -3.49003135559943160000e+001) (1, -7.40908575574151020000e-001) (2, -1.61649603775233470000e+001) (3, -9.05046441368568490000e-001) (4, 1.44017987737739740000e+001) (5, -4.04871238545877870000e-001) (6, -3.49187820851468300000e+001) (7, 3.09560042557674330000e+000) (8, -1.19701362993598690000e+002) (9, -3.33291907952461490000e+000) (10, 2.31774068442895780000e+001) (11, 3.43412693610820430000e+000) (12, -4.96200768510221120000e+001) (13, -9.11851461177441650000e-001) (14, -4.77455901432187910000e+001) (15, 1.81518553388351520000e+000) (16, 1.40839203534427580000e+002) (17, 8.58136785669323740000e+000) (18, 7.28390716854043210000e+001) (19, 8.92171175080427940000e+000) (0, 1.09335965638454230000e+001) (1, -5.27184613337937540000e-001) (2, -2.10426222404718640000e+000) (3, 2.91945042097583320000e-001) (4, -8.94605512350702290000e-001) (5, 1.46325511494618630000e+000) (6, 4.48859505473515060000e+001) (7, 1.88691399606063070000e-001) (8, 2.63388086478259740000e+001) (9, -5.57516182117879810000e-003) (10, -4.28973482490914650000e+000) (11, 9.45873942806340070000e-002) (12, 5.71085033364096000000e-001) (13, -1.23041642749114240000e+000) (14, 2.92731276979232400000e+001) (15, 9.04511666250362060000e-001) (16, 3.82048710841816970000e+001) (17, -1.30867446846333390000e-001) (18, 4.87304522041264040000e+000) (19, 2.69133008451333140000e-001) (0, -3.29550038176279760000e+001) (1, 1.60222005004401940000e+000) (2, -1.31658692851416940000e+001) (3, 8.59271679649605160000e-001) (4, 1.33485178798153880000e+001) (5, -4.99650333605920200000e-001) (6, -3.11110287310082260000e+001) (7, -1.10118381851443510000e-001) (8, -8.80760846868770560000e+000) (9, 8.24026892278634900000e-001) (10, 3.47965707062249900000e+001) (11, 1.24233266304416330000e+000) (12, 2.24225048637137940000e+001) (13, 2.10095690180276500000e+000) (14, 8.45837796733334100000e+000) (15, -1.19808700965186930000e-001) (16, -3.45150742416937320000e+001) (17, 6.24935516981281470000e-001) (18, 2.13577822233708050000e+000) (19, -8.13648310888907100000e-001) (20, -1.03351563212098310000e+000) (21, -8.79427696720316980000e-002) (22, 1.58537313195163040000e+000) (23, -1.83252447561356010000e+000) (24, -1.21276117509334760000e+000) (25, 5.40047899927998110000e+000) (26, 3.59309265043512750000e+000) (27, 6.14243645769388610000e-001) (20, -1.89336120533609980000e+000) (21, 2.17306628638011020000e+000) (22, 5.25962737175851150000e-002) (23, 2.34816040764454390000e+000) (24, -2.14864268693083900000e+000) (25, -3.49366073225110260000e-001) (26, -5.35614691779213930000e-002) (27, 4.08502054556038900000e+000) (20, 2.58515021587767450000e+000) (21, -2.06470682297718170000e+000) (22, -1.73011026739459290000e+000) (23, -3.26633104211751730000e-001) (24, 3.09641406400809500000e+000) (25, -4.74603943741196140000e+000) (26, -3.64895650742508650000e+000) (27, -5.51014189260035430000e-001) 

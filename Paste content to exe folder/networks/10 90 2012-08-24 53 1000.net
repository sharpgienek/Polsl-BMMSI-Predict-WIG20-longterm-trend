FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.51390395002565330000e+000) (1, 1.16483256621302460000e+000) (2, 3.61330850672851230000e+001) (3, -5.68702893561764070000e-001) (4, 7.89387414116594360000e+001) (5, 7.89838774789493310000e+000) (6, -6.32807431563465670000e+001) (7, 3.49474091234851870000e+000) (8, -7.89767773161412800000e+001) (9, 7.52728883186880630000e+000) (10, 2.00845736324310660000e+001) (11, -4.97009883831005470000e-001) (12, 7.25806315117012790000e+000) (13, 2.67665047132511620000e+000) (14, 1.51490299724835580000e+002) (15, -1.05439284999229390000e+000) (16, 1.30346738209866030000e+001) (17, -6.41992190314119030000e-001) (18, -1.85271096669433780000e+001) (19, 8.78887461776731450000e+000) (0, 1.01131969731862720000e+002) (1, 6.46783630761092470000e-001) (2, 8.51326034526952210000e+000) (3, 9.43718107168686980000e-001) (4, -4.88929771072845440000e+001) (5, 8.41389663986857330000e-001) (6, -8.48508485735083800000e+000) (7, 4.44739464900633930000e-001) (8, -3.45514196948065620000e+001) (9, -5.11736551829278910000e-001) (10, 4.30805114611686620000e+001) (11, 5.57614588467352950000e+000) (12, 1.54136045581422270000e+001) (13, -5.34645293048854110000e-001) (14, 5.65574273944811950000e+001) (15, -8.72291144958336600000e+000) (16, -6.42884858714432280000e+001) (17, -3.18670884439343590000e+000) (18, 1.00231298782622730000e+002) (19, -6.74507533315547580000e-001) (0, 1.95291431002871510000e+001) (1, 7.73283329641148990000e-001) (2, -1.81837204959558820000e+001) (3, 1.41754182156353030000e+000) (4, 4.34880761389582630000e+001) (5, -1.00962319343182430000e+000) (6, 7.49056775754384320000e+001) (7, 3.49461105849040400000e+000) (8, 1.09095173875110930000e+002) (9, -2.65236851383816140000e+000) (10, 1.64418570079511650000e+002) (11, -4.07763288691055210000e-001) (12, 8.08908563148454790000e+001) (13, -1.41728780598671400000e+000) (14, 8.89165623977035580000e+001) (15, 4.91783341209894780000e+000) (16, 8.99496519232230010000e+001) (17, -1.33807392070724560000e+000) (18, 4.73245016695119460000e+001) (19, 3.96033763616378650000e+000) (0, -6.10629375086974160000e+001) (1, -6.08240487693923360000e+000) (2, -1.48256583005166130000e+001) (3, -1.06804522434797520000e+000) (4, -2.77642023521261660000e+001) (5, 9.36561285957779770000e-001) (6, 1.72005467028613910000e+002) (7, -9.61987842436882980000e+000) (8, 1.92708941752078400000e+001) (9, 5.74464126217688940000e-001) (10, -1.92579691047147850000e+001) (11, -4.07054786509901020000e+001) (12, 4.08370958483368260000e+000) (13, 3.65619791800675520000e+000) (14, -3.02927144070859410000e+002) (15, -9.44945819937642280000e+000) (16, 1.40923652390477680000e+002) (17, 8.43539229433012850000e+000) (18, -6.26535016494884420000e+002) (19, -1.28703236365823750000e+001) (0, -4.57574404152412200000e+001) (1, -1.11299646084307110000e+000) (2, -3.57458900578905410000e+001) (3, -6.87488652025632920000e-001) (4, -1.18894854702460860000e+000) (5, -1.35853444694559400000e+000) (6, 4.79731429150727080000e+000) (7, -3.43496335383286170000e-001) (8, 3.66254614567154140000e+001) (9, -4.03820798371827490000e-001) (10, -1.85486059680947650000e+001) (11, -4.45811090430353210000e+000) (12, -3.37065519802854750000e+000) (13, 1.79989848392635030000e+000) (14, -1.40335423973855580000e+001) (15, 2.24026121886336460000e+000) (16, 4.20264565074651630000e+001) (17, 3.71344343947781130000e+000) (18, -5.00143861713292640000e+001) (19, 1.16781801920383810000e+000) (20, -1.91318799446157790000e+000) (21, 5.98639133267806210000e-002) (22, -4.66776644755675150000e-001) (23, -2.81604100380373580000e+000) (24, 2.49567660688393820000e+000) (25, 1.95340593606040440000e+000) (20, 2.67738199174543560000e+000) (21, 1.85392848220900360000e+000) (22, 2.21477308840246550000e+000) (23, 2.16344183849212660000e+000) (24, -2.18750403963741190000e-002) (25, -9.21625989230496990000e-001) (20, -8.55853573663454270000e-002) (21, -1.60289816510325320000e+000) (22, -1.09521560161160170000e+000) (23, 2.07731842171082260000e-001) (24, -1.47986255059862250000e+000) (25, 1.21307085984650790000e+000) 

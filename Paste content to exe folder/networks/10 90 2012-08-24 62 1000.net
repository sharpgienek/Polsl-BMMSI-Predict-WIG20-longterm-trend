FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.28298590519344240000e+001) (1, 6.00456332360128190000e-001) (2, -2.50834707808517190000e+001) (3, 2.94511046183915210000e-001) (4, -2.00871329379103610000e+001) (5, 1.76389337544586880000e+000) (6, 1.40625908879388020000e+001) (7, 3.52041092943962000000e+000) (8, -1.48753526267168890000e+001) (9, -9.02118024285203490000e-001) (10, -6.09990716309466750000e+000) (11, -5.72960247052528850000e-002) (12, 1.39810765644384670000e+001) (13, -2.91934448460726190000e-001) (14, -1.44471848882390310000e+001) (15, 2.89024874912233660000e-001) (16, -2.20439457809937340000e+001) (17, -1.54298651688512130000e+000) (18, -2.70550809525893500000e+001) (19, 2.77820658893796150000e+000) (0, 1.16506365182321800000e-001) (1, 7.32255082141622600000e-001) (2, -4.90607387981119200000e+001) (3, 1.27314018999560540000e+000) (4, 7.51398902108524870000e+000) (5, -3.47929841478656470000e-001) (6, -1.63021583092007030000e+000) (7, -5.51708082527639920000e-001) (8, 1.61945301248805760000e+001) (9, 2.12925142931363890000e+000) (10, -1.78991808638309370000e+000) (11, 6.79265229870737900000e-001) (12, 1.36896268273169030000e+000) (13, 6.43553888882434810000e-001) (14, 1.83835963603219670000e+001) (15, 1.02637029547688050000e+000) (16, -1.32159964041631310000e+000) (17, 1.36024290449083730000e+000) (18, 3.25846189427534800000e+001) (19, -2.43418138472491960000e+000) (0, -1.01701097440075840000e+001) (1, -4.21685509714975040000e-001) (2, 2.58044517304488430000e+001) (3, 4.26796026203492400000e+000) (4, 7.29798738774552330000e+001) (5, 1.33917176182276550000e-001) (6, 6.19900961004213790000e+000) (7, 7.57920233110188300000e-001) (8, 3.99359420546250330000e+000) (9, 1.93817492644041220000e-001) (10, 2.64405280300725350000e+001) (11, 6.45210095703382950000e-001) (12, -1.24528842954417550000e+000) (13, -1.88988667006509070000e+000) (14, 4.25679925976720600000e+001) (15, -3.50480745547522470000e+000) (16, 2.61563076190533760000e+001) (17, 3.78767804878131610000e-001) (18, 4.90562022627611040000e+001) (19, 1.67053561081757170000e+000) (0, 1.19664630628950380000e+001) (1, -3.63121780931546510000e-001) (2, -2.95412298075837260000e+001) (3, -3.19309664637088820000e-001) (4, -9.77750131131938720000e+000) (5, -1.32797342067077920000e+000) (6, -8.47749264897732790000e+001) (7, -8.88586945443741620000e-001) (8, 9.66923240447520450000e+000) (9, 1.00213426926969110000e+000) (10, -7.84384189251313480000e+000) (11, -3.30661985478605650000e-001) (12, -4.64030152020118150000e+001) (13, -3.57517220966334590000e-001) (14, -2.07287314997927760000e+001) (15, -7.88320359554505860000e-001) (16, -9.90525562444883080000e+000) (17, 3.98818325902898510000e-001) (18, 1.71675173150862260000e+001) (19, -1.47492191925427930000e+000) (0, -4.17261830865356490000e+000) (1, 6.85632734937383970000e-001) (2, -4.12654262313893310000e+000) (3, 1.94924173549255000000e+000) (4, -4.15541114135009760000e+001) (5, -9.49960832360533800000e-002) (6, 6.70293990377030870000e+001) (7, 2.45358796489027840000e-001) (8, 3.69312652166305890000e+000) (9, 1.73571561560222400000e+000) (10, 1.20577001988182600000e+001) (11, 3.50009510652322350000e+000) (12, -1.10859610242155340000e+001) (13, 2.23605007452939150000e-001) (14, -4.16966992160860310000e+001) (15, 1.23651311019609530000e+000) (16, 5.62919616793985790000e+000) (17, 1.65827056499856380000e+000) (18, 3.29833762113492880000e+001) (19, 1.95901219612767990000e+000) (0, -8.42501562805551530000e+000) (1, -2.98356916629486320000e-001) (2, 6.66657901662026740000e+000) (3, -3.16942125084896920000e-003) (4, -2.41167546727896330000e+000) (5, 4.14813779177883150000e-001) (6, -4.10555655320384890000e+000) (7, 3.25249012633827720000e-001) (8, -8.25155666043115050000e+000) (9, -4.85008827517615320000e-001) (10, -2.19862312649673970000e+000) (11, -1.96351594166820380000e-001) (12, -4.89766929331967300000e+000) (13, -4.95105218797851740000e-001) (14, -9.42784653728645420000e+000) (15, -6.53271504402150760000e-001) (16, -3.63353493984426650000e+000) (17, -6.17712617105446450000e-001) (18, -1.01386606050279560000e+001) (19, 1.14365167933202790000e+000) (20, -6.15571081316122150000e-001) (21, 1.58096105249618410000e+000) (22, 1.86414440814837090000e-002) (23, -2.15368034309996360000e+000) (24, -2.01170093603696460000e+000) (25, 9.88822829543260230000e-002) (26, 1.87206723790030230000e+000) (20, 3.73795180498208610000e+000) (21, -4.65172511808373470000e+000) (22, 2.98541605564541880000e+000) (23, 2.72890355774940920000e+000) (24, 5.85098362460935830000e-001) (25, -6.70375607027279850000e+000) (26, 1.01248310515286040000e+000) (20, -1.84887663299308260000e+000) (21, 1.24987380526563290000e+000) (22, -2.02616901826979130000e+000) (23, 1.83698681932746440000e-001) (24, 1.44906644090489340000e+000) (25, 3.91267292786072000000e+000) (26, 3.88094131638211770000e-001) 

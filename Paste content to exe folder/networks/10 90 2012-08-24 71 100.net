FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.05237074844428150000e+000) (1, 3.84630998456576940000e-001) (2, 2.61168304690378680000e+000) (3, -3.14291308885583880000e-001) (4, 8.53429772398101250000e-001) (5, -5.91956241225934040000e-001) (6, -5.27623414830092230000e+000) (7, -2.45768249991533710000e-001) (8, 1.30513713342290780000e+000) (9, 1.34065107912650090000e+000) (10, 9.11851883932509640000e+000) (11, -3.10684158833808380000e+000) (12, 5.12365947053635920000e+000) (13, 4.11917747502021750000e+000) (14, 4.86172386680925150000e+000) (15, 1.42523492895286510000e-001) (16, 1.53298313065627970000e-001) (17, 7.63167714935555800000e-001) (18, 3.26871893615638310000e+001) (19, 4.63698429861952870000e-001) (0, 9.16184586133100960000e+000) (1, 1.58123469105661420000e+000) (2, -1.07935881886645880000e+001) (3, -3.20164995650047410000e-001) (4, -4.63039498484038340000e+000) (5, 3.66403040565585200000e-001) (6, 8.84102341518144460000e+000) (7, -4.37655627261756330000e-001) (8, -6.87003318390385090000e-001) (9, 1.18439530782393710000e+000) (10, 1.96486089109273370000e+000) (11, 1.94369537580441790000e-001) (12, 4.17761301154346130000e+000) (13, -8.59897655581060290000e-002) (14, 4.30365694611211150000e+000) (15, -1.36180717285133880000e+000) (16, 3.26301474460288030000e+000) (17, -5.47939164123403160000e-001) (18, 1.93709094284707250000e+001) (19, 1.62577260368910510000e+000) (0, 3.51124372988530100000e+000) (1, -8.85805751976753930000e-001) (2, 1.12277104052104380000e+001) (3, -2.51611269381488260000e+000) (4, -7.09599419955938120000e-001) (5, -8.29356480484300110000e-001) (6, 8.40446285210981260000e+000) (7, -7.40750648203358340000e-001) (8, -2.37124021063516150000e+001) (9, -9.88414914236619540000e-001) (10, -1.04101181807450180000e+000) (11, -4.94572538460562480000e-001) (12, -8.25540867392951580000e+000) (13, 8.28108532163605470000e-001) (14, -1.37259863279032300000e+000) (15, 7.27965115198447640000e-001) (16, 7.48447457160972720000e-001) (17, -2.42917596505015710000e-001) (18, -1.16456571448927340000e+001) (19, 1.50067403662947970000e+000) (0, 3.76983175801954480000e+000) (1, 4.69957519465325660000e-001) (2, -7.54787168693077710000e-001) (3, -3.49406931657734520000e-002) (4, 4.36980026664301220000e+000) (5, 4.14573274966722140000e-001) (6, -1.03707910787689920000e+001) (7, 1.36244795575156370000e-001) (8, 1.86555895522951400000e+000) (9, 1.01786901621890590000e+000) (10, 1.32106407141978860000e+001) (11, -3.33312300561563580000e-001) (12, -3.78408119663118660000e-001) (13, 1.90608814295147890000e-001) (14, 1.40962954074861030000e+001) (15, 1.69201846519310490000e+000) (16, 1.67369508295658350000e+001) (17, 3.20950298340175130000e-001) (18, -8.71072583254180130000e-001) (19, 5.73742412372621140000e-001) (0, 6.31387438467897870000e+000) (1, 3.95236609850856960000e-001) (2, 1.28366663826138810000e+001) (3, 3.32585010109632460000e+000) (4, 1.75240320595666790000e+001) (5, 5.88066654984983120000e-001) (6, 5.28550682764177450000e+000) (7, 3.82558952728439090000e-001) (8, -5.95424219351767640000e+000) (9, 3.74009559210118360000e-001) (10, -2.71933734492799280000e+001) (11, 3.35641847687711440000e+000) (12, -3.17739433525769850000e+001) (13, -1.34884894758051880000e+000) (14, 1.10584755471752500000e+001) (15, -4.34011285100303290000e+000) (16, 2.68168382199571910000e+001) (17, -1.15550360240675040000e+000) (18, 6.23522594072733140000e-001) (19, 6.18481920758640170000e-001) (0, 3.89611956558383450000e+001) (1, 2.33155066711716320000e-001) (2, -2.80312987873519290000e+001) (3, 3.45380404913863630000e-001) (4, 8.47886220203010770000e+000) (5, 7.74344645073847810000e-001) (6, 1.23448925670739610000e+001) (7, 8.54807097949268350000e-001) (8, 9.98478188066418500000e+000) (9, 3.26911394906448690000e+000) (10, 4.44462537176541250000e+000) (11, -5.81909648064317550000e-001) (12, -5.49565408098698160000e+000) (13, 3.37762387143426490000e-001) (14, 4.62632965032664600000e-001) (15, 1.54878889131230310000e+000) (16, -2.39384797743843480000e+001) (17, -1.50340532738053280000e-001) (18, -9.77083057488864700000e+000) (19, 4.72290327235763470000e-001) (0, 6.14732292018200970000e+000) (1, 4.79055283471589210000e-001) (2, 1.70527162956867390000e+001) (3, 4.47776204799722520000e-001) (4, -1.24395737060593280000e+001) (5, 2.61242393345332670000e-001) (6, -9.46733138543735640000e+000) (7, -2.84461725758650700000e-001) (8, -9.69006567890637350000e+000) (9, 8.83002977050133310000e-001) (10, -1.53813492643780060000e+001) (11, 2.12976908639815670000e-001) (12, -8.84228736487142260000e+000) (13, 8.95887628979491590000e-001) (14, -7.03321882129005880000e+000) (15, -2.90308889108114120000e+000) (16, -3.33344376841590460000e-001) (17, -2.44851162570492080000e-001) (18, 6.28431780023310440000e+000) (19, 4.70404707783942890000e-001) (20, 2.89258928327123630000e-001) (21, 2.17132826564572080000e-001) (22, -1.39427099168464120000e+000) (23, -5.13907401807780160000e-001) (24, -1.07334757612515070000e+000) (25, -1.08058083136579410000e+000) (26, -4.13103852543119650000e-001) (27, 1.17859613992125320000e+000) (20, 1.02126640277002160000e+000) (21, 1.03104817406483610000e+000) (22, 1.53949916657081150000e+000) (23, -1.28543712404732700000e-001) (24, 2.61646100233549420000e+000) (25, 6.67701368998192430000e-001) (26, -1.99293598293882820000e+000) (27, 3.45444409127936720000e-001) (20, -1.29847884518673150000e+000) (21, -1.07469441075695470000e+000) (22, 2.63725313552598260000e-001) (23, 7.77060623209631870000e-001) (24, -1.33310264007421340000e+000) (25, 7.33903955573835140000e-001) (26, 2.40885880608824540000e+000) (27, 7.12989178948453820000e-001) 

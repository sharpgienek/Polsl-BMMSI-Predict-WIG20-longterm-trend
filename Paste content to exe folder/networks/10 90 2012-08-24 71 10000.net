FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=20 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (20, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (8, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.16903643393879800000e+000) (1, -1.17570072129550830000e-001) (2, 1.66998226526905390000e+001) (3, -5.70200713780281540000e+000) (4, 8.54338692320757500000e+001) (5, -1.96577118691145200000e+000) (6, -3.74969722887970040000e+000) (7, 1.06741087365316470000e+000) (8, -2.02203225270300630000e+001) (9, 1.34298734414640180000e+000) (10, 5.40803039943234790000e+001) (11, -4.42701947125782810000e-001) (12, 1.03353279077400420000e+002) (13, 7.35655567422339370000e+000) (14, 1.34491247038893870000e+002) (15, 9.90398547057535160000e+000) (16, 1.38256900385336050000e+002) (17, -3.06716306012586950000e+000) (18, 2.22054516234953570000e+001) (19, 1.75931479187352260000e+000) (0, -7.03350765380493660000e+000) (1, -5.99855371434946270000e-001) (2, 6.54238052393791180000e-001) (3, 1.81656183257247030000e-001) (4, 5.47102260089755430000e-002) (5, -7.12806977666642920000e-001) (6, -1.44017909413669650000e+001) (7, -3.12152508808734890000e-002) (8, -2.49686140965343810000e+001) (9, -8.84149944655897860000e-002) (10, -3.44810072432106130000e+001) (11, -1.86649166877850380000e-001) (12, -1.87959487024265530000e+001) (13, 4.19236058118727880000e-001) (14, -6.27673762443181800000e+000) (15, -1.98438418101881790000e-001) (16, -4.95966148234313620000e-001) (17, 1.73222323726833910000e-001) (18, 1.96333073855665710000e+001) (19, 4.53122880945735610000e-001) (0, 7.08260951151592050000e+001) (1, -2.45784071279247760000e-001) (2, 2.08710670321096710000e+001) (3, 2.44512933178703410000e+001) (4, 1.03538535317540280000e+002) (5, -6.91747576071806590000e+000) (6, -1.17077490146655550000e+002) (7, -1.90126382316405280000e+000) (8, 6.26928289288334280000e+001) (9, 1.45393432842286320000e+000) (10, -8.88574967153375470000e+001) (11, 2.49427852573453500000e+000) (12, -7.85236487766413930000e+000) (13, -1.09512471846753570000e+000) (14, 3.28553334844469520000e+001) (15, 2.32940013644170920000e+000) (16, -4.40371999583818410000e+001) (17, 2.27967549362106590000e+000) (18, 6.28225031199095700000e+001) (19, 9.14915837642354650000e+000) (0, -7.84923679296786790000e+001) (1, 1.90655803395159820000e+001) (2, -1.71315841424839080000e+002) (3, -1.19522401720211010000e+001) (4, 1.64464253547007670000e+002) (5, 2.37999603424318850000e+000) (6, 3.40365115451149730000e+002) (7, -2.50193836142912470000e+001) (8, 6.57048902088030900000e+002) (9, 1.79713543370817560000e+001) (10, 1.40808651114337330000e+001) (11, 1.26261675594353110000e+001) (12, -8.09404670640264360000e+000) (13, 1.13709276097495370000e+000) (14, -7.50026618704155650000e+001) (15, 1.84512336803356090000e+001) (16, 5.58748346406832680000e+001) (17, -4.33866914485376840000e+000) (18, -2.70230309961033360000e+002) (19, 1.13470822813464270000e+001) (0, -4.22453274839995880000e+001) (1, 4.29609990446590430000e-001) (2, -1.64858138504888810000e+001) (3, -3.27191178807652470000e+000) (4, -8.90452444181201310000e+000) (5, 1.08538972554041640000e+000) (6, -6.84601553246710550000e+000) (7, 2.64108061415949340000e-001) (8, 1.22785892066180690000e+001) (9, -5.62995694434405220000e-001) (10, -2.61696399582391450000e+001) (11, -1.10995522550505330000e+000) (12, -2.21445899761780930000e+000) (13, 3.07332861383098340000e-001) (14, 2.63458398967649390000e+001) (15, 8.72502257650983880000e-001) (16, 1.00204879422812440000e+001) (17, 2.65764381496211010000e-001) (18, 1.80108001749404440000e+000) (19, -1.98383811588673660000e-001) (0, -1.81215024668928030000e+001) (1, -2.67329011223771340000e-001) (2, -5.28851973648284180000e+000) (3, 2.86866930365800970000e-001) (4, 4.08054528335137870000e+000) (5, -8.41621831488114200000e-001) (6, -1.34907705115103870000e+001) (7, -4.50665893698332990000e-001) (8, 1.58899906793178380000e+000) (9, -2.41159090754465700000e-001) (10, -3.83166663787334800000e+001) (11, -2.36102950175656380000e-001) (12, -2.10983495339658590000e+001) (13, 2.10916956748669090000e-001) (14, 9.99170608430054760000e+000) (15, -1.88590839490300230000e-001) (16, 1.11827334243541860000e+001) (17, 4.54875686210963530000e-001) (18, 2.70074386382792470000e+001) (19, 1.36271460924283130000e+000) (0, 4.30694664275706960000e+001) (1, -5.74657844915939080000e-001) (2, 1.61882212251310020000e+001) (3, -2.06695967685648050000e-001) (4, 3.88796347119818080000e+001) (5, -7.78246761050625310000e+000) (6, 5.14976616976307540000e+001) (7, -3.15118809860120440000e+000) (8, -3.26658745666910020000e+001) (9, 1.39241970017921380000e+000) (10, -4.03953078898495550000e+001) (11, 2.83508095968123190000e+000) (12, -8.22497998129366010000e+001) (13, -2.82923260305957440000e-001) (14, -7.10128443227795540000e+000) (15, -4.10205026903409030000e+000) (16, 4.61173473006704460000e+001) (17, -1.93435653018167190000e+000) (18, 1.17409118210464460000e+001) (19, -9.22464210887181110000e-001) (20, 9.05929629460973550000e-001) (21, -5.98967885728040450000e+000) (22, -3.28693963484983960000e+000) (23, -4.84022902352572000000e-001) (24, -5.33405256747206910000e+000) (25, 6.67958967280811060000e+000) (26, -2.45705029670840510000e+000) (27, -1.09646036350110960000e-001) (20, 4.47969107149709780000e-001) (21, 6.01435096836099970000e-001) (22, 2.37176224871633190000e+000) (23, -1.91966163799731460000e+000) (24, 2.71574003669131200000e+000) (25, -2.64732015656326200000e+000) (26, 1.98340406016967560000e+000) (27, 2.46927025594824870000e+000) (20, -1.48031611773518450000e+000) (21, 5.89065027638020220000e+000) (22, 6.22753709180674740000e-001) (23, 2.59643631431321700000e+000) (24, 2.01611149661779440000e+000) (25, -4.19664288609615090000e+000) (26, 1.05391362058225970000e-001) (27, 1.01172582025941790000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.53769703391801650000e-001) (1, 2.76441393912903340000e-001) (2, 1.78096203289533310000e+000) (3, -1.16499061372777120000e+000) (4, -2.32953696608590750000e-001) (5, -5.73007297186333480000e-001) (6, 3.77138601742513460000e-001) (7, 1.88184920863720960000e-001) (8, 1.18822985593572030000e+001) (9, -1.37003051995682210000e+000) (10, 2.13111727948782860000e+000) (11, -1.15513067723821110000e+000) (12, 2.86890121000318080000e-001) (13, 3.03963480866953850000e-001) (14, -7.49410539896418620000e-002) (15, -2.47102193810980710000e+000) (16, -2.06248768579701510000e-001) (17, 1.80039109939181290000e+000) (18, 6.30694141118682490000e-001) (19, -4.54884477677878600000e-001) (20, -5.84034175424917420000e-001) (21, -8.51387780333168420000e-001) (0, -3.51595665581833690000e-001) (1, 3.62193251822708010000e-001) (2, 5.12203503122256000000e+000) (3, 1.98837697960297330000e+000) (4, -2.13136427270012450000e-002) (5, 4.81569360615222430000e-001) (6, 1.66062446801768430000e-001) (7, 5.32186809987403530000e-001) (8, -4.86788779235618470000e-001) (9, -1.30472517006480100000e-001) (10, 5.69291467482252230000e-001) (11, 1.89043527221419310000e+000) (12, -1.17494794530413800000e+000) (13, 4.79118776149971890000e-001) (14, 6.22873483368389210000e-001) (15, 3.91164528426521940000e-001) (16, -1.60813279605350080000e+000) (17, 2.20351740144534560000e+000) (18, 8.60396466849104870000e+000) (19, -5.43172407568300870000e-002) (20, -1.43708184974773640000e-001) (21, 3.98445618247727340000e-001) (0, 9.90720012805270670000e-001) (1, -1.43568369658144960000e-001) (2, 1.38533868246297570000e+001) (3, -3.15067938696633120000e+000) (4, -1.64263625817982480000e-001) (5, 4.59384400941622860000e-001) (6, -4.07762969424082740000e+000) (7, -3.40153078532370650000e-001) (8, 5.31029525650129750000e+000) (9, 4.79864995819322630000e-001) (10, 9.79797292341647590000e-001) (11, -1.22968148507543500000e+000) (12, 2.32553512234326830000e+000) (13, 1.11302351993159370000e+000) (14, -1.29884062357587050000e+000) (15, -2.03316383396169640000e-001) (16, 7.83404393704527300000e-001) (17, 3.02705555166936810000e-001) (18, -5.90301045983401160000e-001) (19, -3.18515506439313760000e-001) (20, -2.66485910703438610000e+000) (21, -4.03618709371862190000e-002) (0, 1.67164033265817280000e+000) (1, -3.18346880224400830000e-003) (2, 5.25214516203195910000e-002) (3, -2.46506923941784520000e-002) (4, 1.07781755519878920000e-002) (5, 3.51599950505766530000e-001) (6, 1.20987324439153450000e+000) (7, 2.16000885962397860000e-001) (8, 7.67416999100713900000e-002) (9, 7.20778321521963860000e-001) (10, 1.34745749459773290000e+000) (11, 2.37132692324231590000e-002) (12, 3.81576158445023740000e-001) (13, 7.21686913673989790000e-002) (14, 1.12257888289427090000e-001) (15, 1.81020855377186040000e-001) (16, 4.69563810372701950000e-001) (17, -2.74103513738117040000e-003) (18, -6.45796260828378770000e-002) (19, 1.58322901756208720000e-001) (20, 1.28935532621325620000e+000) (21, 3.66166307566436550000e-002) (0, 8.89927052305869770000e-001) (1, 1.34782393207500600000e-001) (2, 4.30584621025838550000e-001) (3, 2.55409014030078150000e-001) (4, 3.14832615618252930000e-001) (5, 2.36032419472836680000e-001) (6, 3.96793476063171500000e-001) (7, 7.82574936357985220000e-002) (8, -1.59468214650722230000e+000) (9, 2.41971907273333340000e-001) (10, 1.04756082419048350000e-001) (11, 2.50914930693898310000e-001) (12, 5.00874102390240290000e-002) (13, 4.83833067324188400000e-001) (14, 4.53909485594827020000e-001) (15, 2.07847023989320620000e-001) (16, 9.44011846573944320000e-001) (17, 4.73804770152138570000e-001) (18, 3.14347900259801860000e-001) (19, 2.38059305981438530000e-002) (20, 5.68159836122801090000e-002) (21, 1.39512882459316280000e-001) (0, 2.38472421974252180000e+000) (1, -1.22179595747927630000e+000) (2, 3.35302814778206060000e-001) (3, -1.50719001631112650000e+000) (4, 5.04859989062800390000e-001) (5, 8.51798715472133930000e-001) (6, 6.50197487465312470000e-001) (7, -1.77901975807830460000e-001) (8, 1.11700162802735690000e+000) (9, 6.26176051056010040000e-001) (10, 4.80217430326288640000e-002) (11, -5.41280983635031300000e-001) (12, 7.80656170774041480000e-001) (13, 8.17161640080932980000e-002) (14, -3.55464090308915740000e-001) (15, 5.91060841679352360000e-001) (16, -1.22012422624254820000e-002) (17, -1.28752131441116770000e-001) (18, -2.00903710504670400000e+000) (19, 4.30648310365589980000e-001) (20, 5.92116626563789340000e+000) (21, -6.28869441235705760000e-001) (22, 7.51741635946675420000e-001) (23, 1.24374570819377530000e+000) (24, 1.38616375119698330000e+000) (25, 9.68530048860933440000e-002) (26, 3.52514469579460640000e-001) (27, -2.30745920024012590000e-001) (28, 3.47168255245013930000e-001) (22, -1.11786831489226860000e+000) (23, -3.33405523081143850000e-001) (24, 5.30592003336063050000e-001) (25, 2.20859968915275660000e+000) (26, 2.00416485203638560000e-001) (27, 7.35825064514979090000e-001) (28, 4.26848706160807940000e-001) (22, -1.50617233889581100000e+000) (23, 1.11932054856083000000e+000) (24, -9.69963747586839560000e-001) (25, -2.42638570517020280000e-002) (26, 1.16659582947495370000e-001) (27, -7.09804195940619720000e-001) (28, 1.10471555002821000000e+000) 

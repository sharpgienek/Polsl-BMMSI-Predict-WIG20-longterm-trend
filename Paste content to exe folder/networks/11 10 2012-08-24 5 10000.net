FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.29783241087600540000e+001) (1, 1.01657079623889370000e-001) (2, -8.94042644572530600000e+000) (3, -9.24514624387404620000e-001) (4, 1.71039546582673970000e+000) (5, 2.05698786317737350000e+000) (6, 9.32640499034931740000e-001) (7, 2.36104440681150270000e-001) (8, 9.65255622651655540000e-001) (9, 3.21482289360988490000e-001) (10, 4.19454168306100770000e-001) (11, -5.02194719957470340000e-001) (12, 1.21966076841818590000e+000) (13, -2.55021198199278880000e-001) (14, 7.01562976530580420000e-001) (15, 8.23240339398183090000e-001) (16, 5.95941965904542050000e+000) (17, -1.12279943517846310000e+000) (18, -1.01183543352693180000e+001) (19, 1.04187150769412960000e+000) (20, 4.75906284139366060000e+000) (21, -6.22747874201808220000e-001) (0, 1.97835326416097820000e+000) (1, -1.88152001035884230000e-002) (2, 3.82774777547159320000e+000) (3, -3.81131554804299280000e-001) (4, 6.16271691243164050000e-001) (5, 1.90886470742822830000e+000) (6, 1.85007527922336010000e+000) (7, 6.49881423999922330000e-001) (8, 7.01890653003097830000e-001) (9, 2.35710951066755080000e+000) (10, 2.33185699546810280000e+000) (11, -4.79064737233058760000e-001) (12, 1.60806120596532360000e+000) (13, 4.72743741081199030000e-002) (14, -1.21518190488913690000e-001) (15, 1.00558248385890710000e+000) (16, 1.48511925636903140000e+000) (17, -4.86037007725946770000e-001) (18, -4.58395293305157710000e-001) (19, 3.39914916392525470000e-001) (20, 3.98842171163509110000e+000) (21, -4.71824867337698020000e-001) (0, 7.69384277316885080000e-001) (1, -1.30278661885203840000e-001) (2, 3.39175066541131720000e-001) (3, 2.22408396950551080000e+000) (4, 2.18083665180476550000e+000) (5, 5.70508892767328860000e-001) (6, -1.21048970553362940000e+000) (7, 1.28729771537481640000e+000) (8, -7.83003573432896950000e-001) (9, 1.44295533562234120000e-001) (10, 3.38862371441584760000e-001) (11, 1.49117103355408400000e+000) (12, 3.50071275112880440000e-001) (13, -2.34117480437442380000e-001) (14, 1.78637307314691540000e+000) (15, 3.50861271526684610000e-001) (16, 1.09097354377515270000e+000) (17, -6.23241947965382900000e-001) (18, -2.66124764816412940000e+000) (19, 3.80524328069234420000e-001) (20, 2.89323977265522860000e+000) (21, 5.02223999324738600000e-001) (0, -3.41045717120083860000e-001) (1, -7.42890855085348910000e-001) (2, 1.15036365944917340000e+001) (3, -7.22070749443857300000e-001) (4, 1.92857954411582290000e-001) (5, 2.81829073027915490000e-001) (6, 8.97323375053505570000e-001) (7, 6.41329387181317710000e-001) (8, 2.74869337134275150000e+000) (9, -1.05335482914213930000e+000) (10, 5.59382559959075020000e+000) (11, -4.76825329639777750000e-001) (12, 6.06723328069119440000e-001) (13, 5.03919712415259350000e-001) (14, 8.25928148383912820000e-001) (15, -1.85374109000028240000e+000) (16, -1.36817083562576940000e-001) (17, 5.75565743736770720000e-001) (18, 2.92415241511174790000e+000) (19, 2.14705849973714420000e-001) (20, 1.04525730147577810000e-001) (21, -8.78481531459348710000e-001) (0, 2.89093291840657800000e-001) (1, 5.47832582150376890000e-001) (2, 1.95161056335085710000e-001) (3, 2.22553319139730690000e+000) (4, 2.69607227224421380000e-001) (5, 3.03334345479806030000e-001) (6, 5.08511144561615610000e-001) (7, 6.50053352237433210000e-001) (8, -1.50425753914794470000e+000) (9, 2.83283852120065740000e-001) (10, -5.98773454234608040000e-001) (11, 2.59250876704891290000e+000) (12, -8.57580373315690870000e-002) (13, 5.19717740400697240000e-002) (14, 1.32998410488589690000e+000) (15, 2.64930183939782090000e+000) (16, 9.36767025487136970000e-001) (17, -8.41030562074077000000e-001) (18, 8.74516790745678010000e-001) (19, 4.81055498431019970000e-001) (20, 3.79677646841972860000e-001) (21, 1.03302004129502230000e+000) (0, 4.92068861744904350000e+001) (1, -3.13038125208844390000e-001) (2, 3.85945384360338860000e+001) (3, -1.15639516185804170000e+001) (4, 7.55746378459156180000e+000) (5, 5.98413570894413470000e+000) (6, 1.30100122418796570000e+001) (7, -1.51307443132013450000e+000) (8, 1.73863046112414900000e+000) (9, 1.51445439188426130000e+001) (10, 2.18037826887059350000e+000) (11, -7.49849952028360240000e-001) (12, 2.27645127506790960000e+000) (13, 1.13889398907721180000e+001) (14, -5.61659910521978830000e+000) (15, 2.57828163976553080000e+000) (16, -1.02455288841011920000e+000) (17, 2.00763396095245780000e+000) (18, 2.52009275312070290000e+001) (19, -2.61134408977877710000e-001) (20, -2.23661587558256050000e+001) (21, -5.67942696457778730000e-001) (22, -1.30276438039523400000e+000) (23, -6.94438055977609210000e-001) (24, -9.54309434135255370000e-001) (25, 1.00397451431347680000e+000) (26, -5.27613893488258380000e-001) (27, 8.66317812629314400000e-001) (28, 1.46954795432897160000e+000) (22, 7.55003379482958590000e-001) (23, 2.64014012908069700000e+000) (24, -3.66114745264263030000e-002) (25, -8.57654231376890450000e-001) (26, 4.75324217524314970000e-001) (27, 1.01076548407081470000e+000) (28, 2.15523074627843860000e+000) (22, -1.03431918641712280000e+000) (23, -1.12757841082988540000e+000) (24, 1.92240166058710260000e+000) (25, -4.21437294214826620000e-001) (26, 2.26520237940327270000e+000) (27, -3.41206196688337570000e-001) (28, 2.95743199728266100000e+000) 

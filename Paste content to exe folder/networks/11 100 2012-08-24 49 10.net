FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.50683576442317340000e-001) (1, -9.80053987788132300000e-002) (2, -1.63177435444423260000e-001) (3, -1.48303619025993230000e-001) (4, 3.18133304137058830000e+000) (5, -7.67521042879175940000e-002) (6, 7.75617390706963890000e-001) (7, -2.61305183392956660000e-001) (8, 3.34893898147233690000e-001) (9, -1.32489409805968160000e-001) (10, 1.10764400989314230000e-001) (11, -3.19706094799963180000e-002) (12, -3.06467044197593010000e+000) (13, -2.80732673916823830000e-001) (14, -8.58028876408941880000e-001) (15, -1.00711950911696190000e-002) (16, -4.55594229257186180000e-001) (17, 3.82625458634342360000e-002) (18, 3.64431853854494390000e-001) (19, 1.65138171878060680000e-001) (20, -3.19211795364067100000e+000) (21, -4.51603069421631360000e-002) (0, -1.43745261513030950000e+000) (1, 4.06400722923825060000e-001) (2, 5.21516572650549630000e-001) (3, 3.78964451595192040000e-001) (4, -1.62191462587461620000e+000) (5, 5.03738623376347010000e-001) (6, -8.67077911885907600000e-002) (7, 2.36670573214583900000e-001) (8, -8.50085442811498120000e-001) (9, 3.74307469103922600000e-001) (10, -4.46415081063074310000e-002) (11, 4.43533544354221490000e-001) (12, 3.20731622172773370000e-002) (13, 4.03732518370514990000e-001) (14, 4.36543426853101100000e-001) (15, 6.89468100194232440000e-001) (16, -4.40968328948567910000e-001) (17, 9.66591761697550010000e-002) (18, 7.12965979441658850000e-001) (19, 1.42235750481598450000e-001) (20, 6.96702729827433640000e-002) (21, 6.72646026039750210000e-001) (0, -1.39936667706278480000e+000) (1, -4.21662838989134700000e-001) (2, -1.42357319541751610000e+000) (3, -4.57328011580649780000e-001) (4, -3.06522586190608150000e+000) (5, 1.77684967276465740000e-001) (6, -3.08126590120759670000e+000) (7, 1.46003554238611170000e-001) (8, 7.56898743610031180000e-001) (9, 6.16510075633553980000e-001) (10, 2.82921340406503630000e-001) (11, -7.08592525130980340000e-002) (12, 1.28251607546207260000e+000) (13, 8.48646373119452820000e-002) (14, 1.08951889536515670000e+000) (15, -2.45994259372387670000e-001) (16, 1.27145040146905620000e+000) (17, 7.59017911314219470000e-001) (18, -4.47486210709626460000e-001) (19, 1.75423757267947840000e-001) (20, 3.18444583438572250000e+000) (21, -4.07349256792329310000e-001) (0, 3.37470937435061400000e-001) (1, -3.46020800042628250000e-001) (2, -3.76444947501218370000e-001) (3, 3.40688384406335420000e-001) (4, -1.24125108012888900000e+000) (5, 3.50592113331379570000e-001) (6, -1.33957261479711900000e+000) (7, 2.47378440809947200000e-001) (8, 2.61225114176834470000e-001) (9, 2.07367880123255080000e-001) (10, 2.80948619532838670000e-001) (11, 4.18979705812506930000e-003) (12, 3.11655032556150060000e+000) (13, 6.28270511851930840000e-001) (14, 4.90760501944595920000e-001) (15, 2.28335466901922950000e-002) (16, 2.82985895107912460000e+000) (17, -5.30271460106293670000e-001) (18, -4.65200677644755920000e-002) (19, -7.65603096153045780000e-002) (20, 1.32799302954919130000e+000) (21, -2.15548743050951290000e-001) (0, 2.40046238801278900000e-001) (1, -5.28126463622441310000e-001) (2, -2.46467022565746870000e-001) (3, 2.54572185495183230000e-005) (4, -9.62054289088039470000e-001) (5, 1.09167343641288680000e+000) (6, -3.05549054696137690000e-001) (7, -1.05372176710542520000e-002) (8, 1.21147934640125900000e+000) (9, 2.31582558485487200000e-001) (10, 1.95947975103080650000e-001) (11, -1.39585075003107210000e-001) (12, 7.06508692382638800000e-001) (13, 4.54819471881867170000e-001) (14, 5.62389163213972370000e-001) (15, 7.38533670444117270000e-002) (16, 1.21863266682035180000e+000) (17, 1.06269355286081960000e-001) (18, 1.13917297766568280000e-001) (19, 1.29190567614176970000e-001) (20, 1.12913681587738470000e+000) (21, 1.01203437241843900000e-001) (22, -9.39457080597472520000e-002) (23, 4.76797705006146100000e-001) (24, 6.39211938211335040000e-001) (25, -9.10402521209213310000e-002) (26, -5.74732027885882510000e-003) (27, 3.69858006146995430000e-001) (22, -1.27692046453231870000e-001) (23, 4.77578955017787630000e-001) (24, -2.43516944055934130000e-001) (25, 8.98341815081613180000e-002) (26, 4.90778447136632320000e-001) (27, 3.54410007869927320000e-001) (22, 1.86280879833302600000e-001) (23, 3.43309041141704630000e-001) (24, -6.73090412754019260000e-001) (25, -5.67582770621685500000e-001) (26, -2.60081202115260370000e-001) (27, 6.41843544621594870000e-001) 

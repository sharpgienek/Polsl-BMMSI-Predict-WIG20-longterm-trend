FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.86081620838069650000e+000) (1, 9.09338884321646110000e-001) (2, 3.52528235549929010000e+001) (3, 8.25311979377101210000e-001) (4, -3.30997841440692660000e+000) (5, -1.86915908855629750000e-002) (6, -1.66159131686274860000e+001) (7, 1.09573752881341920000e+000) (8, 3.66448131148287800000e+000) (9, -3.87243945622978420000e-001) (10, -2.86911347177629270000e+000) (11, 3.58042343061335130000e+000) (12, 3.63541208007489520000e+001) (13, -7.77320574236490150000e-001) (14, 3.33033052548820630000e+000) (15, 1.55518988790757450000e+000) (16, 4.87519088949950770000e+000) (17, 3.86444609261437490000e+000) (18, -2.31003819430099270000e+000) (19, -3.24807954927335410000e-002) (20, 2.80797718152104060000e+000) (21, 8.76011035948050410000e-001) (0, -4.52454217433571130000e+001) (1, -3.09404357200189550000e-001) (2, 1.99350463613790440000e+001) (3, 4.09281198562701840000e+000) (4, 4.71328573384396280000e+001) (5, 2.05448235924390680000e+000) (6, -3.61459107938048660000e+001) (7, 1.85953992283512610000e+000) (8, -1.91404935558495310000e+001) (9, -8.37711669502626880000e-001) (10, 3.45230370703920000000e+001) (11, -1.47767550321154760000e+000) (12, 2.16566895476720790000e+002) (13, -3.26513598618504550000e+000) (14, 7.78741324144026660000e+001) (15, -2.05594271165982030000e+000) (16, 3.03329898272686760000e+001) (17, 7.52459017331892130000e-001) (18, 2.67331265985530070000e+001) (19, -1.09194763573922950000e+000) (20, 3.57157922228562370000e+001) (21, -1.16636216787330740000e+000) (0, -5.49066673473845410000e+002) (1, 2.17334111627837460000e+001) (2, 2.38270290731078090000e+002) (3, 1.74004188483441200000e+001) (4, -2.68452156815345370000e+001) (5, 1.49246186193168310000e+001) (6, -1.45786544258924920000e+002) (7, 5.16982645496949050000e+001) (8, -4.83034670147480940000e+001) (9, -3.91255843199435870000e+000) (10, 4.17022628587428060000e+001) (11, 1.05591137659593220000e+002) (12, 4.32620452386660080000e+002) (13, -3.84119952412182510000e+000) (14, -1.01323642161363220000e+002) (15, 3.59972724418796090000e+001) (16, 7.36959012682466690000e+000) (17, 1.25166082492539910000e+002) (18, 6.09176289224289690000e+002) (19, 2.52716776142279050000e+000) (20, 6.04360045797204410000e+002) (21, 2.32203985902219890000e+000) (0, -3.82721755281925450000e+000) (1, -1.41162593387762660000e-001) (2, 4.92532769138051800000e+001) (3, 3.86909310888983440000e+000) (4, -2.64850026859665630000e+001) (5, 8.90446404343322940000e+000) (6, 8.61760535713727190000e+000) (7, 3.05614482497466430000e+000) (8, 4.69143893024463030000e+001) (9, 2.04334483488677330000e+000) (10, 1.42522376081383580000e+002) (11, 5.61840935886755990000e-001) (12, 9.91672915967624960000e+001) (13, 1.09508910810919070000e+000) (14, 6.76004922947848710000e+001) (15, -1.99340725325008280000e+000) (16, 2.51158883736538280000e+001) (17, 1.73303964016390630000e+000) (18, 9.55225079130044180000e+001) (19, -1.83034636785374160000e-001) (20, 1.12076392545262290000e+002) (21, -4.49406670908967150000e+000) (0, -3.44628788133525030000e+001) (1, -1.96566056765918410000e+000) (2, -3.94437268666590630000e+001) (3, 2.38404108498244270000e+000) (4, 3.53783358622439290000e+001) (5, 2.50844657322010050000e+000) (6, 1.88578507563572830000e+001) (7, 1.34007405815073330000e+000) (8, -3.14153443835002700000e+000) (9, 5.63846696032816670000e-001) (10, 1.51301079356824460000e+001) (11, -2.79695537312162460000e-001) (12, 7.85787982948293120000e+001) (13, 2.30612039893055790000e+000) (14, -4.52357339031659580000e+001) (15, -6.22560107903673910000e+000) (16, 4.30462436351379760000e+001) (17, -6.41681887491632710000e+000) (18, 4.03730144522748380000e+001) (19, -1.10801896422005930000e+000) (20, -7.23576526185620850000e+001) (21, -6.80183343584381480000e-001) (22, -5.37229943287844410000e+000) (23, 3.51947622604082880000e+000) (24, 1.73152356003850880000e+000) (25, 3.52058189251723140000e-002) (26, -3.58774304559853930000e+000) (27, 3.51368778588028880000e+000) (22, 6.90212107054712650000e+000) (23, -2.23322342909681560000e+000) (24, -5.75195831857050790000e+000) (25, 2.19873571661825370000e+000) (26, 2.50414676073088050000e+000) (27, 1.31058548107839860000e+000) (22, -5.18298974994534370000e-001) (23, -1.64206333965430360000e-001) (24, 1.77135994312382160000e+000) (25, -1.34117834950143440000e+000) (26, 1.30529239934854930000e-001) (27, 1.71320623406730320000e-001) 

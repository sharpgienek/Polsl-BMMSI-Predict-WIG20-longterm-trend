FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.92385532852856980000e+000) (1, -1.45813384613885850000e-001) (2, 6.82560346856114080000e-003) (3, -1.48303619025993230000e-001) (4, 6.32621246075661500000e-001) (5, -2.03656459994861650000e-001) (6, -1.64013886020813210000e-001) (7, -1.91217494965756630000e-001) (8, 9.79203017029445340000e-001) (9, 1.31770251458964930000e-001) (10, 6.54213650860795530000e-001) (11, -2.28962653614140420000e-001) (12, 1.41830675159809560000e+000) (13, -2.10644985489623790000e-001) (14, 4.35981741502436020000e-001) (15, -1.36975550798113690000e-001) (16, 9.87216933164487000000e-001) (17, 3.82625458634342360000e-002) (18, -3.69075017330399100000e-001) (19, -9.91214893868724020000e-002) (20, 1.29085923993335470000e+000) (21, -4.51603069421631360000e-002) (0, 3.97314526136972770000e-001) (1, -2.37855349676066560000e-001) (2, 7.44222268038896350000e-001) (3, 4.65663585977955300000e-002) (4, -3.04252688695846540000e+000) (5, 1.10307547267489550000e-001) (6, -3.19692752402483920000e+000) (7, 1.30308768268655950000e-001) (8, 1.88164703760750980000e-001) (9, 8.92220196171724930000e-002) (10, 5.80962161537606600000e-001) (11, 2.30074335641217920000e-002) (12, 1.86476719288246300000e+000) (13, 3.41248076032111550000e-001) (14, 5.53087405262865370000e-001) (15, -4.62452954240634150000e-002) (16, 3.05060183825066660000e+000) (17, -6.93782447090492490000e-003) (18, -3.55758933517522190000e-001) (19, -1.49508250947480350000e-001) (20, 3.12540042334962730000e+000) (21, 1.16091722925123310000e-001) (0, -3.04807498274426350000e+000) (1, -6.61564618215936930000e-001) (2, -1.93955142283434510000e+000) (3, -3.29847664883069210000e-001) (4, -3.06522586190608150000e+000) (5, 2.80817419091092310000e-001) (6, -3.08126590120759670000e+000) (7, 1.19059834493063680000e-001) (8, 1.40747938567017620000e+000) (9, 6.31771752553592640000e-001) (10, 1.53072518541361210000e+000) (11, 5.30729344813427180000e-002) (12, 2.47929888856472760000e+000) (13, -6.73567658910781130000e-002) (14, 4.38557132026080100000e-001) (15, -4.96821531515336480000e-001) (16, 1.05964455885128130000e+000) (17, 3.18473821898184740000e-001) (18, -3.05532706515517780000e-002) (19, 1.88556565847584730000e-001) (20, 3.18444583438572250000e+000) (21, -4.87058491906367190000e-001) (0, 8.46885912873013290000e-003) (1, 1.45588440816630140000e-001) (2, -1.95120107213991870000e-002) (3, -2.17133135977999820000e-001) (4, -3.10835940747069640000e+000) (5, 8.78208440654347780000e-002) (6, -3.20668094213892640000e+000) (7, 2.56905459379336790000e-001) (8, 3.15825564844858330000e+000) (9, 3.32912877356726530000e-001) (10, 6.89438708121687170000e-001) (11, -1.01505721956534470000e+000) (12, 3.11655032556150060000e+000) (13, 3.39496276806478590000e-001) (14, 1.14172226528367250000e+000) (15, -7.50403963069415650000e-002) (16, 3.19104373487466390000e+000) (17, -1.05998519875044870000e+000) (18, -9.77151992806312600000e-001) (19, 2.67649545753132070000e-002) (20, 3.07510135033448770000e+000) (21, -4.98873994153814890000e-001) (0, 1.06637491809641880000e-002) (1, 8.08038648005671160000e-002) (2, 6.64385014343203850000e-001) (3, 5.59482817251439000000e-001) (4, -3.06916262954286890000e+000) (5, 4.46296496375982950000e-001) (6, 4.10508937720914850000e-001) (7, 2.36301843436029390000e-001) (8, 1.89686368311317380000e-001) (9, 6.88661651278401620000e-001) (10, 6.45027930623285560000e-001) (11, 8.84149488983561050000e-002) (12, 5.75125359185124640000e-001) (13, 5.24964710438855510000e-001) (14, 6.68550880192554820000e-001) (15, 5.00773099579720940000e-001) (16, 3.59962924490911380000e-001) (17, 5.23892432270412160000e-001) (18, 1.13917297766568280000e-001) (19, 1.99773593135854110000e-001) (20, 7.48722315053668370000e-001) (21, 5.18826514226174100000e-001) (0, 3.07372805929839910000e+000) (1, 1.51453677136444950000e-001) (2, 3.17280032639969090000e+000) (3, 1.70734925566341960000e-001) (4, 7.45945215402911370000e-001) (5, 3.02999763639805520000e-001) (6, 1.28374472322433770000e+000) (7, 3.40396959709437230000e-002) (8, 3.09898440733099800000e+000) (9, -4.60298093471094850000e-001) (10, -7.34981267665939380000e-002) (11, -7.12536514208978120000e-001) (12, 6.94841325069255220000e-001) (13, 8.44838502711797280000e-001) (14, -9.29959622688702910000e-001) (15, -8.37134921393057620000e-002) (16, 3.12562014991540150000e+000) (17, -3.90036101907003880000e-001) (18, -1.22890366783552320000e+000) (19, -5.56343016777275710000e-001) (20, -8.81392083580965210000e-002) (21, 3.42112437487715610000e-002) (22, -5.01041546720822070000e-002) (23, 2.09566172888251630000e-001) (24, 7.31884383229387760000e-001) (25, 8.56216521395094940000e-002) (26, 4.13559178673193640000e-001) (27, -1.53729801261397650000e-001) (28, 4.33658055925815240000e-001) (22, -7.32181686883828510000e-002) (23, 2.72568718237769350000e-001) (24, -1.52701487465186910000e-002) (25, 4.69925011732652970000e-002) (26, 5.19711524004986770000e-001) (27, 2.77643790568948610000e-001) (28, 4.35476903609168190000e-001) (22, -2.07922817480310330000e-001) (23, -6.52607847305226250000e-001) (24, -4.49018866177905260000e-001) (25, -2.56989415589241540000e-001) (26, 1.30686794576628460000e-001) (27, 2.63389810428243940000e-003) (28, 5.54923491011624750000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.61918658302098610000e+002) (1, -1.00973743292424880000e+001) (2, -1.93923706407846910000e+002) (3, 1.97013565451810740000e+001) (4, 7.30879111166304940000e+001) (5, 1.86047504354623050000e+000) (6, 2.13045216213113090000e+001) (7, -3.82244849687424730000e+001) (8, -1.42406204337044280000e+003) (9, 1.62870711983456000000e+000) (10, -1.99148029227892950000e+002) (11, 2.29133415678259670000e+000) (12, -6.13985010110457440000e+002) (13, -9.34320288572578980000e-001) (14, -2.04723818178836860000e+002) (15, -1.63497152528384440000e+000) (16, 5.58177127130027060000e+001) (17, -3.36036377684009790000e+001) (18, 3.89555783078249590000e+002) (19, -1.19224850358234170000e+001) (20, 3.61431166177391840000e+002) (21, 4.75265634288174250000e+000) (0, 2.45110237447066300000e+001) (1, -1.38371811752592790000e+000) (2, -1.93799370053975440000e+001) (3, 7.85623739965344290000e-001) (4, 3.40177501712562600000e+001) (5, 2.07545795621284720000e+000) (6, 4.68862139871565450000e+001) (7, 6.67261096352821830000e-001) (8, -2.03774005822349300000e+000) (9, 7.34828821612801500000e-001) (10, -1.29156095070613940000e+001) (11, 1.59548597067544100000e+000) (12, -2.74493640907992640000e+001) (13, 5.20426992995353020000e+000) (14, 1.59947747660576920000e+001) (15, -1.89678159797079970000e-001) (16, -2.97497816486570910000e+001) (17, -5.48937760116793780000e+000) (18, 1.51981044618766500000e+001) (19, -1.30032288110059760000e+000) (20, -2.41867670729071340000e+001) (21, 4.26884760919903740000e-001) (0, 1.19933797497184050000e+002) (1, 2.68241698726437820000e+001) (2, -1.01008248511111050000e+003) (3, -2.62470638484764360000e+001) (4, 2.75743262898752050000e+002) (5, -1.57671928731855950000e+001) (6, 4.68511275225809360000e+002) (7, -6.36472110771046480000e+000) (8, 1.15603024521226270000e+001) (9, -7.06227838452268040000e+000) (10, -1.21432788862315870000e+002) (11, -7.58698922089892650000e-001) (12, 1.14927693550560660000e+002) (13, 3.71637831872517950000e+001) (14, -3.96563203485444830000e+002) (15, 1.50696558994704080000e+001) (16, -1.07724875589698100000e+003) (17, -2.35280585969262540000e+001) (18, -7.55896651718087010000e+002) (19, 1.19161612186280940000e+000) (20, -6.41035934328664210000e+002) (21, 7.65600362744699230000e+000) (0, 1.50000000000000000000e+003) (1, -4.31305274611014870000e+001) (2, -3.84226448895251390000e+002) (3, -7.07897885612581150000e+002) (4, -3.27976174093889480000e+001) (5, -1.06158521362559300000e+002) (6, -8.80754845039059690000e+001) (7, -6.24533118836774650000e+001) (8, -6.40707732884054620000e+002) (9, -3.86711876521908380000e+001) (10, -9.42051738846894860000e+002) (11, -4.25968155718320090000e-001) (12, 1.50000000000000000000e+003) (13, 1.36216363246897940000e+002) (14, 8.07367621424534950000e+002) (15, 8.88598326855077450000e-001) (16, 2.56892544667130550000e+002) (17, -3.59809433267278750000e+001) (18, 1.50000000000000000000e+003) (19, 1.59115293583015340000e+001) (20, 1.50000000000000000000e+003) (21, -1.58354241073956690000e+001) (0, 1.05584756155990500000e+003) (1, -1.48662130308309540000e+002) (2, 8.70236638907301200000e+002) (3, -3.25433012226023920000e+000) (4, 5.22134580718869300000e+002) (5, 2.19445865516119430000e+002) (6, -1.33916193419172490000e+003) (7, 4.03882597354803470000e+001) (8, 1.50000000000000000000e+003) (9, 1.04918976939434880000e+002) (10, 5.08762182914915170000e+002) (11, 1.83375706657264170000e+002) (12, -1.50000000000000000000e+003) (13, 8.31574607351903180000e+002) (14, 1.50000000000000000000e+003) (15, -4.59764532540073210000e+000) (16, -1.34171927588795300000e+003) (17, -2.79486065581693940000e+002) (18, 1.50000000000000000000e+003) (19, 3.00768976228938720000e-001) (20, 5.83473273434407890000e+001) (21, 1.40728547050063810000e+002) (22, 6.79581806629523170000e-001) (23, -1.98151093588533360000e+000) (24, -7.37964769084004240000e-002) (25, 4.56431362607175260000e-001) (26, 1.46414321704750790000e+000) (27, 4.49118681786982500000e-001) (22, -1.82147004533846110000e+000) (23, 2.06077371268920470000e+000) (24, -1.81244633825269300000e+000) (25, 2.64314922432309580000e-001) (26, -2.31150347846447470000e-001) (27, 1.92038365986669920000e+000) (22, 3.48537938490657950000e-001) (23, -6.04844146302001840000e-002) (24, 2.08687553956777980000e+000) (25, -1.68496254302388590000e+000) (26, -5.30749245650604220000e-001) (27, 4.42959792359277960000e-001) 

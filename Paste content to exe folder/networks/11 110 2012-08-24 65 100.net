FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.58417716363833510000e+000) (1, 1.28759909291470850000e-001) (2, 7.51786062571219200000e+000) (3, 1.04780347071149690000e+000) (4, 8.23228200586326510000e+000) (5, -4.29887957208934080000e-001) (6, 2.16124778816689570000e+000) (7, 4.17504224867398800000e-002) (8, 3.02671905936481880000e+000) (9, -1.04995053658517270000e+000) (10, -6.63617053467181780000e+000) (11, 1.09690010896271130000e+000) (12, -1.33069027180247320000e+001) (13, -1.20830699532547700000e+000) (14, -7.29790201028294840000e+000) (15, -1.74757267643892660000e-001) (16, -1.19657023024616520000e+000) (17, -2.76866626343197050000e+000) (18, -5.20358930985177980000e+000) (19, 5.56373642702366780000e-001) (20, -3.08965334913755950000e+000) (21, -2.09301179143859160000e-002) (0, -4.28502709753470690000e+000) (1, -1.51316184091625060000e+000) (2, -2.68903272031102870000e+000) (3, 7.95832296245222230000e-001) (4, -8.56292238222120260000e+000) (5, -2.30963160797846180000e-001) (6, 5.52067261097913930000e-001) (7, 4.45779007130886200000e-002) (8, 1.44215880309088240000e+001) (9, -2.72716249761579320000e-001) (10, 1.01205018885085300000e+001) (11, 4.69638451960830980000e-001) (12, -3.33172085619398100000e-001) (13, -1.49021999188494720000e+000) (14, 4.45976490975605520000e+000) (15, -3.33506858091681960000e-001) (16, 1.72236488061256380000e+001) (17, -5.87838971961533900000e-001) (18, 2.38394298509401030000e+001) (19, 5.19024915546211440000e-001) (20, 2.48203855095415660000e+001) (21, -1.08656114798827310000e-001) (0, -8.55786737927595280000e+000) (1, 9.66928984533535260000e-001) (2, 1.55877138801412450000e+000) (3, 8.23834785841015880000e-001) (4, -1.58655373279236800000e+000) (5, 2.25076504984174660000e+000) (6, -1.07320333942796870000e+001) (7, 6.68267925144421020000e-001) (8, 8.46856033705596920000e-001) (9, 6.95872370600962960000e-001) (10, 2.41478525532603820000e+001) (11, 9.07118754831226730000e-001) (12, 3.44279394312108740000e+000) (13, 9.87924855539211720000e-001) (14, -1.24253945949496550000e+000) (15, -3.62514787520061830000e-001) (16, 4.67497751548205890000e-001) (17, -8.59951774875888470000e-001) (18, 3.17698366257031450000e+000) (19, 3.76023090652259830000e+000) (20, 3.15519376925267810000e+000) (21, 1.76696855662478480000e+000) (0, 2.56148400369876810000e+000) (1, 4.98453740815839490000e-001) (2, 4.53045518487686130000e+000) (3, -3.62121379949776220000e-001) (4, -4.14398994301073390000e+000) (5, 3.08101697960961150000e-001) (6, -1.29679128781654390000e+001) (7, -3.87219141290948610000e+000) (8, 2.28348051986296100000e+001) (9, 1.98880712990699260000e-001) (10, 1.94611998424718120000e+000) (11, -1.45555814837958120000e+000) (12, 3.08737666019464430000e+001) (13, 7.02549625958593490000e-001) (14, 9.15639330665572790000e+000) (15, -1.90460776489009580000e-001) (16, -2.43969335933026840000e+001) (17, -2.11125016184607570000e+000) (18, -2.21856814807814540000e+001) (19, -8.90063776688806650000e-001) (20, 2.29125406417387790000e+001) (21, -9.65851825386440100000e-001) (0, 2.84393140540410320000e+000) (1, -9.45049087239452130000e-001) (2, -9.65591634342949770000e+000) (3, 6.46622130720446720000e-001) (4, 1.15983549798195650000e+001) (5, 1.53922526185140750000e+000) (6, 1.26485264289366870000e+001) (7, -3.15531786321248790000e-001) (8, 1.78649875842973320000e-001) (9, 4.28942389138091680000e-001) (10, 1.85833961803753920000e-001) (11, 3.25711782070021990000e-001) (12, 3.93702692580343690000e+000) (13, 1.82665888962607960000e+000) (14, -5.67776758436509610000e+000) (15, -1.78899300550532560000e+000) (16, 1.03194674747985070000e+000) (17, -2.58259788110929200000e+000) (18, 2.19643124394261200000e+001) (19, -4.77479733722510350000e-001) (20, -2.85553731796253840000e+001) (21, 1.34301931550207170000e-001) (0, 1.06234361188152140000e+001) (1, 5.85862848253879350000e-001) (2, 1.28082962927660270000e+001) (3, -2.65734076680900380000e-001) (4, 2.13420751203650600000e+000) (5, -1.20320896678401270000e+000) (6, 1.29825150037338960000e+001) (7, 3.00308220004197050000e-001) (8, 8.63146642485579460000e+000) (9, -6.03778832422849690000e-001) (10, -4.84921389017007960000e+000) (11, 5.14907199796074900000e-002) (12, -1.21970218885877570000e+001) (13, -5.25405812770753600000e-001) (14, -3.87949332180222630000e+000) (15, 1.14005773374709810000e+000) (16, -2.31503994972746190000e-002) (17, 7.49669859073954780000e-001) (18, -7.59229067015551350000e+000) (19, -3.15291372697564350000e-001) (20, -1.96167282534348740000e+000) (21, 2.30185359755656790000e-001) (22, -4.32844366281513960000e-001) (23, 5.93716444915926460000e-001) (24, 2.47093517159077740000e-001) (25, -1.37822879355050410000e-001) (26, -8.52354592331220570000e-001) (27, -8.65650016564715960000e-001) (28, 3.84789247340438350000e-001) (22, -8.55676065456880800000e-001) (23, 6.34603816192760960000e-001) (24, 1.18954230709295270000e+000) (25, 1.30848495879913070000e+000) (26, 1.66787305374571870000e+000) (27, 2.52563989439371730000e+000) (28, 1.00508244854106570000e+000) (22, 1.32455501490106250000e+000) (23, -1.37704266888053950000e+000) (24, -1.28435487631842800000e+000) (25, -9.12658550664733780000e-001) (26, -3.90012734384723670000e-001) (27, -1.23560532072614100000e+000) (28, 1.13455077735361880000e+000) 

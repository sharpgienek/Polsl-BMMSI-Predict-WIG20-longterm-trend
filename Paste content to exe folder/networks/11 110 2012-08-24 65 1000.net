FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.68915942425827340000e+001) (1, 2.80269139530871960000e-001) (2, -8.68172793960485660000e+000) (3, 3.74716211628063120000e-001) (4, 4.17339001014518460000e+000) (5, -8.81949809231537780000e+000) (6, -5.76833526588201830000e+001) (7, 3.28733930414767790000e+000) (8, -6.39735151130048860000e+001) (9, -3.85345226570061590000e-002) (10, 2.48570236287673150000e+001) (11, -1.23953101508112410000e+000) (12, -1.35105681350915070000e+001) (13, 2.23736036527037680000e+000) (14, -1.28005264681960950000e+001) (15, -1.69782085767613470000e+000) (16, 3.90479402397904560000e+001) (17, -2.39313457993315160000e+000) (18, -3.23106402252709300000e+001) (19, 5.29651073229377280000e+000) (20, -4.60967336976684480000e+001) (21, -1.18205661148688420000e+000) (0, -2.87684692148366710000e+001) (1, -5.63000288366703240000e-001) (2, 3.87843098649736220000e+001) (3, 1.55680550815005780000e+000) (4, 5.33896521252214210000e-001) (5, 5.35453499250755180000e+000) (6, 7.77788521700722320000e+000) (7, 7.55607469863429770000e+000) (8, -3.94389571757496780000e+001) (9, 1.33901577910473610000e-001) (10, -4.15063850447676830000e+001) (11, 1.92342283646729140000e+000) (12, -2.35331484692116500000e+001) (13, -2.49858489506905770000e+000) (14, -2.06298018979337420000e+001) (15, 2.92815898299909130000e-002) (16, 3.34673046859284040000e+001) (17, 4.89049336740172700000e+000) (18, -4.69425391239070960000e+001) (19, 2.53216375861923470000e-001) (20, -3.62428079915958960000e+001) (21, 2.47536887379242200000e+000) (0, -2.17218284668575910000e+000) (1, -6.47900745330917170000e+000) (2, -4.32126617031223220000e+001) (3, -6.00992063817674230000e-001) (4, -1.48869310968815500000e+001) (5, 3.26538695112426890000e-001) (6, 2.40984724855906120000e+001) (7, 1.72475726109871520000e+000) (8, 3.49788844999271050000e+001) (9, -3.61334768374861410000e-002) (10, 1.35091983594553120000e+000) (11, 2.59804269907555900000e-001) (12, 3.09848256670923260000e+000) (13, -6.46915577168508980000e+000) (14, 8.68544664063727510000e+001) (15, -2.22574644509795940000e+000) (16, 1.06235625359317940000e+002) (17, 6.50620155023049600000e-001) (18, 2.11697956655213350000e+001) (19, 1.61824651245479320000e-001) (20, 2.04629651564697030000e+001) (21, -2.04923981362759290000e+000) (0, 5.00977399308058580000e+001) (1, -3.68496631637719840000e+000) (2, -6.99809054594765540000e+000) (3, -4.03294891932976630000e+000) (4, -7.30891549114692030000e+000) (5, -2.43961339594342520000e+000) (6, -7.77850009740696090000e+000) (7, -4.14504661948023930000e+000) (8, -9.48158851462079610000e+000) (9, 7.88615502999508000000e-001) (10, -5.98550260305316540000e+001) (11, -1.90142729782330680000e-001) (12, -9.23307483011372730000e+000) (13, -5.04446991656512300000e-001) (14, 1.00149384101000760000e+001) (15, -1.03645124716375240000e+000) (16, -1.72381597363784640000e+001) (17, 2.90191780110266750000e-001) (18, 8.95973650649187190000e+000) (19, -1.87507098808101700000e+001) (20, 8.57080627631811320000e+001) (21, -1.90471357300904140000e+000) (0, 4.07716249482173070000e+000) (1, 2.05146368990134550000e-001) (2, -6.63572122701290290000e+000) (3, -1.98654436756475620000e-001) (4, -1.58408753112267560000e+000) (5, 3.35358631189120740000e-002) (6, -3.09731247985917780000e-001) (7, -6.63963419367794020000e-001) (8, 2.95744452147060070000e+000) (9, 2.97579924273974300000e-002) (10, 8.98640334338917950000e+000) (11, -4.88588224712689980000e-001) (12, 6.31368520153337440000e+000) (13, 2.32683101385522340000e-001) (14, 5.33084980213187980000e+000) (15, 2.33645691456546680000e-001) (16, -2.47227669780515620000e+000) (17, 5.93050265312537740000e-002) (18, 7.41102307130824660000e+000) (19, -1.78954376715136860000e-001) (20, 9.79943941374768460000e+000) (21, -3.84737895105066730000e-001) (0, -1.92224504229590390000e+001) (1, -8.98064641700008990000e-001) (2, 1.82737013570611920000e+001) (3, 1.38207558107072010000e+000) (4, -6.36260288698842940000e+001) (5, 4.37844958896131230000e-001) (6, -7.87314541221264360000e+001) (7, 2.46332134593182550000e-002) (8, 1.96336119967365510000e+001) (9, 6.44649949059054040000e-001) (10, 2.00340383981952680000e+001) (11, -2.11023985275428210000e-001) (12, -2.08088245213488850000e+001) (13, 2.34166549217091280000e+000) (14, -3.62350395606498520000e+001) (15, -1.57414692959853110000e-001) (16, -1.71148932901493930000e+001) (17, 3.37727244325441140000e+000) (18, -4.06092160485496190000e+001) (19, 2.11552126428076550000e-001) (20, 1.31971487418301570000e+001) (21, 2.95113191557769650000e+000) (22, 9.07529684462395570000e-001) (23, 1.25361756077271490000e+000) (24, 1.59696343963911920000e+000) (25, -5.46973144033933710000e-002) (26, 2.83563151342109920000e+000) (27, -1.06771094313265060000e-002) (28, 1.63095519719502050000e+000) (22, -2.02184258005056260000e+000) (23, -2.83405009367677830000e+000) (24, -4.90534066753348710000e-001) (25, -1.65450243177838650000e+000) (26, -2.01803473453184520000e+000) (27, 2.43838701331176690000e+000) (28, -2.07688029110355580000e-001) (22, 4.16634596968929850000e-001) (23, 4.95207738171082210000e-001) (24, -1.15023259528153200000e+000) (25, 1.08819401371276280000e+000) (26, -1.72187099031007660000e+000) (27, -1.77106710631569380000e+000) (28, 1.09079856189090000000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.66460814165596280000e+000) (1, -1.04681575173684570000e+000) (2, 1.97040015977971490000e+001) (3, 2.91252200703200900000e-001) (4, 8.63248450354661400000e+000) (5, 6.75003316567871160000e-001) (6, 7.41834276278292220000e+000) (7, 1.65016921362411110000e+000) (8, 3.13903980309436830000e+001) (9, 1.43049844757113400000e+000) (10, 7.69078905507538920000e+000) (11, 1.71065360467947230000e+000) (12, -4.39298035373825120000e+001) (13, 2.33444753956131900000e-001) (14, -6.48076024331864030000e+001) (15, 5.72239340693449060000e-001) (16, 3.43948189621412090000e+000) (17, 3.01682591097678900000e+000) (18, -4.30081154661339300000e+001) (19, -2.15434569863268170000e-001) (20, 6.06290964169553080000e-001) (21, -2.65448790087062520000e+000) (0, 8.97771439426001370000e+000) (1, 9.63576740378801700000e-001) (2, -1.61744897925290730000e+001) (3, 1.47628950845179110000e+000) (4, -1.14917259358349600000e+001) (5, -2.06219224562074150000e+000) (6, 2.57632511424935660000e+001) (7, -1.15204831960448970000e+000) (8, 3.92561899351985530000e+000) (9, -4.83180947195398950000e+000) (10, -2.56569183384031380000e+001) (11, -9.72369888968877660000e-001) (12, 9.63828604781527930000e+001) (13, 1.19581845369269100000e+000) (14, 1.93946729345732140000e+002) (15, 7.53027083857882750000e-001) (16, 3.26820919546077130000e+000) (17, -2.18568238914762350000e-001) (18, 2.35111392107547560000e+001) (19, 1.56698160777319860000e+000) (20, 1.00596601315585140000e+001) (21, 3.68094466496983010000e+000) (0, -8.35937950694319200000e+000) (1, -1.38040681811135540000e-002) (2, -2.66665487014347990000e+001) (3, -7.51937667907035810000e-002) (4, 3.16819868504465770000e+000) (5, 3.19619202736497550000e+000) (6, -9.38890788586433980000e+000) (7, 1.47114673882069510000e+000) (8, -1.03231843493250210000e+000) (9, 2.28740426274514320000e-001) (10, -2.52293331372462500000e+000) (11, 1.68698539824041100000e+000) (12, 1.04753329707383840000e+001) (13, 1.09532906724073790000e+000) (14, -1.53381013524563700000e+001) (15, -5.38968722393793900000e-001) (16, -1.09652452927886670000e+001) (17, -2.91282642221636430000e-002) (18, -6.14001810871070310000e+000) (19, -1.27328194524723170000e+000) (20, -5.84849178633068160000e+000) (21, -5.98356675219587910000e-001) (0, 2.01287723370258500000e+001) (1, -7.79742616989450350000e-001) (2, -4.82692989543278370000e+000) (3, 4.01543813686452420000e-001) (4, -2.76652271200199170000e+001) (5, 3.32759571638432390000e+000) (6, 5.61613170846313370000e+000) (7, -3.26198979900442380000e+000) (8, 2.85110705390308680000e+001) (9, -4.05260631216772640000e-001) (10, -2.66164067551129160000e+000) (11, -4.81106092383378430000e-001) (12, -3.84734973942230670000e+001) (13, 3.60986039768545820000e+000) (14, -3.07198939851557140000e+001) (15, -1.03212048868981320000e+000) (16, -1.78661416011294920000e+001) (17, -4.84884335378966020000e+000) (18, 6.68206109423085430000e+000) (19, -1.98251959381133600000e+000) (20, -3.05536680282760020000e+000) (21, 2.12672803479921630000e+000) (0, 1.38138194948561850000e+001) (1, 1.05107397893669940000e+000) (2, 5.01949523673841330000e+001) (3, 3.24770535705802210000e+000) (4, 7.88659363819328410000e+001) (5, 8.00767492542001770000e-002) (6, 4.88821246846292110000e+001) (7, 2.20710315635146380000e+000) (8, 1.47216079382806630000e+000) (9, -1.57499842391084540000e+000) (10, -4.83439467246409720000e+001) (11, 1.46103243284612700000e+000) (12, -2.13099773317145630000e+001) (13, -6.24790917308705950000e-001) (14, 3.27092310948739810000e+000) (15, 8.10048768739894840000e-001) (16, 3.93125407083888660000e+001) (17, 4.27623048651738990000e+000) (18, -8.77746047761851320000e+000) (19, -4.42943601477592430000e-001) (20, -3.30054585529132960000e+001) (21, 3.62615879739819790000e+000) (0, -4.22129604283822780000e+000) (1, -3.62270989649895180000e-002) (2, 1.85397418288010170000e+001) (3, 3.74629751512667800000e+000) (4, -3.45098501503768200000e+001) (5, 9.16412701973924330000e-001) (6, 2.66674060637826880000e+000) (7, -9.53978631833150790000e-001) (8, 2.32140622398189650000e+001) (9, 1.09812527930993100000e-003) (10, 8.47101350739152890000e+000) (11, 5.78623350172011830000e-001) (12, -3.04410269271277940000e+001) (13, 3.29211746779756290000e-001) (14, -2.43393837688377740000e+001) (15, 8.75043158791114270000e-001) (16, -4.66190945322624640000e+000) (17, 8.82156415531805570000e-001) (18, -3.71034315235159510000e+001) (19, 2.91704248860703560000e-001) (20, 1.56654898871235610000e+001) (21, 1.77441795371822720000e+000) (22, 1.50193847732317230000e+000) (23, 1.75650350348495500000e+000) (24, 5.43095066979115910000e-001) (25, -2.64490091543483300000e-001) (26, -1.79596659316784460000e+000) (27, 6.14350891203219280000e-001) (28, 1.09469769452130580000e+000) (22, 1.82990784294232990000e+000) (23, 4.61504652659936590000e-002) (24, -2.99835137240366430000e+000) (25, 2.65536860555889390000e+000) (26, 1.59287821663899560000e+000) (27, -3.16577755254269100000e+000) (28, 2.59560364940075060000e+000) (22, -2.85525812109522590000e+000) (23, -1.41255700505542590000e+000) (24, 1.78748217972102210000e+000) (25, -1.79016302234652880000e+000) (26, 3.08806992593892270000e-001) (27, 1.93710351446358150000e+000) (28, -3.91756606034550760000e-001) 

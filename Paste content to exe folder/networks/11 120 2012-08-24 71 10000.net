FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.20793942992957760000e+001) (1, 5.94945863425912870000e+000) (2, 8.29595151069210030000e+001) (3, -8.14710698288154590000e+000) (4, 1.34062646599604560000e+002) (5, 2.87022974376385860000e+000) (6, 5.18196551038777000000e+001) (7, 1.06232821239369480000e+000) (8, 1.49875078870294250000e+001) (9, -1.03876694579439090000e+000) (10, 4.59963214196142400000e+001) (11, -1.85655182951786250000e+000) (12, 7.16689353773808160000e+000) (13, 1.38543129035487290000e+000) (14, 3.58589157114181700000e+001) (15, 8.07078787108785360000e+000) (16, -9.35941522797149710000e-001) (17, 3.31593179679759190000e+000) (18, -4.51406796694935790000e+001) (19, 9.61130828369480160000e-001) (20, -5.57404221836799680000e+001) (21, -4.58992522939476190000e+000) (0, 2.79138012122337000000e+001) (1, 9.54552880122297860000e+000) (2, 6.08669456473210740000e+001) (3, -4.26952274090505850000e-001) (4, 2.71273400842175970000e+001) (5, 1.65066316831437000000e+000) (6, 6.39778264131869610000e+001) (7, 1.33207990782568170000e+001) (8, 7.05207663464656780000e+001) (9, 1.72305720669984910000e+000) (10, 1.51392252589323590000e+002) (11, -7.53426932323175700000e-001) (12, -9.56047773027169110000e+001) (13, -9.98127136701771610000e-002) (14, -6.05105671459462120000e+001) (15, -2.58744018541565170000e+000) (16, 9.13202309560327170000e+001) (17, 2.14609813537539030000e+000) (18, 1.64168967742695880000e+001) (19, -3.20147400747305390000e+000) (20, 8.50467131540160180000e+001) (21, -3.81549010348072360000e+000) (0, -1.08094398613177030000e+003) (1, -4.94891155322599020000e+001) (2, 1.50000000000000000000e+003) (3, 4.88455676388531610000e+001) (4, -3.89130549660485710000e+002) (5, 7.07971127467013730000e+002) (6, -7.38082928057777620000e+002) (7, 1.18979398410032960000e+002) (8, 1.50000000000000000000e+003) (9, 3.83631347985495150000e+002) (10, -5.74374308857788490000e+002) (11, 6.40961097534909920000e+001) (12, -1.11079377586365850000e+003) (13, 1.67075209042906490000e+002) (14, 2.10192852979138930000e+002) (15, 2.43104936365932760000e+002) (16, -1.17569595595763230000e+002) (17, 9.97369808384742670000e+001) (18, -3.82995611745357730000e+002) (19, 3.01317937303050700000e+001) (20, -1.27188711016182490000e+003) (21, -1.88512799059398650000e+002) (0, -1.50000000000000000000e+003) (1, 2.64997963017501630000e+001) (2, 4.57222229124506330000e+001) (3, 3.17359794081700270000e+002) (4, -1.50000000000000000000e+003) (5, 9.52321799204542150000e+001) (6, 1.35063237805409590000e+003) (7, -4.52078970835686750000e+001) (8, 1.01209427853811690000e+002) (9, 4.62791247528364200000e+000) (10, 5.41810076771224940000e+001) (11, 3.41874052858349750000e+000) (12, -5.15305536659929330000e+001) (13, 2.31125856759436380000e+001) (14, -4.28727342567821100000e+001) (15, 2.94194001787771030000e+001) (16, -8.19475686731243740000e+002) (17, 2.66980591303154030000e+002) (18, -3.77798257413104180000e+001) (19, 4.60057225087301540000e+000) (20, 1.35202868748723970000e+002) (21, 1.08106277338578180000e+002) (0, 5.42520366125027560000e+001) (1, 3.50539914068197600000e+000) (2, 8.21060668774559300000e+001) (3, -1.13071657574365100000e+000) (4, -1.23672890489290030000e+001) (5, -4.78270396003219210000e+000) (6, 2.26661992500303350000e+001) (7, -4.46018240757698340000e+000) (8, 5.01103269696757710000e+000) (9, -3.74383172728783540000e+000) (10, -4.92846464624702470000e+000) (11, -2.31012728936057240000e+000) (12, -3.25077465474855740000e+001) (13, -3.55997642620858650000e-001) (14, -9.33125640020494450000e+000) (15, 3.48080530805881580000e-001) (16, 8.54240912784623060000e+000) (17, -8.54796991199334790000e-003) (18, -6.41307360569155360000e+000) (19, 9.59209476910342200000e-001) (20, 2.75933216055401390000e-001) (21, -6.27191676991473490000e-001) (0, -3.68519739965987510000e+001) (1, 5.97130050750644740000e-001) (2, -3.44776954609609870000e+001) (3, 2.58154368698228960000e+000) (4, 3.12368653694043490000e+001) (5, 1.32028490721080360000e+000) (6, 1.40549437187097600000e+001) (7, 1.58942838782387770000e+000) (8, -1.03519642080575450000e+001) (9, 7.19250107270117960000e-001) (10, 1.20831561099295010000e+001) (11, -2.45193487846475570000e-001) (12, -2.88882563343167750000e+001) (13, 1.66143208977925520000e+000) (14, -4.79237580260858210000e+001) (15, -2.24271521055571200000e+000) (16, -4.18529287875912550000e+000) (17, 8.80893283202648700000e-001) (18, -5.94873060584939320000e+000) (19, -2.94545880141759090000e+000) (20, -2.83078546380664870000e+001) (21, 2.84567765437991840000e-001) (22, -7.55815260491585540000e-001) (23, 1.18502381428827630000e+000) (24, 2.86464591264350750000e-001) (25, 5.90549721555779340000e-001) (26, -1.13012814602728610000e+000) (27, -1.16880399645576370000e+000) (28, -1.04931917896471510000e-001) (22, -5.13890345849710610000e-001) (23, -1.27530322785186170000e+000) (24, 1.17968432498604290000e+000) (25, -1.93135634060385760000e+000) (26, 2.93493121944225390000e+000) (27, 1.35671123219838500000e+000) (28, 3.04920391229052790000e+000) (22, 1.12273089492182220000e+000) (23, -7.97148945640376860000e-002) (24, -1.41946371326124070000e+000) (25, 9.81152788378688130000e-001) (26, -1.41798240953876790000e+000) (27, -2.51861404398576740000e-002) (28, 1.15778829370447620000e-001) 

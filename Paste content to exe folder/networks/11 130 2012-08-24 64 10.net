FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.62424447586028540000e-001) (1, 3.63971949599325770000e-001) (2, 7.45669522443437980000e-001) (3, 4.31208278726225140000e-001) (4, -1.92609317068067650000e+000) (5, 4.01880885711087930000e-001) (6, 3.22681202192205860000e-001) (7, 3.89425114493681950000e-001) (8, 8.66604083293314400000e-001) (9, 2.89405298097571150000e-001) (10, -1.01140604832002000000e-001) (11, 4.23835231741358180000e-001) (12, -2.60966251854091560000e-001) (13, 4.12220241333906330000e-001) (14, -1.08367167439686180000e-001) (15, 3.18531275094082020000e-001) (16, -1.03009024179932630000e+000) (17, 2.91820205721138480000e-001) (18, -1.55620586112566960000e-001) (19, 4.10568735259188860000e-001) (20, -4.43040460441543940000e-001) (21, 4.46912624663363120000e-001) (0, 7.68212391323721100000e-001) (1, 1.93454264710699180000e-001) (2, 1.41708947548361320000e+000) (3, 1.31936929809644500000e-001) (4, 1.02219183619114150000e+000) (5, 5.41354149784366160000e-002) (6, 3.16849124430423060000e+000) (7, 5.48244913870189620000e-002) (8, -8.32949530332105500000e-001) (9, -2.57416276080677020000e-001) (10, 4.10160775484393200000e-002) (11, 1.93697894603884340000e-002) (12, -7.14486393801242350000e-001) (13, -2.34909945364388670000e-003) (14, 4.40181211131358390000e-001) (15, 3.85226217770378710000e-002) (16, 1.90918423532158240000e-001) (17, -1.03588114634097740000e-001) (18, 3.45582056747170070000e-001) (19, -6.42673357330484360000e-002) (20, -7.09402165209856440000e-001) (21, 5.48495263172027040000e-002) (0, 6.54871805627305400000e-001) (1, -1.08258622636893150000e-001) (2, 3.18183963317501210000e+000) (3, 1.72568188566035540000e-001) (4, -3.04424197487464720000e+000) (5, 2.83034112882068460000e+000) (6, 1.14528061494607100000e+000) (7, -2.84114483641899410000e-002) (8, 2.83582208593360720000e+000) (9, 6.01559349759642760000e-001) (10, 6.11208350041209550000e-001) (11, 1.06633858480601600000e-001) (12, -3.10207888979898440000e+000) (13, 9.48891046664792960000e-001) (14, 1.05761581871788880000e+000) (15, 6.13335489586749880000e-002) (16, 2.32868190401619320000e-001) (17, 1.42174630494575350000e-001) (18, -5.68268340382226840000e-001) (19, -1.00916093230605940000e-001) (20, 6.74983370776119030000e-001) (21, 6.86941917915372400000e-001) (0, 3.18996951610865680000e+000) (1, 1.16995523337000200000e-001) (2, 3.06066653566626720000e+000) (3, 9.46810698794889330000e-002) (4, 3.08331110261202130000e-003) (5, 4.41317527199954350000e-002) (6, 3.03504397669071140000e+000) (7, 9.67495408398758720000e-002) (8, -7.36990056245948040000e-001) (9, -2.49982193938650570000e-001) (10, 5.11357066054835270000e-002) (11, 1.36679361520937240000e-001) (12, -8.44137274639440880000e-001) (13, 1.03225991881818190000e-001) (14, 4.35640195438691980000e-001) (15, 2.56294308610958980000e-001) (16, -4.29787288574848820000e-002) (17, -4.35356235048709180000e-002) (18, -1.81569605047788850000e-002) (19, -3.72226575956763340000e-002) (20, -8.16317450006143200000e-001) (21, 4.47421042915903820000e-002) (0, -1.47559345986455350000e+000) (1, -1.33538585901775090000e-001) (2, -6.74075301104875790000e-001) (3, -2.99802347492604120000e-002) (4, 3.17077630627879970000e-001) (5, -1.18383556379072540000e-001) (6, -5.11890165714001590000e-001) (7, 1.98050050936565190000e-001) (8, 6.02072705476911500000e-002) (9, -3.39142161282101230000e-001) (10, 3.60284962518170550000e-001) (11, -3.22141215012979180000e-002) (12, 4.31252133792646320000e-001) (13, -1.41338878986758510000e-001) (14, 1.64635511385905510000e-001) (15, -4.83762311171321150000e-002) (16, -8.73024972753756460000e-002) (17, -6.30081691403416440000e-002) (18, 2.66120510831960200000e-001) (19, -7.17135285306181730000e-002) (20, 2.73568341205201520000e-001) (21, -1.13278907213188350000e-002) (22, 5.02302992200780900000e-001) (23, -4.02898799023376050000e-001) (24, 2.70966446908816540000e-002) (25, -2.26741581770739780000e-001) (26, 3.07174014815896620000e-001) (27, 4.94588148335820820000e-001) (22, 4.34804753841766260000e-001) (23, -2.88306601000173360000e-002) (24, 4.39156560547238230000e-001) (25, 5.35362844867207570000e-002) (26, 2.57902508439758040000e-001) (27, 3.26992280705696140000e-001) (22, 3.65660812600565150000e-001) (23, -7.49427213340155830000e-002) (24, -6.01982185196776710000e-001) (25, -4.19410118578767980000e-002) (26, 3.85408844057097190000e-001) (27, 7.07956826856759540000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.66618901095241360000e-001) (1, 1.55840111275143630000e-001) (2, 3.10789554027628420000e+000) (3, 6.15084107003310430000e-002) (4, -1.41011494326384760000e+000) (5, 6.05364928683147650000e-003) (6, 3.05405032463017800000e+000) (7, -4.18299789010409930000e-001) (8, 1.31060411327445130000e+000) (9, -1.86048195481838180000e-001) (10, 1.10927226932330920000e-001) (11, -9.06825664771593600000e-002) (12, -2.15245494000686400000e+000) (13, 1.63930049096498790000e-002) (14, 3.20391917568861600000e-001) (15, -7.48475116438729670000e-003) (16, 2.60298226692775030000e-001) (17, -3.46493885834589400000e-001) (18, -1.90724327303866990000e-001) (19, -1.48865577740274010000e-001) (20, -3.08939578414124140000e+000) (21, 1.20896598404893860000e-001) (0, 8.34322391520215400000e-002) (1, 4.54032825605645120000e-001) (2, 1.58672745467175740000e+000) (3, 7.78351466717701610000e-002) (4, 3.08299929967092630000e+000) (5, -7.07147109831794740000e-001) (6, 2.50631915263923590000e+000) (7, 2.04746304182680530000e-003) (8, -1.30094956734659070000e+000) (9, -1.32981070998449890000e-001) (10, 6.13581093328506300000e-002) (11, -3.10241140638642390000e-004) (12, -2.58622680120529860000e-001) (13, -8.87990568915996700000e-002) (14, -1.23610008840873030000e-001) (15, -4.96322724584548010000e-001) (16, 8.43354150750557920000e-002) (17, -1.20365104013582330000e-001) (18, 1.22799947308721190000e+000) (19, -1.42008170742339150000e-001) (20, -1.17740220222434160000e+000) (21, 7.47743179328352880000e-004) (0, 1.11177231366550840000e+000) (1, 7.29740511934467150000e-002) (2, 2.51966754151001740000e+000) (3, 1.45788017419755560000e-001) (4, -3.04424197487464720000e+000) (5, 2.83034112882068460000e+000) (6, 3.13238894884438950000e+000) (7, -2.84114483641899410000e-002) (8, 6.07111106264534460000e-001) (9, 1.63298574618853220000e-001) (10, 3.35303322810942550000e-001) (11, -1.03698343190888000000e-001) (12, -3.10207888979898440000e+000) (13, 1.02022292091742320000e+000) (14, -6.00811590845187690000e-002) (15, 5.65335478381077120000e-002) (16, 2.32868190401619320000e-001) (17, -4.70539332344219880000e-003) (18, -2.15756269211414000000e-001) (19, -4.90760842183830540000e-002) (20, -1.78157197669700950000e-001) (21, 2.90381219388205320000e-001) (0, -5.08583715285026990000e-003) (1, -6.44287001473231150000e-001) (2, -9.36826077869146070000e-001) (3, -2.36039034570269920000e-001) (4, -3.02007205263948730000e+000) (5, 1.96364686992833990000e-001) (6, -1.32793321032680330000e+000) (7, 7.70695102388488230000e-002) (8, 3.15798709375708150000e+000) (9, 3.57095006623318330000e-001) (10, 1.08243271361893930000e+000) (11, 1.63033264904821120000e-001) (12, 7.94707398125944900000e-002) (13, 1.53506908670944300000e-001) (14, 2.56792189626523950000e-001) (15, -5.94567762451106650000e-001) (16, 5.75140890944391140000e-001) (17, 3.20483392397379770000e-001) (18, -2.09964996321927940000e-001) (19, 2.65832512676768220000e-001) (20, 1.09155136609856780000e+000) (21, -2.96809796331074310000e-002) (0, -3.08372561804112430000e+000) (1, 5.61543729462322010000e-001) (2, 3.66346829753014800000e-001) (3, 7.12229680451001020000e-002) (4, 3.12842776714473820000e+000) (5, 6.80446304022217230000e-002) (6, 6.50499516089418810000e-001) (7, 2.10173737120539710000e+000) (8, -3.05066287340782600000e+000) (9, 3.90940613163420910000e-002) (10, 1.62601739803936330000e-001) (11, 8.54948648156486630000e-002) (12, 4.20949310610672920000e-002) (13, -4.27981924158230780000e-001) (14, -6.06638571813249210000e-001) (15, 5.28269716772283990000e-002) (16, -2.32100963001852460000e+000) (17, 1.60744827096062280000e-001) (18, 1.76552501658089670000e-001) (19, -5.44911451563111490000e-002) (20, -3.19317386185953020000e+000) (21, 8.98753120730416830000e-002) (0, 6.67876696469227760000e-001) (1, -2.27725631180543950000e-001) (2, -2.80061160851857170000e-001) (3, -2.15797579089961330000e-001) (4, 2.02913737071224620000e+000) (5, 1.83039783472940480000e-001) (6, 1.59280900093807850000e-001) (7, 2.10739839642369660000e-002) (8, 9.94316940576315810000e-002) (9, -1.13572860691084760000e-001) (10, -1.11533254367764400000e-002) (11, -2.36166793415702070000e-001) (12, 4.48604831345989330000e-001) (13, 1.11787341004946360000e-001) (14, 4.45778765655581720000e-002) (15, -2.36836397762839210000e-001) (16, 5.10420060958209460000e-001) (17, -7.79069520352309170000e-002) (18, 1.82218259475934670000e-001) (19, -1.84919684207849020000e-001) (20, 4.55260584685220630000e-001) (21, -2.04866182442695830000e-001) (22, -6.42122007305225060000e-001) (23, -3.92312978314222070000e-001) (24, 4.43041283152119800000e-002) (25, 3.08585338694657930000e-001) (26, 4.31156523110218930000e-002) (27, -1.85493623560272210000e-001) (28, 5.50764299840635350000e-001) (22, 4.24998458195306630000e-001) (23, 1.82207299168045370000e-001) (24, 6.48227935761344080000e-001) (25, 5.10426636290950140000e-002) (26, -7.92476592327944210000e-002) (27, -2.55915987890897260000e-001) (28, 6.28205707244602230000e-001) (22, -1.19608311831895160000e-001) (23, 2.06687757920738790000e-001) (24, 3.48216003151774620000e-002) (25, -2.28016026485629410000e-001) (26, 3.03526447840309740000e-001) (27, -7.55375046604436500000e-002) (28, 4.42593602933965270000e-001) 

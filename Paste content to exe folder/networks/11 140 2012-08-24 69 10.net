FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.70138592750407660000e-001) (1, -8.05527853813941960000e-002) (2, -1.92972216683826250000e+000) (3, 5.56674004024127200000e-002) (4, -9.90429533651488560000e-001) (5, 2.91928290280705050000e-001) (6, -3.15419681049747690000e+000) (7, 1.72333004341798320000e-001) (8, 4.93828371176711910000e-001) (9, 5.54949035012852750000e-001) (10, 5.10326063339965660000e-001) (11, 5.93783379577099980000e-002) (12, 3.38622498145082660000e-001) (13, 2.50688768336842670000e-001) (14, 4.30467663712482740000e-001) (15, 1.00863562396997380000e-001) (16, 2.23258303951655970000e-001) (17, 2.89140305732021980000e-001) (18, -5.37803790389745910000e-003) (19, 6.80875709623721130000e-003) (20, 3.50752023195214310000e-001) (21, 6.78805353500276100000e-002) (0, 9.64946114371170450000e-002) (1, -1.29947623687623000000e-001) (2, -6.72677596005923360000e-001) (3, -3.19756582656021360000e-001) (4, -2.08137469550200180000e-001) (5, -1.21731602981091950000e-001) (6, -1.35243810161068660000e+000) (7, 1.31799756398023270000e-001) (8, 3.00789624262238490000e-001) (9, 8.22398544144047760000e-002) (10, 1.20168930719287600000e+000) (11, -2.23623694343152430000e-001) (12, 4.61733002479575550000e-001) (13, -1.04647187824779320000e-001) (14, 4.55966192665863130000e-001) (15, 4.48309777684066100000e-002) (16, 2.36811923189874820000e-001) (17, 1.53735791881145670000e-001) (18, 1.06618849727022370000e-001) (19, 1.27411974228146790000e-001) (20, 1.17649399431743660000e+000) (21, 8.90068140208527400000e-002) (0, -3.73875246024363510000e-001) (1, 4.53500585518366970000e-001) (2, 7.19293646007926890000e-001) (3, 6.29549981672563870000e-002) (4, 4.59062405241292880000e-001) (5, 5.71139336270927440000e-002) (6, 6.63531341475102840000e-001) (7, 6.07822661721758810000e-001) (8, -3.55510984346173840000e-001) (9, -1.85060076628195240000e-001) (10, -4.37758934171127930000e-001) (11, -2.07427134994244920000e-001) (12, -1.49312237853309670000e+000) (13, 1.53884803421450440000e-001) (14, -3.60502386149795520000e-001) (15, 1.78665077228205290000e-001) (16, -4.38982665277498800000e-001) (17, -7.92508144986502900000e-002) (18, 2.91186877038762340000e-001) (19, -6.66775721237943820000e-002) (20, -6.31855060577064640000e-001) (21, 1.65420448124594940000e-001) (0, 1.15643575131770440000e+000) (1, -1.50373644055926570000e-001) (2, 6.91683204756003310000e-001) (3, 6.28895876337529360000e-002) (4, -1.10485824629410920000e+000) (5, 1.22494980558635950000e+000) (6, 3.92729065245695170000e-001) (7, 2.26048887632269600000e-001) (8, 3.13638064812262040000e+000) (9, 4.32928974762768540000e-001) (10, 3.16730105873962040000e+000) (11, 1.82196802927806820000e-001) (12, -2.69695202328361420000e-001) (13, 1.21042954169811570000e+000) (14, 3.01622683773843910000e+000) (15, 2.26042160260536360000e-001) (16, 7.14898181544902480000e-001) (17, 8.43148498319822440000e-002) (18, 1.31458801934207060000e-001) (19, 4.61514004055730560000e-002) (20, 1.66266739720960070000e+000) (21, 3.73194120227013540000e-001) (0, 4.55524603758483470000e-001) (1, -9.03020847931956360000e-001) (2, 6.17128760285680530000e-001) (3, -1.24091362156268370000e-001) (4, -1.28208360026859090000e+000) (5, 1.26607223027033640000e-001) (6, -9.12790419581625430000e-001) (7, -8.08392326955847280000e-001) (8, 3.12634036476988350000e+000) (9, 1.01996289157041990000e-001) (10, 1.10785385657586890000e+000) (11, 1.60248888779954940000e-001) (12, 8.62374053027805680000e-001) (13, 1.78196649994203590000e-001) (14, 3.86683351956225550000e-001) (15, -1.12622856125999330000e-001) (16, 1.15786073353052510000e+000) (17, 7.43084466562943940000e-003) (18, 1.17403545850136130000e-001) (19, 1.47937451950993670000e-001) (20, 1.68573258310017370000e+000) (21, -1.47663139851265250000e-001) (22, 4.83589997863860370000e-001) (23, 2.45085129294298710000e-001) (24, 1.92780449091674490000e-001) (25, -5.40840084238666110000e-002) (26, 4.39955658405067840000e-001) (27, 6.98538174084876170000e-001) (22, 1.21125174586427710000e-001) (23, -2.42323261075233170000e-001) (24, 3.39524824109150250000e-001) (25, 8.37508478056014920000e-002) (26, 2.88142855061333970000e-001) (27, 6.83882296689973360000e-001) (22, -7.29305204667867190000e-002) (23, -5.58275566790708210000e-003) (24, 3.55762079737456050000e-001) (25, -4.10653199392221610000e-001) (26, -6.89158342521758590000e-002) (27, 5.83173968292327040000e-001) 

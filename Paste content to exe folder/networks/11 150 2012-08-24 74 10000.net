FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.14623732373316560000e+002) (1, -3.46300273117601520000e+001) (2, -1.93649524261651320000e+001) (3, 1.06331132441658000000e+001) (4, -3.94483998643385520000e+002) (5, 1.66995985259390060000e+000) (6, 7.37036429613434900000e+001) (7, 1.14242834501388460000e+001) (8, 1.40031193267566240000e+002) (9, -4.59847697052126580000e+000) (10, -1.45203503590488480000e+003) (11, -2.74544642109946080000e+001) (12, 1.60566488955933640000e+002) (13, 2.12994614578455500000e+000) (14, 1.01367586382300000000e+002) (15, -7.47092077898876020000e+000) (16, -6.32659491803546300000e+002) (17, -1.84728971448703160000e+001) (18, -2.27216223192914380000e+002) (19, -2.87607646662942040000e+001) (20, -3.97275238498585850000e+002) (21, 7.51350002518578090000e-001) (0, -1.07475125249517320000e+001) (1, 6.18737540417998330000e-001) (2, -8.78456912095251500000e+000) (3, -4.13985259483212630000e-001) (4, 1.92711730769409120000e+001) (5, 2.31906957605648370000e+000) (6, 2.92575496602720310000e+000) (7, 7.07763383852420100000e-001) (8, 1.83889492425932740000e+001) (9, 8.10021451296078610000e-001) (10, 3.85075580809324120000e+001) (11, -3.89638421337588250000e-001) (12, -1.45758433211090900000e+001) (13, 7.81870025695528660000e-001) (14, -1.11437618812536280000e+001) (15, 1.31035992135882350000e-001) (16, 1.67714076555931760000e+001) (17, 1.18425894669790390000e+000) (18, -7.53291779073140070000e+000) (19, -4.76603744697368380000e-001) (20, -2.90487104453301010000e+001) (21, 9.20037800897130830000e-001) (0, 5.59755666968817960000e+000) (1, -8.80728124556039440000e-001) (2, 1.99451020111007620000e+001) (3, 2.33515729754219460000e+000) (4, -1.33815419461038690000e+002) (5, 1.67270505877069060000e+000) (6, -5.58970138555642180000e+001) (7, 2.42031308471243630000e+000) (8, 1.42899934289935630000e+002) (9, 4.53841300071745300000e+000) (10, 5.64608683895835740000e+001) (11, -3.52547809728281040000e+000) (12, -2.59447944150506300000e+001) (13, 3.18406261621473520000e+000) (14, -1.08311314295767770000e+001) (15, 1.99856037304916910000e-001) (16, -2.87344922424204230000e+001) (17, 3.02775726083566580000e+000) (18, -2.97194548516737370000e+000) (19, -4.87509665137781210000e-001) (20, -1.75261349604314700000e+001) (21, 1.08730638257947220000e+000) (0, 1.70596638397704300000e+001) (1, -4.57888552062163610000e+000) (2, 4.77756253888792770000e+001) (3, 2.15848358184275610000e-001) (4, 1.26254577931824670000e+002) (5, 1.57426903645075120000e+001) (6, 2.09924920544177240000e+001) (7, 5.78762216202950430000e+000) (8, 8.78291217458881590000e+001) (9, 4.06190817726671230000e+000) (10, 2.35127475265465190000e+001) (11, 9.48107196230650100000e-001) (12, 1.35145996627795170000e+001) (13, 1.02767342856882160000e+000) (14, 5.64000601467607010000e+001) (15, 1.37094551273168030000e+000) (16, 9.47832775639812720000e+001) (17, 1.16461814558814570000e+000) (18, 3.32887551089897760000e+001) (19, -1.68637677220921570000e-001) (20, -4.55526420949916120000e+001) (21, 1.69896842628163180000e+000) (0, -9.32251594164485480000e+002) (1, 8.95471768955513740000e+001) (2, 1.43947612438233340000e+002) (3, -1.82360802147863010000e+000) (4, 3.59743198001047860000e+002) (5, 7.92534770386055510000e+000) (6, 2.46989599733470470000e+002) (7, 1.64957147161264250000e+001) (8, -1.40393072839113840000e+002) (9, 6.57884935029677640000e+000) (10, 8.97672919529104770000e+002) (11, -3.28641427811672740000e+001) (12, 2.26974953216782410000e+002) (13, 5.59384458795362070000e+000) (14, -4.43395129804672020000e+002) (15, -5.15381265414272760000e-001) (16, 2.34508843698143210000e+002) (17, 3.40391173625160730000e+001) (18, 1.04635250703798010000e+002) (19, -2.37926313600607350000e+001) (20, -2.32680131808588810000e+002) (21, 4.26293299647442080000e+001) (22, -1.42205010534344800000e+000) (23, -2.22282915214626930000e+000) (24, 1.10736080941285310000e+000) (25, 1.73145979980598020000e+000) (26, 4.67582019811221940000e-001) (27, 4.75860472309043940000e-001) (22, 7.34378628481140440000e-001) (23, 2.30102572080841570000e+000) (24, 8.97597754597563720000e-002) (25, -1.59468278427751220000e+000) (26, -1.53992265443685650000e+000) (27, 1.49863957546152030000e+000) (22, 4.28914384009104920000e-001) (23, -1.94058540750717130000e-001) (24, -8.05111998015682560000e-001) (25, -7.68740373269573150000e-002) (26, 7.93569101180153560000e-001) (27, 6.47367284431946910000e-001) 

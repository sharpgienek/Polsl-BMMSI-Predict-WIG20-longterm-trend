FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.15130433411289680000e+000) (1, 5.43433594120603130000e+000) (2, 7.24343149980520310000e+001) (3, 3.72351373871303880000e+000) (4, 3.71066363255970510000e+001) (5, 4.17928368295473800000e+000) (6, -6.57472141320913150000e+001) (7, 3.06633204669060740000e+000) (8, 7.05436058132599440000e+001) (9, 1.57625843181039160000e+000) (10, 8.03994927721282120000e+001) (11, -1.53039529261310330000e+000) (12, 2.32016541523093050000e+002) (13, -1.00725428539482580000e+001) (14, 1.66690129082502180000e+002) (15, -2.36087280898401720000e+000) (16, 2.00694417698136260000e+001) (17, 2.41333753490130750000e+000) (18, 4.24167085607650590000e+001) (19, 9.05707593648322540000e-001) (20, 4.47206686629782770000e+001) (21, 1.85624720321068740000e+000) (0, -1.50000000000000000000e+003) (1, 7.56899340017219660000e+001) (2, 1.00651886302328240000e+002) (3, 8.05316934063994130000e+001) (4, -1.50000000000000000000e+003) (5, 3.48189973292006750000e+002) (6, -5.68078122066513630000e+002) (7, 4.80300205181314010000e+001) (8, -4.43299219531267620000e+002) (9, 3.31194578398044140000e+002) (10, 3.13409821902636050000e+002) (11, -5.01524585378265330000e+001) (12, -6.57795921753501830000e+002) (13, -3.68732599114534170000e+001) (14, 1.00689842693566020000e+003) (15, -3.53022769564599410000e+000) (16, 5.05012293366229930000e+002) (17, 3.14157485659826690000e+000) (18, -5.52034996988257380000e+002) (19, 8.94078222867250640000e+001) (20, 1.50000000000000000000e+003) (21, 1.41428718184902150000e+002) (0, -3.89314437683333210000e+002) (1, -5.12629155680608120000e+001) (2, -1.35868513079386760000e+002) (3, -9.23766233060358210000e+000) (4, -1.50000000000000000000e+003) (5, -1.19386629909258120000e+001) (6, 5.00867661381835940000e+002) (7, -1.09729542517803300000e+001) (8, -2.01846299901646340000e+001) (9, -6.56630625246617510000e+000) (10, 5.55370407923156560000e+002) (11, 2.37487928420899800000e+001) (12, -2.70655528538907620000e+002) (13, 1.37294398385564020000e+002) (14, -9.52616003830308160000e+002) (15, 3.77592711196004130000e+001) (16, -1.35023619153597420000e+002) (17, -4.09746239398966420000e+000) (18, -1.29016014362446370000e+003) (19, 2.56619864851341650000e+001) (20, 1.10464331730038680000e+003) (21, 2.21781972634417850000e+001) (0, -7.00523311468601050000e+000) (1, 7.10207579157361100000e-001) (2, 3.74034348916483880000e+001) (3, 2.50686431054721130000e+000) (4, -5.99362897470223000000e+001) (5, 7.06260074024194310000e+000) (6, 4.37598009291227970000e+001) (7, 1.16169595491792730000e+000) (8, -6.09673016954049810000e+000) (9, 2.24952640830121230000e+000) (10, 8.09641037752786020000e+001) (11, -1.88423943835953710000e+000) (12, 5.30865545335520040000e+000) (13, -3.64992927572476200000e-001) (14, -1.30881095310738720000e+001) (15, 1.38894050773436060000e+000) (16, 6.24776981772164530000e+001) (17, 1.68869413761908530000e-001) (18, -1.21666782972234860000e+001) (19, 3.20994735469081730000e+000) (20, 4.64754900665645960000e+001) (21, 4.05660535979964810000e+000) (0, 4.96972462140466790000e+001) (1, -2.08836785981571670000e+000) (2, 1.04125666163802210000e+002) (3, 3.82719933019752160000e+000) (4, -1.18273002888481910000e+002) (5, 1.54657388356404570000e+000) (6, 5.65802401425431260000e+001) (7, -1.29110955419368220000e+001) (8, 6.90864099654798000000e+002) (9, 3.78161525887491830000e+000) (10, 1.34800094375649450000e+002) (11, 4.39536733943864990000e+000) (12, 5.36630529768680870000e+001) (13, 7.26327847472246280000e+000) (14, 1.15911227692904530000e+002) (15, -1.25664073014435470000e+000) (16, -4.69403440343273030000e+001) (17, -5.12365686954084510000e+000) (18, -7.01044494120746100000e+000) (19, -1.67261718131906380000e+000) (20, 1.37151525110269520000e+002) (21, 6.01313760287123070000e+000) (22, 2.20399400338431930000e+000) (23, -2.29709108845957700000e+000) (24, 2.21158645823264080000e+000) (25, 2.44849326297156830000e-002) (26, -4.07325419389178780000e-002) (27, 2.26290473500989500000e+000) (22, -1.05819426650122030000e+000) (23, -7.28595515690130260000e-002) (24, -1.34783045320615290000e+000) (25, 1.33527608708358820000e+000) (26, 8.60869612991449820000e-001) (27, 3.00892066230171400000e-001) (22, -1.71428336104100270000e-001) (23, 1.35355451547051620000e+000) (24, 5.46087455524913030000e-002) (25, -1.38243189876578330000e+000) (26, -6.76559238559313210000e-001) (27, 7.12588204831157030000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.18192913507545420000e+001) (1, -2.51284274247724480000e-001) (2, -3.27588415957512650000e+000) (3, 4.11358682659281440000e-001) (4, 2.67832829693555860000e+001) (5, -3.77420120712944340000e-001) (6, -4.50152024277985150000e+000) (7, -4.49243153171058650000e+000) (8, 1.58045242105800240000e+000) (9, -3.78736148476692950000e+000) (10, 4.93987021646979870000e+001) (11, -2.24887720878768520000e-001) (12, 9.39369302663105720000e+000) (13, 2.98964833727780480000e-003) (14, -3.32240138390716950000e+001) (15, -1.00232450261191650000e+000) (16, -2.29116340058221720000e+001) (17, -9.48322030203337940000e-001) (18, -9.06872642527955010000e+000) (19, -4.92798046494551220000e-001) (20, -1.05498183991218490000e+001) (21, -6.39160870264366300000e-001) (0, -3.45579476270860160000e+001) (1, 5.14364171346165310000e-002) (2, 1.35400525388797720000e+001) (3, -3.37658153918838360000e-002) (4, -1.07918933970399710000e+001) (5, 5.25412372934244700000e-002) (6, -2.91181436308145700000e+000) (7, -3.08307506442373520000e+000) (8, -3.11577357885458390000e+001) (9, 6.18673410111013410000e-002) (10, 9.83380682032400700000e+000) (11, -6.23322313900969060000e+000) (12, 1.79460142331208740000e+001) (13, -1.42511763586042410000e+000) (14, 1.02028950066192060000e+000) (15, -1.43368449754073350000e+000) (16, 1.99661341722921900000e+001) (17, -5.96179374531589180000e+000) (18, 1.59320154458873780000e+000) (19, -1.02437957874866220000e-001) (20, -3.18646711085037900000e+000) (21, -3.22332802945878690000e+000) (0, -5.79464080827229440000e-001) (1, 2.95213601684781280000e-001) (2, -4.92085573360223450000e+000) (3, 7.17710204072479210000e-002) (4, -8.93008949307127600000e-001) (5, 2.79773958559038140000e-001) (6, -1.81148282692988350000e+000) (7, 1.53915186623683400000e+000) (8, 5.82661765903656730000e+000) (9, 7.78106208279394810000e-001) (10, 1.03602712378706010000e+001) (11, 7.91108579958511910000e-001) (12, 2.10468516529303680000e+001) (13, -3.06915031478416370000e-001) (14, 1.44776764205420320000e+001) (15, 9.76434739861903320000e-002) (16, 1.05436547855690180000e+001) (17, 8.55639467424173180000e-001) (18, -1.50212427446356170000e+000) (19, 2.56484114819938160000e-001) (20, 2.72320672148554530000e+000) (21, -5.34239739132565730000e-001) (0, 1.37675288997120080000e+001) (1, -7.39200828605267810000e-001) (2, 4.14122287053938650000e+001) (3, 4.80892726726222130000e-001) (4, -1.80273038708253570000e+001) (5, -6.24517959514098720000e-001) (6, -3.69995388362683420000e+000) (7, -5.82289301771382290000e+000) (8, 1.59250881328360600000e-001) (9, 1.25767876735696060000e-001) (10, 6.62682781021925570000e+000) (11, -4.33294131660909090000e+000) (12, -2.34521330440227020000e+001) (13, -3.26388436635963180000e-001) (14, -8.27172517727665200000e+000) (15, -6.52236955394796650000e-001) (16, -1.39018490884722180000e+001) (17, -2.33542556054966120000e+000) (18, 2.66247125142123870000e+001) (19, -5.48059287238390260000e-001) (20, 1.65183229834517210000e+001) (21, -1.56038079501146010000e-001) (0, -7.03684396926262770000e+000) (1, -8.35889185242267960000e-001) (2, 1.35609440111876390000e+000) (3, 4.90501216803034930000e-001) (4, -1.45660974991745410000e+001) (5, 4.63539806203845220000e-001) (6, 1.77433259177499740000e+001) (7, -1.80027357941996840000e-001) (8, 4.19179739285745350000e+000) (9, -7.02105614629526920000e-001) (10, -2.83691077321704700000e+001) (11, 4.91890529064547280000e-001) (12, -5.12619091760545940000e+000) (13, 2.44094975650284060000e+000) (14, 7.99562825843328720000e+000) (15, 1.15310177729155930000e+000) (16, 8.14045207762037480000e-002) (17, -2.21190208907002580000e-001) (18, -2.15189413852269020000e+000) (19, 2.67747999454596210000e-001) (20, 1.33743850597001350000e+001) (21, 6.52014694002834520000e-001) (0, 2.47407082536285930000e+001) (1, 1.70671716479777170000e+000) (2, -3.28579030840811010000e+001) (3, -1.89973009894857600000e-001) (4, 3.24073827073242670000e+001) (5, -1.17490330250343860000e+000) (6, 3.38963172978791650000e+001) (7, 4.98689366491789700000e+000) (8, -3.23679071463346590000e+001) (9, 5.52452330066847240000e-001) (10, 1.29644132611419780000e+001) (11, -3.84684486300985280000e-001) (12, -1.17512719463605230000e+001) (13, -3.91649028427252690000e+000) (14, 5.96123239443951820000e+000) (15, 1.34970404210733950000e-001) (16, -2.46847048103437990000e-001) (17, 3.15418444844823350000e+000) (18, 7.78780325999899150000e+000) (19, 1.08884778262555400000e+000) (20, 2.63691065345991370000e+001) (21, -2.47521095109408700000e-001) (22, 9.71624521320589300000e-001) (23, 6.93031377979987480000e-001) (24, 1.84574368280267390000e+000) (25, 8.33754676746806260000e-001) (26, 1.36606872450998830000e+000) (27, 5.86820562231615720000e-001) (28, 1.24162499576043460000e+000) (22, -7.53111610770884180000e-001) (23, -1.17486832690786590000e+000) (24, 9.39622469857318980000e-002) (25, 4.56356978745738160000e-001) (26, -5.50039514510782920000e-001) (27, -1.04535402712695880000e+000) (28, 1.68192632830280770000e-001) (22, -2.80136227444054420000e-001) (23, 4.08612047082687170000e-001) (24, -1.85696749399921290000e+000) (25, -1.12496903801145320000e+000) (26, -7.99395517335980350000e-001) (27, 4.44433517952948440000e-001) (28, 8.93201209665354430000e-001) 

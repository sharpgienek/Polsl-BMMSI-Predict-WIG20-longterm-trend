FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.31799760783490910000e+002) (1, 7.78737669067680120000e+000) (2, 7.20497328669593600000e+001) (3, -5.39236950794329870000e-001) (4, 3.60146591354974250000e+001) (5, 1.40266311808309880000e+000) (6, 8.00532896952504420000e+001) (7, 1.42647215985464830000e+001) (8, -3.03127745663405970000e+001) (9, -7.29968914911021340000e-001) (10, 7.27369165151032180000e+001) (11, 1.34075704735570490000e+000) (12, 1.17587470375786640000e+002) (13, -2.80956718176168030000e+000) (14, 1.04343995382523220000e+002) (15, 1.11592792231118130000e+000) (16, 5.74888158139916870000e+000) (17, 7.12733691060786700000e+000) (18, 1.99177042423500800000e+001) (19, -6.57010124275601130000e-001) (20, -1.87670709405782750000e+001) (21, 2.72648212197922680000e-001) (0, -1.30404830265098760000e+003) (1, 4.36303439935982510000e+000) (2, -9.17874476475394090000e+002) (3, -4.44305761302440350000e+001) (4, -9.23555459801667670000e+002) (5, -6.65104592500882600000e+001) (6, 8.02623911203800160000e+002) (7, -3.29813320831029050000e+002) (8, 1.50000000000000000000e+003) (9, -3.25538162073371980000e+000) (10, -1.86232574634911630000e+002) (11, -2.09438700284882170000e+002) (12, -1.50000000000000000000e+003) (13, -2.23166700632562340000e+000) (14, -1.50000000000000000000e+003) (15, -2.17233725958364410000e+000) (16, 1.50000000000000000000e+003) (17, 3.29844308419334240000e+001) (18, -3.31976963343896500000e+002) (19, 5.28839771143705390000e-001) (20, 3.63601478120937000000e+001) (21, 7.67429749219931350000e+000) (0, 8.35800093526911600000e+000) (1, 6.03863070430261990000e-001) (2, -1.61878414081242920000e+001) (3, -7.23809192304091100000e-002) (4, -1.17588313724741430000e+001) (5, -8.88156046687043200000e-002) (6, -8.99009585356049180000e+000) (7, -2.48931865935154870000e-001) (8, -1.06935901657244430000e+001) (9, 5.07258493727022270000e-002) (10, 9.88084488441567110000e+000) (11, 3.43276868780767690000e-001) (12, -2.15314687673535050000e+000) (13, 4.60119921849925510000e-001) (14, -1.26496153395538970000e+001) (15, -1.37906008461767730000e-001) (16, -9.85633319754237470000e+000) (17, -4.87007950407274510000e-001) (18, -1.67331620750399450000e+000) (19, 2.71936545237765960000e-002) (20, -6.42286999486186880000e+000) (21, 9.70932466650929030000e-001) (0, 4.91797961098733790000e+001) (1, 3.79316395072352150000e+000) (2, 6.26625011484807090000e+000) (3, -8.56184071472467450000e-001) (4, 1.08886205671979640000e+002) (5, -2.22985731686328310000e+000) (6, -9.11977972737431910000e+001) (7, 1.35435685589233330000e+000) (8, -7.52348269658958060000e+001) (9, 4.58699337114041870000e-001) (10, 5.74659180565691370000e+001) (11, -3.00580975630957870000e+000) (12, -2.00006400117790300000e+001) (13, -5.77524576548851430000e+000) (14, -3.06670054096701780000e+001) (15, -2.63592699115219500000e+000) (16, 2.55494192518999200000e+001) (17, 8.10525205299412080000e-001) (18, 6.98585978127569120000e+001) (19, -9.29491164589390630000e-001) (20, -1.33327281421083490000e+001) (21, -8.66548854301463780000e-001) (0, -1.17796064457172620000e+002) (1, -2.93471689384088790000e+000) (2, -4.26951584131257680000e+001) (3, 3.40796758231754280000e+000) (4, 1.79362410367069670000e+001) (5, 2.15502929732620000000e+000) (6, -1.62137839667446570000e+002) (7, 1.13599240050993110000e+000) (8, -2.16119806369650090000e+002) (9, 2.63601425255117980000e+000) (10, 1.74704706365779540000e+001) (11, 1.47904529206429030000e+001) (12, -4.01555969515384130000e+001) (13, -9.86238969427291720000e-001) (14, -1.49073139873677660000e+002) (15, -2.88072503301793730000e+000) (16, -8.14308845292117240000e+001) (17, -1.07861580096266000000e+001) (18, -4.16521093505734720000e+000) (19, 2.72865371323866550000e+000) (20, 1.25650092579724330000e+002) (21, 7.68354170365834840000e+000) (0, 3.01646718043104760000e+001) (1, 1.73558904824354570000e+000) (2, -5.41286651746582680000e+000) (3, 1.04540427119627600000e-001) (4, -6.74359461855427430000e+000) (5, 2.10854349203624110000e-001) (6, -1.54613079752088820000e+001) (7, 5.86509355503770260000e-001) (8, -1.51804143256724920000e+001) (9, 1.33047977675256200000e-001) (10, 2.94157024411450150000e+001) (11, 4.00528215290257120000e-001) (12, 1.00665224432475390000e+001) (13, 7.84840820648441270000e-002) (14, -4.70597516466926710000e+000) (15, -3.49969295354087160000e-001) (16, -1.32659238517944370000e+001) (17, -4.73274819414628680000e-001) (18, 1.19197609676323050000e+000) (19, -1.39673698636102910000e-002) (20, -7.39544326594567640000e+000) (21, 4.92479578714630720000e-001) (22, 5.18849728153298990000e-001) (23, 1.29206412681747770000e+000) (24, -4.10415570104226820000e+000) (25, -1.47292125164798240000e+000) (26, 1.37863288063554170000e+000) (27, 3.43827463786844680000e+000) (28, 8.78212886054455020000e-001) (22, -1.70139659309236910000e+000) (23, -1.54851200922300470000e+000) (24, 5.41516176195020460000e-001) (25, 1.92046166480708740000e-001) (26, -1.71847461255959690000e+000) (27, -3.61003727601917290000e-001) (28, 1.71220843810655050000e+000) (22, 7.45302013806952930000e-001) (23, 6.29466569148254550000e-002) (24, 2.57089527261481400000e+000) (25, 9.69259649239014090000e-001) (26, 2.33001863876931530000e-001) (27, -2.25065291515198450000e+000) (28, 2.91353410857770000000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.12872413731396740000e+000) (1, -2.43242811618009510000e-001) (2, -1.99062422501963710000e-001) (3, 3.17751522831363650000e+000) (4, 1.34489576533844540000e+001) (5, 2.91707629615941200000e-002) (6, 1.97770897617418870000e+001) (7, 3.51952309563977290000e+000) (8, 5.75418460797196740000e+000) (9, 9.50056785849956560000e-001) (10, -1.97808394639603230000e+001) (11, 2.22921272701143320000e+000) (12, 3.13269670245110680000e+000) (13, 7.06330759843114220000e-001) (14, -1.17122670465311830000e+001) (15, 9.32651142190579650000e-001) (16, 3.64680803872083860000e+000) (17, 2.23309323854666220000e+000) (18, 1.79339099123897450000e+000) (19, 4.03610673069270510000e-001) (20, -2.72188063676621150000e+001) (21, 1.17969782571975320000e+000) (0, -2.98431336276295370000e+000) (1, -2.92289092928447350000e-001) (2, 2.61078854206987820000e+001) (3, 2.77004306215584940000e-002) (4, -1.33608684106407660000e+001) (5, 2.30666345567529560000e+000) (6, -6.86831241086588040000e+000) (7, -1.64170921115178860000e-001) (8, 2.94543741069156510000e+001) (9, 1.44442093619921890000e+000) (10, -8.05408150228447720000e+000) (11, -3.21644078100194740000e-001) (12, -2.66997511968333820000e+001) (13, 9.74613289822490510000e-001) (14, -2.08295910567857940000e+001) (15, 5.16148077181187050000e-001) (16, 1.15013550065810770000e+001) (17, 1.45321494258017150000e+000) (18, 2.44082857195596010000e+000) (19, -2.27793771216804000000e-001) (20, 7.12325179734836220000e+000) (21, 6.99329975680265890000e-001) (0, 4.32548427027971890000e+000) (1, 1.06819584487435060000e-001) (2, 5.97057664013272320000e+000) (3, -7.84876810614255180000e-001) (4, -7.22487612836478470000e+000) (5, 2.45320038448948010000e+000) (6, 1.60156758951144300000e+001) (7, 9.76960275514575430000e-001) (8, 1.97064435382429150000e+001) (9, 1.97799981747306820000e+000) (10, 5.33123047929994160000e+000) (11, 5.83460717500638550000e-001) (12, 2.54344315815107040000e+001) (13, -1.77201736617678050000e-001) (14, -7.36760041290588590000e+000) (15, 7.18242428061230290000e-001) (16, 2.60661817913203290000e+001) (17, 3.08102405182462300000e+000) (18, 9.68320996887257830000e+000) (19, -1.36413418949044290000e+000) (20, 2.52529301026625750000e+001) (21, 4.94962911086930140000e-001) (0, 3.72102952645037630000e+001) (1, -1.14465964257968710000e+000) (2, 1.20604835610449060000e+001) (3, -6.47189085593991820000e+000) (4, 8.38698296372852430000e+000) (5, 1.61263921500230860000e+000) (6, 7.35355147116958200000e+000) (7, -8.60109169438354800000e-001) (8, -6.23787604619127660000e+000) (9, -1.61265855020750550000e-001) (10, -4.53616538696921800000e+000) (11, -2.96462364255942580000e-001) (12, 5.21767398259167600000e+000) (13, -5.69438366948040520000e-002) (14, 3.32427952496530990000e+001) (15, 4.72727512957038630000e-001) (16, 3.47591121392627270000e+000) (17, -5.14955393252718000000e-001) (18, -2.74154358575581970000e+001) (19, -2.12064325031879350000e+000) (20, 2.85913362788732360000e+001) (21, -4.61216056303477740000e-003) (0, 6.40889927435607200000e+000) (1, -8.88920087863106830000e-001) (2, 1.77932457292144690000e+001) (3, -2.77365454438519340000e-001) (4, -1.54474205674679880000e+001) (5, 1.43703491630815570000e+000) (6, 1.61395794633780270000e+001) (7, 9.52438921203074160000e-001) (8, 3.68622311882499860000e+001) (9, 1.58230979034520480000e+000) (10, 5.28985160091264460000e+000) (11, 5.19219604458265090000e-001) (12, -3.07512886646861800000e+000) (13, 7.52764194301376750000e-001) (14, 2.63874770118702480000e+000) (15, 1.12046970787640010000e+000) (16, 8.49295022993459980000e+000) (17, 9.34134173641298030000e-001) (18, -1.77714656921743810000e+001) (19, 1.56059030005941350000e-002) (20, 6.61635706066067990000e+000) (21, 5.75146507105967830000e-002) (22, -1.29497330248944160000e+000) (23, -1.72433238784411410000e+000) (24, 1.00944239107619230000e+000) (25, -1.30147928311871830000e+000) (26, 1.95933817531553460000e+000) (27, 1.25793238416613500000e+000) (22, 8.56913235648630530000e-001) (23, 1.19004461582880850000e+000) (24, -9.15418683548366640000e-001) (25, 7.58816297415490500000e-001) (26, -4.13974401300372660000e-001) (27, 2.43612018106831090000e-001) (22, 4.40250875750471230000e-001) (23, 2.66767155124832510000e-001) (24, 8.74031709765990960000e-002) (25, 3.51166043925033200000e-001) (26, -1.24331756216650710000e+000) (27, 7.25095224661479020000e-001) 

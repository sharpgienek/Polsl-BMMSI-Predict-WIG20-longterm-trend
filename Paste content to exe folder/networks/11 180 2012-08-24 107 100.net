FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.36574211242729190000e+000) (1, -3.19433118437405930000e-002) (2, -3.37574973303029320000e+000) (3, 1.68309479004226880000e-001) (4, 4.33515447701152020000e+000) (5, 3.39894504780444420000e-001) (6, -6.70067027206052130000e+000) (7, -9.56596508797070590000e-001) (8, 1.76337982344856490000e+001) (9, 7.61235768934948150000e-001) (10, 1.12950231281502660000e+001) (11, -1.33249232264113520000e+000) (12, 5.41719101891461550000e+000) (13, -1.24118032549279960000e+000) (14, 2.84589742006915890000e+001) (15, -4.29075889656989780000e-001) (16, 2.19612914578558670000e+000) (17, 7.96172080064294350000e-002) (18, 4.56581329901203500000e+000) (19, 5.03133804230797900000e-001) (20, 8.74310511910026020000e+000) (21, -4.47915062422375610000e-001) (0, 4.38080773885152740000e+000) (1, -1.16551354476188050000e+000) (2, 2.42669825884681670000e+001) (3, 1.07365472401193270000e+000) (4, -4.25678060395691560000e+001) (5, 9.43849979394981280000e-001) (6, -1.48187755210216880000e+000) (7, 2.45216717324448960000e+000) (8, -1.45124302141233380000e+001) (9, 6.07094634020646560000e-001) (10, 3.35884201363895670000e+000) (11, 1.22863974951944940000e+000) (12, 2.81587018186014950000e+000) (13, 2.90751241875861720000e+000) (14, -2.48737052797826690000e+001) (15, 1.22032608363732460000e+000) (16, 1.20435173567640600000e+001) (17, 3.56614930068280750000e-002) (18, -2.04526146048383560000e+001) (19, 9.38290326622145540000e-002) (20, -8.97614612531405780000e+000) (21, -1.45566512688214720000e-001) (0, -1.57743440114495160000e+001) (1, 2.77356740800043640000e+000) (2, 6.43774561362419320000e+001) (3, 1.13184485336072280000e+000) (4, -1.37023807106097360000e+001) (5, -3.23200227335056770000e-001) (6, 6.25581147950979320000e+000) (7, -5.04504112201123230000e-001) (8, -5.79886489585305840000e+000) (9, 5.80352760922426710000e-001) (10, 5.34211919577059650000e+000) (11, 3.04287337370554400000e+000) (12, -4.28576868542196220000e+001) (13, 2.93242244435881650000e-001) (14, -3.03444050608695510000e+001) (15, 1.32948556752329890000e-001) (16, -1.89040975465073350000e+000) (17, -6.65532150439339210000e-003) (18, -1.15810129550739730000e+001) (19, 7.27904200967700590000e-001) (20, 1.88116837214511780000e+001) (21, 3.03907673184310800000e+000) (0, -5.73888885364274510000e+000) (1, 8.81806284257133030000e-001) (2, -8.80602302078329830000e+000) (3, -3.06519946480487580000e-001) (4, -4.05641882848868910000e+000) (5, -5.84924931279612200000e-001) (6, -1.03786039456826580000e+000) (7, 2.66768092479386650000e-001) (8, 8.94089511962822310000e+000) (9, -1.15394848713762360000e-001) (10, 1.01154371637673760000e+000) (11, 4.33061931262358810000e-001) (12, -9.45474952255990320000e-001) (13, -1.81154628442624310000e-001) (14, -6.28508723172327780000e+000) (15, -4.82960082650839910000e-002) (16, -1.13540096131353250000e+001) (17, 1.16730412047829500000e+000) (18, 2.03713323766650730000e+001) (19, -3.11082052195662260000e-001) (20, 2.90793966093284740000e+000) (21, -3.89249712427685750000e-001) (0, 7.69006616706806590000e+000) (1, -1.47109958741639280000e+000) (2, 3.97164829841171810000e+000) (3, 4.38613601582401310000e-001) (4, 7.25530988389665940000e+000) (5, 6.68073325878344890000e-001) (6, 1.35353315404671070000e+001) (7, -1.98005735202988590000e+000) (8, 1.69901908396691430000e+001) (9, 1.41685547667825230000e-001) (10, 1.11884014038576040000e+001) (11, 4.41086086541621620000e-001) (12, 1.93855688513719390000e+001) (13, 1.38351782818141440000e+000) (14, 5.29949046888339390000e+000) (15, -2.04823688188143870000e-001) (16, 8.03510129855392210000e+000) (17, -3.36670138397932470000e+000) (18, -3.24703913771188080000e+001) (19, 5.74911338503906080000e-001) (20, 1.30696413900247790000e+001) (21, -4.57393514379865200000e-001) (0, -1.54756550664249730000e-001) (1, -1.35804426738534390000e+000) (2, -5.66899149037868000000e+001) (3, -3.02476274237752580000e-001) (4, 1.26058360472843950000e+001) (5, 1.05966776167609080000e-001) (6, 5.01594881747647040000e+000) (7, 2.04524457768248350000e+000) (8, -5.42275454766922990000e+001) (9, -2.20817773048977630000e+000) (10, -9.13155173075147180000e+000) (11, 2.37742630269003910000e-001) (12, 6.58363970654924910000e+000) (13, 5.23536335520788820000e-001) (14, -2.02386196030189570000e+001) (15, 1.48404817456434080000e+000) (16, 1.34694769659877560000e+001) (17, -2.43788868492225810000e-001) (18, -6.73739160675957120000e+000) (19, -7.76736729656613110000e-001) (20, -1.12669041665566460000e+001) (21, -2.29056811239173900000e-001) (22, 1.71875129653310330000e+000) (23, 1.04842753554484110000e+000) (24, 9.12781215941543270000e-001) (25, 1.85015984501358990000e+000) (26, 1.13554286721562980000e+000) (27, 7.45410462780702780000e-001) (28, 4.78506188525863850000e-001) (22, -1.22824585556649750000e+000) (23, 1.71339986417740900000e-001) (24, -1.46664198584898190000e+000) (25, -3.00795561449696770000e-001) (26, -9.82658315533989770000e-002) (27, -1.09322173992239540000e+000) (28, 1.28526824747694010000e+000) (22, -3.73571810687854670000e-001) (23, -1.34154273581418030000e+000) (24, 5.37953731293617450000e-001) (25, -1.37974661846099880000e+000) (26, -9.23846944961139500000e-001) (27, 3.55414209152575990000e-001) (28, 7.32918809163704780000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.36127749984888190000e+000) (1, -1.47755146542261160000e+000) (2, -1.40958274855417290000e+001) (3, -6.00673283420080860000e-001) (4, -1.26844838333209340000e+001) (5, 5.08880579218694230000e-001) (6, 1.96554152173433250000e-001) (7, 4.49766520304756110000e-001) (8, -3.50028793665403550000e+001) (9, -4.51650072477995430000e-001) (10, -7.00654531246281780000e+001) (11, -5.11204586544511510000e-001) (12, 6.34408185088501320000e+000) (13, 2.12949868443801370000e-001) (14, -9.35551571473520660000e+000) (15, -6.17458185662553280000e-001) (16, 1.84045683619149150000e+000) (17, -8.98282053084203950000e-001) (18, -4.17017961760803860000e+001) (19, -2.62730740035687970000e+000) (20, -7.12871370412615450000e+001) (21, -2.01351555720457130000e+000) (0, 2.66976555148188680000e+000) (1, 1.46237936508659350000e+000) (2, -2.18702205464392870000e+000) (3, -6.17527765334425990000e+000) (4, -4.18930851163491620000e+001) (5, 6.81562698483039500000e+000) (6, -7.06813047077250900000e+001) (7, -1.81666863847442950000e+000) (8, -4.03637432768833480000e+001) (9, 4.26144934644618060000e-001) (10, 1.14859013155537770000e+000) (11, 1.21800862990281250000e-002) (12, -2.10440365056568620000e+001) (13, 5.98652644166138880000e+000) (14, -4.90519977618848630000e+001) (15, 1.41519378917343630000e+000) (16, -3.15174743130929360000e+001) (17, 2.00552862459045760000e+000) (18, -6.93191257214618870000e+001) (19, 8.32240470132855850000e-001) (20, -3.09179887975291020000e+001) (21, -4.51993190113592020000e+000) (0, -6.96159330929283500000e-001) (1, 2.23771433799987470000e+000) (2, -8.14731025200326680000e+001) (3, -1.41559736467830040000e+000) (4, 9.35251138856222470000e+001) (5, 2.83278197267746390000e-001) (6, 5.62293852257027780000e+001) (7, 6.03010623721413810000e+000) (8, 5.93632994351263220000e+001) (9, -2.84442269958064880000e+000) (10, -4.84421294607960890000e+001) (11, -2.65002887673012830000e+000) (12, -7.25684782704396700000e+001) (13, -8.43533605285798770000e+000) (14, 4.48482703271440140000e+001) (15, -8.02630347392875420000e-001) (16, -2.98398535249419830000e+001) (17, -3.17904727422655020000e-001) (18, 1.93643579883000360000e+001) (19, 1.66573899086122770000e+000) (20, 6.82082913561423960000e+001) (21, 9.21365200375733990000e-001) (0, 4.46450484703828250000e+001) (1, 1.03882896333192190000e+000) (2, -3.64342232402582130000e+001) (3, 3.20036752482624310000e-001) (4, 3.00703976261534530000e+000) (5, -2.97586327645238930000e+000) (6, -7.48325882108074490000e+000) (7, -3.40576927106098730000e+000) (8, -3.92464640391798060000e+001) (9, -1.45221266713306370000e+000) (10, 5.24546786600377570000e+001) (11, -2.20895120466932320000e+000) (12, -1.23809175808723000000e+001) (13, -5.49455031939479090000e-001) (14, 5.69733901353013120000e+000) (15, 5.65871050372573350000e-001) (16, -1.16427230399829490000e+001) (17, -1.32931318635392290000e-001) (18, 1.35027514995228760000e+001) (19, 1.94856203538956410000e-001) (20, 2.96944702870405440000e+000) (21, 1.24237131982888420000e+000) (0, -2.38733216439079360000e+001) (1, -6.84847935237475220000e-001) (2, 1.82010741308282780000e+001) (3, 1.89782050098305480000e-001) (4, -4.61558828604021700000e-001) (5, -1.00346193039451660000e-001) (6, -3.75898113894912570000e-001) (7, 4.33950043930112880000e-001) (8, -3.49860688323718790000e+000) (9, 6.67153128057396680000e-002) (10, -2.23234353303601840000e+001) (11, 7.02208083413987770000e-001) (12, 7.86297134008672850000e+000) (13, -6.08294596826184500000e-002) (14, -4.22927122354017730000e+000) (15, -4.49827442787485650000e-001) (16, 6.65664909590211980000e+000) (17, -1.93542669781200690000e-001) (18, -3.63703348980594640000e-001) (19, -3.47372984393867990000e-001) (20, -4.31363570400126070000e-001) (21, 1.05906563341850000000e+000) (0, 7.77718445229002670000e+001) (1, 2.21946839169667150000e-001) (2, -6.97140096532981610000e+000) (3, 1.50692963408768960000e-002) (4, -5.16387892093776060000e+001) (5, -3.50704958156425550000e-001) (6, 1.33570138117062000000e+000) (7, 1.89471020242041810000e+000) (8, 4.68492383250777710000e+001) (9, 3.50588020376334630000e-001) (10, 1.06547308097853670000e+001) (11, -2.00315962118290390000e+000) (12, 3.77902653805117410000e+001) (13, 2.03965992820595600000e-001) (14, -2.28984016565893250000e+001) (15, 3.68541817716285190000e-001) (16, -2.38725448500507340000e+000) (17, -2.01161097397481830000e+000) (18, -3.58120771122564040000e+001) (19, -8.33044305183221150000e-001) (20, -6.94032327605417980000e+001) (21, -5.78114845036702630000e+000) (22, 4.67568658708382170000e-003) (23, -1.81833250500778100000e+000) (24, -1.14036199338443910000e+000) (25, -2.55407596966178920000e+000) (26, -3.91033891979106720000e+000) (27, -1.31776157732148010000e+000) (28, 6.21174744495314400000e-001) (22, -1.29756187756495400000e+000) (23, 1.33888731783936030000e+000) (24, 7.09185695370505440000e-002) (25, 1.15617998497226710000e+000) (26, 2.73963920513342620000e+000) (27, 2.29731213678848260000e+000) (28, 1.15134049538748280000e+000) (22, 8.96799951211769140000e-001) (23, 1.31923561205860300000e-001) (24, 7.47962804002959000000e-001) (25, 6.87638932836491800000e-001) (26, 3.51402596549003850000e-001) (27, -7.32863588483465440000e-001) (28, 7.73495914951495610000e-001) 

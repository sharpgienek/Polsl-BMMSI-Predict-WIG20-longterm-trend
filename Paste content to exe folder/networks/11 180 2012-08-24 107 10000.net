FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.32000576034283630000e+001) (1, 3.17084972321135440000e+000) (2, 3.59021008791648340000e+001) (3, 3.12611572307402770000e+000) (4, 2.64337931122958950000e+001) (5, 7.94594823128964830000e+000) (6, 3.26082865753294160000e+001) (7, 5.30192712542292990000e+000) (8, 1.38486832276006310000e+002) (9, 1.02124799449339520000e+001) (10, -5.88702982612405950000e-001) (11, 2.97225000000366140000e+000) (12, -5.03412061661706080000e+001) (13, 8.17764534421495550000e-001) (14, 3.52889688235283220000e+001) (15, 9.26846454852538580000e-001) (16, 6.13786002414704510000e+001) (17, 2.11990266096589060000e+000) (18, 4.55316591315744500000e+001) (19, -1.48413243984564790000e-001) (20, -1.10490517127152080000e+001) (21, -3.88938434740722800000e+000) (0, 1.50000000000000000000e+003) (1, 1.62677146950002580000e+001) (2, -8.32066001124480290000e+001) (3, 1.85525537073763540000e+001) (4, 6.85430179425035250000e+002) (5, 8.32229429107827490000e+001) (6, -2.77090991016618370000e+002) (7, 2.18596987887618870000e+002) (8, -1.50000000000000000000e+003) (9, 2.77305160832217330000e+001) (10, 7.39910951102868810000e+002) (11, 2.24399359253487370000e+000) (12, -5.63693073360414810000e+002) (13, 1.07396830323950210000e+001) (14, -1.16658156238201660000e+002) (15, 3.01063121190654530000e+001) (16, 9.60697981746516010000e+002) (17, 2.38297350909513030000e+001) (18, 7.87257072788076360000e+002) (19, -6.09544549311767360000e+000) (20, 5.98025030591153240000e+000) (21, 1.44345991401393280000e+001) (0, -3.93192129645704140000e+002) (1, -8.55304653924225990000e+001) (2, 1.50000000000000000000e+003) (3, -1.74245106954410430000e+001) (4, -1.07480801063165200000e+002) (5, -1.35456007532713190000e+002) (6, 1.31973070891181830000e+003) (7, 1.82657221147989970000e+001) (8, -5.01041424135651030000e+002) (9, -1.11028715651033170000e+002) (10, -1.25781327338225260000e+003) (11, 3.38982048586014100000e+001) (12, 1.30041951084436800000e+003) (13, 1.46737644295884790000e+001) (14, 2.59000027354168540000e+002) (15, 1.46878601708972720000e+001) (16, -4.59904021557500260000e+001) (17, 8.06117887775364320000e+001) (18, -1.32103939837922130000e+002) (19, 2.27234158237314040000e+001) (20, 2.00373349715363420000e+002) (21, -1.32931832455072050000e+001) (0, 5.09817515595410270000e+002) (1, -2.04124725058108150000e+001) (2, -4.94240926815491660000e+002) (3, -1.71583543067344290000e+002) (4, -1.50000000000000000000e+003) (5, 2.72594519553321180000e+001) (6, -9.72995400471733430000e+002) (7, -6.29458656724444410000e+001) (8, -1.42941450241311940000e+002) (9, 3.68814245241522160000e+001) (10, 1.50000000000000000000e+003) (11, -1.87086799310898390000e+002) (12, -3.28076838858353940000e+002) (13, -6.88412616170263900000e+000) (14, 1.50000000000000000000e+003) (15, -6.47309264755456870000e+001) (16, 2.63938008932723450000e+002) (17, -7.56131769586281170000e+001) (18, 6.94455635595645960000e+002) (19, -9.27467314107671290000e+000) (20, 6.15532196454519860000e+002) (21, 4.59751639616759530000e+001) (0, -1.01579192930789870000e+003) (1, -3.77430993978286590000e+000) (2, -7.48839091968598150000e+002) (3, 3.32542891267114770000e+001) (4, 5.76817985789618890000e+002) (5, 7.89530656241103210000e+000) (6, 5.95217572842169830000e+002) (7, -2.11937238662958090000e+001) (8, -4.66305979371297720000e+002) (9, -1.68891999614999300000e+001) (10, -1.65950115791897870000e+002) (11, 6.46572181327872530000e-001) (12, 3.02522008114422080000e+002) (13, -7.55554495961571600000e+000) (14, -4.71057739374298250000e+002) (15, 6.25310164405034730000e+000) (16, -5.68893678627080820000e+002) (17, -4.72830969744761820000e+000) (18, -8.39132445832438660000e+001) (19, 1.35004990924467790000e+001) (20, 3.15881114109985560000e+002) (21, 6.23286257490692320000e+001) (0, 5.53610601394583310000e+000) (1, -8.38202575965888650000e-001) (2, -8.10395568379491670000e-001) (3, 1.34060810680418510000e+000) (4, -2.70798593101635490000e+001) (5, 2.22241209538400500000e+000) (6, 4.06327767509110420000e+000) (7, 3.05934339012460210000e+000) (8, -3.56627811433221780000e+001) (9, 2.38628838514707540000e-001) (10, 1.04049197987900260000e+001) (11, 6.42767088226260160000e-001) (12, 9.63882262546618480000e+000) (13, 3.00006492505297740000e+000) (14, 5.12652386950691690000e+000) (15, 1.51187189571997900000e+000) (16, 7.81359097095595790000e+000) (17, -2.78262874593497240000e-001) (18, -2.08636317768078920000e+001) (19, 1.21105009047506190000e-001) (20, 4.26624520455575330000e+000) (21, 2.27736938588462360000e+000) (22, 1.64000731395390820000e+000) (23, 8.89247106499542610000e-002) (24, 1.52490297500988680000e+000) (25, 1.52419567804474480000e+000) (26, 1.53736931497648620000e+000) (27, 4.56201464048067790000e-002) (28, -8.08371178699086730000e-002) (22, -1.74423293365284340000e-001) (23, -1.10967539610430670000e+000) (24, -7.81629272409845250000e-001) (25, -7.69799227697136160000e-001) (26, -1.82348227065197020000e+000) (27, 2.12925584129457100000e+000) (28, 9.74008675943923370000e-001) (22, -8.78415367708563320000e-001) (23, 6.79885026184516960000e-001) (24, -5.29427349452955220000e-001) (25, -5.09866346933220750000e-001) (26, 1.59785120183824400000e-001) (27, -1.67212601966405420000e+000) (28, 1.62151341378989410000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.73509658573290070000e-001) (1, -3.20344197779486140000e-001) (2, -1.48975971984127220000e+000) (3, -1.31182109185905280000e-001) (4, 1.25084493241201080000e+000) (5, -1.32258409410988540000e-001) (6, 4.69551694910229240000e-001) (7, -2.11646443607848010000e-002) (8, -1.33277940180526720000e+000) (9, 4.82219046797460820000e-002) (10, 1.93203040246689300000e-001) (11, -1.17347520516924000000e-001) (12, 3.01919009674114390000e-001) (13, -6.19043487623210490000e-001) (14, 1.81893225625034930000e-001) (15, -1.26718312678952840000e-003) (16, 2.27464736012167270000e-001) (17, -7.92493754179674080000e-002) (18, 6.10943580687939970000e-001) (19, -1.96570759789452820000e-002) (20, -4.15709959852583470000e-001) (21, -2.40367529946504200000e-001) (0, 3.11001346022971870000e+000) (1, 1.17753732504327580000e-001) (2, 3.03244998251143280000e+000) (3, -1.01628886089277960000e-001) (4, 1.22130450826387850000e-001) (5, -2.23153860990954470000e-003) (6, 7.01045813248409530000e-001) (7, -7.06592469940678510000e-002) (8, 1.30147969879152760000e+000) (9, -1.36229716682995490000e-001) (10, -4.63908452670567790000e-001) (11, -5.30426613152976960000e-002) (12, -3.01811282409466750000e+000) (13, 6.54678416042245410000e-001) (14, 2.98485244882955300000e-001) (15, 1.74584030897434460000e-002) (16, 5.56083478910683440000e-001) (17, -2.01732275464544060000e-001) (18, -1.29114121759105990000e+000) (19, -4.66550329026004570000e-001) (20, -2.25561605900181930000e-003) (21, -2.78831885988417790000e-001) (0, -3.11850345059060440000e+000) (1, -1.90550767392193340000e-001) (2, 3.14941165417617250000e+000) (3, 1.68895863361775170000e-001) (4, -3.13418948598059450000e+000) (5, 8.35068985170860810000e-001) (6, 1.70198358741451120000e-001) (7, 1.51958581490155240000e+000) (8, 5.67842153375744120000e-002) (9, 7.77095277114107970000e-001) (10, 1.02928940228016730000e+000) (11, 3.40035493790680150000e-001) (12, -4.79359767670096000000e-002) (13, 1.14473039962648840000e+000) (14, 1.03258530076678000000e+000) (15, 5.84694493155264890000e-001) (16, -1.37895694904388830000e-001) (17, -8.00241029690548780000e-004) (18, -1.48109845257267620000e+000) (19, 3.96160045884320630000e-002) (20, 4.63035079037065920000e-001) (21, 2.14165639426972390000e-001) (0, 5.87636387730352540000e-001) (1, -3.97369970545278510000e-002) (2, 1.45059434973546830000e+000) (3, -1.23552714540968460000e-001) (4, -1.18523301288790470000e+000) (5, -1.18543809597250100000e-001) (6, 3.91404707694720740000e-001) (7, 2.29777636785790730000e-002) (8, 3.05255496327977040000e+000) (9, -8.42949014559814660000e-002) (10, 3.29875654680544750000e-001) (11, -1.50766051443364660000e-001) (12, -1.29823960636870920000e+000) (13, 4.99819029345622670000e-001) (14, 6.81886877416044150000e-001) (15, -2.16712361652086070000e-002) (16, 4.73879489925736090000e-001) (17, -2.91130470156055980000e-001) (18, -4.92445976371682690000e-001) (19, -1.68626806221234100000e-001) (20, 1.94779331716652360000e+000) (21, -1.92839453066405680000e-001) (0, -3.14965579480481050000e+000) (1, -3.88739329463132060000e-001) (2, -3.03542239466510020000e+000) (3, 1.02578799384229350000e-001) (4, -3.08548953408303370000e+000) (5, 6.03793236511680260000e-001) (6, -3.17605350027629200000e+000) (7, 2.53851278416622750000e-001) (8, 3.04858767806440320000e+000) (9, 8.99317343722111810000e-001) (10, 3.21182010237175590000e+000) (11, 4.28292361422531960000e-001) (12, 3.12326419284904500000e+000) (13, 2.76684563619726380000e-001) (14, 1.10888535073186430000e+000) (15, 2.42144768183168320000e-001) (16, 2.62181594003707330000e-001) (17, 3.68562388462286670000e-001) (18, -2.05319419521442230000e-001) (19, 3.24996065982347810000e-001) (20, 3.07673098903064620000e+000) (21, -1.05278305020562830000e+000) (0, 3.43089737735114030000e-001) (1, -3.62354696452366340000e-001) (2, -1.45315083257700730000e+000) (3, -4.93699011720646550000e-003) (4, 1.62606461346105170000e+000) (5, -1.69019623795435700000e-002) (6, 1.15902008072292440000e-001) (7, -1.18140582839502130000e-002) (8, -5.91889881551280750000e-002) (9, -7.39417447565998700000e-002) (10, 3.95633601944288040000e-001) (11, -9.77674421001581000000e-002) (12, 1.86510145558146350000e-001) (13, -6.40076202780372360000e-001) (14, 5.18986460699772110000e-002) (15, -3.23157675738244830000e-002) (16, 3.07884659085517490000e-001) (17, -1.31782335185144480000e-001) (18, 8.33507976057517250000e-001) (19, -2.94288046401803840000e-002) (20, 3.73528231183978270000e-002) (21, -1.71153661727637190000e-001) (22, -6.00010980544239260000e-002) (23, -3.11742042728817280000e-001) (24, 3.70942164546940070000e-001) (25, -1.30183214067565720000e-001) (26, 4.50379421590022420000e-001) (27, -7.74815670649032090000e-002) (28, 4.55073025175587560000e-001) (22, -7.40803432364493950000e-002) (23, 1.13485015848776450000e-001) (24, 4.50887546223754430000e-001) (25, 7.54906305169910090000e-002) (26, -1.52616671670986360000e-001) (27, -9.65290740397115460000e-002) (28, 4.63039646014209830000e-001) (22, -3.17230809194861960000e-002) (23, -9.20585734466691920000e-002) (24, -1.97011130431882290000e-001) (25, -2.84239600912749020000e-001) (26, -6.44950257393142380000e-001) (27, -9.72487352747818110000e-003) (28, 5.90543928642934150000e-001) 

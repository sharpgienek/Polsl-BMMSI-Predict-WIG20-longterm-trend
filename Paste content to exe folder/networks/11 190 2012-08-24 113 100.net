FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.14257745775708380000e+001) (1, 4.95250207768554380000e-001) (2, -1.76849171819479170000e+000) (3, -3.91400631480474830000e-001) (4, 1.10231819823743620000e+001) (5, -1.20941641414291960000e+000) (6, 1.59894996578924860000e+001) (7, -2.75039181323957570000e+000) (8, 1.90766931821852100000e+001) (9, -5.50403229545456620000e-001) (10, -1.76821437198777890000e+001) (11, -8.02880226664292930000e-001) (12, -5.47186579348066270000e+000) (13, -2.04914125388850770000e+000) (14, 8.13480236593314740000e+000) (15, -1.25112059786989560000e+000) (16, 1.09626018855887430000e+001) (17, -9.87414834385966920000e-002) (18, 1.26816752650050650000e+001) (19, 3.21477092402837620000e-002) (20, 2.37824754967350310000e-001) (21, -4.07215009988982470000e-001) (0, -2.39881767604815400000e+001) (1, -1.31658898826330040000e+000) (2, -6.58864321135732660000e+000) (3, 9.33933927737005120000e-001) (4, 9.96318340299284880000e+000) (5, 3.04034608064531480000e-001) (6, 1.34369613418724650000e+001) (7, -6.56336612661041370000e-001) (8, -2.91684094832469260000e+001) (9, 2.53938540448367940000e-001) (10, -9.23115241207874960000e+000) (11, 1.50155822285741200000e+000) (12, 1.75353277807271870000e+001) (13, -4.13521794511462980000e-001) (14, -1.14099264785319860000e+001) (15, -2.23563005874092970000e-001) (16, 1.67334408821320220000e+000) (17, 2.05111029092639450000e+000) (18, 2.38887814421869390000e+001) (19, 7.21908513952271740000e-001) (20, 1.29178774345032090000e+001) (21, 1.20590362458830120000e+000) (0, 2.48552516589120120000e+000) (1, -1.08486372740320650000e+000) (2, -3.77495665101512450000e-001) (3, 3.10862543784417190000e-001) (4, 1.45200739550171900000e+000) (5, 1.50949554323713350000e-001) (6, 1.37461669852333480000e+001) (7, 7.82729795260155400000e-001) (8, 6.87515369886735160000e+000) (9, 2.29613003347570320000e-001) (10, -2.92900598669839520000e+001) (11, -7.95644489851940690000e-001) (12, 3.88530899742175310000e-001) (13, -2.05987819766469850000e-001) (14, 1.76097124575772100000e+001) (15, -4.97282145045661870000e-002) (16, -5.75566212510130630000e+000) (17, -8.86720553804427490000e-001) (18, -1.08838316846685680000e+001) (19, 2.70141179509143960000e-001) (20, -1.36165567910928020000e+000) (21, 4.77693842465885750000e-001) (0, -3.28109536864670970000e+000) (1, -1.17650652853823230000e+000) (2, -1.45398914031793220000e+001) (3, 1.04978544981957670000e+000) (4, 1.37253059639699760000e+001) (5, 5.05681549815649280000e-001) (6, 1.56574230189220330000e+001) (7, 5.74756849645520430000e-001) (8, -2.39865466611605530000e+000) (9, 9.71599629181566730000e-001) (10, -2.93366681366816020000e+001) (11, -6.96620598259503760000e-002) (12, -4.24321518842733500000e-001) (13, -9.42155569040063260000e-001) (14, 5.79145601389188090000e+001) (15, 8.27766182078022440000e-001) (16, -2.44295804658618690000e+000) (17, -2.78549859256062070000e-001) (18, -1.25410407605041350000e+001) (19, 9.83005481772739280000e-001) (20, 1.43174309728787300000e+001) (21, -7.13967213937054530000e-001) (0, 2.34954834017212110000e+000) (1, -1.47019063966111170000e+000) (2, 1.08503009488487120000e+001) (3, 1.14623245832197700000e+000) (4, -1.27461545144791530000e+000) (5, 6.21729709782405520000e-002) (6, -7.32476413319423260000e+000) (7, -1.61248413986845220000e+000) (8, -1.63179679079660860000e+001) (9, 9.30512866451916000000e-001) (10, -8.54752242234541450000e+000) (11, 1.33847541174965000000e+000) (12, 8.48207027946457790000e+000) (13, -1.03134786957010860000e+000) (14, 1.48953792323614190000e+001) (15, -2.31220280603048220000e-001) (16, 9.86366232522956190000e-001) (17, 4.64373867614023990000e-001) (18, 6.16234825422917250000e+000) (19, 7.81145069259792550000e-001) (20, 2.25488448472169160000e+001) (21, -8.03851693727026140000e-001) (0, -1.79385512314944190000e+001) (1, -9.08205691954081630000e-001) (2, -1.74328246884323580000e+001) (3, 3.96308213064837790000e-002) (4, -4.30694731225917380000e+001) (5, 4.58100767564178890000e-001) (6, 2.45807384099536930000e+001) (7, 2.08563746524046910000e-001) (8, 7.02365017354787260000e+001) (9, 9.36321988831374070000e-001) (10, 2.54747513940396480000e+000) (11, -1.57833637117355920000e+000) (12, 1.27870553778064580000e+002) (13, 5.03323730371832870000e-001) (14, -4.30705193991471000000e+000) (15, -1.40960306274001360000e+000) (16, 2.19937766617852400000e+000) (17, 5.87561777531870220000e-001) (18, 4.83613028626847380000e+001) (19, 5.82224676030603350000e-001) (20, 1.24245970872827090000e+001) (21, 9.28951195620868890000e-002) (22, -4.79187452792105010000e-001) (23, -1.97126533498881960000e-001) (24, -1.31146468413119430000e+000) (25, 1.38171027137474910000e+000) (26, -2.08067914650355900000e-001) (27, 8.55774687761630790000e-001) (28, 5.60597427296605780000e-001) (22, -6.29896181057313150000e-001) (23, -7.95660797388701770000e-001) (24, 9.61074322468366220000e-001) (25, -1.38269175470044910000e+000) (26, 1.16537098951796780000e+000) (27, -3.87990651848882980000e-001) (28, 8.35273848629717430000e-001) (22, 1.35044299521036030000e+000) (23, 1.21648392863544670000e+000) (24, 2.93755534195243360000e-001) (25, -7.39921482606559070000e-002) (26, -1.08613734710658010000e+000) (27, -5.02652303458569370000e-001) (28, 9.83275865765500300000e-001) 

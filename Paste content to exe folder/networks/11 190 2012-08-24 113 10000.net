FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.82966489419985830000e+001) (1, -1.30142142211454260000e+000) (2, -5.45271482466584560000e+001) (3, 1.36643965057575500000e+001) (4, -1.91802327365064340000e+002) (5, 1.00797092319873000000e+001) (6, -1.59810355861052730000e+002) (7, 6.42989101340571430000e+000) (8, 9.91845504440716040000e+001) (9, 1.46685554436453100000e+001) (10, 5.31529248457012050000e+002) (11, 4.31193256964773750000e+000) (12, -2.51126260372984580000e+001) (13, 9.75186036501326830000e+000) (14, -1.16544120716240700000e+002) (15, -1.10369985980872490000e+000) (16, -5.65557911339265190000e+001) (17, -2.57670823879937090000e+000) (18, -1.79923658540785890000e+001) (19, -1.00879144173100070000e+000) (20, 3.98495679362660200000e+001) (21, 8.86668033530180110000e+000) (0, 5.18044856652566860000e+002) (1, 4.22827218375158580000e+001) (2, 1.50000000000000000000e+003) (3, -2.18349565395448620000e+001) (4, -7.58855560224089800000e+002) (5, 1.18555920133133830000e+000) (6, 3.13248261529981450000e+002) (7, 2.19847237805883360000e+001) (8, 1.50000000000000000000e+003) (9, 1.41166079719017010000e+002) (10, -7.62644867071865860000e+002) (11, 2.05835029154138600000e+001) (12, -6.36893483603599180000e+002) (13, 4.32706801815303520000e+001) (14, 8.00933660583946330000e+002) (15, 1.85911987176888060000e+002) (16, 4.68383411469138480000e+002) (17, 9.12361380396869780000e+001) (18, 4.62635260366885520000e+002) (19, 2.27727067119744680000e+001) (20, 7.29446936765715580000e+002) (21, 4.87110246243237910000e+001) (0, -1.49296204837916660000e+002) (1, 1.08532119497734720000e+001) (2, 9.89305553368685930000e+001) (3, -1.30184013538366240000e+000) (4, -2.09815556242665090000e+001) (5, 1.00772106445579100000e+001) (6, 3.32486242665927560000e+001) (7, 5.38269963964863770000e+000) (8, 6.13310237977398670000e+001) (9, 8.51702570434696500000e+000) (10, 3.02908932589136270000e+001) (11, 1.34287068968541090000e+001) (12, 2.38557915218495200000e+002) (13, 1.92651671099256430000e+000) (14, 1.56082190435889320000e+002) (15, -1.07576408126060660000e+001) (16, 2.80188812864240280000e+002) (17, -2.21908897910596090000e-001) (18, 1.42266598430020790000e+002) (19, -5.30921406512138730000e+000) (20, -8.78357528989474610000e-001) (21, -4.62825792654775730000e+000) (0, 4.18331680737906990000e+002) (1, 1.33256323079380130000e+001) (2, 4.64155449410484720000e+002) (3, -4.87584528136252790000e+000) (4, -2.65801661157432820000e+001) (5, 5.61078582430151940000e+000) (6, -6.56708727565695990000e+002) (7, 5.06101195845654320000e+000) (8, -9.14554617200650450000e+001) (9, 3.72391069493785930000e+000) (10, 1.22144634661961790000e+002) (11, 6.67599893526925300000e+000) (12, 2.97869384811164510000e+001) (13, 3.04654978481946030000e+000) (14, -8.92171882693699840000e+001) (15, 2.75220974117472090000e-001) (16, 4.57431250868172360000e+002) (17, -2.29624918521474180000e+000) (18, 2.45674830990685390000e+001) (19, -1.56662925669516860000e+001) (20, -3.33210235510924350000e+002) (21, -4.37468490675528710000e+000) (0, -4.26183160634837610000e+001) (1, 4.42609516050709840000e+000) (2, -4.87966448541611020000e+001) (3, -1.72446796119989520000e+000) (4, 2.12943773996275520000e+002) (5, -6.76213844769697840000e+000) (6, 3.97362268171804660000e+002) (7, 3.25603607594603340000e+000) (8, 2.14295055590135800000e+002) (9, -7.82400395399174720000e+000) (10, -2.26415818248122780000e+002) (11, -8.02115665515024220000e-001) (12, -6.53824113834297730000e+000) (13, -6.74730635415675200000e+000) (14, 2.87052720051482910000e+001) (15, -1.08187707677716920000e+001) (16, -4.05475544001015250000e+001) (17, -1.46627374538839010000e+001) (18, -9.35991911543948160000e+001) (19, 2.01710833337977210000e+000) (20, -5.77874446871607270000e+000) (21, -6.19541029478818570000e+000) (0, 1.50000000000000000000e+003) (1, 4.95306613557311480000e+001) (2, -1.49228325299095200000e+003) (3, 4.15624868704101900000e+001) (4, 1.50000000000000000000e+003) (5, -6.10850265722894150000e+001) (6, -5.54315003997355920000e+002) (7, -2.83897532649447230000e+001) (8, 1.50000000000000000000e+003) (9, -5.28698651009962790000e+001) (10, 1.22563603846844440000e+003) (11, -3.61900122240286990000e+001) (12, 2.95399656619224520000e+002) (13, 2.64533596620273140000e+000) (14, -4.57839193853302330000e+002) (15, 8.76118189249790680000e-001) (16, -1.09916700121833330000e+003) (17, -1.02260306752642210000e+002) (18, -1.47908995879685970000e+003) (19, 1.14322373113073360000e+001) (20, -2.22678080334374730000e+002) (21, 2.46719536252521050000e+001) (22, -2.98045733009431320000e-003) (23, 2.20778933976510420000e-002) (24, 1.87881485889690030000e+000) (25, -1.83981408203902810000e+000) (26, -1.87633569531841780000e+000) (27, 1.86249545310178700000e+000) (28, -2.71906998775709560000e-002) (22, 1.43395363379262930000e+000) (23, 1.32262686244492130000e+000) (24, -1.29029609713364500000e+000) (25, 1.31803890951902700000e+000) (26, 1.44641905249845480000e+000) (27, -1.26732149542471450000e+000) (28, -5.90423620895179220000e-002) (22, -1.76157232972042440000e+000) (23, -1.43170574040704920000e+000) (24, -1.77909176395968590000e-001) (25, 4.51534513424454930000e-002) (26, -1.05098661810122900000e-002) (27, -2.13588429490714490000e-001) (28, 3.26275652317534750000e+000) 

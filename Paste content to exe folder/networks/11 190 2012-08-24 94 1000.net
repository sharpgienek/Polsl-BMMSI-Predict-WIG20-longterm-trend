FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.52477962539422230000e+000) (1, -2.11605496384566120000e+000) (2, 5.74040523963324320000e+001) (3, 2.24847068741041280000e+000) (4, -4.82925188456531630000e+001) (5, 3.93489183308718540000e+000) (6, -1.72455904799144830000e+001) (7, 6.92186396782991510000e-002) (8, 2.47697753856988730000e+002) (9, 1.97959866777806970000e+000) (10, 3.82937227152998220000e+001) (11, 1.78743387396986720000e+000) (12, -2.54514992186649770000e+000) (13, 3.08838533162121290000e+000) (14, -1.08150011468614450000e+000) (15, 1.07603826804250560000e+000) (16, -4.85127614011234410000e+001) (17, -1.04167217377438770000e+000) (18, -2.14439804336056240000e+001) (19, 9.31047622669428200000e-001) (20, 2.89824473492067900000e+001) (21, -1.90095661132321880000e+000) (0, 4.73293823678039800000e+001) (1, 1.42246251609668420000e+000) (2, -1.53242720419999560000e+001) (3, 2.04425101851700130000e+000) (4, 7.27263997707389010000e+000) (5, 3.70863737538697700000e+000) (6, 9.33699857797796540000e+001) (7, 8.83868707058429770000e+000) (8, 1.32344945609896090000e+002) (9, 2.92294273905574360000e+000) (10, 3.60850926101955520000e+001) (11, 2.81798707886470810000e+000) (12, -1.13233177027565440000e+001) (13, 2.05816901128942740000e-001) (14, -1.49342440856008910000e+001) (15, 1.64731573535666760000e+000) (16, -5.29698894223600690000e+001) (17, 5.58800461697863130000e-001) (18, -2.83151482708993960000e+001) (19, 6.73061342409015500000e+000) (20, -2.47657370183331340000e+001) (21, 3.58917518889619510000e+000) (0, -5.33622436794308450000e+000) (1, 2.66565888115317230000e-001) (2, -2.29841584265423540000e+001) (3, 1.54926302359051360000e+000) (4, -4.52014921799928400000e+001) (5, 2.06353151649959180000e+000) (6, -2.85008903221997090000e+001) (7, 2.61441745614055470000e+000) (8, -3.70138710064710420000e+001) (9, 1.91774680227818410000e+000) (10, 5.01316312047710680000e+001) (11, 9.87169584787963130000e-001) (12, 1.82970758337411790000e+000) (13, 2.91840870791864050000e+000) (14, 6.26432976404972400000e+000) (15, 1.53832237076970310000e+000) (16, -1.03008223296151320000e+001) (17, 4.83788384272037520000e-001) (18, -4.98730565457293760000e+001) (19, 1.53332110373859460000e-001) (20, 1.28744492835489040000e+001) (21, 1.76367503692993080000e+000) (0, 5.89130864920335170000e+002) (1, 9.32008344408069430000e+000) (2, 6.74236073586918110000e+001) (3, -6.24805473549447670000e+000) (4, 6.82866190819867280000e+001) (5, 8.36833314605764400000e+000) (6, 2.10343072815007730000e+001) (7, 6.29522510967867600000e+001) (8, -2.64567369607497540000e+002) (9, 9.73218098947705630000e+000) (10, 2.00257621351222440000e+002) (11, 5.96101714284665630000e-001) (12, 2.61900704917952820000e+001) (13, -1.45491434516574980000e+001) (14, 1.35985279911713890000e+002) (15, 7.69141585284776720000e-001) (16, 1.93685803238149360000e+002) (17, 1.57938068073519040000e+001) (18, 2.66957031036347250000e+002) (19, 1.29044576753062850000e+000) (20, 8.90635346948209020000e+001) (21, 8.25214485304392300000e+000) (0, -4.41816329901587610000e+001) (1, 9.59382204182150260000e-001) (2, -5.35149367528129640000e+001) (3, 4.73179900254251430000e+000) (4, 4.39712684586654350000e+001) (5, 5.31821538108858240000e-001) (6, 3.61754107023201000000e+001) (7, -9.09667072682943330000e-001) (8, -3.89612578139842610000e+001) (9, -2.08858356639414630000e-001) (10, 6.32490427508614510000e+000) (11, 1.37884218452385770000e+000) (12, -8.02402398122771740000e+000) (13, 1.51669610211106730000e-001) (14, -1.26795284712236440000e+001) (15, 8.93928558364433410000e-001) (16, -2.52226879113644740000e+000) (17, -1.94495555630753490000e-001) (18, -2.04497388334068010000e+001) (19, 1.50726143114822690000e+000) (20, 2.51225075602531370000e+001) (21, 1.97934867976560460000e+000) (22, 1.13606383628478520000e+000) (23, -1.70059422610064080000e+000) (24, 2.88701746613821970000e-001) (25, 1.13471739276836940000e+000) (26, 1.28101267503450610000e+000) (27, 4.76447845466713150000e-001) (22, -4.28470518559642910000e-001) (23, 1.28120059606641880000e+000) (24, 9.89893720783384670000e-001) (25, -8.76559192227162940000e-001) (26, -1.54069302807181940000e+000) (27, 4.49204420151406210000e-001) (22, -5.21932201806383440000e-001) (23, 2.08991924412367830000e-001) (24, -1.89671583019730530000e+000) (25, -1.65251050101952980000e-001) (26, 3.03191593571800530000e-001) (27, 2.08938866306620600000e+000) 

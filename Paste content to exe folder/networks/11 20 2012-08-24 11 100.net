FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.33941445917476410000e+000) (1, -8.80120683182242510000e-002) (2, 4.63998944039264890000e-001) (3, 2.40037098157819430000e-001) (4, 3.07499405015039030000e-001) (5, 2.27293963823320040000e-001) (6, -1.17946586412238920000e+000) (7, -4.81282258613542070000e-001) (8, 3.91873443970952850000e+000) (9, -2.78495987889039290000e-001) (10, 3.49100864559816150000e+000) (11, -4.79641831810922600000e-002) (12, 8.83940740700017940000e-001) (13, -4.27645955537242000000e-001) (14, 1.64010808618514780000e+000) (15, -6.64059520266324420000e-001) (16, 1.21775803042084600000e+001) (17, -9.95551555614621050000e-002) (18, -4.32869912200893130000e+000) (19, -3.05632425015412900000e+000) (20, -1.10123273365929620000e+001) (21, -4.86237566477657590000e-001) (0, -2.21986415239850030000e+000) (1, -9.00374324179626370000e-002) (2, -1.01049291712431180000e-001) (3, 8.86442019929420730000e-001) (4, -1.26846464924206170000e+000) (5, -2.33418771069037880000e-001) (6, 1.68266463538457930000e+000) (7, -2.26356508204719150000e+000) (8, 3.28786927942181830000e+000) (9, -5.05886970465159960000e-001) (10, 4.56039601268389830000e+000) (11, -2.20432880992047050000e-001) (12, -2.77107245484517320000e-001) (13, 6.09484458101696380000e-001) (14, 4.51153527226677390000e+000) (15, -1.30969467066906750000e+000) (16, 7.35059316214290100000e-001) (17, 3.76311301697317690000e-001) (18, 2.83928888300390430000e-001) (19, -4.13710779103805140000e+000) (20, -3.85214614722658450000e+000) (21, -1.67372382373381810000e+000) (0, 4.54646949882107880000e+000) (1, 7.69167543750742480000e-001) (2, 1.13448044812125270000e+000) (3, 3.16273833234117010000e-001) (4, 1.66005361487910110000e+001) (5, 7.81385228910941860000e-001) (6, -3.21861816667073120000e+000) (7, 1.58175525624355840000e+000) (8, 3.48318365538487530000e+001) (9, 7.71606190786978010000e-001) (10, 1.11160236767877700000e+000) (11, -1.07803446925426920000e+000) (12, 6.24895946605105210000e+000) (13, 5.46549571809498810000e-001) (14, -2.73371582639218400000e-001) (15, 1.11600709676631730000e-001) (16, -3.09093760852258460000e+000) (17, 3.68853685446005330000e-001) (18, -4.27108758212225490000e-001) (19, 3.89083883666938140000e+000) (20, 3.78341556512106040000e+000) (21, -1.13310592913652930000e+000) (0, 1.13186664010232210000e+000) (1, 3.19420501313458160000e+000) (2, 4.59946280541044580000e-001) (3, 6.75897508052870410000e-001) (4, -2.80429115249680060000e+000) (5, 1.26907997325859470000e+000) (6, 5.05561286742551270000e+000) (7, 8.66318219049299200000e-002) (8, -7.69901967424821890000e+000) (9, 1.00312541436250900000e+000) (10, -5.21031375204144330000e-001) (11, 2.35917452737222710000e+000) (12, 2.46886470605417640000e+000) (13, 5.61930171047606560000e-001) (14, -4.99085836023860030000e-001) (15, 2.32136200305336620000e+000) (16, -1.18341924293368760000e-001) (17, 4.94863686118693910000e-001) (18, 3.71332741229766940000e+000) (19, -6.91933794260824580000e-001) (20, -8.34070036656683020000e+000) (21, 6.45918084657996610000e-001) (0, -8.41084886450154560000e+000) (1, -5.16444043163384770000e-001) (2, 2.99868829154427090000e-001) (3, 2.52429144882922430000e+000) (4, 1.38309523338310610000e+000) (5, -7.56572494349173950000e-001) (6, 7.04134353524511590000e-001) (7, 2.91485616220062140000e-001) (8, -8.52403859830200440000e+000) (9, 3.02212840788813050000e-001) (10, -5.96394766491402770000e-001) (11, 7.36307159831945830000e-001) (12, -1.30036072575197450000e-001) (13, -3.11436292655672690000e-001) (14, 7.70192377898680450000e-001) (15, 6.76613438121357740000e-002) (16, 2.35513260069497710000e+000) (17, 3.90673911260025760000e-001) (18, -4.50513667595148350000e+000) (19, 2.24294811686119070000e+000) (20, -1.24944874534220550000e-001) (21, 2.35048969173285240000e+000) (0, 1.59115701275881650000e+001) (1, 5.79711910662768500000e-001) (2, 8.00662855553835050000e+000) (3, 2.36323892895710070000e-001) (4, 1.79064868572301070000e+001) (5, 2.27365648533896270000e+000) (6, -4.28350971913535970000e+000) (7, 5.52991877533524970000e-001) (8, 2.67112338619737780000e+001) (9, 1.47626488706553820000e+000) (10, 1.38865606571374520000e+000) (11, -7.67657079503780150000e-001) (12, 6.61897846381438000000e+000) (13, 1.33770069487427870000e-001) (14, -3.07836309158202930000e-001) (15, 1.36769236609792150000e-001) (16, -3.09374312493248370000e-001) (17, 4.03040009577571520000e-001) (18, 2.93287279294989990000e-001) (19, 9.74074170543540730000e-001) (20, 1.33888680527544570000e+001) (21, -8.72190502000297130000e-001) (22, -1.61668011969956370000e+000) (23, 1.49368354156027120000e+000) (24, 5.56038493838918460000e-001) (25, 3.16523498590386750000e-001) (26, -4.34186483813773060000e-001) (27, -5.05409577994699430000e-001) (28, 1.02890387304560530000e-001) (22, 1.74928274144566660000e+000) (23, -2.10078210368010910000e+000) (24, 5.69537249510448260000e-001) (25, 5.68503037191593900000e-001) (26, -3.12460961088778080000e-001) (27, 1.74441253254047870000e+000) (28, 1.18434375690919970000e+000) (22, -4.27157165443299850000e-001) (23, 2.33721933833511840000e-001) (24, -1.90176180306436300000e+000) (25, 1.20231833418483200000e+000) (26, 6.15238630309449030000e-001) (27, -9.43417165389840990000e-001) (28, 9.30313243430001550000e-001) 

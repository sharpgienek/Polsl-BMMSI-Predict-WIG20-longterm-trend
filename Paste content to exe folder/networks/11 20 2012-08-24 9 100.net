FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.09344644477559720000e+000) (1, 5.56656044272998860000e-001) (2, 2.76506098560210580000e-001) (3, -1.41020684059562140000e-001) (4, 1.08951893304638610000e-001) (5, -2.84345111813962880000e-001) (6, -1.63586957079642370000e+000) (7, -1.02216774226671300000e+000) (8, 1.67907314148113400000e+001) (9, -3.32665011916661600000e+000) (10, 3.67601941672832890000e+000) (11, -6.75332813938802070000e-001) (12, -2.53582401674557190000e+000) (13, 6.44547508068683660000e-001) (14, 5.16661048497109370000e-001) (15, -1.53750271809987080000e+000) (16, -3.15451294123161400000e+000) (17, -2.98947912380243100000e-001) (18, 1.51234550446184210000e+001) (19, 4.37250170711045790000e+000) (20, 2.07388546545819920000e+001) (21, -3.66669693426391730000e+000) (0, 1.03451113463419180000e+001) (1, 5.56241545994437980000e-001) (2, 1.19910102190580980000e+000) (3, -1.18166076052533110000e-001) (4, 4.69601462633480720000e+001) (5, 8.15107886300481480000e-001) (6, -5.41472533936214530000e+000) (7, 7.53152148346838630000e-001) (8, 1.89127493748733320000e+001) (9, 6.27788791441155180000e-001) (10, 3.63809630631478810000e+001) (11, -2.96086208657131330000e+000) (12, 1.56333742929140680000e+000) (13, 5.85692284187758540000e-001) (14, -2.69334617978666040000e-001) (15, 3.16380160800231460000e-001) (16, -1.80911917887895360000e+000) (17, 5.31110944648111800000e-002) (18, 1.59979661258932660000e+000) (19, 2.02643585734944360000e+000) (20, 3.10093441704034060000e+000) (21, -9.99258128241011790000e-001) (0, 2.78837674780978870000e+000) (1, 5.89667794660893380000e-002) (2, 3.15795316722003060000e-001) (3, -1.58890352828598690000e+000) (4, -6.37940069892571500000e+000) (5, 1.08717014234020580000e+000) (6, 5.23761448985277230000e+000) (7, 6.34633282309601030000e-001) (8, 1.29319633339802850000e+000) (9, -3.85038384428592780000e-001) (10, 3.73772690638360230000e+000) (11, -9.92107092088921560000e-001) (12, 2.12702359106420190000e+000) (13, -3.72466830307423970000e-002) (14, -1.18594762021982650000e+000) (15, 3.46336374689535580000e-002) (16, 2.40175924100465690000e+000) (17, -8.97745501797567870000e-002) (18, -7.62716671106513420000e-001) (19, 5.26297168918939120000e+000) (20, 1.06933675791576400000e+000) (21, -8.21814415220475710000e-001) (0, 2.08437275352783650000e+001) (1, 6.58624743945359640000e-001) (2, 5.34393098488641720000e+000) (3, 5.73420034643528640000e-001) (4, 1.83369285896577130000e+001) (5, 1.51268026629379300000e+000) (6, -5.87305689668716990000e-001) (7, 1.82503963112270370000e+000) (8, 7.42808519355611190000e+000) (9, 1.00993851337263550000e+000) (10, 8.18031295214144020000e+000) (11, 5.74735574918258390000e-002) (12, 8.21715901852582480000e-001) (13, 4.53509705210184470000e-001) (14, -2.99387251457024470000e+000) (15, 8.33465741184945820000e-002) (16, 7.32526350856077400000e-002) (17, -3.78718455645685390000e-002) (18, 3.30393441662110510000e+000) (19, 1.10398927746091260000e+000) (20, 8.85430980121561720000e+000) (21, -8.05437391137988290000e-001) (0, 7.09192848993265400000e-001) (1, 1.07988320724361730000e+000) (2, 4.35282385837488570000e-001) (3, -6.00966112905350510000e-001) (4, 1.58291865222929400000e+000) (5, 7.70921072339319950000e-001) (6, -1.71708168635946060000e+001) (7, -4.91846085425739490000e-002) (8, 3.32486841375529210000e+001) (9, -1.88915386457593030000e+000) (10, 2.34542404422777050000e+001) (11, -2.37894894729101350000e+000) (12, -2.55596069890132730000e+000) (13, 9.60992652843669750000e-001) (14, 7.71964909875594070000e-001) (15, -6.36817847844842080000e-001) (16, -1.58425596071631820000e+001) (17, 6.43909917276735130000e-002) (18, 2.39798130638368520000e+000) (19, 5.92418217608204230000e+000) (20, 9.90259764014183650000e+000) (21, -3.29337631770022870000e+000) (22, 4.48829215173000510000e-001) (23, 4.67580784884802650000e-002) (24, -7.27978793898788950000e-001) (25, -5.39362257276049110000e-002) (26, 1.37460408536892230000e+000) (27, 1.12736294904710690000e+000) (22, -1.46427817012777490000e+000) (23, 9.09313289704334120000e-001) (24, 9.72838211307791910000e-001) (25, 1.67367880464959320000e+000) (26, -6.11255202992539660000e-001) (27, 2.25111467330860570000e-001) (22, 1.68800309612197360000e-001) (23, -2.13136818988434170000e+000) (24, -1.02835519784545570000e+000) (25, -9.93959022344270140000e-001) (26, -1.19702828515979130000e-001) (27, 2.02178753227915830000e+000) 

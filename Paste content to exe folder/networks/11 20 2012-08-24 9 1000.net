FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.14548875597396100000e+000) (1, 1.78774171989843820000e+000) (2, 1.53728376600432100000e+001) (3, -2.11801422025111210000e+000) (4, 1.04404063573923150000e+002) (5, 2.47636106620683980000e+000) (6, -2.71042214928253670000e+001) (7, 1.58749740826219980000e+000) (8, 2.85548139903715170000e+001) (9, 3.66533027524184100000e-001) (10, 1.94776232582959250000e+001) (11, -4.66649605343775950000e+000) (12, 2.29617606349363390000e+000) (13, 2.55889554818529240000e+000) (14, -4.72963459924776330000e+000) (15, -8.21423707334064670000e-001) (16, -1.58824473001291260000e+001) (17, 6.29913569102371900000e-002) (18, -2.08531857274787760000e+000) (19, 8.28218222903502270000e+000) (20, 9.15929256669249630000e+000) (21, -1.74670293203424780000e+000) (0, -2.60905878717520880000e+001) (1, 1.97404063822657040000e-001) (2, 1.38131875812661580000e+000) (3, 6.93447975290256700000e-001) (4, 1.07444795287446570000e+001) (5, -2.90112255649201110000e+000) (6, -3.89418592503825770000e-001) (7, -3.15579374779355290000e+000) (8, 5.24046377909740500000e+001) (9, -9.28173960907713310000e-001) (10, 3.58019710632232790000e+000) (11, 5.63093229942527530000e-001) (12, -4.96290232511106540000e-001) (13, 3.63980270457387010000e-001) (14, 4.94757267426762230000e+000) (15, -6.11536692520665750000e-003) (16, -2.67002229688483080000e+000) (17, 1.15341906554710570000e+000) (18, 9.98363177807316400000e+000) (19, -4.88994824650771330000e+000) (20, -2.70486649161297560000e+001) (21, -4.51091136884398110000e-001) (0, 1.09785123889563960000e+001) (1, 4.15850526563377790000e-001) (2, 1.11108387920068500000e-001) (3, 1.70557700270984270000e-001) (4, 2.80688298811236290000e+000) (5, 1.48411449284290710000e+000) (6, -2.80257332622148910000e+000) (7, 1.83220981501385440000e+000) (8, -4.54281971646571310000e+000) (9, 1.14702008619851600000e+000) (10, 5.92530932924837030000e+000) (11, 1.92186432392667670000e-002) (12, 4.42765611361256750000e-001) (13, 4.01176496575375800000e-001) (14, 1.97139092668838050000e+000) (15, 1.38825915342140870000e-001) (16, 2.09488919962748630000e-001) (17, -1.45742378865277910000e-001) (18, 3.57635591726198800000e-001) (19, 3.20402812395493010000e-001) (20, 3.15687528676089050000e+000) (21, -6.34795491685537780000e-002) (0, -1.31039425015161410000e+001) (1, -4.89852129596808960000e-001) (2, 1.86470414971598410000e-001) (3, -1.14116611200355310000e-001) (4, -1.33468113853055660000e+001) (5, -9.74086350545857680000e-001) (6, 8.56631947111767110000e+000) (7, -1.38944012349832200000e+000) (8, 3.34681325756100990000e-001) (9, -6.82863149411741640000e-001) (10, 1.36867345141539830000e+001) (11, 3.24038403689793810000e-001) (12, 1.76974587898263300000e+000) (13, 8.38007529757602620000e-001) (14, 7.30783091680317740000e-001) (15, 2.03463030507111020000e-002) (16, -3.29394612283087640000e-001) (17, -4.22738046960974890000e-001) (18, 3.11489229554647510000e+000) (19, 2.90772512295341870000e+000) (20, 3.05500662838509630000e+001) (21, -2.70452205368995830000e-001) (0, -1.69689693203624080000e+000) (1, -1.03065214871939670000e+000) (2, 1.43151309857132420000e+000) (3, 5.44218689297623070000e-001) (4, -3.88945766316268700000e-001) (5, 1.95502344595141150000e+000) (6, 1.49734909598608130000e+000) (7, 3.28418751310958970000e+000) (8, -1.87295210261973500000e+001) (9, 9.84480673514954940000e-001) (10, -2.33854189472059630000e+001) (11, 3.35994114313123670000e+000) (12, -4.13294262659594410000e+001) (13, -6.22083625161234320000e-002) (14, 9.52587580254438900000e-001) (15, 1.30789636147924180000e+000) (16, 4.13382186214258740000e+001) (17, 1.52779917022386940000e-001) (18, -1.44817776002618950000e+001) (19, -1.75232507691187660000e+000) (20, -1.46173245666187370000e+000) (21, 1.30903092980194490000e+000) (22, -2.95963813774707050000e-002) (23, 1.73919055061025760000e+000) (24, 3.64050092722070630000e+000) (25, 1.22242420272416920000e+000) (26, -6.50116311023164690000e-001) (27, -2.22095143624898360000e-002) (22, 2.44339333199014860000e+000) (23, -1.58013515454229460000e+000) (24, 1.51759682484565820000e+000) (25, -2.12632986087247740000e+000) (26, 1.37021663378844670000e+000) (27, 7.47581271323302540000e-001) (22, -2.97729479986549480000e+000) (23, 6.19479757250084530000e-001) (24, 1.07327356378608200000e+000) (25, 4.92107239627573130000e-001) (26, 1.24780585261417710000e+000) (27, 1.72464998637601630000e+000) 

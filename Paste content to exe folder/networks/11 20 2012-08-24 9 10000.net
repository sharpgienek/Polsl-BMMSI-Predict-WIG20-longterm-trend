FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.49964339895306860000e+001) (1, -1.28454866348263640000e+000) (2, -1.97727200819305050000e+001) (3, -1.13556445633988770000e-001) (4, -5.15759106914322130000e+001) (5, -2.74294885771686970000e+000) (6, 1.71742492016561950000e+001) (7, -1.21347437141083560000e+000) (8, -2.18923714568509630000e+000) (9, -4.43494231976818860000e-001) (10, -1.03037454748692100000e+001) (11, 2.45123447223351710000e+000) (12, -4.38363471702300720000e-001) (13, -3.36878477033018870000e-001) (14, 6.74972728371012390000e+000) (15, 3.26563303023499290000e-001) (16, 4.34941039333526810000e+000) (17, -3.54329066371310840000e-001) (18, -3.75854490925238990000e+000) (19, -7.72385259421491630000e+000) (20, -1.63736377256433800000e+001) (21, 1.56624349156792420000e+000) (0, 2.65132206522913450000e+001) (1, 1.04852153892414470000e+000) (2, 9.48936057603845700000e-001) (3, 6.35043335063509410000e-001) (4, 9.67999123676714390000e+000) (5, 1.86112870206754710000e+000) (6, -4.42717196837777300000e+000) (7, 2.76359778363143120000e+000) (8, 8.13460969950859440000e+001) (9, 6.35428007581082870000e-001) (10, 7.11974808754991790000e+000) (11, -5.57483931126890210000e-001) (12, 4.40029194745059550000e+000) (13, 4.78701582763406570000e-001) (14, -2.48045423789978690000e+000) (15, 2.36580613583340590000e-001) (16, -6.03439296023143970000e+000) (17, 2.74754999096058610000e-001) (18, 5.13984236120146500000e+000) (19, 4.68252482932456180000e+000) (20, 4.27249783758301120000e+001) (21, -3.60872027345816190000e-001) (0, 2.77856258450856820000e+000) (1, -1.46326440430330580000e-001) (2, -5.91516084660189810000e+000) (3, 8.79896606303517680000e-002) (4, -2.14802498974333790000e+000) (5, 7.97083064865215070000e-001) (6, 1.15786965993843950000e+001) (7, -2.19211499270979690000e-001) (8, -2.35182625764703200000e+001) (9, -6.54131816004322600000e-002) (10, -4.48787292032586470000e+000) (11, 4.15320941158735800000e-001) (12, 5.35329209050065870000e-001) (13, -5.18023658991255690000e-001) (14, -2.27844035930798630000e-001) (15, -5.87543873566520780000e-003) (16, 3.72169231128771290000e+000) (17, 3.73741738174873880000e-001) (18, -4.23174218758863500000e+000) (19, -1.15171551973858780000e+000) (20, -1.07772739137642710000e+001) (21, 1.05953099114845430000e+000) (0, -2.00134069121000290000e+000) (1, 9.03078382767083410000e-001) (2, 9.10585340456746440000e-001) (3, 2.52289278471564900000e-001) (4, 3.15440695961074320000e-001) (5, -2.00683154722272080000e-001) (6, 2.61730558236940740000e+000) (7, 1.99225556572992790000e+000) (8, -1.01987007610607470000e+001) (9, 6.63265875335971030000e-001) (10, -1.72636424384255440000e+000) (11, 1.03757805718253570000e+000) (12, 1.08844258038238650000e+000) (13, -1.01596532659205690000e-001) (14, 6.64537145013130880000e-001) (15, 1.13799030462877760000e+000) (16, 5.01079794575417200000e+000) (17, 2.88117726686969390000e-001) (18, -1.22654957179691020000e-001) (19, -1.37268910111796380000e+000) (20, -4.90366544885279950000e+000) (21, 6.76959996778583430000e-001) (0, -5.67495113206075530000e+000) (1, -1.62522345867309290000e-001) (2, -1.10735847796483870000e+001) (3, -1.23690980296054230000e-001) (4, -2.51208478363567740000e-001) (5, 2.46741189425978280000e-001) (6, -3.55385805832353400000e+000) (7, -1.37894364906985300000e+000) (8, 4.66910570675977170000e+000) (9, -1.50228729145652930000e+000) (10, 3.76227509383053550000e-001) (11, 1.14926096527291330000e+000) (12, -4.99552068344444380000e-001) (13, 9.75462476640401310000e-002) (14, 3.30327717996887270000e+000) (15, -4.32519496413646610000e-003) (16, 1.71957551625148630000e+000) (17, -6.64071788791160970000e-002) (18, -3.00256346878230830000e-001) (19, 1.26583774790898840000e+000) (20, 1.17379158802358850000e+001) (21, 3.76765434809971660000e-001) (22, -3.02367533396104450000e-001) (23, -1.32678784437562380000e+000) (24, -4.01044840739122410000e+000) (25, -1.17484263728133120000e+000) (26, -6.65693506459336120000e-001) (27, 3.01861252041112230000e+000) (22, -1.78513544122370080000e+000) (23, 3.69873877437425680000e+000) (24, 2.29726749442903300000e+000) (25, 3.44860024180987470000e+000) (26, -1.42129419006111530000e+000) (27, -1.06576178124943940000e-001) (22, 1.24869411904851520000e+000) (23, -2.75763859977135440000e+000) (24, -4.67496698012127230000e-001) (25, 2.23288214976510610000e+000) (26, 2.04086450991959810000e+000) (27, 3.59595947090738030000e+000) 

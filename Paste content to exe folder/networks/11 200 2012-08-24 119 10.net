FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.12650515969421420000e+000) (1, -2.68720372795296420000e-001) (2, -1.09381656069308800000e-001) (3, -1.35375916533708280000e-001) (4, 1.57868229500662040000e-001) (5, 1.77090958952948410000e-001) (6, -4.31705068744959950000e-001) (7, 6.86567643554339690000e-002) (8, 3.77842590414494420000e-001) (9, 5.17933529751563040000e-003) (10, 6.39873295227950780000e-001) (11, 8.19057145931429700000e-002) (12, 1.34187242428726040000e+000) (13, 2.02716894355252920000e-001) (14, 4.47239895299498760000e-001) (15, 7.22664529582648650000e-002) (16, 2.42097883183800930000e-001) (17, 2.60454370646517550000e-001) (18, 7.88340926449049710000e-002) (19, 1.13261985640680140000e-001) (20, 5.11284426124327450000e-001) (21, -3.70912767076439710000e-002) (0, 1.42062216667022060000e+000) (1, 3.70500585441235490000e-001) (2, -2.21280651553245330000e-002) (3, 9.14803204320737970000e-002) (4, 3.13735110712145640000e+000) (5, -2.33556207903632880000e-001) (6, 3.04639041240666140000e+000) (7, -1.34631872115730410000e-001) (8, -3.09422366507255740000e+000) (9, -1.71308205027820210000e-001) (10, -1.35205358012058170000e+000) (11, -1.67351372932728980000e-001) (12, -9.29666640536225720000e-001) (13, -1.82965976986206370000e-001) (14, -9.46697843546710600000e-001) (15, -1.93195469326137680000e-001) (16, -4.03525522417232270000e-001) (17, -1.16148979591628870000e-001) (18, 2.56200593446439700000e-001) (19, -1.34563286506648420000e-001) (20, -3.15806643946138890000e+000) (21, 5.61660852943373510000e-002) (0, 4.00175354419153530000e-001) (1, -8.38016649398392320000e-002) (2, -4.59280267400284940000e-002) (3, -1.41833892367086790000e-001) (4, 7.10017981350855250000e-001) (5, -4.01004924136410120000e-002) (6, -1.46106353368251420000e-001) (7, -3.87943400504278250000e-002) (8, -8.59151923300676580000e-001) (9, -1.56561732730595540000e-001) (10, -1.59691538579804120000e-001) (11, -1.39093413810625480000e-001) (12, -3.27143262747324470000e-001) (13, -3.81291017619242110000e-001) (14, 7.96090665772896560000e-001) (15, -3.83140325940252100000e-001) (16, 3.62619236507879360000e-001) (17, -1.12012114578957680000e-001) (18, 4.81656103516041880000e-001) (19, -1.33307280911905380000e-001) (20, -7.34115300343735840000e-001) (21, -7.02579635661473580000e-002) (0, 3.07471072532866700000e+000) (1, 9.64704711221232440000e-002) (2, -4.11728261806657340000e-001) (3, 9.37788206913895280000e-002) (4, 3.20740726050912440000e+000) (5, 3.13290689940603080000e-002) (6, 3.20166995573613190000e+000) (7, -1.44673042788443230000e-002) (8, -3.11889407559642520000e+000) (9, -1.61493473252085380000e-001) (10, 6.00012521286735770000e-002) (11, 2.67254755222184060000e-001) (12, -3.05063235582924630000e+000) (13, -4.25918935846239850000e-001) (14, -3.29729727335882790000e-001) (15, 3.35055295214794010000e-003) (16, -1.16120170631238360000e-001) (17, 6.07579812511756250000e-005) (18, 2.40749712968229850000e+000) (19, 2.21798989358520520000e-002) (20, -3.04584109599222600000e+000) (21, 5.60134974014386140000e-002) (0, -1.83377489978353680000e+000) (1, 1.13831848546544990000e-001) (2, -3.01691653501434140000e+000) (3, 3.99628316543036990000e-002) (4, -4.13772329096796730000e-001) (5, -1.04019888926269650000e-001) (6, -1.74188533078731880000e+000) (7, 1.84044293042448510000e-002) (8, -1.23952988869699120000e+000) (9, 1.48824244111423640000e-001) (10, 3.08767459270934360000e+000) (11, -1.42874869974003980000e-001) (12, 3.06068484621341510000e+000) (13, -5.76912988895796790000e-001) (14, 7.77231836962868350000e-001) (15, 4.00091705592942050000e-003) (16, -2.27315085961571410000e-001) (17, 2.08743186327987050000e-001) (18, 3.13935306027628780000e+000) (19, 2.04248487946343480000e-001) (20, 3.19861819787815720000e+000) (21, -1.61844596819174930000e-001) (0, -1.54828300327466910000e+000) (1, -2.06971104297035640000e-001) (2, -3.07159793231353270000e+000) (3, -2.82784177402603250000e-002) (4, -9.69018400519937820000e-001) (5, 2.69112797741671160000e-003) (6, -4.24277090118649450000e-001) (7, 1.43180534283825380000e-001) (8, 5.39049319116181590000e-001) (9, 5.60934685145542120000e-001) (10, 6.72014408988140690000e-001) (11, -1.00411127810033090000e-002) (12, 1.43531724989844680000e+000) (13, 5.79377009060637330000e-003) (14, 9.57631319062627190000e-002) (15, 3.57098295573871000000e-002) (16, 2.42359657236928480000e-001) (17, 4.20216067299651940000e-001) (18, 4.85930421840273300000e-001) (19, 2.14701428778371780000e-001) (20, 1.30027159424078720000e+000) (21, -2.42939122411125860000e-001) (22, 2.08305515578055990000e-001) (23, -6.90264785361478510000e-001) (24, -3.39567327244088830000e-001) (25, -1.55966911184715590000e-001) (26, 4.72414154982487120000e-001) (27, 2.80203148330323450000e-001) (28, 7.15420498555192410000e-001) (22, -7.19268577980216040000e-002) (23, 2.55280169860832020000e-002) (24, -1.44421783030649370000e-001) (25, -1.46701774327904290000e-001) (26, -4.57822012493507740000e-001) (27, -2.27832599028059250000e-001) (28, 6.85794033269973680000e-001) (22, -1.00504136057261300000e-002) (23, 4.74557166576765890000e-001) (24, -2.04468227585082930000e-001) (25, 2.88515010895131600000e-001) (26, 1.60996593993732400000e-001) (27, -5.04685522225033490000e-001) (28, 6.52421051058201360000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.06232371766647220000e+001) (1, -9.56919357295533230000e-001) (2, -5.68723106238315700000e+000) (3, -7.73728552671490710000e-002) (4, -1.00303040124686760000e+000) (5, -3.16672300439619970000e-001) (6, 8.07713467930462390000e-001) (7, -4.85672058436523060000e-001) (8, 1.14323727058250280000e+001) (9, 9.53129064550607420000e-002) (10, 2.07076402782413220000e-002) (11, 4.93460004792687260000e-001) (12, -5.21660130584517890000e+001) (13, -1.31724839569827320000e+000) (14, -1.31248243364115980000e+000) (15, 1.50063851264611030000e-001) (16, -1.30553178157033200000e+000) (17, 7.56109222169828120000e-001) (18, 1.29334746568735110000e+001) (19, 8.55172617665342920000e-001) (20, -6.27563248852633370000e-001) (21, 1.94916388191468530000e+000) (0, 7.94125460387978510000e+000) (1, -2.16729168886607320000e+000) (2, 2.58231428220220540000e+000) (3, 7.67431675679148270000e-001) (4, 7.03663553349796020000e-001) (5, -1.84555311780526480000e-001) (6, -3.82340909581335130000e+000) (7, -1.61213268152714030000e-001) (8, -1.90262829971477740000e+001) (9, 7.24162407244610340000e-001) (10, -1.30205582106030530000e+001) (11, 2.47645218564560250000e+000) (12, -2.07377073784715830000e+001) (13, -3.23652962344265600000e-001) (14, -9.52427525683205880000e-001) (15, 3.40125002352568980000e-001) (16, 1.92987050446043750000e+001) (17, 1.54770834499484170000e+000) (18, 8.16186988259965140000e+000) (19, 6.05752100990233800000e-001) (20, 8.26262242703297470000e+000) (21, 4.84946277745497030000e-001) (0, -4.06742432361441360000e+001) (1, -7.51963593046875880000e-001) (2, -7.17525715845510610000e+000) (3, -2.06445489952530400000e-001) (4, -2.03832923666594650000e+001) (5, 1.07558918394996290000e+000) (6, -1.71374441331820360000e+001) (7, 3.74286993447090930000e+000) (8, -9.81663461679477220000e+000) (9, 6.37761103033862580000e-001) (10, 1.43192783031949030000e+001) (11, 1.07430325207474060000e+000) (12, 4.69280531616408860000e+000) (13, 3.22165947524599040000e+000) (14, 7.74045770255994280000e+000) (15, 1.56899734780918810000e+000) (16, -7.15746250251575680000e-001) (17, 6.09678637122384130000e-001) (18, -1.02529223629129190000e+001) (19, 1.76021163798841360000e-001) (20, 2.74690752803948260000e+000) (21, -9.75186649913028090000e-002) (0, -4.16123928045626630000e+000) (1, -5.60859823837848380000e-001) (2, 1.85250834609394090000e+000) (3, 6.28513617643187360000e-001) (4, -2.34889238177027830000e+001) (5, 7.29988426645473030000e-001) (6, 9.69320608639318020000e-001) (7, -1.39222183160439860000e-001) (8, -3.33938693249374600000e+000) (9, 1.50559792120474350000e-001) (10, 3.52334292686854230000e+000) (11, 5.68719994223022110000e-001) (12, 4.46464374887658530000e+000) (13, 8.75759251240564750000e-001) (14, 2.39267229191872710000e+000) (15, 3.13651032873183910000e-001) (16, 1.48106322089627840000e+000) (17, 6.56800932136786250000e-001) (18, -1.01190916880800220000e+000) (19, 2.83682951741680070000e-001) (20, 1.53604791971345770000e+001) (21, -2.58688731630361930000e-001) (0, -9.89163644533309490000e+000) (1, 1.94869560059075500000e+000) (2, -1.31456855253091490000e+001) (3, -6.22864589236736380000e-001) (4, -4.79353063281065140000e-001) (5, 7.84192682014223790000e-003) (6, 7.03950936576254800000e+000) (7, 2.64996625633488140000e-001) (8, -7.01225683233804900000e+000) (9, -7.71863435826591890000e-001) (10, 3.69408247484498080000e-001) (11, -1.10038265170063450000e+000) (12, 2.64190912058125880000e+000) (13, 5.91352556284129970000e-001) (14, -7.33680878347815300000e+000) (15, -1.70399691240158620000e-002) (16, -5.45009773742837210000e+000) (17, -4.10114580190551530000e-001) (18, -1.00329371631297030000e+000) (19, -5.17107268719918630000e-001) (20, -1.27137659681051880000e+001) (21, 5.38826765373400240000e-001) (0, -6.65200235584523790000e-001) (1, -4.94558395222315930000e-001) (2, 4.12396617300240250000e+001) (3, -5.53453223884341040000e-001) (4, -2.57441970573831340000e+000) (5, 1.06164820529906700000e+000) (6, 1.59271386431500160000e+001) (7, -1.57563710750164290000e+000) (8, 3.03714985199961650000e+000) (9, -1.75927106801782360000e+000) (10, 1.01711901270445320000e+001) (11, -1.37090671194094680000e+000) (12, -3.46091053166406300000e+001) (13, -9.09078266765179890000e-001) (14, 1.13416948238344590000e+001) (15, -4.69415255377411690000e-001) (16, -1.22299506521661970000e+001) (17, -7.70629681711072590000e-003) (18, 4.40948241932851760000e-001) (19, 6.62808518663325980000e-003) (20, 1.04458490500785680000e+001) (21, 2.01691789566318610000e+000) (22, 1.01805606370684850000e+000) (23, -1.18975217132538690000e+000) (24, -2.98200989366429300000e-002) (25, 1.35586909287864610000e+000) (26, -2.46082527186102430000e-001) (27, -1.10868560602893210000e+000) (28, 4.75484809295783960000e-001) (22, -1.33233973684183260000e+000) (23, -2.24283522073172980000e-001) (24, 8.24234345477989790000e-001) (25, -1.38232456846995430000e+000) (26, -1.50595978774340430000e+000) (27, 1.00511560279430910000e+000) (28, 1.33406502781354840000e+000) (22, 3.10976182415537980000e-001) (23, 1.41070741512550190000e+000) (24, -8.34791677213122200000e-001) (25, -1.64787560905771820000e-002) (26, 1.74448983268497270000e+000) (27, 9.08198373960566740000e-002) (28, 5.41650957701856450000e-001) 

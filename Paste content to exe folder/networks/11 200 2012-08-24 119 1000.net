FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.89633016623198780000e+001) (1, -8.27806937172240080000e+000) (2, 3.79689654508943740000e+000) (3, 3.98128106600035410000e+000) (4, -5.33263472097928040000e+000) (5, 2.03934872214203370000e+001) (6, 1.77902407071957000000e+001) (7, -2.54657207236743230000e+000) (8, 3.09908817880131100000e+002) (9, -5.02532032372857260000e-001) (10, 2.02489350511879640000e+001) (11, -3.91290664539556630000e-001) (12, 5.80397486055911500000e+001) (13, 6.82218882588673830000e+000) (14, 4.80405978201231410000e+000) (15, -2.54718127742779950000e+000) (16, 2.81360033879839020000e+001) (17, -1.80750584892986130000e+001) (18, -3.04864878816050220000e+001) (19, -2.24420263877716540000e+000) (20, -5.75924564135290050000e+000) (21, 2.68620977428301750000e+000) (0, 5.74534968960674280000e+001) (1, -1.94172172418963980000e+000) (2, 6.12397217911110090000e+001) (3, 1.07256111492730590000e+001) (4, -9.28197420698030130000e+001) (5, 1.66414266021524920000e+001) (6, 2.98721369273977010000e-002) (7, 2.72855250488355520000e+001) (8, 1.00636277795797060000e+002) (9, 1.78768053632812600000e+001) (10, 2.34964081203499180000e+002) (11, 5.02258286259954280000e+000) (12, 3.34239060262133730000e+001) (13, 1.00016166749308460000e+001) (14, 9.99409454710499720000e+001) (15, 4.64061501111408430000e+000) (16, 5.60557423092158120000e+000) (17, 1.44978539296141570000e+000) (18, -1.04050677306102600000e+002) (19, 4.17264262768631600000e-001) (20, 7.01470110247453250000e+001) (21, 3.32872803874933560000e-001) (0, -1.10612159045448450000e+001) (1, 2.55897635813347830000e+000) (2, -7.22290789053683540000e+001) (3, 2.47454055885984480000e+000) (4, -1.94870234678498200000e+001) (5, 4.63455903373159120000e-001) (6, 4.64747127935264360000e+001) (7, 3.77797606072281810000e+000) (8, -2.82273676440416740000e+000) (9, -2.92331830613218590000e+000) (10, -1.45579570499226990000e+001) (11, 4.62116115554019920000e+000) (12, -2.68665023877102770000e+001) (13, -2.57247093588901960000e+000) (14, -2.00043609017010930000e+000) (15, 2.06265509370907060000e+000) (16, 5.30231610435250000000e+001) (17, 1.02259297214387650000e+001) (18, -4.88831873500183600000e+001) (19, 3.36623636338882540000e-001) (20, 1.68083951747700450000e+001) (21, 5.15754776974241750000e+000) (0, 3.99992354592136580000e+001) (1, -6.50197956930345370000e+000) (2, 2.93931620392997490000e+001) (3, -7.10508581638144230000e-001) (4, 1.42533975262325430000e+001) (5, 4.57197056276769500000e+000) (6, 4.48059290451630050000e+001) (7, 1.25529865702031370000e+000) (8, -5.24098089347525900000e+001) (9, 2.23094923266093080000e+000) (10, -5.58442453686783440000e+001) (11, -4.11805359576566500000e+000) (12, 4.70186653888569670000e+001) (13, 9.92433621054037010000e-002) (14, -9.40090483205414530000e+000) (15, -5.84039625768335040000e+000) (16, -5.88687569414451200000e+001) (17, -3.44770138552095990000e+000) (18, -4.02218644456745340000e+001) (19, -1.47923503977962500000e+000) (20, -3.86223725468704300000e+001) (21, 4.25254406689581630000e+000) (0, -1.51137876115140760000e+002) (1, -4.84398015923630430000e+000) (2, -7.50058812593767230000e+000) (3, 6.67229132198661020000e+000) (4, 2.22092855675912200000e+001) (5, 3.87519017581212340000e+000) (6, -2.82136499102311120000e+001) (7, 4.06168330809629370000e+000) (8, 1.18699240744979150000e+001) (9, -1.12145089889247410000e+000) (10, 7.01235096603401050000e+001) (11, -8.94338808533652770000e-001) (12, 2.09520162344971970000e+001) (13, 3.43899817363694280000e+000) (14, 1.85324701332264010000e+001) (15, 2.26942896982750320000e+000) (16, 1.25405002798081410000e+001) (17, 1.10944552404515890000e-001) (18, -1.09575389792361560000e+002) (19, -8.91612138253342730000e-001) (20, 5.80186439686906040000e+001) (21, 6.49235241433527400000e-001) (0, -6.57332857586218470000e+001) (1, 2.32408864402704700000e+000) (2, 2.67466002397263370000e+001) (3, 6.77486389894445650000e-001) (4, 4.12762776198545040000e+001) (5, -4.90531307085505830000e+000) (6, -8.59817438840529750000e+000) (7, 1.92551499831316430000e+000) (8, -3.92346021702249170000e+001) (9, -1.61444275694089300000e+000) (10, -2.02599176824199280000e+001) (11, 5.59521228887934430000e-001) (12, -5.06706492951528420000e+001) (13, -1.87997354775505880000e+000) (14, 7.92791859832287130000e+000) (15, 3.22648218788242640000e+000) (16, 8.04939119152695960000e+000) (17, 3.01361732685455630000e+000) (18, -4.67563644833004800000e+001) (19, 3.06160212491239430000e-001) (20, 1.57836723570875270000e+001) (21, -7.44916380037299870000e-001) (22, -1.67791761328450020000e+000) (23, -7.72472271309386760000e-003) (24, -1.41456860580601960000e+000) (25, -1.66076264771209310000e+000) (26, 1.64123912703376070000e+000) (27, -1.85976365786296040000e+000) (28, 1.45761904139252410000e+000) (22, 1.38828030013193480000e+000) (23, 1.29201001191280820000e+000) (24, 3.83368918663408110000e-001) (25, 5.50477258566431150000e-001) (26, -1.41444824558704970000e+000) (27, 1.29920761145277220000e+000) (28, 7.28942614324328830000e-002) (22, -7.18319146488335810000e-002) (23, -1.86561362921329650000e+000) (24, 4.60818279512826110000e-001) (25, 5.73935224560254590000e-001) (26, 5.33380246313196890000e-002) (27, 1.64215204122406620000e-001) (28, 1.89032270743973200000e+000) 

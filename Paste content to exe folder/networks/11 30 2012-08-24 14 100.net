FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.00075953287943420000e-002) (1, 3.29348786650141890000e+000) (2, 3.10045531247061360000e-001) (3, 2.26108420288722410000e-001) (4, 1.16576366227354880000e+000) (5, 1.26586008425271210000e-001) (6, 5.03114232289212100000e+000) (7, 2.30315218950565240000e+000) (8, -5.05137427207082300000e+001) (9, 9.54395311556397450000e-001) (10, 3.92869134304399060000e-002) (11, 1.25789532650833040000e+000) (12, 2.51004092967869760000e+000) (13, 1.86064026531823690000e-001) (14, -9.69299746778560680000e-001) (15, 2.65201335721159290000e+000) (16, -2.22551071690822690000e+000) (17, 2.76720040631215640000e-001) (18, 9.55857913519206370000e+000) (19, -1.59873684520416210000e+000) (20, -1.98588958202506590000e+001) (21, 3.96669086322033290000e-001) (0, 5.11209005302061210000e+000) (1, 3.15042280895796720000e-001) (2, 4.62563780125994570000e+000) (3, -7.45191887238552670000e-002) (4, 4.14302883295322460000e-003) (5, 2.96823568451824070000e+000) (6, 4.82666209528275040000e+000) (7, -4.17844245960866390000e-001) (8, 1.61523791126226220000e+001) (9, 1.36061150088545180000e+000) (10, 4.31524949526246480000e-001) (11, -1.02441265713343020000e+000) (12, -5.83802546508892740000e+000) (13, 2.64661995170918430000e-001) (14, 2.00602794766010820000e+001) (15, -5.55487422064597500000e-003) (16, 1.04360370561426600000e+000) (17, 3.84337484286081920000e+000) (18, 1.21936652805804970000e+000) (19, 1.52000372518765250000e-001) (20, -3.28734737541548650000e+001) (21, 4.08829070725499140000e-002) (0, 1.69344498466796050000e+001) (1, 4.84275016412459960000e-001) (2, -2.41075990253972750000e-001) (3, -2.39521534611654650000e-001) (4, 3.77904600146274610000e+000) (5, -9.35898101245736690000e-001) (6, -1.21606220634290270000e+000) (7, 3.39517104354190910000e+000) (8, -9.88194254680311520000e+000) (9, 4.33969458986600660000e-001) (10, 6.03318357682155360000e-001) (11, -9.74248039735032160000e-001) (12, 2.54107735511106330000e+000) (13, -8.26971302254098510000e-002) (14, 1.03595057722315340000e+000) (15, -1.20707623614418900000e-001) (16, 6.55609902390395740000e-001) (17, -1.04359553517307120000e+000) (18, 1.22187620932824070000e+000) (19, -2.16434491255802750000e-001) (20, 3.74519120744519110000e+001) (21, -8.74661035675583070000e-001) (0, -5.03843395762195190000e+000) (1, -2.66226394615440460000e-002) (2, 3.65292887990641970000e-001) (3, -3.86378288954180930000e-002) (4, 3.05622684808007360000e-001) (5, -3.28976148120227800000e-001) (6, -1.10193969887067670000e+000) (7, -1.10285426926927940000e-001) (8, 9.76625484124639700000e+000) (9, 1.53773074846768310000e-002) (10, 6.78194523779991700000e+000) (11, -1.02537347167567850000e-001) (12, 1.58672001326574620000e+001) (13, 1.52660464248409180000e-001) (14, -1.66407321040537380000e-001) (15, -2.37316901617329180000e-002) (16, 3.63840097331319450000e-001) (17, -1.91418263091768490000e-001) (18, 4.88259357286158660000e+000) (19, 1.82634897493491350000e-001) (20, 2.07542312181824400000e+001) (21, -8.61248910812101640000e-001) (0, -1.15147673644461830000e+000) (1, 5.29671165450206430000e+000) (2, -8.56842302849992330000e-002) (3, 3.65163302779932750000e-001) (4, 5.45298270718721860000e+000) (5, -1.10621534324020370000e-001) (6, 1.49579190706440120000e+001) (7, 2.64935125624036120000e+000) (8, -4.93685800593366300000e+001) (9, 2.82904428415579110000e-001) (10, 1.14531920761711630000e-001) (11, 9.38809480513372540000e-001) (12, 2.44857609393301700000e+000) (13, -4.19506104936503250000e-001) (14, 4.64877559208792480000e-001) (15, 2.90233041681473970000e+000) (16, -4.40781794942435300000e+000) (17, 3.80585444800651210000e-001) (18, 5.46874027159809590000e-001) (19, -2.39686123616304640000e+000) (20, -1.17906265530523200000e+001) (21, 1.51429509469578360000e+000) (22, 1.02974372208424000000e+000) (23, 4.31071640436606840000e-001) (24, -5.54606820973215450000e-001) (25, 1.85556672799650090000e+000) (26, -7.19943414014767140000e-001) (27, 3.97786460385454070000e-001) (22, -4.92434033981539730000e-001) (23, 5.43866631523898580000e-001) (24, 2.49641567005434470000e+000) (25, -2.79285796848300990000e+000) (26, -1.40019888436021220000e+000) (27, 1.34870539991078680000e+000) (22, 1.69403491140825700000e-001) (23, -8.65397895814288500000e-001) (24, -2.44494132970757370000e+000) (25, 1.20849444702316760000e+000) (26, 2.66998196432483500000e+000) (27, 8.99869795231671320000e-001) 

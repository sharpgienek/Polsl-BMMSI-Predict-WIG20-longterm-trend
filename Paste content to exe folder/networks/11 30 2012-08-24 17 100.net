FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.14428964057287000000e+000) (1, 1.34519018638081990000e-001) (2, 4.04642590163000640000e+000) (3, -5.47662364336541780000e-002) (4, 4.26670219805626310000e-001) (5, 7.59162380442924830000e-001) (6, -3.40693913155655730000e-001) (7, 8.29830572550187330000e-001) (8, 6.00324845345205030000e+000) (9, 7.90863946594390410000e-001) (10, -3.43038201854809930000e+000) (11, -8.01492122665575240000e-002) (12, 5.68771278011667600000e-001) (13, 1.67074112081378610000e+000) (14, 3.41761645641062650000e-001) (15, -8.14944077493460430000e-001) (16, 8.77158297748006240000e-001) (17, 6.72996712212618030000e-001) (18, 1.52104714997105540000e+000) (19, -1.18407486520367840000e-002) (20, 6.79532064626905190000e+000) (21, -8.14655607112364070000e-001) (0, 1.41050349905174620000e+000) (1, 4.97536626820741200000e+000) (2, 4.94249128028874330000e-001) (3, 1.61111160214785250000e-001) (4, 1.61249206896522970000e-001) (5, 1.85198970916346740000e-001) (6, 6.38184876441473660000e+000) (7, 1.69972372607136220000e+000) (8, -6.93877879148821110000e+001) (9, 1.77781539332514230000e-001) (10, 1.00991533301157080000e-001) (11, 2.16279515487449590000e+000) (12, 8.46091894076287860000e+000) (13, 1.62779978574709680000e-002) (14, 8.29648272529136200000e-001) (15, 3.22247154914958990000e+000) (16, 6.94131076156508820000e-001) (17, 6.08383759416650790000e-001) (18, 6.49295975428356930000e-001) (19, -1.52459848561390010000e+000) (20, -1.67872364655652890000e+001) (21, 7.69353077055582760000e-001) (0, 1.64582695797581290000e+000) (1, -2.68089401878265580000e-001) (2, -4.95848440748181040000e+000) (3, -2.44049718499235430000e-001) (4, -3.30681896058854730000e-001) (5, -9.05971404213490180000e-002) (6, 4.06195235128399670000e-001) (7, -6.58559067052917560000e-001) (8, 3.24686019845575970000e+000) (9, -1.16696726360759120000e+000) (10, 4.24651982939948990000e-001) (11, 3.79550015903736550000e-001) (12, 2.00919932247077630000e-001) (13, -4.03951181941679120000e-002) (14, -8.93412186352921310000e-003) (15, -1.44899485323416800000e-002) (16, -8.23330541711725770000e+000) (17, 3.90060654973696240000e-001) (18, 1.23478543955995620000e+001) (19, 1.18824497736177510000e+000) (20, 7.79471048023141040000e+000) (21, 3.57724838416858650000e-001) (0, 1.07384025967156480000e+001) (1, 1.15600451296647980000e+000) (2, 2.05215372922590400000e+001) (3, 1.46035091719686890000e+000) (4, 2.36855543908161750000e+000) (5, 1.12253245920980520000e+000) (6, -4.10587274526845360000e+001) (7, -7.86131002586051400000e-001) (8, 1.29622679338271690000e+001) (9, 2.46207873872266880000e+000) (10, 2.80690822786075640000e+001) (11, 1.46789734459896910000e+000) (12, 3.35344150530366920000e+000) (13, 2.61658898067897990000e-001) (14, 1.44040913759937800000e-001) (15, 1.61981916084421980000e+000) (16, -5.15466728922393540000e+000) (17, 2.23597806935521940000e-002) (18, 2.51831884250476820000e+001) (19, 5.56071809375372170000e+000) (20, 1.15995548473735100000e+001) (21, 1.17026329763189920000e+000) (0, 3.79723736133491970000e-001) (1, 1.06906544366273230000e-001) (2, 6.29746781147180520000e-001) (3, -4.07056590634199020000e-001) (4, -7.65635373209197170000e-001) (5, 6.44308761019402600000e-001) (6, 2.84819965864272890000e+000) (7, 7.20485396146018030000e-001) (8, 1.08538980299745610000e+001) (9, 2.23568204610385180000e-001) (10, -3.38281896090242510000e-001) (11, 1.14505041194184140000e+000) (12, -4.03038228579024940000e-001) (13, -1.72130778846151270000e+000) (14, 1.44420383290158330000e+001) (15, 6.35552313179475540000e+000) (16, 1.05001403090152920000e+001) (17, -3.77026859294953500000e-001) (18, 6.00862591255936770000e-001) (19, 2.86909195492043430000e+000) (20, 1.91306223626226620000e+000) (21, 1.11059757632923310000e+000) (0, 3.59398228140979950000e+000) (1, 7.63557800439371050000e-001) (2, 1.64035694979291690000e-001) (3, 1.56757776978245780000e-001) (4, -4.70461049145557630000e-002) (5, -1.72754211749588330000e-001) (6, 1.05241270994345990000e+001) (7, 1.11787739018736690000e+000) (8, -4.63860872908658810000e+001) (9, -3.40700969390379970000e-001) (10, -1.57319983946393550000e+001) (11, -9.40850811101678120000e-001) (12, -3.24202933460105740000e+001) (13, -9.90410000867806390000e-001) (14, 3.59471848276812220000e-001) (15, 9.01625996958113190000e-001) (16, 9.19133198547129030000e+000) (17, 3.95304858491753450000e-001) (18, -9.63261699766412070000e+000) (19, -9.60371906838237590000e-001) (20, -4.68943174061374110000e+001) (21, 5.84848683775602660000e+000) (22, 1.38876690855707170000e-002) (23, 7.22006979540841250000e-002) (24, 1.28480196177243740000e-002) (25, 4.58804495192445540000e-002) (26, -2.17727008857350850000e-002) (27, -1.50408762641139830000e+000) (28, 1.41691056285601500000e+000) (22, 1.93480350848260520000e+000) (23, -7.35730899285659600000e-001) (24, -1.19386485057056930000e+000) (25, 7.21293515332779080000e-001) (26, 1.90767287721019210000e+000) (27, 8.21275249617236860000e-001) (28, -1.55455731154102490000e-001) (22, -1.67276739905457460000e+000) (23, 2.39129049418571200000e+000) (24, 1.36014756284742380000e+000) (25, 2.22132441859594100000e-001) (26, -2.47347840577701520000e+000) (27, 7.14016989390751640000e-001) (28, 1.22823241774586140000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.28329452303950520000e-001) (1, -9.42614354381320570000e-001) (2, 4.99376466962509980000e-001) (3, 1.79112339080880840000e-001) (4, 2.34013975641583660000e-001) (5, 8.14949894141442090000e-002) (6, 6.46443599491759590000e-002) (7, 1.37121822176485830000e-001) (8, 1.16213242183780750000e+000) (9, 7.76888202685243390000e-001) (10, 3.16446292393170390000e+000) (11, 1.40424866520936830000e-001) (12, 2.32605222036799340000e-001) (13, 1.06041815512013300000e+000) (14, 3.09506127282596850000e-001) (15, -1.81097979191034180000e-001) (16, -2.47846942798167440000e-001) (17, -3.79966554708881080000e-001) (18, -2.07244251093818830000e-002) (19, 2.96155530685193900000e-001) (20, 1.20067002006831250000e+000) (21, -1.01209865599045970000e+000) (0, -2.85088480152083320000e-001) (1, 3.08460877605153170000e-001) (2, 1.87188039245004520000e-001) (3, 5.64583522572077450000e-001) (4, 5.13501078543062930000e-001) (5, 6.02186257967229580000e-001) (6, 2.48133135929813880000e+000) (7, -5.35088015807562160000e-001) (8, -7.00901129011567650000e-001) (9, 1.72452634330415520000e-001) (10, -1.76104681730804240000e-001) (11, 7.94611029942743350000e-001) (12, 1.61340916811560790000e-002) (13, 7.47689536608674210000e-001) (14, -2.22000254843527680000e+000) (15, 2.92067558454620790000e-001) (16, 2.75793362611665540000e-001) (17, 1.04635633395027480000e+000) (18, -1.72910360340668980000e-001) (19, 1.44308052021266650000e-001) (20, -3.58297649960822250000e-001) (21, 4.30176158163969420000e-001) (0, -1.05632919283659500000e+000) (1, -1.87226648455485260000e-001) (2, 4.05868764866129880000e-001) (3, -1.72286939288768260000e-001) (4, -3.02942874223203780000e+000) (5, -4.90434085651850590000e-001) (6, 1.12979599557470720000e+000) (7, 4.15584443500469500000e-002) (8, -9.83337248389555270000e-001) (9, -5.61176964844101040000e-002) (10, 1.07462021350252400000e+000) (11, 1.29840997050593540000e-001) (12, -9.44744718517606770000e-001) (13, -1.43059834200657400000e+000) (14, 3.02754275587580950000e+000) (15, 1.10862289955607850000e+000) (16, -1.07233261104381450000e+000) (17, -1.28474717691121710000e+000) (18, 1.03911606258284590000e+000) (19, 3.50617215593716450000e-001) (20, -6.56933486036678450000e-001) (21, -2.57972127891904490000e-002) (0, 3.08318850865812080000e+000) (1, 3.10021966460242380000e-001) (2, -1.53824567022111110000e+000) (3, 1.14851787537686430000e-001) (4, 1.32201987027905690000e+000) (5, 9.23899069706203720000e-001) (6, -3.31172874516483250000e-002) (7, -2.83590599368521710000e-003) (8, 7.22181857807556280000e-001) (9, -2.82003828792329550000e-001) (10, -3.13692996453705590000e+000) (11, -1.63495716041284490000e-001) (12, 1.11127182537680060000e+000) (13, -3.45827758973122290000e-001) (14, -1.97561709719989050000e+000) (15, 4.14079724015158410000e-001) (16, 1.21918198323478720000e+000) (17, -2.37261464239248380000e-001) (18, -1.55481709385757740000e+000) (19, 8.34110630677203230000e-002) (20, 5.76323605809273000000e-002) (21, 2.88231872394203840000e-001) (0, 6.37557042771103140000e-001) (1, 1.27642725638424020000e-001) (2, 4.32995735025575420000e-001) (3, 1.59550571211262790000e-001) (4, 3.48502990367925310000e-001) (5, 2.42677717176816130000e-001) (6, -3.07994143829723570000e+000) (7, 1.24028585022341820000e+000) (8, 3.11413943685370050000e+000) (9, 4.25206203564921170000e-001) (10, 3.20277469208071870000e+000) (11, -1.09946701066782860000e+000) (12, 5.14636332466229530000e-001) (13, 1.74512427908666110000e-001) (14, 1.69823013614697340000e-001) (15, -1.01715483566150930000e-001) (16, 6.24409639553761940000e-001) (17, 1.61564948204473480000e-001) (18, -1.51910542340355730000e+000) (19, -1.89473106582097340000e-001) (20, 3.20100467252309340000e+000) (21, -4.18723879505160210000e-001) (0, 3.10187747378035810000e+000) (1, 3.01594667469423820000e-001) (2, -1.03757125779238500000e+000) (3, 5.86915839129032310000e-002) (4, 3.14740359750562520000e+000) (5, 2.00677769304545880000e+000) (6, -1.24576768175869160000e+000) (7, 8.98619662758518010000e-003) (8, 6.70586186310608510000e-001) (9, 2.28233433562842180000e-001) (10, -1.02652870187490520000e+000) (11, -2.94624997891545230000e-002) (12, 5.38786867940395760000e-001) (13, -5.50236060013164390000e-001) (14, -5.77741192365770930000e-001) (15, -1.78998634829916540000e-001) (16, 3.54290843855244950000e-001) (17, 3.54371822082154950000e-001) (18, -1.02997657134913740000e-001) (19, 6.88405009037069280000e-004) (20, 5.56065920932248710000e-001) (21, 1.37066765000981810000e-001) (22, 7.34590305258081560000e-001) (23, 3.90231087584306860000e-001) (24, 5.40281439433424550000e-001) (25, -5.38401615663497420000e-001) (26, 3.67278499879159890000e-001) (27, 8.86088976025716370000e-002) (28, 3.84896614848567020000e-001) (22, -1.14972709676639860000e-001) (23, 9.23326268360637470000e-002) (24, -1.62303106079087770000e-001) (25, 5.51518049155153230000e-001) (26, 7.03835352499052940000e-001) (27, 7.28029688797076640000e-001) (28, 4.61823513557427680000e-001) (22, -7.35592636005930390000e-001) (23, 6.71504563086337440000e-001) (24, 1.18166025041908330000e-001) (25, 3.11322781414433760000e-001) (26, -7.90487656355179920000e-001) (27, -6.12257504907084300000e-001) (28, 6.37038009838370780000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.47808321405884870000e+000) (1, -8.95137732997858220000e+000) (2, 2.68620792750227230000e+000) (3, -7.46726001454239840000e-001) (4, -2.49959062596538680000e+001) (5, -2.04036748684272370000e+000) (6, 6.94263430654162230000e+000) (7, 2.53791376608336950000e-001) (8, 5.66629434600217290000e+001) (9, 8.52971923798972240000e-001) (10, 6.16333425352436580000e+000) (11, -6.11665103002925310000e-001) (12, -1.88637634846968580000e+000) (13, 7.49590768057482810000e-001) (14, 1.04913334909349000000e+000) (15, -4.31897460304093980000e-001) (16, 1.94856148656266050000e+001) (17, -6.59085262135416380000e-003) (18, 2.22244213974129190000e+000) (19, 3.56502001957930310000e+000) (20, 3.92379428116776290000e+000) (21, -2.28989548421220630000e+000) (0, 7.08119542289612090000e+000) (1, 1.51641192394258910000e+000) (2, 4.98380360596861390000e+001) (3, 4.36913097553734140000e-002) (4, -1.85973012887206050000e+000) (5, 2.02668689903260240000e+000) (6, -7.15937550885429320000e-001) (7, -4.88035201686282840000e-001) (8, 3.31242032483450370000e+000) (9, 1.38743842738721200000e-001) (10, 5.08598209926157450000e+000) (11, -6.75926179937719080000e-001) (12, -1.62306749043309400000e+000) (13, 1.95087335054890370000e-001) (14, 6.21844016340771240000e-001) (15, 9.39185692472857770000e-001) (16, 1.08081918713899280000e+001) (17, 5.05679033645468960000e-001) (18, -1.18311969485577130000e+001) (19, -4.64175479696111730000e-001) (20, -1.98209277444361400000e+001) (21, 6.24812181329443380000e-001) (0, 1.78410454824640640000e+000) (1, 4.50259735243459410000e-001) (2, 1.39978997525131860000e+001) (3, 2.15084336909552700000e-001) (4, -8.66750011948491220000e-001) (5, 1.04957860295436340000e+000) (6, -6.05973768474922100000e+000) (7, -3.12715254677846610000e-001) (8, 3.96510996333945870000e+001) (9, 7.38224910836559720000e-001) (10, 5.41844746244773390000e+001) (11, -8.89855597663900540000e-001) (12, 1.62329511652848310000e+001) (13, 5.54433607995550080000e-001) (14, -6.69287087343671950000e+000) (15, -1.38701733088201410000e-001) (16, -7.85040375343701770000e+000) (17, -4.85508395677072100000e-001) (18, 6.54958595789021290000e+000) (19, -2.54414240800211970000e-001) (20, 4.15588694770396640000e+001) (21, -2.62471310512197540000e+000) (0, 7.14137853051061010000e+000) (1, 3.42176534080225250000e-001) (2, 1.39058856147409670000e+001) (3, 1.84301331501914500000e+000) (4, 9.43552876515565940000e+001) (5, 9.12361679291748610000e-001) (6, -5.31613840581756140000e+000) (7, 1.44692104303588450000e+000) (8, 1.22363637912454810000e+001) (9, 3.58799577487202540000e-001) (10, -2.53944630053969390000e+000) (11, 1.11406644186949260000e+000) (12, 2.27092322324088580000e+001) (13, -1.23210497142736810000e-001) (14, 6.54203754551760850000e+000) (15, -2.33597432398067910000e-001) (16, -6.45689534447010430000e+000) (17, 3.67476246753832350000e-002) (18, -2.91739261702159140000e-001) (19, 3.09023803425559570000e-001) (20, 3.25291616054664770000e+001) (21, -1.26087602106732470000e+000) (0, 3.74495558895223580000e+001) (1, 6.33998645500292450000e-002) (2, 3.74033107298114050000e+000) (3, -3.58758230523708480000e+000) (4, -3.31652951233713590000e+000) (5, -3.68871377273251920000e-001) (6, -4.39366528134605620000e+000) (7, 7.92002732402258490000e-001) (8, 5.76719300327993790000e+000) (9, 2.93279914345489120000e+000) (10, 3.57254626482870990000e+001) (11, 5.79928107982951860000e-002) (12, -1.60401519558787230000e+000) (13, 8.68472560192667280000e-001) (14, -1.25509111345916650000e+001) (15, -9.64467261371063090000e-002) (16, -3.44609203206662460000e+000) (17, -4.18815475189475540000e-001) (18, 1.05135262398492520000e+001) (19, -2.18321532341345710000e-001) (20, 7.24005903721846610000e+000) (21, -1.17658718004057050000e+000) (0, -1.97052980406991410000e+001) (1, -1.53293211153644690000e-001) (2, -2.43109526413035440000e+001) (3, 9.78453966098931090000e-001) (4, 4.20134758978929050000e+000) (5, -5.90829322194522110000e-001) (6, 2.30236774316173020000e+000) (7, 2.00585472048103310000e-001) (8, 6.18682234227047090000e+000) (9, 7.66869211431864260000e-002) (10, 1.22688621945899850000e+001) (11, 1.97984114590905480000e+000) (12, -1.82885662605716350000e+001) (13, 4.73279797610810900000e-001) (14, -1.79031075334725460000e+001) (15, 8.85982763481970690000e-001) (16, 8.22322036429117450000e+000) (17, 1.51362565578948320000e+000) (18, 5.79798537256418630000e+000) (19, 1.81226318339725380000e-001) (20, -4.40045062659505250000e+001) (21, 1.73612511032425190000e+000) (22, 4.79390046561624650000e-002) (23, -1.21926549213365560000e+000) (24, 2.14954195913436810000e+000) (25, -8.50354254659743350000e-001) (26, 9.75562240501836150000e-001) (27, 2.18265186571704370000e+000) (28, 9.67390596098384290000e-001) (22, 2.10597880858048650000e+000) (23, 3.86925909274512670000e+000) (24, -1.38136164369320640000e+000) (25, 3.27759556581791770000e+000) (26, -5.20743939475448390000e-001) (27, -1.37956829729389140000e+000) (28, 9.20887847132822570000e-001) (22, -3.10093841218208600000e+000) (23, -2.25806315464905390000e+000) (24, -1.30236554124558230000e+000) (25, -3.29960024694372360000e+000) (26, 6.06968707516921450000e-001) (27, 5.84356426188122000000e-001) (28, 1.88240610089804860000e+000) 

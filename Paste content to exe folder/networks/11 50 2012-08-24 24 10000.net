FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.69559031902830380000e+001) (1, 1.17854700426804100000e-001) (2, 1.09213080072452680000e+002) (3, 1.26040773328388520000e+000) (4, -1.84693317633394830000e+001) (5, -8.62792152834806040000e-001) (6, 6.99496404381745830000e+001) (7, 2.68316802137890550000e+000) (8, -5.19937438201788190000e+000) (9, 9.14955457171407010000e+000) (10, 8.91966311200977910000e+001) (11, 2.60594777363576920000e+000) (12, 1.97484580420914140000e+002) (13, 5.16401118235355960000e-002) (14, 5.15618611358277050000e+001) (15, 2.03840056529645430000e+000) (16, 4.52291118630923210000e+001) (17, 6.11037782637137990000e+000) (18, -1.02457841145273650000e+002) (19, -1.78853973126578830000e+001) (20, -7.79303002787837760000e+001) (21, 2.93446479222507830000e-001) (0, 2.88797719396731000000e+002) (1, -1.30352003808845080000e+001) (2, -1.15989483382944580000e+002) (3, -2.76057467975013020000e-001) (4, 2.04558086626522200000e+001) (5, 5.18712187587777950000e+000) (6, -3.10504102396856820000e+001) (7, -6.45954318037214960000e+001) (8, -8.04272669611364110000e+001) (9, -1.70393533478882060000e+001) (10, 6.87750369841417410000e+002) (11, -1.32194612043760880000e+000) (12, 4.09210091800986430000e+001) (13, 8.27062608152751370000e+000) (14, -5.89224488504930300000e+000) (15, -6.59998284365528460000e+001) (16, 5.55728125496163220000e+002) (17, 1.27464369354579830000e+000) (18, 9.23770804944104210000e+001) (19, 7.30767161179571520000e-001) (20, 5.55575487316706290000e+001) (21, -1.07045830053309790000e-002) (0, 3.13167978423439620000e+000) (1, -1.52700773152554130000e+000) (2, -2.15825169521810980000e+001) (3, 4.97791523555937250000e-001) (4, -3.25927462575660700000e+001) (5, -2.86681843474943280000e+000) (6, 5.74942368132806790000e+001) (7, -1.00913097628100770000e+000) (8, 2.73941238880775370000e+001) (9, 1.01697607268970500000e+000) (10, -1.38407922336798460000e+000) (11, 1.32184939150740390000e+000) (12, 1.05884452910011110000e-001) (13, -1.22038793589693830000e+000) (14, 1.54821131400689640000e+001) (15, -3.80066738578717760000e-001) (16, -2.30875838368356910000e+001) (17, 2.45699336644334130000e-001) (18, -3.94678879218920910000e+000) (19, -4.93963161359683500000e+000) (20, -1.82217753684659240000e+000) (21, 1.05161527843450590000e+000) (0, -1.47118641361978520000e+002) (1, 6.06279677157087620000e+000) (2, 1.34973769184842020000e+001) (3, 3.48612688743367550000e+000) (4, -2.61469596834327620000e+001) (5, 1.47239385009291230000e+001) (6, 5.99401433014863580000e+001) (7, 8.68463300538903530000e-001) (8, 6.01582178772402330000e+001) (9, 6.75464781847006310000e-001) (10, -3.65984722677435390000e+001) (11, 2.76955889981552960000e-001) (12, 4.81222045328018880000e+001) (13, 2.10691108878636420000e+000) (14, -7.42202988143505140000e+001) (15, 5.73084332283952320000e+000) (16, 5.75782350128427820000e+000) (17, 4.44637618550502010000e+000) (18, -1.07775040687538150000e+002) (19, 1.23104249950493170000e+001) (20, 9.77001090657076360000e+001) (21, 5.49873911013521700000e+000) (0, 1.45310585101167910000e+001) (1, -1.12150905245126680000e+000) (2, -1.52156467420528260000e+001) (3, 6.15847684314462240000e-001) (4, -5.90400277220689150000e+000) (5, -1.40548554516076240000e+000) (6, 5.93762525636760400000e+001) (7, -1.15082992196058840000e+000) (8, 6.04773247131386360000e+001) (9, -2.06585302842256290000e-001) (10, 7.73132920490173770000e+001) (11, 1.24140589374516300000e-001) (12, 3.46507183185274030000e+001) (13, 4.63091862120234010000e-001) (14, 3.91687767591521950000e+001) (15, -9.26482352600286550000e-001) (16, 4.28536922076153960000e+001) (17, -1.17878417987150440000e-002) (18, 3.56271391307978010000e+001) (19, 3.61842125905112280000e-001) (20, 2.83002625033934690000e+001) (21, -4.15093743139678810000e-002) (22, 1.85403411182918470000e-002) (23, -1.21145956981478300000e+000) (24, 1.70051627268942620000e-003) (25, -1.04223572668791350000e-002) (26, 4.03295463835318650000e+000) (27, 2.76023489273423420000e+000) (22, 3.52076932216111870000e+000) (23, -1.10582692714233490000e-001) (24, -3.64792507652542990000e+000) (25, -3.42060088488233440000e+000) (26, 7.89569653943645310000e-002) (27, 3.29942956474258150000e+000) (22, -3.52882068146638690000e+000) (23, -1.34050088383295490000e-001) (24, 3.66900484291258120000e+000) (25, 3.90816040016311070000e+000) (26, -3.60501882295743400000e+000) (27, -5.40098903050372670000e-001) 

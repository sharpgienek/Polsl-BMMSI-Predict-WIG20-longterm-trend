FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.19318652200648680000e+000) (1, -4.85478497536192060000e+000) (2, -3.83539458967929430000e+001) (3, 9.00741458660924250000e-001) (4, -1.29233314228023040000e+001) (5, -3.35993259583484970000e-001) (6, 4.90685397212453790000e+001) (7, 8.21186215294143480000e-001) (8, 1.01346866936196660000e+002) (9, -5.37107282522487850000e-001) (10, 1.14584162755424540000e+002) (11, -2.49327204728086560000e-001) (12, 6.04187363916228860000e+001) (13, 4.56422462007798290000e-001) (14, 4.54385404026990470000e+001) (15, -8.77285371588481630000e-001) (16, 5.57194461907718690000e+001) (17, 8.21092629927318350000e-001) (18, 5.47004474877432330000e+001) (19, 9.21108271650190820000e-001) (20, 2.53275666019038540000e+001) (21, -1.56510678043390670000e+000) (0, -9.11788384382731820000e+000) (1, -2.71579782651436340000e-001) (2, -1.57773418953995480000e+000) (3, -3.75664162083066550000e-002) (4, -1.02077841741179930000e+001) (5, -1.59973189352720360000e+000) (6, 2.68694352401631530000e-001) (7, -3.35804551666160300000e-001) (8, 3.22865724711202380000e+001) (9, 2.78432382123685150000e-001) (10, 1.83941775702751260000e+001) (11, 9.97363250994439680000e-002) (12, -7.57626570187252040000e+000) (13, 5.80272577538571090000e-001) (14, -7.31140046574903660000e+000) (15, 4.76403449526095480000e-002) (16, 4.74448397569960620000e+000) (17, -2.44174212076338240000e-001) (18, 5.31124757673759620000e+000) (19, 9.04309228781465140000e-001) (20, 5.17162378847556600000e+000) (21, 3.10306365349235340000e-001) (0, -5.55035364671733960000e+000) (1, -1.30252709096088900000e+000) (2, 2.47749560925314150000e+001) (3, 7.34616304866137710000e-001) (4, -3.24043412342713780000e+001) (5, -2.07859322658053070000e-001) (6, 1.65576911255867860000e+001) (7, -3.12487034222194260000e-001) (8, 5.13794729847094980000e+000) (9, 7.77752160158055710000e-001) (10, 4.21497338254161990000e+001) (11, -8.27108386313081700000e-001) (12, 9.27326721017340250000e+001) (13, 2.67602986074502170000e-001) (14, 2.43796869212533270000e+001) (15, -6.24060136758261220000e-001) (16, 5.40892115409400350000e+001) (17, 5.23009054322525020000e+000) (18, -5.99091052261936420000e+000) (19, 3.89781698877710580000e-001) (20, 2.15807779997375460000e+001) (21, 3.11025625858886330000e+000) (0, -1.15151097181594700000e+001) (1, 2.72670180769154400000e-002) (2, -2.21263460336759410000e+000) (3, 6.37208478823167170000e-002) (4, 9.65838580090245990000e+000) (5, 3.91695960108786380000e-001) (6, 2.98027322814717590000e+001) (7, -7.39110337559229390000e-001) (8, -2.23159880736987160000e+001) (9, -4.45021737871558190000e-001) (10, -4.53193185036993640000e+001) (11, 8.85507420263796360000e-001) (12, -4.07245165830924890000e+000) (13, 2.58693844915295510000e-001) (14, -1.43119171142130210000e+001) (15, -8.55782801218256120000e-002) (16, -8.95186196973218170000e+000) (17, 6.02309851919865860000e-001) (18, -1.23215251254113710000e+001) (19, 1.92013054555938290000e+000) (20, -3.75833294663807620000e+000) (21, -6.89679235740308540000e-001) (0, 5.45324111749344360000e+000) (1, -3.55429656745784190000e-001) (2, 9.55528500342897760000e+000) (3, 2.21106680250024000000e-001) (4, 2.68284136500107140000e+000) (5, 8.06575591015649910000e-001) (6, -1.41666498310968890000e+001) (7, 1.40808203464510770000e+000) (8, 4.64681481934491250000e+001) (9, 4.33136262922197200000e-001) (10, -4.01249973691091310000e+001) (11, -6.58066716287265210000e-001) (12, 7.78861255773645760000e+000) (13, 3.82430956056044250000e+000) (14, 3.20348530624900580000e+001) (15, 1.22056555338022530000e+000) (16, 1.08589742542384120000e+002) (17, -2.35546202152785660000e+000) (18, -1.03897609188299520000e+001) (19, 2.42676533026995810000e+000) (20, 1.46789447619852890000e+001) (21, -3.99875422780089530000e-001) (0, -1.09194947451520470000e+001) (1, -5.52920790989320900000e-001) (2, -3.39466674779096240000e+000) (3, -8.20625476165351530000e-001) (4, -7.23946256518598120000e-001) (5, -2.58466474991445020000e+000) (6, 2.45225155383507600000e+001) (7, 1.92781553721322240000e+000) (8, -2.30871327465655900000e+001) (9, 2.35092344411116900000e-001) (10, -1.08539491948687670000e+002) (11, -4.50343687781338320000e-001) (12, -3.97805772636908280000e+000) (13, -3.04849635725403410000e-001) (14, -1.52412616298064240000e+001) (15, 4.72307110604794490000e-002) (16, 1.45425101362715750000e+001) (17, -7.84260232351516430000e-001) (18, -3.13340398756331990000e+001) (19, -7.71691824164497660000e+000) (20, -4.06866274209358710000e+001) (21, -6.63869373623778960000e-001) (22, 3.10266672112505580000e+000) (23, 2.17839191661984310000e+000) (24, 5.48831497182715510000e-001) (25, -5.18681930383867900000e-001) (26, -1.11641118972094390000e+000) (27, -9.77388019151833320000e-002) (28, 2.94135425374942110000e+000) (22, -2.83918922768893410000e+000) (23, -3.45107015561510000000e+000) (24, 2.11351713741584170000e+000) (25, -3.39224356756829470000e+000) (26, 2.49887838206148730000e+000) (27, -2.92492218109737400000e+000) (28, 3.14976312054526200000e-001) (22, -3.21637859062718020000e-001) (23, 2.98109376616606840000e+000) (24, -3.10248415254003660000e+000) (25, 2.90259248884329320000e+000) (26, -2.46508800438375890000e+000) (27, 2.69988723649855620000e+000) (28, 3.61177344514391360000e+000) 

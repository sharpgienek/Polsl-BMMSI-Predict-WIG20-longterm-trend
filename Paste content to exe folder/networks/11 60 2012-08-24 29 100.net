FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.18181514079041680000e+001) (1, -1.44877245692740160000e-001) (2, -2.59739716906306310000e+000) (3, 1.19113768448087360000e+000) (4, 3.52321092123963450000e+000) (5, -9.65148857445480070000e-001) (6, 5.60355426831169900000e+000) (7, -3.46708080087098920000e+000) (8, 8.78554354123291640000e-001) (9, -3.46924945220117300000e-001) (10, 1.18545477322392960000e+000) (11, 1.45801964669541500000e+000) (12, 2.33701605310487270000e+000) (13, 5.24287312664815440000e-002) (14, -5.30739435902268970000e+001) (15, 7.96682970818844200000e-001) (16, -3.24092522634792250000e+000) (17, 3.71518457551371470000e+000) (18, 2.84499905824872600000e+001) (19, 6.39568337335862050000e-001) (20, -8.31862848488060390000e+001) (21, 9.89953784200933160000e-001) (0, 2.28886465206175630000e+001) (1, -8.08326831761133900000e-002) (2, 1.25244081179194970000e+001) (3, 3.33364163054454770000e-001) (4, -1.03869848865183110000e+001) (5, 1.23809020825451690000e+000) (6, -2.28178836907047040000e+001) (7, -7.27709030182559280000e-001) (8, 6.80970024663804810000e+000) (9, 7.84690978111345780000e-002) (10, 2.78091034755535520000e+001) (11, -1.15780141611549840000e-001) (12, 2.01215667779948220000e+001) (13, 2.31636960153935370000e-001) (14, 1.46112098430254810000e+000) (15, 2.89765848340597320000e-001) (16, 8.84401860707443000000e+000) (17, 4.55560084351056830000e-001) (18, 1.97045661712191840000e+001) (19, 1.60314563623887130000e-001) (20, -5.26886828938797970000e+000) (21, 7.04161844324982970000e-001) (0, -1.96732513606729040000e+001) (1, 1.59427542768365530000e+000) (2, 2.29005274464034380000e-001) (3, 1.68884334701652090000e-001) (4, -7.01732537836658680000e-001) (5, 1.30673564760587470000e-001) (6, 7.53371452391273460000e-001) (7, -6.14407006695209400000e-002) (8, -2.12771148095468790000e-001) (9, 1.98774127879859970000e+000) (10, 7.23541161339853290000e+000) (11, 7.64152208814249390000e-001) (12, -1.50134177178889730000e+000) (13, 4.99696953206346830000e-001) (14, -3.69938839664671360000e+000) (15, 1.37773364281246670000e+000) (16, 2.38837629202752100000e+001) (17, 1.59626095984346410000e+000) (18, -5.53532963773680020000e+000) (19, -2.82637959201429810000e-001) (20, -1.04972167866230650000e+001) (21, 1.18783909054887720000e+000) (0, 5.53090240179174140000e+000) (1, -5.33666985615879510000e+000) (2, -3.90403936779239800000e+001) (3, 2.41667804277256980000e-001) (4, -6.56565003518077980000e+000) (5, -6.87654338638333110000e-002) (6, 5.69017124112200510000e-001) (7, 8.30828347956333980000e-001) (8, 5.05254378233658490000e+001) (9, -5.72359916547467210000e-001) (10, 7.39731535753689260000e+001) (11, -1.88636185230654200000e-001) (12, 6.61012672588921820000e+000) (13, 2.97171536344665920000e-001) (14, 1.53186857288295800000e+001) (15, -1.18332221060717350000e+000) (16, 2.11054066833921330000e+001) (17, 8.38341081698608660000e-002) (18, 4.14515336093826860000e+001) (19, 7.79269484203276690000e-001) (20, 2.66012097838141490000e+001) (21, -1.14393012087637500000e+000) (0, -2.99000560864838580000e+001) (1, 7.63011839658720330000e-001) (2, 7.20477706723230060000e+000) (3, 7.81331375252437450000e-001) (4, 1.08830857020950940000e+001) (5, 9.09179191973235490000e-001) (6, -2.24898507445777970000e+000) (7, 1.99551547480489120000e-001) (8, 1.85760750558117280000e+001) (9, 1.03185867780940210000e+000) (10, 6.44658164327731380000e+001) (11, -6.71513862376423630000e-001) (12, 4.55077833989853960000e+001) (13, 5.72464057086029880000e-001) (14, 2.94412493213000270000e+001) (15, 4.06698564518252540000e-001) (16, 3.86680267799741630000e+001) (17, 3.45468386861789290000e+000) (18, -3.65159927358196370000e+001) (19, -1.10868161189408630000e+000) (20, 1.24577489915005850000e+001) (21, -2.35584391148147830000e-001) (22, -8.13428972505418620000e-003) (23, -1.91125704567884050000e-001) (24, 1.92327771095236530000e+000) (25, 2.06585924013573450000e+000) (26, -8.06185406150761870000e-002) (27, 2.30832596017669670000e-001) (22, -2.39385021152170820000e+000) (23, 2.01402063419044050000e+000) (24, 2.44768846395459480000e-001) (25, -1.14362764385998390000e+000) (26, 8.39835301423839000000e-001) (27, 6.05915127995304560000e-001) (22, 6.13831290722987480000e-001) (23, -4.62432359617709400000e-001) (24, 9.18182019093795270000e-001) (25, -4.69254057900346850000e-001) (26, -1.45719392254994330000e+000) (27, 6.00983983623506580000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.02790654129486450000e+001) (1, 8.73248739500272110000e+000) (2, 7.27885909908723510000e+001) (3, 1.17449697973120770000e+000) (4, 2.89783834697067010000e+000) (5, 8.17674854466098890000e-001) (6, -2.70197634619526710000e+001) (7, -7.42606514965628460000e-001) (8, -1.36811844436089060000e+001) (9, -5.41169307280490950000e-001) (10, -5.48722537211338660000e+001) (11, 4.80769988510101280000e-001) (12, 1.25944145767344420000e+001) (13, -2.79645968103495900000e-001) (14, -1.72917783829697950000e+001) (15, 1.14396269326039570000e+000) (16, -5.34215071046402910000e+001) (17, -7.79253826658797940000e-001) (18, -2.10253571568994710000e+001) (19, -8.63714891554660750000e-001) (20, -6.36088007978370840000e+001) (21, 6.14521999600282990000e-002) (0, -4.56950151400704240000e+001) (1, -1.05856812499311510000e+000) (2, 1.45054847901222000000e+001) (3, 1.09701468849895050000e+000) (4, 1.26126166105891360000e+000) (5, 6.16903805443571250000e-002) (6, 2.92945322692995200000e+001) (7, 3.70656439063319490000e+000) (8, -8.13323401898358610000e+001) (9, 4.74888144626808780000e-001) (10, -1.19090671120970380000e+001) (11, 5.12027707484555170000e-001) (12, 8.53999547822799910000e+001) (13, -3.43198666599917490000e-001) (14, 1.39251177932723560000e+001) (15, -1.28111966944239590000e+000) (16, 9.84024638468211350000e+001) (17, 5.96534007633597960000e+000) (18, 4.11324656162712450000e+000) (19, -1.97611303517381940000e+000) (20, 4.66773538986991950000e+001) (21, 2.39219839833057350000e+000) (0, 1.34189567874691860000e+001) (1, 5.62073527506797840000e-001) (2, -4.79406929431357030000e+000) (3, 1.04014807891881110000e+000) (4, 1.32722911941317160000e+000) (5, 4.96839220714068470000e+000) (6, -2.79465220510498970000e+001) (7, -1.01691074790888990000e+001) (8, 2.29421098310524380000e+001) (9, -2.76336366543953060000e+000) (10, 5.76824110610543620000e+000) (11, -1.70312688476044550000e-001) (12, -1.08226736542098840000e+001) (13, 7.98473095711476950000e-001) (14, 5.46177019513669180000e+001) (15, 5.76230290728906440000e+000) (16, -3.17869578253734380000e+001) (17, 8.89810284952725960000e-001) (18, 1.50148570718466200000e+001) (19, 7.46522057814504250000e+000) (20, -3.25333041177251730000e+001) (21, 1.03827430219731120000e-001) (0, 7.43897927835666910000e+001) (1, -8.15471279526128970000e+000) (2, 1.27495403329757780000e+002) (3, -2.62918029827465540000e-001) (4, -1.30278499000628670000e+002) (5, -8.82701336054718590000e+000) (6, -7.46171920846045820000e+001) (7, 2.58083347036981120000e+001) (8, 4.68703185771139270000e+001) (9, 2.41660717061872250000e+001) (10, 2.39901446326221700000e+002) (11, -1.16286090517647390000e+001) (12, -4.79447390320375040000e+001) (13, 2.41794106949045520000e-001) (14, -3.37459203520906500000e+001) (15, -7.08014411757948990000e-001) (16, 4.51378961587620960000e+001) (17, -5.75232840874796380000e+000) (18, 7.10935334882418320000e+001) (19, 1.22689855331754820000e-001) (20, 3.90788898688060020000e+001) (21, -2.31003093420311640000e+000) (0, 4.02379449134483170000e+001) (1, -2.29063833661984930000e+000) (2, 2.83097058073481380000e+001) (3, -1.14686131685089170000e+000) (4, -5.42822487041498290000e+001) (5, 6.36303064900342610000e-001) (6, 4.26418685724113190000e+000) (7, 3.26668021967734200000e-001) (8, -3.20372560023578290000e+001) (9, 2.12269875654175160000e-001) (10, -2.73933009361837490000e+001) (11, -1.41867300946507660000e+000) (12, -4.41691395918331150000e+000) (13, -7.05554049621979100000e-001) (14, -2.32626232974114760000e+001) (15, -9.15622704560638320000e-001) (16, 5.45584880534455970000e-001) (17, -9.87735153703477090000e-001) (18, -4.17922799893569920000e+001) (19, -1.91863576950372710000e-001) (20, 2.00242933640829510000e+001) (21, -2.63716135123232490000e+000) (22, -2.46390254693216230000e+000) (23, -2.18569350418047000000e-002) (24, 1.62851214813431140000e-002) (25, 1.19118287488578790000e-001) (26, -2.56673501914192760000e+000) (27, -2.44210114056525110000e-002) (22, 2.07353360342888450000e+000) (23, 2.02739554886728920000e+000) (24, 2.14840723223564960000e+000) (25, 2.13725698897310720000e+000) (26, 2.27597365661036340000e+000) (27, 2.16302267990724490000e+000) (22, -3.61851757905978580000e-002) (23, -2.20574042740637790000e+000) (24, -2.19962008483321240000e+000) (25, -2.17463791620984370000e+000) (26, -8.54880282629098540000e-002) (27, 2.08374358366749490000e+000) 

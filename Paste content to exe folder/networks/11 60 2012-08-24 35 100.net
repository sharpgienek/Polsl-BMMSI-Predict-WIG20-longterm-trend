FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.30885721446181420000e+000) (1, -6.32020878746144990000e-001) (2, -1.25973821763778990000e+001) (3, -1.34665162242735360000e-001) (4, 4.51873713550339840000e-001) (5, -2.28720488086440850000e-001) (6, 1.39001571934777140000e+001) (7, 1.14532669606287270000e+000) (8, -2.80327883036801250000e+001) (9, 7.58288588291656020000e-001) (10, 9.22331445078549980000e+000) (11, 1.11096247067075900000e+000) (12, -3.49462296576646450000e+001) (13, 3.50914803775582540000e-001) (14, -2.98280145244511060000e+001) (15, 1.78827975246942290000e+000) (16, 2.31265439364309810000e+001) (17, 3.58412307195503390000e+000) (18, 3.27248087344875960000e+001) (19, 7.66047718365407860000e-001) (20, -3.99125244160856880000e+001) (21, 1.22980107804996130000e+000) (0, -1.32976164108710680000e+001) (1, -3.74770979910489410000e-001) (2, -6.28613899143957070000e+000) (3, -1.20439554390834620000e+000) (4, -6.93008484314373010000e-001) (5, -3.94152851783347190000e-001) (6, -1.08788699666212560000e+000) (7, -6.36902879266805890000e-001) (8, -2.43593269255510330000e+000) (9, -2.16542315426219820000e-001) (10, -9.56776288873283810000e-001) (11, 4.31247744841873670000e-001) (12, -3.66310646987101260000e+001) (13, -3.55293238140061920000e-001) (14, 5.31867730221880650000e+000) (15, 2.09728098070403070000e-001) (16, -2.19155617739777500000e+000) (17, -5.22716983387940150000e-001) (18, -1.03493370442326570000e+001) (19, -4.23154616584120510000e-001) (20, -9.55722027258349980000e+000) (21, 4.20291615484993390000e-001) (0, 3.07679519501656880000e+000) (1, 5.91250229137840200000e-002) (2, 6.86392809574577620000e+000) (3, 1.04867049233697800000e-001) (4, 1.75394891088886480000e+000) (5, 3.85074527241194840000e-001) (6, 2.41518505518646800000e+000) (7, -9.50432118937787900000e-002) (8, 1.51935348333419940000e+001) (9, 3.45571356825763230000e-001) (10, 3.40513542583887410000e+001) (11, -1.08706436365853280000e-001) (12, 8.44557545950217480000e+000) (13, 5.41336988675040210000e-001) (14, 2.34917713401330880000e+001) (15, 4.47687148667927150000e-002) (16, 2.72016263321227890000e+001) (17, 8.62016798308853030000e-001) (18, 2.10867154811994800000e+001) (19, -5.49596075347975280000e-001) (20, 1.78812274690140680000e+001) (21, -4.83720722033532340000e-001) (0, -5.81832676989719120000e+000) (1, -5.99078754152155210000e+000) (2, -3.28762550066647630000e+001) (3, -9.96481927974529500000e-001) (4, 1.39609435017268010000e+000) (5, 7.19782450472395860000e-001) (6, 4.02130286499946710000e+000) (7, 8.45849940017585400000e-001) (8, 1.85418225991304240000e+000) (9, 1.97565513781891190000e-001) (10, 9.37920310527429990000e+000) (11, -8.84773114096679690000e-001) (12, 9.49144649492081880000e+000) (13, -4.81474849064482860000e+000) (14, 1.79491107421163500000e+000) (15, 9.05648923305377300000e-002) (16, 2.84146206460174300000e-001) (17, -1.83159046456201490000e-002) (18, 5.25579484085572090000e+000) (19, 2.03438001570000360000e+000) (20, 1.20015261185464670000e+001) (21, -7.81792069249741210000e-001) (0, -2.42201900147414160000e+001) (1, 3.55080467940851690000e-001) (2, -2.61135793874767440000e+001) (3, 3.26534432185173750000e-001) (4, -5.75097690619025710000e-001) (5, -1.70721120989010470000e+000) (6, 4.93632115805757280000e+000) (7, 9.70219830711017360000e-001) (8, 2.09337858801890990000e+001) (9, 2.74353379960477100000e-001) (10, 8.65459490657087120000e+000) (11, 1.46372856449387800000e-001) (12, -1.82270555114365290000e+001) (13, 1.27379949879028400000e-001) (14, -2.96748048867439080000e+000) (15, -4.22165216139285590000e-001) (16, -4.19821897377494220000e+000) (17, -8.04637305988368470000e-001) (18, 3.36947865951534170000e+001) (19, 1.34728774895366340000e+000) (20, 3.64992333640888800000e+001) (21, -1.30919991233598940000e+000) (0, 1.88253125384233290000e+000) (1, -2.34612535074041690000e+000) (2, -2.17200476415745700000e+001) (3, -1.88058197651975370000e-001) (4, 7.22351311180513720000e+000) (5, -5.31378993406457670000e-001) (6, 1.05189819011893850000e+001) (7, -1.31304432036805660000e+000) (8, 4.06946019853203910000e+000) (9, -2.30056345889668680000e+000) (10, -3.80859511681386920000e+001) (11, -2.36496923542565300000e-001) (12, -3.48828938396097630000e-001) (13, -3.69869288912783590000e-001) (14, -3.14406937495114460000e+001) (15, -6.97437962955241810000e+000) (16, 1.50608002825042410000e+001) (17, 1.05591420299341830000e+000) (18, 3.27180513430984780000e-002) (19, -7.40807281789124250000e+000) (20, 6.35981607197873270000e+000) (21, -8.59167263832920190000e-001) (22, 4.71140304297878730000e-001) (23, -4.68266762110997160000e-001) (24, 1.16059828035221880000e+000) (25, 1.34218712002632180000e+000) (26, 1.11250603178883910000e+000) (27, 4.95395450112792120000e-001) (28, 1.14274084323746710000e+000) (22, -1.35873489005410520000e+000) (23, -1.20688049268686570000e+000) (24, 8.60405854121720550000e-001) (25, -4.44881990727826420000e-001) (26, -1.42512934743977500000e+000) (27, -1.44016762886155860000e+000) (28, 6.53725597966960280000e-001) (22, 9.27593655024864460000e-001) (23, 1.77985995718430830000e+000) (24, -1.66160394879485240000e+000) (25, -7.45952533165653910000e-001) (26, 4.84153613925875080000e-001) (27, 6.70787612179609140000e-001) (28, 1.11994865605859980000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.91137172179888990000e+001) (1, -3.17083491725208790000e+001) (2, -4.78581944785567090000e+002) (3, 2.65898866297283740000e+000) (4, 5.83426680216221240000e+001) (5, -3.51756537754114930000e+000) (6, -1.90962404316874410000e+001) (7, -3.14772771581729760000e+000) (8, 1.45936183636370880000e+002) (9, -3.58761707664977170000e+000) (10, 3.22874741906267730000e+002) (11, -6.12694584488657860000e+000) (12, 5.96337036630505180000e+001) (13, -2.87938318528053760000e+001) (14, -1.41689699618462810000e+002) (15, -2.74853389133397470000e+000) (16, -2.65474222880664430000e+001) (17, 2.29995883709787030000e+000) (18, 2.67406687005190200000e+001) (19, -7.79042760088654870000e+000) (20, -1.97437520515009570000e+002) (21, -3.11406569212748210000e+000) (0, 6.60416453557784000000e+001) (1, 1.19988237349779110000e+001) (2, 1.43355503510666750000e+002) (3, 1.99099511451435560000e+000) (4, 4.46938915663551410000e+001) (5, -1.57021328174799770000e+000) (6, -6.85953320652333220000e+001) (7, -4.00254926121378500000e+000) (8, 7.54320933944046330000e+000) (9, -5.08446999248372780000e-001) (10, -7.05552174670325180000e+000) (11, -7.33414961868630220000e+000) (12, -4.03959341061598350000e+001) (13, 2.21455359366703200000e+000) (14, 3.74821109677632120000e+001) (15, 2.17419440408358030000e+000) (16, -1.82919086575627430000e+001) (17, 9.17897408277878690000e-001) (18, 7.84123144907754290000e+001) (19, 1.17328844298899180000e+001) (20, 1.42282403852018660000e+002) (21, -1.35949412661758060000e+000) (0, -4.37068662777372640000e+000) (1, 7.67432902176827800000e-001) (2, 2.75238809066618410000e+001) (3, 8.25998019079979830000e-001) (4, 6.86925271986614130000e+000) (5, -9.59074897201508400000e-001) (6, -3.89916158713454660000e+001) (7, -9.93704227941021760000e-001) (8, 1.24256216053200070000e+000) (9, -1.39507048380750120000e+000) (10, -9.19121275498467940000e+000) (11, -2.95714474120436440000e-001) (12, -4.00041231275639570000e+000) (13, -3.33358026446317290000e-001) (14, -1.22739753585590870000e+001) (15, 6.16918883530259030000e-001) (16, -6.49436950946396770000e+000) (17, -3.86747344039843190000e+000) (18, -1.63996056447554610000e+001) (19, 3.56410903513627200000e-001) (20, -1.41580381081510470000e+001) (21, 2.47216304015615010000e+000) (0, 6.15763629712485330000e-001) (1, 1.39534780469970370000e-001) (2, 1.68704825828743100000e+001) (3, -5.78544528461130480000e-002) (4, -8.98568887896898790000e+000) (5, 4.63891597338025870000e-001) (6, -2.27774625269154360000e+001) (7, 2.06577873716149930000e-002) (8, -8.53073884956002360000e+000) (9, -1.19632000174376920000e-001) (10, 9.52966840461627330000e-002) (11, -1.18706201999833620000e+000) (12, 4.57234585419810880000e+001) (13, 1.12043986176695610000e-001) (14, 2.50241042414802630000e+001) (15, -1.20579102086033350000e+000) (16, 1.49588660274913680000e+001) (17, -4.62989676003451840000e+000) (18, 1.29259440297900260000e+001) (19, -1.82359757894473500000e+000) (20, 6.03647684177799420000e+001) (21, 4.87230662974033890000e-001) (0, -1.76990231357279630000e+001) (1, 2.07984584928180640000e+000) (2, -2.73232291196404460000e+000) (3, 1.07155364251807580000e+000) (4, 3.36059043389102060000e+000) (5, -9.55104555303718850000e-001) (6, -4.39725979299917750000e+000) (7, -1.14151097791801390000e+000) (8, 2.98379518975686400000e+001) (9, -6.28760233583219530000e-001) (10, 1.00001474871116970000e+001) (11, 1.81393581113140860000e-001) (12, -5.27110245787395200000e+000) (13, 1.43116646133032920000e+000) (14, -1.65194445702680160000e+000) (15, 9.68370754147464210000e-001) (16, 7.03537148393505250000e+000) (17, -2.94652960159258770000e+000) (18, 1.95342937429829460000e+001) (19, 1.34847595435606450000e+000) (20, 2.70588968215737220000e+001) (21, -7.21788685504263120000e-001) (0, 1.81919532200155200000e+001) (1, 8.11381180079871810000e+000) (2, 5.03105347499779330000e+001) (3, 7.45499579763822860000e+000) (4, -6.40369929755587320000e+001) (5, -1.02019304098720800000e+000) (6, 1.48537256768563480000e+002) (7, 1.21125753863120100000e+001) (8, -9.95455063241590390000e+000) (9, 1.29445927628758670000e+001) (10, -1.87595545902781850000e+002) (11, 2.46293850223382820000e+000) (12, 1.96086621780762640000e+002) (13, -2.38456582396953420000e+000) (14, -1.03591347297716670000e+002) (15, 1.31894420664374240000e+001) (16, 2.18090853457991220000e+001) (17, 3.39048202416815370000e+000) (18, -5.91744026561386180000e+001) (19, 2.87007595909554890000e+001) (20, -3.56364025694101940000e+002) (21, 8.17475244712646010000e+000) (22, 2.65225252896799590000e+000) (23, -6.64706423779213570000e-002) (24, -3.22920664330944000000e+000) (25, -4.65961636007329800000e-002) (26, 3.24083900621223230000e+000) (27, 2.21765829500235840000e-002) (28, 2.61307032208395600000e+000) (22, -7.50446405645929020000e-001) (23, 3.21536349532298970000e+000) (24, 1.95247372395155720000e-001) (25, 3.07581426033240610000e+000) (26, -4.20715712100023700000e+000) (27, 1.89245260008978430000e+000) (28, 1.18264062232356880000e+000) (22, -2.18169419864135290000e+000) (23, -3.27409779858579330000e+000) (24, 3.24769108196521920000e+000) (25, -3.42069073229103630000e+000) (26, 8.59007062941574250000e-001) (27, -2.10881431655846900000e+000) (28, 1.61870530290260480000e+000) 

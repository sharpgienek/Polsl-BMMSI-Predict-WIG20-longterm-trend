FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.45732980623253550000e+000) (1, 8.95285845520607390000e-002) (2, 8.20023559474190830000e+000) (3, 1.21935501705447560000e+000) (4, -2.03994640844506420000e+001) (5, 5.62968190613561850000e-001) (6, 2.19903938312156070000e-001) (7, 3.53511920656565470000e+000) (8, -1.37147573236811450000e+001) (9, 1.81109851423839970000e+000) (10, 3.06628271529722020000e+001) (11, 1.30257778412960850000e-001) (12, 8.44441628780334950000e+000) (13, 1.95301218889456750000e+000) (14, -1.97293450492611200000e+001) (15, -5.53915391787855540000e-001) (16, 8.79556005344159220000e+001) (17, 8.47573588035429150000e-001) (18, 3.08044661794447360000e+000) (19, -1.08423532761942740000e+000) (20, 3.65270184845947690000e+000) (21, 2.51048354418535070000e-001) (0, 6.95986675893719390000e+000) (1, 4.67785196296451480000e+000) (2, 3.61601858242196100000e+001) (3, -1.24264922218203870000e+000) (4, 1.22442933638204110000e+000) (5, 1.31089506723770580000e+000) (6, 9.39150728053302690000e-001) (7, 2.88700237149519400000e+000) (8, -3.21228540890445590000e+001) (9, -3.88188782664753540000e-001) (10, -3.90996649201201760000e+001) (11, 1.67973908161713590000e-001) (12, -4.59331663113162230000e+000) (13, 4.36901809262279080000e+000) (14, -3.37841237716536470000e+001) (15, 8.28622552944649040000e-001) (16, 4.29693854527714190000e+001) (17, 4.71410279042678400000e-001) (18, -1.11683878074651530000e+001) (19, 1.60853592755619390000e+000) (20, 3.72576681934918110000e+000) (21, 2.14243185445979690000e+000) (0, 2.70398386477556540000e+000) (1, -4.28386210245479400000e+000) (2, -1.90208595276895400000e+000) (3, 5.92629288480243100000e-002) (4, 1.36542866858252570000e-001) (5, -6.25293498906818850000e-001) (6, 1.01288577911092760000e+000) (7, 1.00867186815124450000e+000) (8, 4.38069490413767150000e+000) (9, -5.50141469002478510000e-001) (10, -1.45268101905233650000e+001) (11, -3.17413717664951970000e-001) (12, -1.49534361018020870000e+001) (13, 1.20838985301618670000e+000) (14, 4.43105802581385700000e+000) (15, -8.03617175999958810000e+000) (16, -1.06334642614178970000e+001) (17, 1.12280097606372320000e+000) (18, 7.89362325842910200000e+000) (19, -1.72313831018280880000e+000) (20, 6.08938751891546060000e+001) (21, 4.10382098003733210000e-001) (0, 1.93042480252153260000e+001) (1, 6.50674711422977730000e-002) (2, 2.31452589498399950000e+001) (3, 1.89035174677591590000e-001) (4, 5.34420797555808310000e+000) (5, 6.19362341313266510000e-001) (6, -6.33185762412670790000e+000) (7, -3.32430827450912460000e-001) (8, 2.92384663554106550000e+001) (9, -4.99390743837605290000e-001) (10, -3.52660843584671110000e+000) (11, -1.17618180410674730000e-002) (12, 1.75553026338727740000e+000) (13, 1.95443321346671580000e-001) (14, 1.75924335986615180000e+001) (15, 7.87230957108784290000e-003) (16, 5.88907987976636790000e+000) (17, -2.71184940076873160000e-002) (18, 1.28858165083064180000e+000) (19, 3.16177433249992530000e-002) (20, 3.33516838573344360000e+001) (21, -7.37401301621480880000e-002) (0, 7.86887132322106500000e-001) (1, 6.49226251125666790000e-001) (2, -1.00746910276385950000e+001) (3, 2.29109977457259940000e-001) (4, 8.86069439579167390000e-001) (5, -1.04722018959502490000e-001) (6, 6.18514877342814630000e+000) (7, 1.23270684268593740000e-001) (8, 1.02664880770389730000e+001) (9, 1.26651663096390230000e-001) (10, 2.14229475731351150000e+001) (11, -2.78596414977163750000e-001) (12, 9.10834072020999660000e+000) (13, 4.08395605442513080000e-001) (14, -4.89136223858095480000e-002) (15, 1.39452559226315780000e-001) (16, 1.35663027577725530000e+001) (17, 2.78204313109227390000e-001) (18, 2.14846356099233620000e+000) (19, -1.66447495763648170000e-001) (20, 1.14778704719540010000e+001) (21, -1.31902810057009210000e-001) (0, 4.22156692793593710000e+000) (1, -1.92804117634563020000e+000) (2, 1.46065222647841220000e+001) (3, -4.08664909226027160000e-001) (4, -2.34812864346741580000e+000) (5, 1.43636687210678100000e-001) (6, 1.46848920202362030000e+001) (7, -3.19846055910461560000e-001) (8, 3.72003509744572940000e+001) (9, -1.43641481759131500000e-001) (10, -2.04097637298174150000e-001) (11, 4.84351351091522000000e-001) (12, 3.35956961240157480000e+000) (13, 7.71416686672825700000e-001) (14, 1.70799998439805560000e+001) (15, -8.78629231691612670000e-001) (16, 1.90772885565736190000e+000) (17, 6.46965132173753730000e-001) (18, 1.01224388300931900000e+001) (19, 7.03718176411164960000e-001) (20, 3.32906458511366580000e+000) (21, -3.52054655859864170000e-001) (22, -1.11321703136734060000e+000) (23, -7.34611923347933240000e-001) (24, -3.85334382221580900000e-001) (25, -9.92686969553222550000e-001) (26, 3.01599834942209100000e+000) (27, 1.65565888982779240000e+000) (28, 1.01583076685695280000e+000) (22, 2.32308463500224920000e+000) (23, 2.67647011194500410000e-001) (24, -1.22275362644868140000e+000) (25, 1.99140052071957020000e+000) (26, -2.59825657254086590000e+000) (27, 3.06124600666240580000e-002) (28, 5.14239614092691590000e-001) (22, -1.04293114565059540000e+000) (23, 5.71454642861515370000e-001) (24, 1.16886102133262450000e+000) (25, -7.85975710175163660000e-001) (26, -3.61664490772535760000e-001) (27, -1.50834941892703790000e+000) (28, 1.01223402730261890000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.24159186534840590000e+000) (1, 4.50521735339029450000e-001) (2, 4.32007415630470250000e+000) (3, -4.46979967701664700000e-001) (4, 1.16997239087248220000e+001) (5, -5.49389814672977290000e+000) (6, 4.23100654098428280000e+001) (7, 5.01651512379109770000e-001) (8, -4.23487027789397250000e+001) (9, -1.50871273063264890000e-002) (10, 3.32166737798535030000e+000) (11, 4.75466635738277020000e-001) (12, 2.71283508914209330000e+001) (13, -3.84215989986287190000e+000) (14, 1.20615502588211320000e+001) (15, 1.15594293825103200000e+000) (16, 2.17821351704755520000e+001) (17, 5.48671458110873460000e+000) (18, 3.10111845210130500000e+001) (19, 2.50572011596654280000e+000) (20, 5.95352709684319590000e+000) (21, -3.77808541797906020000e-001) (0, 2.53772938499371110000e+001) (1, 5.24550059491309820000e+000) (2, 4.26374190768420790000e+001) (3, 6.11324209090181810000e-001) (4, 3.29997795338044850000e+001) (5, -1.51424286373531850000e+000) (6, -1.75879638396866330000e+001) (7, 1.85932308495676850000e-001) (8, -2.07753641508988380000e+001) (9, -1.53189242966153840000e+000) (10, -5.83597879795554850000e+001) (11, -8.88813063809108960000e-001) (12, -5.46095501675646220000e+000) (13, -7.01814032578012890000e-001) (14, 4.94700459492725740000e+000) (15, 6.74181054295363900000e-001) (16, 3.34420174535879650000e+001) (17, -6.03937460806842410000e-001) (18, -1.42124867493100380000e+000) (19, -2.92674504147239970000e+000) (20, -7.89702805728963570000e+001) (21, 1.60837925132196860000e-001) (0, 3.73175480199754470000e+001) (1, 7.90952150018719440000e-001) (2, -4.21350368725896200000e+000) (3, 1.86874074089649270000e+000) (4, 3.39109384533527920000e+000) (5, 6.84674522913204850000e-001) (6, 2.05908048121557740000e+001) (7, 8.86012934147460850000e-001) (8, 3.47682933878669330000e+001) (9, 1.93073165071310670000e+000) (10, 2.36824629701872880000e+001) (11, -6.34921551306382950000e-001) (12, 3.68479352440049790000e+001) (13, 1.34079013316138980000e+000) (14, 4.48784804286910270000e+001) (15, 5.76671316968199180000e-001) (16, 2.13377386036139570000e+001) (17, 1.39945715123984190000e+000) (18, 3.62898418182261920000e+000) (19, -1.17850456204891750000e-001) (20, -1.16938766967148290000e+001) (21, -2.84485960662376690000e-001) (0, 2.55956505432405090000e+001) (1, 1.19051031590553080000e+000) (2, -2.39518954899612170000e+001) (3, -4.48791628363724490000e-001) (4, 5.24368510946248900000e+000) (5, 9.08727499536618690000e-001) (6, 7.88161944140374530000e+000) (7, 6.71036494223726800000e-001) (8, 2.23567338568586890000e+001) (9, 2.02800112686355630000e+000) (10, -2.49071769176864160000e+000) (11, -8.72412592700470890000e-001) (12, 5.32297442736563300000e+001) (13, 1.32236294491462660000e+000) (14, 1.56102937590235910000e+001) (15, 4.25097808878222460000e-001) (16, 1.95917754885343560000e+001) (17, 1.19056538272962680000e+000) (18, 7.47233004411835470000e+000) (19, -6.99527513115914550000e-001) (20, -8.25507270610965520000e+001) (21, 4.47679566906595560000e+000) (0, -4.14969478575110130000e-001) (1, -1.73619125767380610000e+000) (2, 1.58423084606745410000e+001) (3, -1.47273947808739610000e+000) (4, -3.13044532726482460000e+001) (5, -1.70308701530579060000e-001) (6, -7.88348044909180200000e-001) (7, 1.53185065084201090000e+000) (8, -3.31015774966617610000e+001) (9, 9.28514475038586420000e-001) (10, -3.46263587383402300000e+000) (11, 3.00929799888459960000e+000) (12, 1.63860930855423920000e+001) (13, -1.14135258915990680000e+000) (14, -3.66065798217041450000e+001) (15, 1.75015560776521630000e+000) (16, -1.74844406903161520000e+001) (17, 2.41500389825357690000e+000) (18, -9.10103563174296410000e-001) (19, 3.11716470829086180000e+000) (20, -6.52433572927869230000e+000) (21, -5.04718397069872200000e-001) (0, 6.45432756386011870000e+000) (1, -8.95832668434373480000e-001) (2, 4.63224456926174570000e+001) (3, -8.91628848054126790000e-001) (4, -1.85706240866870370000e+001) (5, -9.85783225115299590000e-001) (6, -1.33505728253755530000e+000) (7, -4.27053007795965110000e-001) (8, 3.71806524499303850000e+001) (9, -5.51984210544032020000e-001) (10, 3.13177490733523630000e+001) (11, 5.87341529491039350000e-001) (12, 1.66522190991038170000e+001) (13, -4.06648194774802540000e+000) (14, 2.04167305380558380000e+000) (15, 3.08848535928149650000e-001) (16, 1.97244496520390950000e+001) (17, 4.33083784500197930000e+000) (18, 5.60012408603410630000e+001) (19, 2.72486519844848370000e+000) (20, -8.26965552167754050000e+000) (21, -5.65201105823693980000e-001) (22, -1.18109296922509990000e-001) (23, -1.97881935173125250000e+000) (24, -7.04581367238166920000e-002) (25, 8.40443794919765870000e-003) (26, -2.40081813886704420000e+000) (27, 2.42530828036418100000e+000) (28, 1.97580820141795970000e+000) (22, -1.91912252608920400000e+000) (23, 1.88901871419033250000e+000) (24, 2.93465864956666160000e+000) (25, -2.27251060805530080000e+000) (26, 2.55351889595778570000e+000) (27, -5.68442661014083360000e-001) (28, 1.15553907552473860000e+000) (22, 2.02312015494382580000e+000) (23, -1.31667184038327170000e-001) (24, -2.89891789126164530000e+000) (25, 2.23052831802358710000e+000) (26, -2.97128834116840930000e-001) (27, -1.84766435064964020000e+000) (28, 5.68776416252222750000e-001) 

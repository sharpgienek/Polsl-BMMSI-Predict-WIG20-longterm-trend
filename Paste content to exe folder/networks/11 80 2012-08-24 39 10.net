FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.75991511621223350000e+000) (1, 4.17439405124722110000e-002) (2, -1.29532212585648530000e+000) (3, 2.01150651103000790000e-001) (4, 7.11017868857606320000e-002) (5, -1.65063166731815850000e+000) (6, 4.94579103609773700000e-001) (7, 2.20119253864710150000e-001) (8, -6.03192852901280220000e-001) (9, -1.65840198914239040000e-001) (10, 1.56443490271280110000e+000) (11, 6.05711917765781700000e-001) (12, -1.64084162810977550000e+000) (13, -1.30223668484700220000e+000) (14, 9.15718438748607590000e-001) (15, 1.75557077301644600000e-002) (16, -1.21869858955845570000e+000) (17, 4.74870851362972860000e-001) (18, 7.98013551141064430000e-001) (19, 4.62483351108429200000e-002) (20, -3.12358767918199030000e+000) (21, 2.33987565654808940000e-001) (0, 6.41258442877376660000e-001) (1, -3.34909103018179550000e-001) (2, -4.97406522920053550000e-001) (3, -1.70893983175486990000e-001) (4, -2.24005870107788670000e+000) (5, 2.74385859739011070000e-002) (6, -3.07937381133565240000e+000) (7, 3.33223422139336760000e-001) (8, 1.21537949294375070000e+000) (9, 4.36212929219165880000e-001) (10, 3.14136722046255110000e+000) (11, -4.20400872289686810000e-002) (12, 1.11428085862476370000e+000) (13, 1.35021076018473100000e-001) (14, 9.12773617817431300000e-002) (15, -1.81389023810999330000e-001) (16, 1.12684799748390360000e+000) (17, 4.54848236751984550000e-001) (18, 5.91844730059144510000e-001) (19, 1.08644457837649710000e-001) (20, 1.17925278342104580000e+000) (21, -6.23002315573139980000e-002) (0, 1.44992011248427420000e-001) (1, -2.49954458422642050000e-001) (2, 6.63548832690118770000e-001) (3, -5.51454477249611610000e-002) (4, -8.55100002432582770000e-001) (5, 1.88576651961803150000e+000) (6, 1.03532577932324130000e+000) (7, 2.96542894214669340000e-001) (8, 5.23502969894158120000e-001) (9, 7.00015408965287690000e-001) (10, 7.68282326991169160000e-001) (11, 2.44677022383762020000e-002) (12, 1.21484575435342060000e+000) (13, 3.45657465625242470000e-001) (14, -3.33875290477863800000e-001) (15, 9.89468808269932940000e-002) (16, 1.39680406573080560000e+000) (17, 5.79670550271372040000e-001) (18, -1.27037048228774330000e+000) (19, -2.45801500549937340000e-002) (20, 3.18524539494451190000e+000) (21, 5.31416126550614100000e-001) (0, 4.82890681754811040000e-001) (1, 1.27667294550821990000e-003) (2, 7.71681985244953020000e-001) (3, 4.05389780841498630000e-001) (4, -6.19346258098338460000e-002) (5, -3.61215565741459520000e-001) (6, 8.90897576079048710000e-002) (7, 2.42856369977177800000e-001) (8, 5.45501330810346020000e-001) (9, 9.85135312111608820000e-002) (10, 5.38402779214846690000e-001) (11, 2.01999435774612020000e-001) (12, 4.62529353326403600000e-001) (13, 1.36874127485903270000e-001) (14, 2.57812493026010610000e-001) (15, 3.15067369488246930000e-002) (16, 4.98418810577511750000e-001) (17, 4.10108751696118550000e-001) (18, 1.55732483936538160000e-001) (19, 5.43324735050212840000e-001) (20, 6.05892235805211790000e-001) (21, 5.09303089111729170000e-001) (0, 3.12575442726115240000e+000) (1, -1.49458093205189930000e-001) (2, 6.37068875214693460000e-001) (3, -1.72706549260234130000e-001) (4, -2.41355615898727390000e-001) (5, 3.24154990494655630000e-001) (6, -1.40928014347332400000e+000) (7, 7.02787452846042740000e-002) (8, 3.17968509212728190000e+000) (9, 6.77034767037724580000e-001) (10, -1.93863724990537310000e-001) (11, 7.95357608693244290000e-002) (12, 3.08179080355916830000e+000) (13, 1.31037085463958060000e-001) (14, 1.35859165461350070000e-001) (15, -2.45869392147320450000e-001) (16, 2.67148492528166770000e+000) (17, -3.21160608108117140000e-001) (18, -2.16641278990226670000e-001) (19, -2.87100903530394250000e-002) (20, 3.11077639969421240000e+000) (21, -1.82413130505335060000e-001) (22, 1.60659239636291030000e-001) (23, 3.00767708187995090000e-001) (24, 4.15274222822284820000e-001) (25, 2.15469894959712530000e-001) (26, 4.31364108957769870000e-002) (27, 1.49435958428855240000e-001) (22, -5.23460111317167300000e-001) (23, 6.66243827066472780000e-002) (24, 1.40268795960213970000e-001) (25, 2.03424388859807960000e-001) (26, 6.56213971060743830000e-002) (27, 7.33487089151554580000e-001) (22, 2.32013181012352240000e-001) (23, -8.98948832745552370000e-001) (24, -6.87251981384975340000e-002) (25, 1.60336808312667110000e-001) (26, -4.32875067109218910000e-001) (27, 6.48671416307500690000e-001) 

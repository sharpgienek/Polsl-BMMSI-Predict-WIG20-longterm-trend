FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.14982320936317310000e+001) (1, 4.33944799472294140000e+001) (2, 1.79860991115641550000e+002) (3, 1.26265810202502580000e+001) (4, 7.69539929785764090000e+000) (5, 6.10701272851501460000e+000) (6, 1.59441829558590830000e+002) (7, 1.08487883371500510000e+001) (8, 3.57813530524079400000e+002) (9, 6.27138789980386060000e+000) (10, -2.51310645078972360000e+002) (11, -1.05618858659344220000e+000) (12, -1.22270939135471670000e+001) (13, 5.26382618325068050000e-001) (14, 3.10941913622291930000e+001) (15, 4.86632663788625660000e+000) (16, -5.26463199538217590000e+001) (17, 3.21581945466096110000e+000) (18, -9.42369636534263720000e+001) (19, -1.96008945774371810000e+001) (20, -4.28572580352424520000e+001) (21, 3.89112961746080680000e-001) (0, -7.75546432438817850000e+000) (1, 3.58419120266233550000e+000) (2, 1.89144553857491500000e+001) (3, 3.59636543190511420000e-001) (4, 1.42629228643528250000e+000) (5, 1.21903312605974710000e+000) (6, -7.10041035238715160000e+000) (7, 1.08081892369441630000e+000) (8, -3.35501365136503790000e+001) (9, 8.48681237842209280000e-001) (10, -5.04692420599987340000e+001) (11, -3.62933884405250820000e-001) (12, -1.23664443807343070000e+000) (13, -3.30020721162475050000e-001) (14, -5.99329765364522340000e+000) (15, -9.25875829085197190000e-002) (16, -7.68419048863528880000e+000) (17, -1.76156134442130190000e-001) (18, -1.95517530381832150000e+001) (19, -2.24953321262851300000e+000) (20, 9.37622981018032680000e-002) (21, 7.42616025343304950000e-001) (0, 2.89747769069357110000e+000) (1, -5.20360809463601900000e+000) (2, -7.36046551998515500000e+001) (3, -8.84587838247299470000e-001) (4, -4.80395642056782680000e+001) (5, -6.87592254793636130000e+000) (6, 1.25758430376137350000e+001) (7, -1.27062302549750190000e+000) (8, 3.72842896009863840000e+001) (9, -2.04723797960190400000e+000) (10, 2.41574260613486300000e+001) (11, -1.44598677549977820000e-001) (12, -2.77540564673235440000e+001) (13, 9.51273572817156880000e-002) (14, -3.95633038318125260000e+001) (15, 1.67220220635312610000e+000) (16, -1.46909795259944430000e+001) (17, 1.72545238802126180000e+000) (18, 7.10505784834371880000e-001) (19, 3.72348576156156110000e+000) (20, -6.73705373920673480000e+001) (21, -3.49506916826572490000e+000) (0, 1.58058435443447130000e+001) (1, -1.00787449278809090000e+000) (2, -1.67788979088522790000e+001) (3, -7.17783647356096120000e-001) (4, -4.83807870407893150000e+001) (5, -4.27774509625811650000e+000) (6, 9.84702756858157930000e+001) (7, -1.21394641820420920000e-001) (8, -9.96639666978449770000e+000) (9, -6.90557669988268950000e-001) (10, -3.50399331286470930000e+001) (11, 2.51464927807655810000e+000) (12, 1.60849253495274920000e+001) (13, -1.54905346523883920000e+000) (14, -3.22239863524741640000e+001) (15, 6.61955281079707470000e-001) (16, -2.34378515430840650000e+001) (17, 2.68463202658513070000e+000) (18, -4.80698513892518380000e+001) (19, -6.45827124217905110000e-001) (20, -1.07728476277520830000e+002) (21, -8.07790654959777000000e-002) (0, 1.91526647548365570000e+001) (1, 1.92618139442684510000e+000) (2, -1.05223739543278330000e+002) (3, 4.43109364663415880000e-001) (4, -1.15402120662176450000e+001) (5, 2.01097078480645130000e+000) (6, 1.64665484958624190000e+000) (7, 1.05322339042310060000e+001) (8, 4.18988165404616590000e+001) (9, 8.77708918293040650000e-001) (10, 5.09944808206824900000e+001) (11, 1.29074685231958150000e+000) (12, -9.56528714973780440000e+001) (13, 3.87963401625428930000e+000) (14, -2.12833009087199410000e+001) (15, 4.67642776192788660000e-001) (16, -4.04787123470400230000e+001) (17, -7.66026457586560180000e-001) (18, 3.45283867995265300000e+001) (19, 1.22003485331151820000e+000) (20, 1.97695598141747300000e+001) (21, -1.22394472034289170000e+000) (0, 1.99758388725012170000e+001) (1, -3.19919812862644970000e+001) (2, 9.24949581484224040000e+002) (3, 2.72856075992616810000e+002) (4, 1.24497365156244130000e+003) (5, 2.19435497310248810000e+000) (6, -9.63158276865500080000e+001) (7, -1.10195668659867870000e+001) (8, -4.05458060869244080000e+001) (9, -5.03473537900102850000e-001) (10, -6.27098622813138490000e+002) (11, 2.54084440041157260000e+001) (12, -1.38124738979621090000e+001) (13, 7.23620402548464050000e-001) (14, 1.09662887597407760000e+001) (15, -6.98999073080013410000e-001) (16, 9.10647052372817620000e-001) (17, 1.31228040804097790000e+001) (18, -7.16205293130107070000e+002) (19, 4.17277349329507030000e+001) (20, -2.87933523898635710000e+002) (21, 5.01015098808248640000e+001) (22, 3.09263743420498650000e+000) (23, -5.25119804970677070000e+000) (24, -2.09053524850507880000e+000) (25, -2.99600881931740840000e-002) (26, -2.94026418807937710000e-002) (27, -3.83400307044488920000e-002) (28, -1.03103206319384350000e-002) (22, -7.98865655443692920000e-001) (23, 1.29405535963418280000e+000) (24, 2.53043474345532140000e+000) (25, -2.21917216571059580000e+000) (26, -2.04452043415883720000e+000) (27, -2.02542226642500630000e+000) (28, 4.09447642810927180000e+000) (22, -2.92508837317566960000e+000) (23, 5.08675895801838780000e+000) (24, -2.78762498042829820000e-001) (25, 2.29436804210107280000e+000) (26, 2.50329181322100470000e+000) (27, 2.37487780283523660000e+000) (28, -2.52083402622613690000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.10727298167325740000e+000) (1, -1.44302572909095370000e-001) (2, -4.73668701673999050000e-001) (3, -1.32107127641308410000e-001) (4, 5.46623936888305240000e-002) (5, -6.65025387948870670000e-001) (6, 5.50174955784616060000e-001) (7, 4.55559699483985950000e-001) (8, -6.13843044831164090000e-002) (9, 1.97073898591840800000e-001) (10, 1.34478990479948420000e+000) (11, 4.32796674484150550000e-001) (12, -2.17691783099638950000e+000) (13, -6.01877746985686970000e-001) (14, 7.87337556153368200000e-001) (15, -2.42520376280615600000e-001) (16, -3.06538338363858190000e-001) (17, 1.28830489371809830000e-001) (18, 8.14150719239647990000e-001) (19, 2.88309279984314830000e-001) (20, -3.76219117419728240000e-001) (21, 2.76535569697786980000e-001) (0, -1.17425035457370130000e+000) (1, 2.18568547194606670000e-001) (2, 3.03538334006420000000e-001) (3, 3.22410243156644400000e-001) (4, 1.16949881926862660000e-001) (5, 3.27151662915406370000e-001) (6, 9.84492932471306090000e-001) (7, 8.15117848397985120000e-002) (8, -1.48511006647176480000e-002) (9, 2.68399583248426330000e-001) (10, 1.60612142249444690000e+000) (11, 7.03690536251762870000e-002) (12, -1.14179796151199800000e+000) (13, 3.30551712254401110000e-001) (14, 7.08583224792420860000e-001) (15, 1.01714063803591980000e+000) (16, -2.51203864883060290000e-001) (17, 2.82004319779277700000e-001) (18, 1.12089150199615990000e-001) (19, -3.14520969551887880000e-002) (20, -1.12227281473667560000e+000) (21, 7.60766832035472570000e-001) (0, 1.21723496172139930000e+000) (1, 2.85464151312773640000e-001) (2, 3.77888418506078790000e-001) (3, -2.51679050405564650000e-002) (4, -3.11695315759875320000e+000) (5, 1.35804188845998850000e-001) (6, -3.06089846926347330000e+000) (7, 1.95296255447943660000e-001) (8, 3.44690711058503570000e-001) (9, 1.37348297887867180000e-001) (10, -1.07148422235929750000e+000) (11, -1.52519950683694820000e+000) (12, 3.10019900695847190000e+000) (13, 6.74749379611292000000e-001) (14, 3.38848871186671730000e-001) (15, -1.67194909875739100000e-001) (16, 3.06517093026463790000e+000) (17, -4.31180455452077390000e-001) (18, -6.31457411438305360000e-001) (19, -3.35398111762539420000e-001) (20, 3.08166262972913340000e+000) (21, -1.12529521716799630000e-001) (0, 8.77577569039639350000e-001) (1, 1.51079175162368300000e-002) (2, 1.38775865543976850000e+000) (3, 9.77208405827415110000e-002) (4, -3.13926150754054860000e+000) (5, 1.33141318096590310000e+000) (6, -4.50252830758413490000e-001) (7, -5.44373191514809510000e-002) (8, 1.15409491432852550000e+000) (9, 1.23575333155503470000e-001) (10, 1.85259913996987050000e-001) (11, -3.97606540855983850000e-001) (12, 1.42939291875404000000e+000) (13, 3.96456874994888630000e-001) (14, 6.26412207689639680000e-001) (15, -7.90108403712323220000e-002) (16, 3.08771121380363930000e+000) (17, -5.89719543679515620000e-001) (18, -3.37295798476775150000e-001) (19, -1.09017527687871570000e-001) (20, 3.07106082293052920000e+000) (21, 4.83845302925181300000e-002) (0, 4.04698245358325600000e-001) (1, 1.38453799907053920000e-001) (2, 1.08570375716183940000e-001) (3, 3.90830654332437970000e-001) (4, 2.08306803557837570000e+000) (5, 5.99825420640673230000e-001) (6, -1.50327262663178280000e-001) (7, -2.80156587933968190000e-001) (8, -7.45190703038396680000e-002) (9, -1.70883412322516690000e-001) (10, -3.04288089086999050000e+000) (11, 9.63456165122571760000e-002) (12, -2.24739020738703390000e-001) (13, 1.24112489492750780000e+000) (14, -1.79376635426548800000e+000) (15, 4.63087268110559840000e-001) (16, -2.21302741390623840000e-001) (17, 4.98342329757731910000e-001) (18, -1.63868113829960280000e-001) (19, 3.05962438131534560000e-002) (20, -2.55293220412746440000e-001) (21, 7.78497545190305780000e-001) (0, 9.85701436028012970000e-001) (1, 7.60579075176594400000e-001) (2, 2.21931476488400930000e+000) (3, 2.62169860287099650000e-001) (4, 3.08168704379199720000e+000) (5, -9.22767246887828680000e-002) (6, 3.20301883270935670000e+000) (7, -1.48413778863451330000e-001) (8, -1.01929916298792960000e+000) (9, -5.65563234293334330000e-001) (10, -2.90260643540158290000e-001) (11, -2.73692027737078430000e-002) (12, -3.04740359601550900000e+000) (13, -2.22699599251868390000e-001) (14, -7.48978499118803100000e-002) (15, 5.96669528072858170000e-002) (16, -3.12026126311679790000e+000) (17, -4.25234519921999620000e-001) (18, 4.42226166251401040000e-001) (19, -9.30616314831610590000e-002) (20, -3.15535037496779140000e+000) (21, 2.40591331333811390000e-001) (22, 5.10794173843118320000e-001) (23, 2.91928636333411540000e-001) (24, -3.10801686149777410000e-003) (25, 2.25999640667614100000e-001) (26, 1.41153487602311810000e-001) (27, -7.57198267971677110000e-001) (28, 1.38644942643056570000e-001) (22, 3.27920418308027210000e-001) (23, 3.30828223842381360000e-001) (24, 2.20183775677083250000e-001) (25, 7.86939336721891980000e-001) (26, 4.72033088401333570000e-001) (27, 1.30555084896015420000e-001) (28, 3.61766973476990550000e-001) (22, 1.34565153481614160000e-001) (23, 2.93124925413737640000e-001) (24, -2.04639147214400630000e-001) (25, -3.61609513431162430000e-001) (26, 3.37625686969186540000e-001) (27, 7.58508149530992440000e-001) (28, 3.00382034070462880000e-001) 

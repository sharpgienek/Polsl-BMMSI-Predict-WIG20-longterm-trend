FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=22 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (22, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.02971669818727740000e+001) (1, -1.84721438728133740000e+000) (2, -1.47122719811065770000e+001) (3, -9.72233386665910750000e-001) (4, 2.01327391632326470000e+000) (5, -1.81843809481099020000e+000) (6, 2.00145196666630980000e+001) (7, 2.67793407752556060000e-001) (8, -2.67391545075691400000e+001) (9, 2.00117150484742410000e-002) (10, 8.09601678709895540000e+000) (11, 1.90329138109257020000e+000) (12, -5.01622875247539070000e+001) (13, -8.12158350983171130000e-001) (14, -4.80973104528915910000e+001) (15, 1.50398243115323730000e+000) (16, 4.91711505404084810000e+000) (17, 1.12266430871025550000e+000) (18, 7.80784456085083440000e+000) (19, -1.78082301835932240000e-001) (20, -6.78273009094185110000e+001) (21, 3.20326772563235450000e+000) (0, 5.65994334925686070000e-001) (1, 4.56256301194233500000e+000) (2, -1.29868062801609640000e+001) (3, -1.09201477474694470000e-001) (4, 2.92520915980146010000e+001) (5, 1.49359635146167500000e+000) (6, 7.37839348749280610000e+000) (7, 2.37677139066427980000e+000) (8, -2.66853787442073860000e+000) (9, -6.05375487156818710000e-002) (10, -4.14145073690323220000e+001) (11, -1.41223934386619420000e+000) (12, -4.61951804125930730000e+000) (13, 3.53015624701036530000e+000) (14, -7.55907171602320280000e+000) (15, 4.31685428755602620000e-001) (16, -4.47229856584026750000e-001) (17, -7.36777139221926780000e-001) (18, -6.13989488869110290000e+000) (19, -1.84304216451925500000e+000) (20, -1.58122415811593630000e+001) (21, 2.12111114695340190000e+000) (0, 1.07490672353029860000e+001) (1, 6.68659907631304320000e+000) (2, 9.16981948831000580000e+001) (3, 1.21455380456674010000e+002) (4, -2.06628099503198510000e+001) (5, 3.17579616254514900000e+000) (6, 7.90187686042095270000e+001) (7, 1.49474411161979810000e+001) (8, 1.73114413933152180000e+002) (9, 1.62527123525871920000e+001) (10, -8.61792424289406680000e+001) (11, 6.82851116966305940000e+000) (12, -2.44465961092576830000e+002) (13, 9.68716477483659060000e+000) (14, -7.47182305982877980000e+000) (15, -6.06952368507731380000e-001) (16, 5.93969722545288330000e+001) (17, 5.83043534606356140000e+000) (18, -7.54950021921681580000e+001) (19, -1.05019944992585060000e+001) (20, -5.47885067485144290000e+001) (21, 2.38312992429980070000e+001) (0, 4.89668580901813830000e+001) (1, 4.65884478134293010000e-001) (2, 3.94548903643708400000e+001) (3, 3.84447412712726310000e-001) (4, 2.46264366583767610000e+001) (5, 3.98884875949350180000e+000) (6, -3.65532894982761290000e+001) (7, 2.79495797063253360000e+000) (8, -4.30755527799725260000e+001) (9, -3.24866132193563200000e-001) (10, -3.69227792695731840000e+001) (11, -1.38353706959841150000e+000) (12, -2.25302207260361800000e+001) (13, 6.87635623603871980000e-001) (14, 2.38261104781129910000e+001) (15, 4.93126257445722520000e+000) (16, 2.70934148078667900000e+001) (17, -8.70923923882985450000e-001) (18, -5.17091001627181440000e+001) (19, -1.62382030489683420000e-001) (20, -4.18680136294151030000e+001) (21, 1.56338251084784300000e+000) (0, -2.96142224863680320000e+001) (1, 1.46684024347044510000e+000) (2, 1.13927659573015110000e+002) (3, -3.75625341332497530000e-001) (4, 2.63785111626199720000e+001) (5, 2.63201061202661710000e+000) (6, -5.40953263449384460000e+000) (7, 7.28700576851496340000e+000) (8, 4.25187239058461440000e+001) (9, -1.85198129704120060000e-001) (10, 3.14487802643672440000e+001) (11, -2.53258919545608530000e+000) (12, 8.88476567448720690000e+001) (13, -1.18418606658840850000e-001) (14, 2.02824303192257390000e+001) (15, -1.54823407871435910000e+000) (16, 5.55540063151090490000e+001) (17, 1.16382960819747400000e+001) (18, -4.84580674266758180000e+001) (19, -9.42815472935616630000e-001) (20, -2.33131164654994900000e+001) (21, 3.18770461934029600000e+000) (0, -5.30071324315872430000e+000) (1, -1.56019632357637920000e+000) (2, -1.35388722444845030000e+002) (3, 1.75252959981285230000e+000) (4, -2.81551016437539840000e+000) (5, -1.32379799462795320000e-001) (6, 2.11289861979143080000e+001) (7, -2.37434574216504240000e-001) (8, -2.17219942309349640000e+001) (9, 8.92246241022488950000e-001) (10, 1.02691026554009390000e+001) (11, 1.80031540693554780000e+000) (12, -4.70628827176735740000e+001) (13, 1.56556505777322500000e+000) (14, 9.45400800837433620000e+001) (15, 2.99384372601619300000e+000) (16, 2.00956496584681150000e+001) (17, -2.33981674585875780000e+000) (18, 6.99742608243122960000e+001) (19, 2.21227125990377130000e+000) (20, 7.71879941566817390000e+001) (21, -7.30618136469006090000e-001) (22, -4.10547519336749290000e-002) (23, -8.87842290523205710000e-002) (24, -1.28646237215727040000e-001) (25, 5.54473369842381280000e-002) (26, 1.95731962465147410000e+000) (27, 1.97997251067043470000e+000) (28, 5.84486039509227590000e-002) (22, -2.09608215862101410000e+000) (23, -2.29951814869395930000e+000) (24, 9.85156972416115220000e-001) (25, 1.22059649635411850000e+000) (26, -1.38170021922076120000e+000) (27, -1.12942640805267750000e+000) (28, 2.21387615113376320000e+000) (22, 2.13477369888368520000e+000) (23, 2.62789507269383550000e+000) (24, -8.28239561926063520000e-001) (25, -1.23942658560990320000e+000) (26, -1.67589844367343700000e-001) (27, -7.00642652988939240000e-001) (28, 7.90819085983915590000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.05156407084095440000e+000) (1, 3.25849128710106070000e-001) (2, 3.37468530056451910000e-003) (3, 2.49962835977742620000e+001) (4, 7.69240617751552390000e-001) (5, 1.33257226699294520000e+000) (6, -2.05213843896172390000e+001) (7, -1.65138309354047610000e-001) (8, 8.54761256517152470000e+000) (9, 4.00658512483901830000e-001) (10, -8.80858415957247410000e+000) (11, -1.01901244369083950000e-001) (12, 5.58068922751393530000e-001) (13, 1.51857379269673530000e+000) (14, -2.48613500604038220000e-001) (15, 1.11426648675473410000e+000) (16, -6.00039988110740110000e-001) (17, 2.37356805319343780000e+000) (18, 2.07302462122128350000e+000) (19, 2.78298459184483530000e+000) (20, 4.64302500576611600000e-001) (21, -1.89590198186496410000e+000) (22, 2.19120181060988850000e-001) (23, 5.98633608003341420000e-001) (0, 7.98277642652793220000e-001) (1, 9.41708262049521740000e-001) (2, 6.38499571992860120000e-001) (3, 5.54346866683326570000e-002) (4, 1.73991211353191570000e-001) (5, 2.01059869753011070000e-001) (6, 2.39613396373613880000e-002) (7, 7.56721209326018500000e-001) (8, 7.74140598056401900000e-001) (9, 8.35784968166137230000e-001) (10, -6.70245195258786010000e-001) (11, 3.17049874700418290000e-001) (12, -7.03560380715869240000e-001) (13, -7.98273753869850890000e-002) (14, 9.53302453407487320000e-001) (15, -2.31644538941500250000e-001) (16, 5.59167182583670260000e-001) (17, 3.16913586192250240000e-001) (18, 1.14603062483003740000e+000) (19, -3.70420906654029270000e-001) (20, -3.19032469846791620000e-001) (21, 6.60656298061475300000e-001) (22, 4.92021330244515910000e+000) (23, 7.51463999999446910000e-001) (0, 1.21030262625225430000e+000) (1, -1.96193572457229480000e+000) (2, -1.52243421895402580000e-001) (3, 1.57224936126381660000e-001) (4, 3.41926025143545530000e-001) (5, 4.32937336858138840000e-001) (6, 6.36314800190037280000e-001) (7, 2.07441012609882850000e-001) (8, 6.34205738002630690000e-001) (9, 1.42453926803703830000e-001) (10, 5.40980495841769660000e-001) (11, -4.10077689396745160000e-001) (12, 1.17573311475350910000e+000) (13, 2.23366038943902860000e-001) (14, 2.14728562126021760000e-001) (15, 7.38462727670619160000e-001) (16, 2.52562107318006270000e-001) (17, 1.94988557640974840000e-001) (18, 2.60099777242700060000e-001) (19, 5.66767428446909080000e-001) (20, 5.21906548254548960000e-001) (21, 5.36981610902765420000e-001) (22, -2.53648800239484720000e-001) (23, 3.43035724467815220000e-001) (0, 1.49980514800088490000e+003) (1, 1.50000000000000000000e+003) (2, 1.05832368933996230000e+000) (3, 2.23200014131394770000e+002) (4, 1.50000000000000000000e+003) (5, -1.50000000000000000000e+003) (6, -1.49999933877067560000e+003) (7, -1.18124685410378660000e+001) (8, 6.94307339843724780000e+002) (9, -2.28441985888817980000e+002) (10, -5.67691035772733910000e+001) (11, 1.49684482098395670000e+003) (12, 8.23380054203292850000e-001) (13, -2.07986858761883390000e+000) (14, 5.02910575431209230000e+000) (15, 1.50000000000000000000e+003) (16, -1.47444625668230650000e+003) (17, 2.87171042072059280000e+001) (18, 3.44770514191876960000e+001) (19, 8.88766029158307980000e+000) (20, 8.62606118328238410000e-001) (21, -2.11012234131451830000e+002) (22, -5.82581593650848840000e+002) (23, -5.65608301509170300000e-001) (0, 9.81475449285315720000e-001) (1, -4.16165034003259380000e-001) (2, -1.70790900259565390000e-001) (3, 4.79282171367780570000e+000) (4, 2.10044235258979500000e-001) (5, 1.01044682760294720000e+000) (6, 8.97993069824420260000e-002) (7, -6.88091479649131920000e-002) (8, 1.56962703472406870000e-001) (9, 1.75657917647727040000e-001) (10, -7.45318494322157020000e-001) (11, 1.74277806905102080000e-001) (12, 2.55236421587860860000e-001) (13, 1.17527299424700700000e+000) (14, -1.15963738324887040000e-001) (15, -6.28355760884527910000e-002) (16, 2.06527694421058370000e-001) (17, 1.70685324209977040000e+000) (18, 2.36323564805545370000e-001) (19, 3.95358685042752790000e-001) (20, 6.51452097253700010000e-001) (21, 1.21124851052112490000e-001) (22, 4.85290034972470810000e-001) (23, 1.09939338268878340000e+000) (0, 5.06440983850571900000e-001) (1, 1.49502992136100020000e-001) (2, 1.33518312378593020000e-001) (3, -1.69581128169127150000e-001) (4, 1.13190585928298980000e+000) (5, -7.19543170270553590000e-001) (6, -6.01708079068774880000e-001) (7, 4.32521709106574730000e-001) (8, 3.27370178811386350000e+000) (9, 7.79597340580652080000e-002) (10, 7.37865996810608670000e+000) (11, 2.63137255049330830000e-001) (12, 1.17358957982624630000e+000) (13, -1.18163118090697220000e+000) (14, 9.82642042492185120000e+000) (15, 3.76786860451786220000e-001) (16, -2.14607854278274360000e-001) (17, -1.15015911485991350000e+000) (18, 3.80623074803447650000e-001) (19, 1.80643942516361380000e+000) (20, 2.91821341288186930000e-001) (21, 3.38378862752668210000e-001) (22, 9.35059985932142120000e-001) (23, -8.45847262673405490000e-001) (24, 6.75969255421246420000e-001) (25, -1.33724461198871910000e+000) (26, 8.33870381504123510000e-001) (27, 7.56981652956148170000e-001) (28, -1.07517156118017280000e-002) (29, 6.97694207252819280000e-001) (30, 3.78744499459489900000e-001) (24, 5.34446434871597780000e-002) (25, 1.85562144987976900000e+000) (26, -8.27361890196596890000e-001) (27, 1.33412889389936120000e+000) (28, 3.71526046764323660000e-001) (29, 4.45447458032294670000e-003) (30, 1.21164240841694020000e+000) (24, 1.64274152181477070000e+000) (25, 5.47562234389966650000e-001) (26, 6.57067049463861410000e-001) (27, -9.80015968486400160000e-001) (28, 1.67659948660242740000e+000) (29, -1.51351070070082280000e+000) (30, 1.14874382110585520000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.77648603552501700000e+002) (1, 1.57131545090456880000e+000) (2, -2.10274636384980590000e+001) (3, -4.69087456025422430000e+000) (4, -3.71781701868749110000e+002) (5, -3.49813297421091330000e+000) (6, 5.78088426623390460000e+001) (7, 1.35510261235325260000e+000) (8, 6.52693933234635610000e+001) (9, -2.17732207976046640000e+000) (10, -1.16078207235233920000e+002) (11, 1.33204957442605220000e-001) (12, -1.89420321317238380000e+001) (13, -5.28811740481663860000e+000) (14, -1.32692038767263110000e+002) (15, -9.91637991120590150000e-001) (16, -1.59664423776916290000e+002) (17, -1.10047219862928450000e+001) (18, -1.24406564506469980000e+002) (19, -4.74500609461238470000e+000) (20, -3.09008966239594660000e+002) (21, -2.54000108474920050000e+001) (22, -5.91564040907226510000e+002) (23, -3.23214618426580060000e+000) (0, 1.31660194354882380000e+002) (1, 1.41960163880251300000e+000) (2, 1.08810729382496310000e+003) (3, 1.76119852119521030000e+001) (4, -1.78745032248557550000e+002) (5, 2.63734133153221820000e+002) (6, -1.09491702058252120000e+003) (7, 7.05860851311458500000e+001) (8, -8.72639346473640240000e+001) (9, 1.23227946778561610000e+001) (10, -3.70000942215581120000e+002) (11, -1.31267964159309830000e+001) (12, -4.97261241455357210000e+002) (13, 4.08914486128947980000e+001) (14, -8.61153876527998930000e+002) (15, 4.90640605830289050000e+001) (16, 6.84449409571099750000e+002) (17, 2.50703207591466890000e+001) (18, 5.92796472924867770000e+002) (19, 8.47685170188203760000e+001) (20, -3.76796395258209940000e+002) (21, 5.19355195794162510000e+001) (22, -1.47251577268517010000e+003) (23, 4.61284920185979250000e+001) (0, -1.49832605669410010000e+003) (1, 2.70549016118670180000e+002) (2, -1.38578687271534610000e+003) (3, 1.23303531740082310000e+002) (4, 7.09122219387112690000e+001) (5, 1.14698771516833930000e+002) (6, -8.90192359420140750000e+002) (7, 1.13290933119362970000e+003) (8, 1.50000000000000000000e+003) (9, -2.77303738548693220000e+002) (10, -4.94325911091949480000e+002) (11, 2.01812499736600270000e+001) (12, 1.49999897758766340000e+003) (13, -6.18353667503973720000e+002) (14, 1.28467690155968430000e+002) (15, 1.69503317659030560000e+002) (16, 1.15597800147223890000e+003) (17, 4.22099927663373150000e+001) (18, 1.18469200455831340000e+002) (19, 7.92981317921759910000e+002) (20, -1.11780224695325180000e+003) (21, 4.27594742980823210000e+000) (22, 1.44316958924060760000e+003) (23, 4.18036370744248130000e+002) (0, 2.44291176765938720000e+001) (1, 3.88094863891834980000e+000) (2, -1.86509016700335200000e+001) (3, 1.32447300720931340000e+000) (4, -9.26555100802658700000e+001) (5, 1.41335946045838480000e+000) (6, 5.10673242858552980000e-001) (7, 4.97607832167187510000e-001) (8, -6.05399879793839160000e+001) (9, -5.23361210023071190000e-002) (10, 2.84929298012554640000e+001) (11, 2.71532510298457690000e+000) (12, 5.14784841126091240000e+001) (13, -3.37865264385473980000e-001) (14, 4.07100410153630110000e+001) (15, -5.04258199414808090000e-001) (16, -8.33524153893182880000e+000) (17, 1.15580989307959080000e+000) (18, -8.41942355811391430000e+000) (19, 3.90152865902017790000e+000) (20, -1.82002731969212730000e+001) (21, 1.82288999516666170000e+000) (22, 2.06446528133288890000e+001) (23, -1.50058569672248280000e+001) (0, 3.54390098241502530000e+002) (1, -1.02590300859700050000e+001) (2, 3.53443630092816140000e+002) (3, -2.76967798883740880000e+001) (4, 8.13421231728565430000e+002) (5, 2.00916731341381420000e+000) (6, -1.38702434209286140000e+002) (7, -1.84455799942091190000e+001) (8, 1.97604785471916530000e+002) (9, -8.89635014852827770000e+001) (10, -2.85981039265407560000e+002) (11, 4.86208976521095690000e+001) (12, 1.50000000000000000000e+003) (13, -4.96302881805158340000e+000) (14, 4.33263878474281280000e+002) (15, 6.76122416786510740000e+001) (16, -1.10163373792426640000e+003) (17, 1.18801680103011310000e+000) (18, 5.98017166817731320000e+002) (19, -2.98840613224490850000e+001) (20, 8.71135424590128650000e+002) (21, -1.40064737104890270000e+001) (22, -7.13197693050612540000e+002) (23, 9.61217491695549060000e+000) (0, 6.40937122732731690000e+001) (1, 8.82323609726252660000e+000) (2, -6.22728521543401840000e+000) (3, 4.54816479325671090000e+000) (4, -8.46808607895656420000e+001) (5, -4.68055785750408240000e-001) (6, -1.71883530149163060000e+001) (7, -9.67138568413935750000e-001) (8, -1.01833003721378020000e+002) (9, -2.81831232719877710000e+000) (10, 3.15307600797515980000e+001) (11, 2.98102465709410240000e+000) (12, -1.88861605086936810000e+002) (13, 3.50017864967787950000e+000) (14, -1.09157293998161140000e+002) (15, 1.32457807531851150000e+000) (16, -1.74683471693476380000e+001) (17, 5.00865217307279750000e+000) (18, -1.33362620220261080000e+002) (19, 3.85360909330588890000e+000) (20, -1.60534787874553610000e+002) (21, 2.24919570842537110000e+000) (22, 1.12681574192680130000e+002) (23, 6.01996998429346690000e+000) (24, -6.95884123634364920000e-001) (25, 6.45186700573534670000e-001) (26, 6.92797394270970200000e-001) (27, 9.55290932857474570000e-001) (28, -7.46896250006306770000e-001) (29, -1.54927903682468670000e+000) (30, 1.00745834489999500000e+000) (24, -5.20308435440646750000e-001) (25, -2.02319223830969720000e+000) (26, 5.35033263903681890000e-001) (27, -5.21257180653422410000e-001) (28, 1.90636710760718550000e+000) (29, 2.40350277703812630000e+000) (30, 9.60246458424811380000e-001) (24, 7.30459606273455300000e-001) (25, 7.16461072709558830000e-001) (26, -2.02948978997134510000e+000) (27, -7.22790158835357350000e-001) (28, -7.18289435742544670000e-001) (29, 8.39663044700940110000e-002) (30, 1.90496498686898510000e+000) 

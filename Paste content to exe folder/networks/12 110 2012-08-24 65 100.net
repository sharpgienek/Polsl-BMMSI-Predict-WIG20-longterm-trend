FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.08177104472102140000e+000) (1, -3.10735251970930330000e+000) (2, -5.21180952550717080000e+000) (3, -1.60023010541421500000e+000) (4, 4.81385909243001680000e-001) (5, -1.93981800050263380000e+000) (6, -5.45529362591226530000e+000) (7, -6.85408861765060000000e-001) (8, -1.32597409766708800000e+001) (9, 1.09359241666546850000e+000) (10, -3.56917293933351160000e+001) (11, -1.71062183496125080000e+000) (12, -1.79912660294804330000e+000) (13, -7.85888318712824830000e-001) (14, -9.10898074218137130000e+000) (15, 1.77988286910152230000e+000) (16, 7.93822888987528770000e+000) (17, -4.09725264418806910000e-001) (18, 1.17411431823766100000e+000) (19, -3.78576446069206650000e-001) (20, -4.24404887798262290000e+000) (21, -2.74258260250216470000e+000) (22, -1.95984986861881770000e+000) (23, -7.61460971172734920000e-001) (0, 8.61916365588182030000e+000) (1, 4.27847192052398030000e+000) (2, 2.39552681177685260000e+001) (3, -5.92466487696099720000e-002) (4, -2.11213823355077150000e+000) (5, 1.03207966415188550000e+000) (6, 1.04640443225960150000e+001) (7, 1.82123245485195850000e+000) (8, 3.31805607615974480000e+001) (9, -6.02455132152140190000e-001) (10, -1.08023255265017990000e+000) (11, -1.31479779657693310000e-001) (12, -1.00301985948234030000e+001) (13, 2.28382609797928240000e+000) (14, -1.94255021120762870000e+000) (15, -4.96157356469045410000e-001) (16, 7.45691721052529680000e-001) (17, 3.73902396338453900000e-001) (18, -5.26906547726423470000e+000) (19, 4.01760601744180960000e+000) (20, 8.48247474604716830000e-001) (21, 1.15423592845067730000e-001) (22, -7.14426100795832220000e+000) (23, -1.10039569506792420000e-001) (0, 9.71106681633991360000e+000) (1, -1.53900057088539180000e+000) (2, -6.29079881094868030000e+000) (3, 3.12371255251029510000e+000) (4, 1.96347286779293600000e+001) (5, 3.22898240753031200000e-001) (6, -1.95345600343739750000e+001) (7, -8.37044244690067500000e-002) (8, -6.85288995255436850000e-001) (9, 3.48969470371611580000e-001) (10, 3.67315997072365750000e+000) (11, 3.65112571186761680000e+000) (12, 1.95324546262999700000e+001) (13, -1.70851885128238510000e-001) (14, -8.99962519339593210000e+000) (15, -1.25688531528323240000e+000) (16, 2.37719070618620790000e+000) (17, 2.09993852126068870000e+000) (18, 1.24030340995507550000e+001) (19, -1.00135210649864500000e+000) (20, -8.78248613760675310000e+000) (21, 3.99872997054016070000e+000) (22, -1.32723366139701470000e+001) (23, 2.22769648642691910000e+000) (0, -1.31506721460672830000e+001) (1, 1.93369046197329460000e+000) (2, 1.39062601529611400000e+001) (3, -1.08664814577041540000e+000) (4, -7.86573503306252770000e+000) (5, -4.96621449407941450000e-001) (6, -3.23190997666128010000e+001) (7, 1.47743090109934830000e+000) (8, 3.98959177643861460000e+000) (9, -3.69498595538117980000e-001) (10, 7.21582006533739320000e+000) (11, 8.88832113270568550000e-001) (12, 1.20364916788017310000e+001) (13, 9.49846735447585470000e-001) (14, -1.63248503422655810000e+001) (15, 1.39485024069340090000e+000) (16, 2.57123939638804580000e+000) (17, 7.24516095323188390000e-001) (18, -7.68742348075991360000e+000) (19, 2.01784669533474180000e+000) (20, 2.20904781058019360000e+000) (21, 4.25895574308606200000e-001) (22, 1.81646692547547170000e+001) (23, 9.18567885930212660000e-002) (0, -8.13696448212476220000e+000) (1, 4.06148310584467880000e+000) (2, 2.72718422357945700000e+000) (3, -1.46960602606237580000e+000) (4, 1.50176180717097090000e+001) (5, 5.11111932373345400000e-001) (6, -1.28089615266867690000e+001) (7, 2.78239269555034060000e+000) (8, 1.83386064999128640000e+001) (9, 6.99025385383215350000e-001) (10, -2.23206622593092160000e+001) (11, -1.53398257948952720000e+000) (12, 1.26190759628071550000e+001) (13, 9.93762941194848090000e-001) (14, 9.21721163188369450000e+000) (15, 1.09774837061094920000e+000) (16, 6.25034994599088510000e-002) (17, -1.86610915280773360000e+000) (18, -3.23905329552963510000e+001) (19, 3.35699349534388200000e+000) (20, -3.11097676951404130000e+000) (21, -2.47044675814417140000e+000) (22, 2.16410419197857560000e+001) (23, -6.91923524202700540000e-001) (0, 1.14181792822983220000e+001) (1, 5.74085286090319500000e-001) (2, -1.60552915513976830000e+001) (3, 6.70328470175330370000e-001) (4, -2.45772221179294590000e+001) (5, 1.08584673358999460000e+000) (6, -3.84755243393964270000e+000) (7, 1.20579958307926250000e+000) (8, -1.00106145434743590000e+001) (9, -1.90514492546752230000e-002) (10, -1.93268968096292540000e+001) (11, 2.11150189973022870000e-001) (12, 4.47925196156771930000e+000) (13, 8.64991616079499370000e-001) (14, -3.46280086475138520000e+001) (15, -2.80691302351858370000e+000) (16, 5.05053907618755020000e+000) (17, -1.89359701186362390000e-001) (18, 7.06805059439404300000e-001) (19, 9.36531907674922670000e-001) (20, -4.52037371050279280000e+000) (21, 1.89886781474362800000e+000) (22, 7.05716452537055790000e+000) (23, -1.05035359662282070000e-001) (24, -2.36911777723142620000e-002) (25, -1.29425756205213530000e+000) (26, -1.32257014830389410000e+000) (27, 4.26488894223530980000e-001) (28, -2.51095241820775080000e-001) (29, 1.36547040317072720000e+000) (30, 1.07572426351605950000e+000) (24, -1.69452048361355520000e+000) (25, -2.30057172044997480000e-001) (26, 1.57227746274473690000e+000) (27, -5.00889585982982610000e-001) (28, 1.81116671509165350000e+000) (29, -1.65983256400907280000e+000) (30, 2.23513809219194980000e-001) (24, 1.52065008675732250000e+000) (25, 1.53181294477638440000e+000) (26, -9.40844917572860730000e-002) (27, -8.00696487489745010000e-002) (28, -1.43412267160944330000e+000) (29, 9.36929110413140530000e-002) (30, 1.44924998951852470000e+000) 

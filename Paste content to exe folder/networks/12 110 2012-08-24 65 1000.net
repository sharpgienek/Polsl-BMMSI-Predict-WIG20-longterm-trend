FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.88578606182878480000e+001) (1, -3.36344101194156100000e+000) (2, -8.21167619503725920000e+001) (3, -1.28818281946200640000e+000) (4, 1.31102650654897250000e+002) (5, -2.19170988017855390000e+000) (6, 7.02281842815928030000e+001) (7, 1.55057698699796220000e+000) (8, 3.93596884541761230000e+001) (9, 5.39211187350521910000e+000) (10, 9.18233029203474300000e+001) (11, -1.17130724715979580000e+000) (12, -1.95684451243397960000e+001) (13, 1.05700340747728630000e+000) (14, 8.35502560441276780000e+001) (15, -1.85617817610021390000e+000) (16, -1.17627575976001690000e+002) (17, -9.50080135791242370000e-002) (18, 1.73164948053966090000e+001) (19, 1.83801994678782940000e-001) (20, -1.37836858793479890000e+000) (21, -4.56993967391496980000e+000) (22, -5.44882061421264920000e+000) (23, 2.74244541650894780000e+000) (0, -8.27637583752019520000e+000) (1, -1.46997785335899310000e+000) (2, 3.12677812402366580000e+001) (3, 6.42318292639406650000e-001) (4, -2.91780044257311320000e+001) (5, -1.42568531111971280000e+000) (6, -4.64279918916643060000e+001) (7, 6.23725881847093100000e-001) (8, 5.18189445480679200000e+000) (9, 2.68104264524131470000e+000) (10, -1.34328610075057430000e+001) (11, 6.68447336073159090000e+000) (12, 2.73591401121478310000e+001) (13, -6.56181196129101420000e-001) (14, -2.53217389924377800000e+001) (15, 5.26236974730785520000e+000) (16, -7.61680036355348640000e+000) (17, 5.27147800637491940000e+000) (18, -7.64846539657227350000e+000) (19, -5.32365060255634900000e-001) (20, -3.63244804889148010000e+001) (21, -1.87291160430753440000e-001) (22, -5.72132683920327450000e+001) (23, 2.22560661996403160000e+000) (0, -1.77930559344592890000e+001) (1, 1.74513177048098210000e+000) (2, 6.34904288312122060000e+001) (3, -9.62260226006870670000e-001) (4, 1.02737373563950650000e+001) (5, -3.14202140082105070000e+000) (6, -2.06900035262882030000e+000) (7, -1.08000983668753180000e+001) (8, 1.11672157175667480000e+002) (9, -3.10764170049185820000e+001) (10, 5.54659626115548750000e+000) (11, -5.77197779510513990000e-001) (12, 7.12215473796866410000e+000) (13, -4.58486228428733340000e+000) (14, 1.42821137314428130000e+001) (15, 6.08899213520168740000e+000) (16, -3.10722943411642590000e+001) (17, -8.84068603228614500000e-002) (18, -1.19244831116297390000e+001) (19, -4.86299769832995830000e+000) (20, 8.44033521792823220000e+001) (21, -4.40835029000227770000e+000) (22, -8.43821472877718120000e+000) (23, -6.39906869380147850000e-001) (0, -5.37680356837156950000e+001) (1, 9.88290698842476220000e-001) (2, -5.39106682017387410000e+000) (3, -5.21666256625879300000e-002) (4, 3.62981176291820920000e+000) (5, -1.41204882268897740000e-001) (6, 9.09130419382555920000e+000) (7, 3.93200356373945330000e+000) (8, 9.60354116636833480000e+001) (9, -4.40207507768715640000e-001) (10, 2.11154966361963330000e+001) (11, 6.17994799476599740000e-001) (12, 8.92354740104733680000e+000) (13, -1.27776416510760990000e+000) (14, 2.47222811361044810000e+001) (15, 1.56866435361556200000e+000) (16, 1.20602404347771610000e+000) (17, 3.66048152555765900000e+000) (18, -4.68240922271183460000e+000) (19, 1.73106586819588790000e+000) (20, 5.70270265481245040000e-001) (21, -7.80369095578966280000e-001) (22, 1.42875531996680590000e+001) (23, 6.69443227681662980000e-001) (0, 4.75375520482573530000e+001) (1, -6.81590792225124000000e+000) (2, -3.84381816405075940000e+001) (3, -7.21430123913917480000e-001) (4, 6.61639575713157480000e+001) (5, 1.79929024890251280000e-001) (6, -7.75581400379844780000e+000) (7, 1.15116152693928280000e+000) (8, -4.18813188972611880000e+001) (9, 3.44663501528456750000e+000) (10, 2.68740953794853610000e+000) (11, -5.76137510554839860000e-001) (12, -1.53753165186193140000e+001) (13, 1.19506238941408300000e+000) (14, -1.26180625073392410000e+001) (15, -2.52937996388175620000e+000) (16, -2.97485690464367390000e+001) (17, -3.67497342525766730000e+000) (18, 5.52697805921105140000e+001) (19, -1.46957148013043980000e+000) (20, -1.33211352403781720000e+000) (21, 3.97371165859604860000e-001) (22, 4.55521763852549720000e+000) (23, -3.01112133524051360000e-001) (0, -5.72792481321068410000e-001) (1, 3.60976260130004480000e+000) (2, 1.16070053651832270000e+001) (3, 9.01919090942492450000e-001) (4, -8.71623530245026500000e+000) (5, 1.37805488615219400000e+000) (6, 4.50081349522045930000e+001) (7, 5.16156874845064890000e-001) (8, 4.16711896087026900000e+001) (9, -1.04776601907652640000e-001) (10, 2.44115504767831610000e+000) (11, -3.11471186817110110000e-001) (12, -8.96735954427719760000e+000) (13, 2.22333457751595590000e+000) (14, 4.46414388075630200000e+001) (15, 5.86537522125913250000e-003) (16, 2.65363082793780510000e+001) (17, 6.03830227213641210000e-001) (18, 1.02924834436171860000e+001) (19, 2.05142734094865280000e+000) (20, 7.12554689316523770000e+000) (21, -4.73810989325198940000e-001) (22, -3.60867406875185280000e+000) (23, 2.26103700557189090000e+000) (24, -4.33383918778565080000e-001) (25, -1.02856476991042340000e+000) (26, -4.91922288618962030000e-001) (27, 6.63882736327252920000e-001) (28, -3.44090437287775050000e-001) (29, -1.93429861332429790000e+000) (30, 1.91682025506416860000e+000) (24, -1.42848314123368490000e+000) (25, 1.25252338518346740000e+000) (26, 1.64074917331502300000e+000) (27, 1.38942230165694050000e+000) (28, 2.82093103590649900000e+000) (29, 2.40726552971394180000e+000) (30, 5.99532637208130990000e-001) (24, 1.15475801333612700000e+000) (25, 5.80025972706522900000e-001) (26, -6.64412617097277500000e-001) (27, -1.50228054469251910000e+000) (28, -1.57273248793740320000e+000) (29, 3.80636452317839770000e-001) (30, 3.12228946807174000000e-001) 

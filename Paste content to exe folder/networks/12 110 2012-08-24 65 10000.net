FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.89332892722862030000e+001) (1, 5.18003392722511390000e-002) (2, -1.19647019355558240000e+000) (3, -2.41376967197800200000e+000) (4, -3.92688640912262980000e+001) (5, 4.20292431280208050000e-001) (6, -8.72196049543900780000e+001) (7, 1.91442284981754710000e+000) (8, -5.53671668505495380000e+001) (9, 1.75954533734636160000e+000) (10, -4.59929639442071620000e+001) (11, 1.03215590656619360000e+000) (12, -3.98584484945282750000e+001) (13, 1.19724439676360790000e+000) (14, -2.53809699252994960000e+001) (15, 8.86755985980561160000e+000) (16, -5.44978367210431540000e+000) (17, -4.16166273390601470000e-001) (18, -4.55508334630748590000e+001) (19, -5.25045469359377300000e+000) (20, -6.54752659458107990000e+000) (21, -1.64328634308583550000e+000) (22, -3.44562241848865870000e+001) (23, -9.89222212838462010000e-001) (0, 2.18591336763657860000e+001) (1, -1.05982076135916930000e+001) (2, 3.97494607060046410000e+001) (3, 3.34731041343744850000e+000) (4, 2.43959815031202500000e+001) (5, -2.69448980751422870000e+000) (6, -1.09805838922812700000e+001) (7, -2.49239516233656610000e-002) (8, 4.82627904123763540000e+001) (9, 1.91402759508718410000e+000) (10, -1.31224004713623510000e+002) (11, -4.24695698293618220000e+000) (12, -8.03762291670066990000e+000) (13, 6.89616834804824390000e-001) (14, -4.04529742901712340000e+001) (15, 5.95639249427684000000e+000) (16, -7.78093680411472230000e+001) (17, 1.21990955349904630000e+000) (18, -4.99435082856157780000e+001) (19, -7.14848434016975620000e+000) (20, -8.86086749007244200000e+000) (21, -3.77364948487783790000e-001) (22, -1.90812730064930010000e+002) (23, -4.29857808960745300000e+000) (0, -1.26172801863902710000e+001) (1, 2.47401778259049140000e+000) (2, 7.57455892503778610000e+001) (3, -1.92744841148353020000e+000) (4, 7.94276729673876360000e+001) (5, 3.36583696852462590000e-001) (6, -5.83092574693858360000e+000) (7, 2.88339195957796960000e+000) (8, -2.87516254858383920000e+001) (9, 5.95941598295458160000e+000) (10, 8.36680807202332490000e+001) (11, 2.28749863909597420000e+000) (12, -4.63690646976576350000e+001) (13, 8.57954652118507430000e+000) (14, -3.76372603105536360000e+001) (15, 1.13717096594741830000e+001) (16, 5.78848512956988300000e+001) (17, -1.98556715413729180000e-001) (18, -1.61759575692531960000e+001) (19, 2.36827137313678810000e+000) (20, -8.37437651752029670000e+000) (21, -2.89264577911578110000e-001) (22, -1.30205397413841100000e+002) (23, 4.89483251761820350000e+000) (0, -1.79236728126223850000e+002) (1, 4.54688644323073060000e+001) (2, -5.21012295941860870000e+000) (3, 4.46353435513712430000e+001) (4, -6.77074407298874380000e+001) (5, 3.52329771553971090000e+001) (6, 7.61347201921648430000e+002) (7, -1.29707871132550930000e+000) (8, 2.88274986215495740000e+002) (9, -2.18911518150342040000e-001) (10, 3.16384560247726540000e+002) (11, -6.41727666063037190000e+000) (12, -5.70237729667682840000e+001) (13, 9.27523066867417330000e+001) (14, 5.71577364768302690000e+002) (15, -2.33995118086941420000e+000) (16, 3.16477375161242610000e+002) (17, 2.73373679449874630000e+001) (18, 1.26347285423287660000e+001) (19, 1.17766861800300930000e+002) (20, 4.94057809323147980000e+002) (21, 1.90339041142364490000e+001) (22, -9.53137858716170170000e+002) (23, 3.15659612572888260000e+001) (0, 5.39444549560321550000e+002) (1, -5.21223588393949410000e+001) (2, 8.41658876557887230000e+000) (3, 1.28677992037941160000e+001) (4, 8.71735003477686940000e+001) (5, -5.73399961210843220000e+000) (6, 8.66642128938839420000e+001) (7, -2.02150866083046910000e+001) (8, 2.26338298518799150000e+002) (9, -6.62982846872322720000e+000) (10, 3.34855368916800670000e+002) (11, -2.84538204820710880000e+000) (12, 1.59742674893258650000e+002) (13, -7.44833209063862880000e+000) (14, 1.21882437113104940000e+002) (15, -1.59116727464518400000e+001) (16, -6.77024288382764090000e+000) (17, -3.35308435916733870000e-001) (18, 1.53030612358092140000e+001) (19, 9.17554305257860750000e+000) (20, -3.98804683328017120000e+001) (21, 1.27726477779273370000e+000) (22, 1.11676993951190690000e+001) (23, 3.24678398270143380000e+000) (0, 3.24450283615296370000e+001) (1, -2.66735290446444620000e+000) (2, 3.54127967554232440000e+001) (3, 1.88781755686762810000e-001) (4, 6.51346380590458120000e+001) (5, -1.11138202491138620000e+000) (6, -3.09620197289474250000e+001) (7, -1.37679663433534770000e+000) (8, 4.64302735855290290000e+001) (9, 1.40480136722932470000e+000) (10, 2.61411662956184010000e+001) (11, -4.64232741929438470000e-001) (12, -3.49089661504763950000e+001) (13, 2.16407731840128030000e+000) (14, 2.69825511731258380000e+001) (15, 1.57376318130088680000e+000) (16, -3.92313576751154970000e+001) (17, 9.51111587798196600000e-001) (18, -1.36004491991487840000e+001) (19, 8.72472251713213520000e-001) (20, -4.80719102973655410000e+001) (21, 1.90985806072154540000e+000) (22, -1.42787016996727910000e+002) (23, -6.71179467254025040000e+000) (24, -2.23262225565237400000e+000) (25, 1.27595350211108930000e-002) (26, -3.79421398797856730000e-003) (27, -2.20676982836887390000e+000) (28, -2.19304758587978380000e+000) (29, 1.29996857370699840000e-002) (30, 2.19530392175197430000e+000) (24, 2.36331126164431820000e+000) (25, -2.40313478341885210000e+000) (26, -2.44467245098623520000e+000) (27, 2.30789930123526600000e+000) (28, 1.09079774877230850000e-002) (29, 2.45521819512322590000e+000) (30, 2.40938889779245760000e+000) (24, -2.30211819692651140000e-002) (25, 2.69669012175326950000e+000) (26, 2.72519320954555470000e+000) (27, -3.79779428864916520000e-002) (28, 2.48218301773651320000e+000) (29, -2.75222458077146070000e+000) (30, -2.49369475070145900000e-001) 

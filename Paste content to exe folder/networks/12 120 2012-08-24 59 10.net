FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.55179731121293870000e-002) (1, 3.46079772651192300000e-002) (2, 3.29325310880383470000e-001) (3, 7.80141929670377540000e-001) (4, 1.38693468081811530000e+000) (5, 4.45395116647586080000e-001) (6, 6.17741947241918000000e-001) (7, 6.52810018740587750000e-002) (8, 1.33756334219180010000e+000) (9, 1.52927140233504450000e-001) (10, -4.54294819543150430000e-001) (11, 5.55308291393940140000e-002) (12, -1.03174223822262850000e-001) (13, 1.28437108092147810000e-001) (14, -3.20553348118432790000e+000) (15, 3.59604099744200320000e-001) (16, 3.51505486992143850000e-001) (17, 3.28885105145826640000e-001) (18, -6.09049460521049250000e-001) (19, -8.24147295567799610000e-002) (20, 8.11775145262635390000e-001) (21, 4.18406433885193520000e-002) (22, -3.06550662362901520000e+000) (23, 4.88003759860629330000e-001) (0, 9.57526014100382180000e-003) (1, 2.19513055292027300000e-001) (2, 5.10136965169728950000e-001) (3, 2.35406610216359720000e-001) (4, 9.05799804866836980000e-001) (5, 1.70062370961404700000e-001) (6, 1.84353537527052970000e-001) (7, 3.45826077336288950000e-001) (8, 2.73164437821996510000e-001) (9, 1.88318050688238090000e-001) (10, 2.36880393778514110000e-001) (11, 2.17926141205880440000e-001) (12, -8.02819530867090460000e-002) (13, 1.02061110460952830000e-001) (14, 1.68726626612581950000e-001) (15, 2.94709133215212190000e-001) (16, 1.17906560583390980000e-001) (17, 1.90003321108098980000e-001) (18, 2.07192164903048430000e-001) (19, 1.07708854407264900000e-001) (20, 2.49340102491852290000e-001) (21, 8.68775552687293400000e-002) (22, 1.11542678731467840000e-001) (23, 2.38238641508560280000e-001) (0, -3.09529061064673430000e-001) (1, 1.73557370675002380000e-001) (2, 2.29720227059725450000e-001) (3, -2.23028779478328640000e-001) (4, 5.02375634322226320000e-001) (5, 7.37709922349444880000e-002) (6, -3.13595950553821990000e+000) (7, 1.63814706201432280000e+000) (8, 2.22957487505104220000e-002) (9, 5.09653993838638100000e-002) (10, 1.40185777674361180000e+000) (11, 3.65597752177262700000e-001) (12, 1.95228504357691570000e-001) (13, -5.24782398275525850000e-002) (14, -4.72617573722430740000e-001) (15, 5.53006987076816610000e-001) (16, 6.31423194092434190000e-001) (17, 1.74111281138670800000e-002) (18, 3.99589748105081240000e-001) (19, 4.20584325262251480000e-001) (20, -1.25026231311610260000e+000) (21, -6.59914236226647190000e-002) (22, 1.54522668442425610000e+000) (23, 4.42257909569588050000e-001) (0, 3.83760142595000850000e-001) (1, -1.73578434369665330000e-001) (2, -4.68046040451184590000e-001) (3, -1.13306495179152390000e-001) (4, -3.04950320542179560000e+000) (5, -1.61408302536550170000e-001) (6, -3.07709719997360320000e+000) (7, -2.70075353284237210000e-001) (8, -3.19734256309352370000e+000) (9, 7.22505888206554040000e-001) (10, 2.09895734266451530000e-001) (11, 3.89735820672934770000e-001) (12, 1.31977769739552330000e+000) (13, 1.45989036909601190000e-001) (14, 6.66386967498035280000e-001) (15, -3.33847401271142100000e-001) (16, 5.14281252340858640000e-001) (17, 8.56227556641561830000e-002) (18, 8.22651171302322130000e-002) (19, 5.67084977968354660000e-001) (20, 9.32045978799724620000e-001) (21, 4.72918802547714960000e-001) (22, 1.48698693746266630000e+000) (23, -3.51083729652983400000e-001) (0, 3.70675987281622490000e-001) (1, 3.28183268287519790000e-002) (2, 4.48951487549125340000e-001) (3, 8.08636388239812880000e-002) (4, 3.04797122297709230000e+000) (5, 8.34820470661236100000e-002) (6, 2.99647592513501260000e-001) (7, -1.43328957976825990000e-002) (8, 4.02046275679985470000e-001) (9, -4.57730850389127810000e-002) (10, 1.71968487607541550000e-001) (11, -1.52771549293993590000e-001) (12, 1.30561559867882040000e-001) (13, -8.13792133441446770000e-002) (14, -5.77264922547536360000e-001) (15, -8.53728481044298620000e-003) (16, 1.53407019192680900000e-001) (17, 3.65971083067227680000e-002) (18, 1.50334927094443990000e-001) (19, 9.56985565865420690000e-002) (20, 7.18931185826901630000e-001) (21, -2.65932951503001640000e-002) (22, -1.51357525969724340000e+000) (23, 1.04812701604555660000e-002) (24, 8.67527288151436200000e-002) (25, -1.57096061592166240000e-001) (26, 4.28671483585884530000e-001) (27, 4.24682828847038060000e-001) (28, -4.42331024561259000000e-001) (29, 5.08743506263425570000e-001) (24, 4.36874608708120620000e-001) (25, -9.27405918831950280000e-002) (26, 5.16250830594043420000e-001) (27, -4.93911835876747970000e-001) (28, 1.33247132038980250000e-001) (29, 4.57943944959578190000e-001) (24, 5.71494536180427560000e-001) (25, -1.23722037657354540000e-001) (26, -2.51135200426971020000e-001) (27, 4.63267224449312590000e-002) (28, 1.43453186488055220000e-001) (29, 5.72342924864944540000e-001) 

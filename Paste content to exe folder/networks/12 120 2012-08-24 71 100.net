FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.79132085115743720000e-001) (1, 1.41899120125720410000e+000) (2, 6.34605985860404510000e-001) (3, -8.63478545658789010000e-001) (4, 3.14564536654981720000e+000) (5, 2.65927564864832540000e-001) (6, -1.40779426961412990000e+000) (7, 3.14250983309920920000e+000) (8, -1.00458778492423080000e+001) (9, 5.79279059034061290000e-002) (10, 2.14845878858423380000e+001) (11, 1.62376876662578520000e+000) (12, 1.60141167296397170000e+001) (13, 5.12243919234901530000e-001) (14, 7.65905033322831130000e+000) (15, 6.41877912835056240000e-001) (16, -1.31869253185893530000e+001) (17, -2.40928761905946980000e-001) (18, -1.31023028603867200000e+001) (19, 6.83978640590964690000e-001) (20, 1.56065597544939890000e+000) (21, 4.31188565387531640000e-001) (22, -1.03569338946425230000e+001) (23, -3.58958586571944150000e+000) (0, 1.81329133310895020000e+000) (1, 1.07026597909819250000e+000) (2, 1.33832728307884190000e+001) (3, 9.55882676971703370000e-001) (4, 4.31567088833618510000e-002) (5, 2.97374572544148900000e-001) (6, 1.02455859614705310000e+000) (7, -1.62289088051321340000e+000) (8, 1.02774939487029330000e+001) (9, 6.52834543272493910000e-001) (10, 5.66245656307436640000e+000) (11, -2.93719943832838060000e-001) (12, -1.43488461004120850000e+000) (13, -1.86847610511707170000e+000) (14, -4.85497420554703570000e+000) (15, -3.49587348214974500000e-001) (16, 5.89150783470292080000e+000) (17, -8.49541567629943100000e-002) (18, -2.28139222827567160000e+000) (19, -1.28557368110449270000e+000) (20, -2.18374685540046510000e+001) (21, 1.11116185999702080000e+000) (22, 2.37488593317437060000e+000) (23, -3.45311401593335230000e-001) (0, 7.04655045865384080000e-001) (1, 3.31122818367745210000e-001) (2, 2.29462353325325540000e+000) (3, 1.05583914067524320000e-001) (4, 6.74906394416170840000e-001) (5, 1.30148522479296150000e-001) (6, 1.22079586513851020000e+000) (7, 2.53864664514250440000e-001) (8, 1.20839279198817760000e+000) (9, -6.44374274618582930000e-002) (10, -2.02253583839879750000e+000) (11, 1.45984540697237620000e-001) (12, -5.04667730467046050000e-001) (13, -1.73215921453457820000e-001) (14, 3.08086399683296500000e+000) (15, 1.41382299341636620000e-001) (16, -3.24697737528038170000e+000) (17, -9.82192632287891280000e-002) (18, -3.29271991136155860000e+000) (19, -5.04025789940964810000e-001) (20, -1.91489092399151200000e+000) (21, 9.38922270702519380000e-002) (22, -6.13190895266637500000e-001) (23, -2.60720433446740560000e-001) (0, -7.04173239411582760000e+000) (1, 3.58687139359450900000e-001) (2, 1.41223961579098360000e+001) (3, -1.09831049281839070000e+000) (4, 1.88498177299250250000e+001) (5, -1.44284126859301390000e-001) (6, 1.51713548273598430000e-001) (7, 9.19369037884034230000e-001) (8, 3.37663233395930150000e+001) (9, -5.66080027763978590000e+000) (10, 1.26947174251298580000e+000) (11, 5.62694437027359550000e-002) (12, -2.18216783924969880000e-001) (13, 1.86261551247363040000e-001) (14, 2.31032429157428080000e+000) (15, 2.39027825987566360000e+000) (16, -2.19268654344561220000e+001) (17, -1.26230401850933840000e-001) (18, 5.41480401792107460000e+000) (19, -2.84558091870029890000e+000) (20, 1.68206167141132750000e+001) (21, -1.45419680541929770000e+000) (22, 5.58224195305258330000e+000) (23, -2.93025403297684020000e-002) (0, 3.78987851795779070000e+000) (1, -1.95979853345544660000e-001) (2, -8.62075211571567080000e-001) (3, 1.70535097689364880000e+000) (4, 3.54387821410956080000e+001) (5, 8.45814825651504450000e-001) (6, -3.08908793293998500000e+000) (7, 2.18181698767180430000e+000) (8, -1.51646050174053930000e+001) (9, -7.61862335101402670000e-001) (10, 9.38046007161017490000e-001) (11, 1.22682283003438640000e+000) (12, -2.69515748679869030000e+000) (13, 2.41021705627574580000e-001) (14, -2.84081289044658410000e+000) (15, 8.93876111049711990000e-001) (16, -2.32360362175490350000e+001) (17, 6.49099102361016980000e-001) (18, 4.59507696946237940000e-001) (19, -3.71945677941277310000e-001) (20, 1.09370865638154340000e+001) (21, 2.48218507120788260000e+000) (22, -6.96914080626044360000e+000) (23, 8.33268991296180480000e-001) (0, 2.06406280107618520000e+000) (1, -7.35103293998259800000e-001) (2, 7.67468449458936660000e-001) (3, 3.22376205576753060000e-001) (4, 4.79682311799359780000e+000) (5, 5.03887960625891470000e-001) (6, -1.01300829382343170000e+001) (7, -1.01528841917549100000e+000) (8, -7.36858143100841280000e+000) (9, -1.56399619669437970000e-001) (10, -1.60476444513252030000e+000) (11, -1.66503014317172150000e-001) (12, 1.02624137199955800000e+000) (13, -2.45160999491388400000e-002) (14, -2.97606800018239300000e-001) (15, 5.40487009618050960000e-001) (16, -2.23049581456410360000e+000) (17, 5.62702704058973270000e-001) (18, 1.95434086853364160000e+000) (19, -1.48412427721588290000e+000) (20, -9.33914326703080100000e+000) (21, 9.80120484159429210000e-001) (22, 8.68372166931806430000e+000) (23, -6.08470537947492620000e-001) (24, 1.60106077662971670000e+000) (25, -2.42712053241207840000e-001) (26, -1.35735528741006030000e+000) (27, -3.48433126565762030000e-001) (28, -7.62315173693142830000e-001) (29, 1.51486938398642110000e+000) (30, 1.52986529390002260000e+000) (24, -3.39891910877090780000e-002) (25, 1.85404891309303400000e+000) (26, -2.21183387312724160000e+000) (27, 1.40303926489757270000e+000) (28, 9.77464676445627290000e-001) (29, -1.33246445919728300000e+000) (30, 7.84519104515052690000e-001) (24, -1.24552869104310470000e+000) (25, -1.08281679249309890000e+000) (26, 2.77387081956024590000e+000) (27, -7.89645959789927690000e-001) (28, -1.55690011954953300000e-001) (29, -2.14892069728715110000e-001) (30, 2.66554430138271460000e-001) 

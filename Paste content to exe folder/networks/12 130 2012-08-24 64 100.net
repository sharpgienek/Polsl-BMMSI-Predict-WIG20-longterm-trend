FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.92081486232293220000e+000) (1, -1.65445852221092780000e+000) (2, -4.58133038703758600000e-001) (3, -1.03898239111984750000e+000) (4, 4.65752336403365060000e+001) (5, 4.59664690851172340000e-001) (6, 8.20750641388320190000e+000) (7, 1.73526601926656950000e-001) (8, -3.04767548349172750000e+000) (9, 1.99913064526100940000e+000) (10, -2.47807981597018030000e+001) (11, 1.43615165347821790000e-001) (12, 1.67911062960033280000e+001) (13, 7.91394201448158420000e-001) (14, 3.12022614821560440000e+000) (15, -3.12405554299922850000e+000) (16, 2.29904558291177400000e+000) (17, -5.92522859870874830000e-001) (18, 2.69215017137821490000e+001) (19, -1.79239264537271010000e-001) (20, -2.11784391672282480000e+001) (21, -2.70141557308972190000e-003) (22, 1.14554869887599720000e+001) (23, -2.45546683304705940000e-001) (0, -5.35493315557640330000e+000) (1, 2.90723367396052530000e+000) (2, 1.02713957990264310000e+001) (3, 9.55878008829866130000e+000) (4, 2.41626690233011840000e+001) (5, 8.32283124179401650000e-001) (6, -1.59353480255357920000e+001) (7, 3.44080026683530490000e-001) (8, -2.48389974923934570000e+001) (9, -1.14054412413897530000e+000) (10, 1.20003671835221550000e+001) (11, 1.20728644601321440000e+000) (12, -5.97946198078157390000e+000) (13, 6.50381149360123480000e-001) (14, 9.62476341004887640000e+000) (15, -1.74198381558478970000e-001) (16, 7.91475837935143470000e+000) (17, 8.25437948529851530000e-001) (18, -8.12408702779829990000e+000) (19, 1.33969326678163840000e+000) (20, 1.48779478321932190000e+000) (21, 4.23624182381139120000e+000) (22, 4.42029210630728820000e+000) (23, 4.64382039255679670000e-001) (0, 1.92539213828909680000e+000) (1, 2.46052586379782670000e+000) (2, 9.54113572700432290000e-001) (3, -5.92470495618185880000e-001) (4, 5.23636877851059950000e-001) (5, -7.17801445334399160000e-001) (6, -9.60114762887986830000e+000) (7, -7.18354560096397420000e-001) (8, 1.18650368354607770000e-001) (9, -3.85583333713433650000e+000) (10, 1.72937290981198400000e+001) (11, 9.01520209905851130000e-001) (12, 9.41041745003431270000e+000) (13, -1.26811831456473940000e+000) (14, 1.28242474053503270000e+001) (15, 2.99117103735287640000e+000) (16, 1.19800276344681580000e+001) (17, 1.94393662899512040000e-001) (18, 2.82610377471451810000e+000) (19, 1.59916701411605920000e+000) (20, -1.45504166480395870000e+001) (21, 8.72651963684962890000e-003) (22, 7.48215261743222810000e+000) (23, 1.99516172844829610000e-001) (0, -9.28549577165009630000e-001) (1, 1.20037638414021240000e+000) (2, 1.64600793185390980000e+000) (3, -3.04407600700830670000e-001) (4, -3.21708898758501790000e+001) (5, 9.67603286848274350000e-001) (6, -2.66695157118493320000e+001) (7, 9.85787818074296610000e-001) (8, -2.50789258160119250000e+000) (9, -7.16699507650886640000e-001) (10, 3.40115694658537540000e+001) (11, 7.47823929836137070000e-002) (12, 4.49153275230995950000e+000) (13, 1.98764617351310480000e-002) (14, -3.32743975745809670000e+000) (15, 2.96614830296378610000e+000) (16, -2.50140363503507100000e+000) (17, 1.46498828295469010000e+000) (18, 3.26698414265153710000e+000) (19, -1.49221727415258190000e-001) (20, 3.88139409937487020000e+001) (21, -5.98551140691966080000e-002) (22, 9.75423046929375030000e+000) (23, -7.35446864504961330000e-001) (0, -3.49180455712259750000e+000) (1, 5.40467130935488040000e-001) (2, 2.58186952532795890000e-001) (3, -8.35136612195968130000e-001) (4, -1.91492017159401540000e+000) (5, -4.38857523831162780000e-001) (6, -5.00648024291199430000e+000) (7, -4.95169890920406920000e-002) (8, 2.38117187427281780000e+001) (9, -2.46379695692322990000e+000) (10, 2.11718312935884080000e+001) (11, 9.16663755935654000000e-002) (12, -2.33941452850734110000e+000) (13, -4.98703694888493480000e-001) (14, 4.95592012584035310000e+000) (15, 2.30354482188750430000e+000) (16, -4.64167820723239190000e+000) (17, 5.27207263598956500000e-002) (18, 2.28528454332859900000e-001) (19, -9.42625668454639460000e-001) (20, 1.20775934894319030000e+001) (21, -9.59164805406483300000e-001) (22, 2.63474154863303720000e+000) (23, 2.76749265893357190000e-001) (24, 5.53981592514896540000e-001) (25, -5.26235176047534780000e-001) (26, 1.46337205246364750000e+000) (27, 1.68375306069425150000e+000) (28, -2.35203697271841960000e+000) (29, 5.19474061950218280000e-001) (24, 7.67206258645017350000e-001) (25, 1.19793962890901610000e+000) (26, -7.45671337940182140000e-001) (27, -2.22850443461584200000e-001) (28, 1.98533737779167450000e+000) (29, 7.39504854655084980000e-001) (24, -1.36056404567527810000e+000) (25, -7.71079014085133680000e-001) (26, -5.07151226807543880000e-001) (27, -1.33121510510752070000e+000) (28, 6.31984919828922940000e-003) (29, 1.11686427612621910000e+000) 

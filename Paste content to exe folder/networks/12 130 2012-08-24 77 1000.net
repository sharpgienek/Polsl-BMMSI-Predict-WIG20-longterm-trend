FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -8.59382966299185110000e+000) (1, 3.07469501026258160000e+000) (2, -8.23284979268913450000e+001) (3, 1.24765809600943570000e+000) (4, -2.21571486726851710000e+001) (5, 3.57589130743516480000e+000) (6, -8.61838282317466590000e+001) (7, 5.17241127575701040000e+000) (8, 1.13021453781856310000e+002) (9, -1.12107903551062060000e+000) (10, -4.38402133810933710000e+001) (11, -1.70884399087556590000e+000) (12, -4.24369145159627050000e+001) (13, 4.31993587428234620000e+000) (14, 1.94774866128628590000e+002) (15, -7.52641681201109640000e-001) (16, -1.37067880398577190000e+002) (17, 7.25584386262627110000e-001) (18, -2.97591754785909050000e+001) (19, -3.84328107366744560000e+000) (20, 1.05927624960970550000e+002) (21, 3.44817876302993820000e-001) (22, 3.70550247438759110000e+001) (23, 4.37674817237022120000e-001) (0, -6.96710928288431720000e+001) (1, 4.49914649138096670000e+000) (2, 1.78997315523226920000e+001) (3, -1.46224883692173420000e+001) (4, -1.99219508214040640000e+002) (5, -9.28626750179435860000e-001) (6, 8.55067835389016150000e+001) (7, -9.64088284866888580000e-001) (8, -2.50018431246158780000e+001) (9, -7.27886969602176140000e+000) (10, -1.95798395683037080000e+001) (11, 3.47771358884864900000e+000) (12, 1.36213640376879570000e+002) (13, -4.38615450614347500000e+000) (14, -1.32236272013113880000e+002) (15, 1.71962234842977750000e+001) (16, 1.35430852479462170000e+002) (17, 2.28834904622644240000e+000) (18, 1.48393046780365210000e+002) (19, 7.98320377812921420000e-001) (20, 1.42187339547011200000e+001) (21, 1.59948269958383980000e+000) (22, 5.72759053643020620000e+001) (23, 2.71734361343980350000e+000) (0, 2.17612072482264510000e+000) (1, 2.69340447277731830000e+000) (2, 9.51031949952959010000e+000) (3, -1.98601618615217770000e+000) (4, -5.77194382832308860000e+001) (5, 3.69526781995531570000e-001) (6, -4.16686819695275330000e+001) (7, 7.03078801129760840000e-001) (8, -2.04302040039831970000e+000) (9, -5.11885194879860840000e-001) (10, 4.21805862057545010000e+001) (11, 8.14737742996474610000e-001) (12, -4.62687369370872940000e+000) (13, 1.68989472566423240000e-001) (14, -1.00971952549090780000e+001) (15, 2.27363542320714230000e+000) (16, -3.12081807671279510000e+000) (17, 1.45458601762671340000e+000) (18, -5.70173847810493320000e+000) (19, 7.14894283167112120000e-001) (20, 2.80393392194687970000e+001) (21, 2.90852466914976290000e-001) (22, 7.19764741527324500000e+000) (23, -1.25193146234248660000e+000) (0, -1.59058988888434460000e+001) (1, 1.53378504057913160000e+000) (2, 5.11341809429914250000e-001) (3, -1.33362407821907200000e+000) (4, 9.70148617983203470000e+000) (5, 2.65935239918055790000e-002) (6, -6.69286050680283570000e+000) (7, 5.79440188178515840000e-001) (8, 3.58163923732152870000e+001) (9, -6.95126714170696760000e+000) (10, -6.05851819396942390000e+000) (11, -1.53263393350235950000e-001) (12, -4.73731049555046280000e+000) (13, -2.74864522122310270000e-001) (14, 1.37409938201536050000e+001) (15, 2.95686411408172530000e+000) (16, -4.22068378475325120000e+001) (17, -6.71439976030489830000e-002) (18, -4.99275510337746820000e+000) (19, -3.10151595105852400000e+000) (20, 2.55883496872301810000e+001) (21, -9.70806155856671070000e-001) (22, -2.00827341148587160000e-001) (23, -1.47008138286401290000e+000) (0, 8.10932517049298130000e+001) (1, 7.56725265466095550000e+000) (2, -2.40031672140052700000e+001) (3, 2.11224857857375660000e+000) (4, -5.04909429174632220000e+001) (5, 4.93998726909262230000e+000) (6, -4.81465279062531690000e+001) (7, 1.64060243096999480000e+001) (8, 4.57913422288512000000e+000) (9, 2.59870320600476080000e+000) (10, 5.18331336421533420000e+001) (11, 5.99901922548341650000e+000) (12, -1.16107956362540510000e+002) (13, -2.64017673647316430000e-001) (14, 1.21422067065071420000e+000) (15, 1.90579333658517760000e+000) (16, -3.09613658493790420000e+001) (17, 1.15028308083169000000e+000) (18, 1.77742026855976080000e+001) (19, 8.47869953976820770000e+000) (20, 5.56612937365464620000e+001) (21, 3.29349547745277070000e+000) (22, -4.94105528610230490000e+001) (23, 6.81020502164042420000e-001) (0, 3.55829067962107710000e+000) (1, -3.34000460183323690000e-001) (2, -3.61114158522225500000e+000) (3, 1.51170055607213390000e+000) (4, 2.43290450819058710000e+001) (5, 3.87350172512890390000e-001) (6, 5.08397569534922860000e+000) (7, -7.05133321655528920000e-003) (8, -5.22747306532585030000e+000) (9, 4.51993659880537800000e-001) (10, -5.89725228847123170000e+000) (11, -2.67977351045911800000e-003) (12, 3.33637338497692990000e+000) (13, 5.56622350511580270000e-001) (14, 1.11800324021017110000e+001) (15, -1.27300206741839260000e+000) (16, -1.08824778043932790000e+001) (17, -4.24811778112383800000e-001) (18, -8.62015081118935540000e-001) (19, 2.21087645846044650000e-001) (20, -3.43708878284980730000e+000) (21, 8.57191630877484480000e-002) (22, -1.75883611075679340000e+000) (23, -4.49475557031273010000e-001) (24, 2.67827267218973430000e-001) (25, 1.16846115752468570000e+000) (26, 2.79208109425576230000e+000) (27, -4.93874930941372250000e-001) (28, -2.27311573804331690000e+000) (29, 3.50062224296569240000e+000) (30, 2.09766273255279680000e+000) (24, -1.64745085460611710000e+000) (25, -1.68158151041135070000e+000) (26, -2.27753886675045560000e-001) (27, 1.89123247030463150000e+000) (28, 2.59429971714549950000e-002) (29, -6.54358966712653810000e-001) (30, 1.97811620563738620000e+000) (24, 9.45547870879909210000e-001) (25, 1.08693143139208800000e-001) (26, -1.98661979937574350000e+000) (27, -1.06368087619946250000e+000) (28, 1.23795442094407830000e+000) (29, -2.28885566585054660000e+000) (30, -3.87146767539957140000e-001) 

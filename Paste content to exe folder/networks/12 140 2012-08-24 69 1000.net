FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.17457982214202570000e+001) (1, 8.89238017132182710000e+000) (2, 2.45195296473713000000e+001) (3, -1.13025523724934580000e-002) (4, -8.00308897407394330000e+000) (5, 1.19156588461872830000e+000) (6, 1.25046080239103650000e+002) (7, 4.95131556457085690000e+000) (8, 1.80147577780337600000e+002) (9, 8.51670014631251470000e-001) (10, 2.00789969706137730000e+001) (11, -8.73629270790658440000e-001) (12, -1.92446050392189110000e+001) (13, 1.21598253433943680000e+000) (14, 9.54674062972605380000e+001) (15, -2.31795923796008150000e+000) (16, 4.79129186383952690000e+001) (17, 1.34037678820821180000e+000) (18, 1.73551430605560030000e+001) (19, 2.20916084076806470000e+000) (20, -2.71093704247739280000e+001) (21, 2.34723144145087080000e+000) (22, -4.50263124244919910000e+001) (23, 7.51618958481816080000e+000) (0, 6.86155448009192240000e+001) (1, 3.43016649311807950000e+000) (2, 1.28664672565583430000e+002) (3, 9.40532416581506150000e+000) (4, 6.23797030510879940000e+001) (5, 2.51708166638241120000e+000) (6, 2.11114437693627310000e+002) (7, 2.87864279891316870000e+000) (8, 2.30761288610292610000e+001) (9, 1.75379722708741350000e+001) (10, 2.01626417122054850000e+001) (11, -5.81438029672323500000e-001) (12, 7.92079451137821450000e+001) (13, -3.97929247497823990000e+000) (14, 9.00650275326580640000e+001) (15, -1.58366640888629920000e+001) (16, 2.07135321463986290000e+002) (17, 9.12665897141906270000e-001) (18, 1.33782227873661640000e+001) (19, 3.82117358797702030000e+000) (20, -2.80294703667616750000e+001) (21, 1.52505725953953550000e+000) (22, 7.63799113826546120000e+001) (23, 1.24060181637053920000e+001) (0, -1.33058667453238950000e+001) (1, 3.73645675351154960000e+000) (2, 3.24426159547703910000e+000) (3, -2.32784282857622670000e+000) (4, -1.74379806838144980000e+001) (5, -1.08540897989365460000e+000) (6, 5.73363278297791790000e+001) (7, 1.76593760416241310000e+000) (8, 6.94764189197941420000e+001) (9, 4.69572615038793550000e-001) (10, 1.29430729331159310000e+002) (11, 4.52883247236304910000e-001) (12, 1.07573118484996280000e+001) (13, -3.11073752203495260000e-001) (14, 4.69864117657397810000e+001) (15, 2.98605388304093110000e+000) (16, 7.98100226956641560000e+000) (17, 2.50849495038666070000e+000) (18, -1.25959472255957790000e+001) (19, 2.73004441401366190000e+000) (20, 4.82659070384295460000e+001) (21, 7.04333727941224170000e-001) (22, 6.32471746111220060000e+001) (23, -3.19761432681351210000e-001) (0, 6.36879426120798300000e+001) (1, -9.29579398276265120000e-001) (2, -9.95481315013758210000e+001) (3, 1.04442974243002460000e+000) (4, -3.33119036254402870000e+001) (5, 4.22487988808873020000e+000) (6, -2.96722966637579470000e+001) (7, 3.19444040806467290000e+000) (8, -1.42175863486656710000e+001) (9, 1.13230565138188590000e+000) (10, 4.97748615002526670000e+000) (11, 7.80458698515546520000e+000) (12, 1.06527593583388180000e+002) (13, 5.59841968826075930000e+000) (14, 1.24332323303271180000e+002) (15, -2.80945180112709580000e-001) (16, -5.81897217881400910000e+001) (17, -2.38765512527908940000e+000) (18, -4.72926198806829630000e+001) (19, -3.47728362781386470000e-001) (20, -3.28441290319875290000e-001) (21, 4.74744867290207310000e+000) (22, -7.99802546178272000000e+001) (23, 3.30061523801246630000e+000) (0, -1.49089627921601250000e+001) (1, -2.30749333505208480000e+000) (2, -2.83301826135211210000e+001) (3, -2.45699234166279150000e+000) (4, -1.59994576099412850000e+001) (5, -2.03698928286846440000e+000) (6, -8.29890751598128600000e+000) (7, -1.46457083322131520000e+000) (8, -3.22654066930014880000e+001) (9, -9.05837139552173150000e-001) (10, -1.10446200599398980000e+001) (11, -3.86949446589730380000e+000) (12, -9.47113814295542330000e+000) (13, -2.63416628123209810000e+000) (14, -3.21231992049705180000e+001) (15, 1.28882008271113820000e+000) (16, -1.03416927511541790000e+001) (17, 7.85480344396599290000e-003) (18, -2.11983380368876300000e+001) (19, -1.88034523335181380000e+000) (20, -1.66188947157673120000e+000) (21, -7.12729572253771250000e+000) (22, 5.28786407741252800000e+001) (23, -1.68054165838950540000e+000) (24, -2.09835369278780440000e+000) (25, 1.64940690514484120000e+000) (26, 1.67767015899884940000e+000) (27, 1.71462803987555580000e+000) (28, 4.20655033455243560000e-002) (29, 3.69707068417010120000e-001) (24, 3.39408234357402920000e-001) (25, -1.65413298903697340000e+000) (26, -3.29233768034080440000e-001) (27, -2.09694363733851800000e+000) (28, -2.18882755929999200000e+000) (29, 1.45418678978157740000e+000) (24, 1.15466382883203770000e+000) (25, 2.58312927993360860000e-002) (26, -9.73403756697069470000e-001) (27, 1.01236377560421160000e-001) (28, 1.24501538504772260000e+000) (29, 9.75788574615738980000e-001) 

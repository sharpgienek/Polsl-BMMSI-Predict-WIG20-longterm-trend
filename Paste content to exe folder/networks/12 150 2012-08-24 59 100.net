FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 5 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (5, 5, 5.00000000000000000000e-001) (5, 5, 5.00000000000000000000e-001) (5, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.84672956547182390000e-001) (1, -1.49881009391850230000e+000) (2, -3.58256346242649170000e+000) (3, 5.38162508746892530000e-001) (4, -7.16296874294635680000e-003) (5, -7.93606453926045670000e-001) (6, 9.07515650489416890000e+000) (7, -1.23962596012412600000e+000) (8, -1.91902509495302900000e+000) (9, 3.09146786914809730000e-001) (10, -2.27925028991284900000e+001) (11, -7.65900930519052390000e-001) (12, -1.34358919481715230000e+001) (13, -7.73217188393157230000e-001) (14, 1.67307762128694610000e+001) (15, -1.67790980711448620000e+000) (16, -4.61028925459913630000e+000) (17, -1.11088098183307180000e+000) (18, -1.86124231808006990000e+000) (19, -4.93017263440718110000e-001) (20, 1.08316305841548070000e+001) (21, 4.27152064966336630000e-002) (22, 2.97712692425014770000e+000) (23, 1.58107500732954230000e+000) (0, 5.80897949786795390000e+000) (1, -6.29184639325390480000e-001) (2, -4.25477549426166420000e+001) (3, 4.54849013867831590000e-003) (4, -8.48135757093765540000e+000) (5, 2.66093505894826300000e+000) (6, 1.22164836452377430000e-001) (7, 1.12495102247537830000e+000) (8, 1.01490668867956120000e+000) (9, 1.64119026009698810000e-002) (10, -2.35806731525055870000e+000) (11, 5.39985731482925280000e-001) (12, -1.08561401130631240000e+000) (13, 3.36021324277979440000e+000) (14, -4.80391911357429180000e+001) (15, -9.31500048764053870000e-002) (16, -1.50477135084313680000e+001) (17, 1.24108273683723470000e-001) (18, 1.14008460563061900000e+001) (19, 1.07777442691339060000e+000) (20, 5.41879908307661840000e+000) (21, 2.49849281142286190000e-001) (22, -4.25505393599747970000e+000) (23, 1.99289634015741600000e+000) (0, 1.42343175939274980000e+001) (1, 2.64940814940212820000e+000) (2, -1.22789422633616300000e+001) (3, 5.90081366501270410000e-001) (4, -1.74466240115696290000e+001) (5, 8.22455400935804380000e-001) (6, 1.88225286112523520000e+000) (7, -3.45070770349172880000e-002) (8, 9.88049357976576740000e+000) (9, 4.01094153541748790000e-002) (10, 1.29466087686855320000e+001) (11, -1.13139417371165630000e-001) (12, -2.00923841019143340000e+001) (13, 2.60398311620907790000e+000) (14, 2.12643120199769800000e+001) (15, 1.41561036618706030000e-001) (16, 8.10331480933537310000e+000) (17, 4.84065746517505170000e-001) (18, 4.95732283227927710000e+000) (19, 2.69345505552508870000e+000) (20, -4.23592145030647590000e+000) (21, -8.64090087700043360000e-001) (22, -1.11130220986175630000e+001) (23, -3.19280209130832100000e-001) (0, -4.79231617161838840000e+000) (1, -1.01641685041251000000e+000) (2, -8.18773257877465350000e-001) (3, -7.63395875765000560000e-001) (4, 3.16027819013786270000e+001) (5, 1.64950469816187510000e-002) (6, -1.55331563293007080000e+000) (7, 2.05405613446799920000e-001) (8, -2.42179735102207160000e+000) (9, -1.00011062363612750000e+000) (10, -1.35036592585180270000e+001) (11, 2.03541901941482750000e-001) (12, 5.61470469792064540000e+000) (13, -5.52756065175711520000e-001) (14, -1.72532061112256300000e+001) (15, 1.00301737241959570000e+000) (16, 4.84026157645382330000e+000) (17, 3.92668718782321850000e-001) (18, 4.24384199846483320000e+000) (19, -5.08333569132671470000e-001) (20, -7.81379218981436630000e+000) (21, 3.04442865574020390000e-001) (22, -1.46122496101390490000e+001) (23, 4.00729838516334230000e-002) (24, -1.62639123393567960000e+000) (25, 1.25662862411405230000e+000) (26, -2.10167507221352250000e+000) (27, -1.68301845248289440000e+000) (28, 5.75130436047560310000e-001) (24, 2.00901954655401560000e-001) (25, -1.45765512312529540000e+000) (26, 1.00900199885902840000e+000) (27, 8.61414606486249010000e-001) (28, 1.51689014758565200000e+000) (24, 9.19104897888186720000e-001) (25, 2.28855389945316930000e-001) (26, 5.54119070198674010000e-001) (27, 4.83964145752171780000e-001) (28, 4.42744291293830360000e-001) 

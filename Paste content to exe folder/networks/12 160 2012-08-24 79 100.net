FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.77829432685090530000e+000) (1, 1.54594746542500540000e+000) (2, 6.57522399790975780000e+000) (3, -5.76269349892641000000e-001) (4, -3.51663293748994190000e+001) (5, 6.03871128140021750000e-001) (6, -2.55968469050415840000e+001) (7, 1.11352078359828300000e+000) (8, -1.33949419071051250000e+000) (9, 2.09593200615129140000e+000) (10, 1.05118743457894010000e+001) (11, 1.03209602068484950000e+000) (12, 7.28795013358828570000e+000) (13, -4.00811983103992880000e-003) (14, 1.91399897972623600000e+000) (15, 2.37147420924413900000e+000) (16, 2.47062265739304900000e+001) (17, 1.17707719499966230000e+000) (18, 1.59994778010406970000e+001) (19, 1.99331629630797760000e-001) (20, -1.99085671648816920000e+001) (21, -9.91593616344069280000e-001) (22, -1.09812649159113520000e+001) (23, 8.32020458110772630000e-001) (0, -2.99381142004055540000e+001) (1, 1.85252249235740930000e-001) (2, 1.21144164828374510000e+000) (3, -6.46031805369206900000e-001) (4, 2.80519990603040550000e+001) (5, -9.40088166917879780000e-001) (6, -2.40528108112480540000e-001) (7, 1.13638856439463500000e+000) (8, 3.93907246275982330000e+000) (9, 1.90864086070350860000e+000) (10, 5.80976401770645200000e+001) (11, 1.37684664839183400000e+000) (12, 1.17392540454215910000e+001) (13, -4.09450410065045340000e-001) (14, 1.90643116511994460000e+001) (15, 1.64266604492467040000e+000) (16, 1.80589645144383400000e+001) (17, 5.72522505467501390000e-001) (18, 1.05129019374109800000e+001) (19, 1.94740826368766350000e+000) (20, -1.49702861475819680000e-001) (21, -5.76440966992302410000e-001) (22, 2.47997530952383900000e+001) (23, -5.50749414773137660000e-001) (0, 3.46435209658671450000e+000) (1, 1.22599996642951470000e+000) (2, 1.97706003709237680000e+000) (3, -6.12729731947074920000e-001) (4, 1.61752532665255980000e+001) (5, 1.92187119271220420000e-001) (6, -7.68295305317398380000e+000) (7, 1.68139132790540070000e+000) (8, -2.14276746188450030000e+001) (9, -5.38673384908286930000e+000) (10, 4.54283403072850760000e+001) (11, -1.09537723345287650000e-001) (12, 1.47657855740319380000e+000) (13, 1.34738086733407640000e+000) (14, -1.00968325247030010000e+000) (15, 2.02050891813978060000e+000) (16, -4.04831357276779440000e+000) (17, 9.89883062248805570000e-002) (18, 4.60599896896248500000e+000) (19, -2.47728582998822140000e+000) (20, 7.66562769488806150000e+000) (21, -9.80538631338032100000e-001) (22, -1.36538950469190590000e+001) (23, -1.05113248662446530000e+000) (0, -1.20100152343830240000e+001) (1, -5.51443409298533080000e-001) (2, 1.20752819998618190000e+001) (3, -9.91110268687128700000e-001) (4, -1.94947797825230820000e+001) (5, -1.68727387371937690000e+000) (6, 1.02797736131395020000e+001) (7, 2.42802240496557430000e+000) (8, -2.97336373485134970000e+001) (9, 5.10157867198540500000e-001) (10, -3.31015606798585220000e+001) (11, -4.50741221105926790000e-001) (12, -2.04960436872785290000e+001) (13, -5.17377802319728300000e-001) (14, -1.51006425634575740000e+000) (15, 2.07840037555143380000e+000) (16, 2.90694397606600390000e+001) (17, 1.13840631498139710000e-001) (18, 6.66309963682266740000e+000) (19, -1.34994507731179190000e-001) (20, -2.21077030897605620000e+001) (21, -2.75393808066720910000e+000) (22, 5.33108168232679880000e+000) (23, 1.96309124018365700000e-001) (0, -1.37771690625757510000e+001) (1, 2.65038600722367290000e-001) (2, -8.98550665656997340000e-002) (3, -6.79104752691764070000e-001) (4, -5.49522610389923740000e+000) (5, 2.12472292293712030000e-001) (6, -2.28820184868922420000e+001) (7, -8.66509895434247830000e-001) (8, 2.08371753105043850000e+001) (9, 3.21120574130043980000e+000) (10, -3.21925700879746210000e+000) (11, 3.80122655875768710000e-001) (12, -2.14369304559593200000e+001) (13, -8.66240216328751370000e-001) (14, -6.38180210250674280000e-001) (15, 2.56219275414750420000e-001) (16, 1.88186849467502140000e+001) (17, 8.41028953412442440000e-001) (18, -5.44549480096237910000e+000) (19, 1.12492583715202940000e+000) (20, -2.37094835689427800000e+001) (21, 5.34249315539281270000e-002) (22, -9.07336736764045360000e-001) (23, 5.51772171471355600000e-001) (24, 1.78870395532216060000e+000) (25, 9.63812318407947120000e-001) (26, -4.71476946237135600000e-001) (27, -1.45873845816236720000e+000) (28, -1.27101075122848380000e+000) (29, 4.19715380321325150000e-002) (24, -1.46404799713017940000e+000) (25, 1.56479330128347920000e-001) (26, 1.34865302634879010000e+000) (27, 2.45707918271956590000e-001) (28, 1.48475838838939360000e+000) (29, 1.38830362905177560000e+000) (24, -7.48473322272106970000e-002) (25, -7.28878903607865450000e-001) (26, -7.69536748310496900000e-001) (27, 7.43796648808524030000e-001) (28, -2.61830710982929320000e-001) (29, 7.60575631980751290000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.37591917308115870000e+001) (1, 8.56587764670465710000e-001) (2, 2.28075958779763290000e+001) (3, 1.09594632151968210000e+000) (4, 6.60834664397456350000e+001) (5, 1.95746740173397530000e+000) (6, -1.28489870201024050000e+002) (7, -3.11544807893444810000e+000) (8, 7.45082894891988160000e+001) (9, 5.87272477611727160000e+000) (10, 1.45842343029859480000e+002) (11, -1.86959592736960530000e-001) (12, -3.19355367686142310000e+001) (13, -6.76530739949522620000e-001) (14, 4.35701759279534930000e+001) (15, 6.91655714765974320000e-001) (16, 1.63574487882409160000e+001) (17, 3.13252439991956950000e+000) (18, -4.16152976844671090000e+001) (19, -1.51409593180438470000e+000) (20, -3.00238531325660140000e+001) (21, 6.27675708293411040000e-002) (22, 2.37023112787263840000e+001) (23, 1.27187139140321030000e+000) (0, -2.09561617986549290000e+001) (1, -1.98122114349299670000e+000) (2, 3.84082204430618790000e+001) (3, 3.94975059814368510000e+000) (4, -1.04268167056014410000e+002) (5, 1.71123450395635840000e-001) (6, 9.99410750112571830000e+001) (7, 1.96711338770503570000e+000) (8, 3.44442627872453780000e+001) (9, 3.10347399867895790000e+000) (10, -6.36287573676576560000e+001) (11, 3.12935777995397140000e+000) (12, 1.05530859486202590000e+002) (13, 1.40836310280854190000e+000) (14, 2.01876501762019130000e+001) (15, 3.08890880866676430000e-001) (16, 3.67716357388779540000e+001) (17, 6.20140392405139000000e-002) (18, 2.95126136500296850000e+001) (19, 2.36281739031736350000e-001) (20, 1.74930988896173230000e-001) (21, 7.41657850195117790000e-002) (22, 4.90767406942562000000e+000) (23, -3.18807840482049710000e+000) (0, 6.24510119716118480000e+001) (1, -4.04780725614702060000e+000) (2, 8.23720413243327270000e+001) (3, 1.15254473017626040000e+001) (4, -1.11824335937242150000e+002) (5, 6.99313057133562070000e-001) (6, 8.70232798604853030000e+001) (7, -2.01609955369140170000e+000) (8, 5.68827724121033280000e+000) (9, 1.69536691814876580000e+001) (10, -1.62020075656361710000e+002) (11, 1.88201769677658250000e+000) (12, 1.20500034635497630000e+002) (13, -9.45058979036402570000e-001) (14, 1.41896753916873150000e+001) (15, 2.77917981879130750000e-001) (16, 1.81683430349432660000e+001) (17, 1.03348197456207110000e+001) (18, -2.74309639132265810000e+001) (19, -5.85435569849227820000e+000) (20, -1.05080310193889180000e+002) (21, -3.30018035415839340000e+000) (22, 2.20621278260004060000e+001) (23, 2.42823764920721440000e+000) (0, 8.15232410710689090000e+001) (1, 2.13636863801036610000e-001) (2, -6.52254798876388970000e+001) (3, 1.12586710827842180000e+001) (4, -9.49327356652071470000e+001) (5, 3.10142786011431370000e+000) (6, 4.91368975713471060000e+001) (7, 1.88535142532739780000e+001) (8, 2.92515731324281100000e+001) (9, 8.42070291620052420000e-001) (10, 4.43788501594320370000e+000) (11, 1.99008740385541770000e+000) (12, 4.83798677902306120000e+001) (13, -8.95114832055484590000e-001) (14, -3.87571191615583430000e+001) (15, 3.23513586703945590000e+000) (16, -1.47437148494112850000e+002) (17, 1.57173528243267670000e+000) (18, -5.79505057340340460000e+001) (19, -5.88597246763222670000e-001) (20, 6.32627491911938690000e+001) (21, 1.69985650440665780000e+000) (22, -3.93543974894969110000e+001) (23, 1.00300281088471570000e+001) (0, -3.80635918782828570000e+001) (1, -1.22891183116520390000e+000) (2, 4.97059585335411850000e+001) (3, 1.00301196016926150000e+000) (4, 1.43661304370851150000e+001) (5, -1.10089393890498480000e+000) (6, 6.92394327454605470000e+001) (7, 1.06255412464737080000e-001) (8, -4.61853337917059910000e+000) (9, 6.70040207349994030000e-001) (10, -5.08475814488827500000e+001) (11, 8.21070304879011230000e-001) (12, 1.53594923430352480000e+001) (13, 7.59024890297622660000e-001) (14, 4.65673031525088810000e+000) (15, -1.71330610702645660000e-001) (16, 3.98774737561680080000e+001) (17, -1.04464629770630420000e+000) (18, 4.43746321581821520000e+001) (19, 6.60007662998989610000e-001) (20, -3.11789477808511430000e+000) (21, -6.35960123320216900000e-001) (22, -1.51495758361044200000e+001) (23, -4.11765246109539000000e+000) (0, -2.11851957345986110000e+001) (1, 1.95920266761074750000e+000) (2, -2.93590651106707180000e+002) (3, -1.07327916187513570000e+001) (4, -1.36622513893123280000e+002) (5, 4.32047715616453760000e+000) (6, 3.62648292089147690000e+001) (7, 3.19679291044509740000e+000) (8, -3.48456141096706700000e+001) (9, 2.03780712088556870000e+001) (10, -6.21828533001515850000e+001) (11, 1.24424032051307110000e+001) (12, 1.70846054923001870000e+002) (13, 1.69114189507527120000e+001) (14, -3.24300825532576840000e+001) (15, -3.36243955422182110000e+000) (16, -1.85085717193843410000e+002) (17, 6.73351381972604380000e+000) (18, 2.11552109231153660000e+001) (19, 3.60816061846641110000e+001) (20, 4.30106590412267050000e+002) (21, 5.54133005003808140000e+001) (22, 3.50981127030498900000e+002) (23, 1.51856351213050330000e+001) (24, -9.72369614173748340000e-001) (25, 1.87223825682488120000e+000) (26, 6.61040704938687940000e-002) (27, -2.02776459823781160000e+000) (28, -2.74168887359402100000e+000) (29, 7.10979034466398650000e-001) (30, 1.21409922078502870000e+000) (24, 1.80780876942270010000e+000) (25, -3.41883858328148470000e-002) (26, -1.64117387200969220000e+000) (27, 1.71345441468800910000e+000) (28, 1.72439898636110290000e+000) (29, -1.65362337298710170000e+000) (30, 1.50431084589650110000e+000) (24, -5.91724378454609790000e-001) (25, -1.16722106190927800000e+000) (26, 1.15499654493672140000e+000) (27, 2.82848084866357160000e-002) (28, 5.94200999242927020000e-001) (29, 7.73737475851501770000e-001) (30, 2.95865149203468290000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.08672846192889110000e+000) (1, 4.17070758869096780000e-001) (2, 7.94787910379552320000e-001) (3, -9.18715355275403040000e-001) (4, 9.29297592939796860000e+000) (5, 5.67804778961958130000e-001) (6, 1.09875370209910290000e+001) (7, 1.92562254711572120000e-001) (8, -7.18891155915962180000e+000) (9, -1.05888304483056620000e+000) (10, -1.97423922071138980000e+001) (11, -7.17400842139386930000e-001) (12, 2.42923127518277050000e-001) (13, -1.13910164922821400000e+000) (14, -2.18658035370587670000e+001) (15, 6.49009529491413110000e-001) (16, -1.62311588802201610000e+001) (17, -2.44186524136947250000e-001) (18, -5.60769992008121410000e+000) (19, -1.27704611651003200000e+000) (20, 9.54435543145017580000e-002) (21, 3.31655497107453290000e-001) (22, 4.39714954704673120000e+000) (23, 2.10477972358718950000e+000) (0, 2.68712918428839090000e+000) (1, 1.67555117251081230000e+000) (2, -1.44412639715984640000e+000) (3, -1.01240329608023020000e-001) (4, -1.89916041710182490000e+001) (5, 9.17664150638918400000e-002) (6, -7.36158957687089450000e+000) (7, 1.48389294358320160000e-001) (8, 7.61068492511981720000e+000) (9, 6.26780183173979160000e-002) (10, 5.95739376911387740000e+001) (11, 3.71529922415610720000e-001) (12, 7.66048076403080810000e+000) (13, -2.57536124516739070000e-001) (14, 8.33010927713151080000e+000) (15, 9.74594805068320640000e-001) (16, 1.04533746550166280000e+001) (17, 1.82203221520696260000e+000) (18, 1.69310959059555910000e+001) (19, 3.50051754257359630000e-001) (20, 1.82914895360482920000e+001) (21, -1.20189358179468770000e-001) (22, 5.38612690285558400000e+000) (23, -8.86272949354509900000e-002) (0, 1.77157700051682240000e+001) (1, 1.78541320211656450000e+000) (2, 3.48222350549502610000e+000) (3, 4.50446412149599460000e-001) (4, -3.00550754024983440000e+000) (5, 1.10126571083679540000e+000) (6, 1.05987369276564980000e+001) (7, 1.06228725601084570000e-001) (8, 1.25198962667724240000e+001) (9, 2.03214453279986660000e+000) (10, -5.74474259419624380000e+000) (11, 2.35453126135520750000e-001) (12, -1.19335954894309180000e+001) (13, 1.99115134109004010000e+000) (14, 3.04536955262164840000e+000) (15, 1.78952733953334330000e+000) (16, -2.35169817166247790000e+000) (17, 1.00157209916863050000e+000) (18, 1.84160565208894190000e+000) (19, 1.44514144267523090000e+000) (20, -9.91063604895940810000e-001) (21, -2.96412765664951730000e-001) (22, -9.51102229453128340000e+000) (23, -7.78420401042398960000e-001) (0, 1.01295829208733700000e+000) (1, 5.78002168152328270000e-002) (2, 3.30043077284317830000e+000) (3, 1.18483372392507640000e+000) (4, -1.98881913550953760000e+001) (5, -4.39057635681620650000e-001) (6, 2.38735781732652800000e+001) (7, -2.35490679504835400000e+000) (8, 1.19330275718713420000e+000) (9, 2.76053587158982160000e+000) (10, -5.50986122782724760000e+001) (11, 6.86032530366556810000e-002) (12, -8.03294390239417130000e+000) (13, -3.70658501946704520000e-001) (14, -7.76840386809021940000e+000) (15, -3.08942983166938000000e+000) (16, 1.06191431599697770000e+001) (17, 1.93265663118683480000e-001) (18, 1.25009128524523590000e-001) (19, 3.04235017601462720000e+000) (20, -6.60295595732763730000e+000) (21, 5.65750657104530760000e-001) (22, 1.29140615884928300000e+001) (23, -7.85234483998347830000e-001) (0, 1.41319886288659710000e+001) (1, 7.11395635284079120000e-001) (2, 9.80484489482884310000e+000) (3, -3.22940709658419420000e-001) (4, 3.35404335721877090000e+000) (5, 3.43234824947208490000e+000) (6, -2.39717300173766970000e+001) (7, 1.01030699131914050000e+000) (8, 2.33561491663607380000e+000) (9, 1.17048983208609770000e+000) (10, -2.00139295422433320000e+001) (11, 1.72609399595364420000e-001) (12, 6.80471774690362800000e+000) (13, 7.31987685697591650000e-001) (14, -2.66024433744992410000e-002) (15, 2.12551029095253250000e+000) (16, -3.30641401368878500000e+000) (17, 4.87949175412554230000e-001) (18, -7.77429954777233600000e+000) (19, 3.88852554364144730000e-001) (20, -2.37765797047758090000e+001) (21, 9.14471523051889500000e-001) (22, 1.15380481543100510000e+001) (23, 3.17039797811747640000e-002) (0, 1.56738105614953810000e+001) (1, -3.76604706437283610000e-001) (2, -2.86277799661393720000e-001) (3, 6.52577635157714050000e-001) (4, -9.27242747162166130000e+000) (5, 4.44292892266881960000e-001) (6, 3.22612684276948510000e+001) (7, 2.68923583963737390000e-001) (8, 2.27384630537462100000e+000) (9, -1.76265768897305750000e-001) (10, -3.53929344927938350000e+001) (11, -2.17038926587991090000e-001) (12, -1.16757017252970520000e+000) (13, 7.41634048580426810000e-001) (14, 5.59667243638268250000e-001) (15, 4.29647467098044740000e-001) (16, -6.32783146601533450000e+000) (17, -8.78647843842306650000e-001) (18, -9.94668696409646460000e+000) (19, -2.61110604506820440000e-001) (20, -3.64025683342336540000e+000) (21, -3.51568216086864670000e-001) (22, -1.68833676239875640000e+001) (23, 3.37764381222305900000e-001) (24, -1.05851617282433440000e+000) (25, 1.59118050134988100000e+000) (26, -2.06613757406970500000e+000) (27, 5.51631332110807500000e-001) (28, 2.11724717676447320000e+000) (29, 1.23428468471845830000e+000) (30, 6.59243770339034030000e-001) (24, -1.16563309691628430000e-001) (25, -1.43570016730262510000e+000) (26, 1.75163862974242400000e+000) (27, -1.27158738035431210000e+000) (28, -7.45882774007540220000e-001) (29, -1.50485764427611260000e+000) (30, 7.60381057180530510000e-001) (24, 8.34015773734025020000e-001) (25, -1.70100610229273020000e-002) (26, 7.45696262875974740000e-002) (27, 6.70528281103604300000e-001) (28, -9.22430588908143330000e-001) (29, 3.11042793603741600000e-001) (30, 9.00590598945090300000e-001) 

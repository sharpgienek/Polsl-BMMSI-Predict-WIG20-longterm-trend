FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.62060501496553970000e+001) (1, 2.00711404588697340000e+000) (2, 3.18436673565838930000e+001) (3, 2.15154232537400340000e+000) (4, -8.79128149264520610000e+000) (5, 8.69729707679018920000e-001) (6, 6.68885582169916830000e+001) (7, 5.17286204374508670000e-001) (8, 1.62453631168525340000e+001) (9, -2.17187619762059940000e-001) (10, -7.00807038906372670000e+001) (11, -2.57026935968291740000e+000) (12, 2.09390088352316750000e+001) (13, 1.78268782989645640000e+000) (14, -2.22435648364572030000e+001) (15, 1.57742521603849010000e+000) (16, -2.18159759865898590000e+001) (17, 6.16981459607892760000e-003) (18, -4.11151024328689940000e+001) (19, 3.54678046250584700000e+000) (20, -1.70261910505890950000e+001) (21, -5.48237169304688690000e-001) (22, -8.81601466786051300000e+001) (23, -9.26716003710605140000e-001) (0, 7.77174525261914080000e+001) (1, 5.45698013440498820000e+000) (2, 2.19582562179881970000e+001) (3, -1.17078218218328180000e+000) (4, -4.14926142750994340000e+001) (5, 3.61484854162622020000e+000) (6, -7.68639543675416520000e+001) (7, 2.69767698746666750000e+000) (8, -9.59784079179008210000e+000) (9, 2.40336930177691950000e+000) (10, 2.10779606022862570000e+002) (11, 2.35323620105462620000e+000) (12, 4.20314040417313780000e+001) (13, 2.01728013960267960000e-001) (14, 3.24853948412656100000e+001) (15, 4.91996384925323320000e+000) (16, 2.86339058542509900000e+001) (17, 1.67195061317981670000e+000) (18, -3.35176800037397490000e+000) (19, 5.42669749910472790000e-001) (20, 6.12320259867899920000e+001) (21, 4.04903640704799210000e-002) (22, 4.51534041707218850000e+001) (23, -1.93880408409148370000e+000) (0, 1.00011882353265830000e+002) (1, -2.59508576123031980000e+000) (2, -6.96690395225760020000e+000) (3, -6.44442076729512700000e+000) (4, -1.94943940211013600000e+002) (5, 2.57563829427874700000e-001) (6, 3.19872464418470380000e+001) (7, 9.18274777780806590000e+000) (8, 3.87251870643409820000e+000) (9, 1.19063601156528030000e+000) (10, -3.54949328303573800000e+000) (11, 6.99110781628735540000e+000) (12, 8.46769841252549180000e+001) (13, -6.00417426199063890000e+000) (14, -1.60540186004841870000e+002) (15, 1.11984112725878670000e+001) (16, -1.51124663613089150000e+001) (17, -8.97684857814503020000e-001) (18, -1.57625931613397190000e+001) (19, 3.87657334833572290000e-001) (20, 8.53318873943322060000e-001) (21, -1.99363770799375730000e+000) (22, 2.00759354290938070000e+001) (23, 9.34044280317919730000e+000) (0, 1.52636292859534550000e+001) (1, -8.42171974922482300000e-001) (2, -2.99916234947405690000e+001) (3, 2.17002470264243820000e+000) (4, 5.51311314578825820000e+001) (5, 5.17128916022999040000e-001) (6, 2.97061124330695700000e+001) (7, -8.74109128559317550000e-001) (8, -1.08240553137839510000e+001) (9, 2.15306476937616380000e+000) (10, -1.01796707302141250000e+001) (11, 5.46107360351111740000e-001) (12, 6.10035183520972880000e+001) (13, 1.07860957210283570000e+000) (14, 2.86515130997099200000e+001) (15, -5.02934763334875880000e+000) (16, -1.43669218786888030000e+001) (17, -7.14982877306365340000e-001) (18, 5.14973549122441130000e+001) (19, 3.35569911305043210000e-001) (20, -1.42271453800330470000e+001) (21, 1.15209984969507780000e+000) (22, 1.37674015195981350000e+001) (23, 5.05286042783478880000e+000) (0, 9.50297735203291300000e-001) (1, 2.85366812566998230000e+000) (2, 1.17237905431208860000e+001) (3, 9.24531562043421130000e-001) (4, 1.36267880647816830000e+001) (5, 9.59541984884487050000e-001) (6, 7.06282718309988410000e+001) (7, -8.51588836309614570000e-001) (8, 1.83675816298765360000e+001) (9, 1.48013816313509540000e+000) (10, -4.08931296935061680000e+001) (11, -1.80711153383305830000e+000) (12, 1.25720087132876730000e+001) (13, 2.99313417392452100000e+000) (14, -6.50053191102478410000e+000) (15, -2.74548249870377530000e-002) (16, -1.98582270339205780000e+001) (17, 2.78393716405528010000e-001) (18, 4.12085802533143570000e+000) (19, 2.96769593208886650000e+000) (20, -4.39925145660784340000e+001) (21, -9.44696167661684680000e-002) (22, -9.11358910767883830000e+001) (23, 2.39718252254756600000e+000) (0, 1.02945420938806080000e+001) (1, -3.18738995490581660000e-001) (2, 2.87685352152250150000e+001) (3, -7.19438179276724270000e-001) (4, -6.81337715647157880000e+000) (5, 3.34280848405213880000e-001) (6, 1.04321249337139470000e+001) (7, 3.10914934085495530000e+000) (8, 1.69613207707922240000e-001) (9, 1.12801183837621320000e+000) (10, -2.83201811944895460000e+001) (11, 3.95687761362414040000e+000) (12, 4.71663370262008570000e+001) (13, -9.76259923938198830000e-001) (14, -3.46975539295378750000e+001) (15, 4.61993811362714270000e+000) (16, 6.76351541382867620000e+000) (17, -6.04886604276081430000e-002) (18, 6.83813566815000050000e+000) (19, 1.36624243359240150000e+000) (20, -1.36683762884411970000e+001) (21, -2.11028707386190150000e-001) (22, -8.53107628170800150000e+000) (23, 3.34275471980389890000e+000) (24, 2.47842087133903500000e+000) (25, 1.84461954462814550000e+000) (26, 4.07463587609478500000e-002) (27, 1.98451690068672850000e+000) (28, -2.45072927084062050000e+000) (29, -2.42507653674280190000e-002) (30, -1.02641557763243520000e-001) (24, -2.37200710028634500000e+000) (25, -1.43138853996151950000e-001) (26, -2.14233138604560040000e+000) (27, -1.39557757113055650000e+000) (28, 2.13207432025042510000e+000) (29, 2.06637393952956310000e+000) (30, 1.28045234401261140000e+000) (24, 5.41766534582594890000e-003) (25, -1.35349152271690270000e+000) (26, 1.63056395202172880000e+000) (27, -1.51522776426124990000e-001) (28, 1.01347477682021860000e-001) (29, -1.70726338241499450000e+000) (30, 1.51524897473129560000e+000) 

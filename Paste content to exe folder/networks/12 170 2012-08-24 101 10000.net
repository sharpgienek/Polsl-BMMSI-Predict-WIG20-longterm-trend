FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.42620113686181130000e+002) (1, 6.46200917741673490000e+001) (2, -4.19798606518011890000e+001) (3, 3.11705503160757720000e+001) (4, -1.46601080043826550000e+003) (5, -2.20698167438883750000e+000) (6, -4.52848380808928430000e+002) (7, -3.58963068216708900000e+001) (8, -1.70053985649340430000e+002) (9, -5.35732783989576400000e+001) (10, 1.50000000000000000000e+003) (11, -1.15550372439635380000e+001) (12, -4.72908553894688910000e+002) (13, 8.81930598583518940000e+000) (14, 4.35078655391287380000e+002) (15, 1.72464758944986530000e+002) (16, 1.50000000000000000000e+003) (17, 3.64703999933446070000e+001) (18, -3.89101785822038720000e+002) (19, -7.72043720876175410000e+000) (20, -4.88512464953590500000e+002) (21, -1.86173415876809540000e+001) (22, -1.43007248873857340000e+003) (23, 3.63029663616184020000e+001) (0, 5.79495268803148180000e+002) (1, 8.94941796166703260000e+000) (2, 4.08522033978904420000e+001) (3, 1.87936089268085600000e+001) (4, -6.05742302867390440000e+002) (5, 2.64541698900096490000e-001) (6, 7.04470932127511110000e+002) (7, 6.06570100593163450000e+000) (8, 4.08125385152244860000e+002) (9, 4.92207480812136500000e+001) (10, 3.14775464558675940000e+002) (11, -5.82811905947003250000e+000) (12, 3.24913704416335580000e+002) (13, 2.76761712998106860000e+000) (14, 1.91952406490438850000e+002) (15, -1.06256538891635050000e+001) (16, 2.89486662355492400000e+002) (17, -1.40637439342374850000e+000) (18, -3.00482133722755460000e+002) (19, 1.30840395705108140000e+001) (20, -3.09873059559888300000e+001) (21, 1.42380445739152920000e+000) (22, 7.40227889860709350000e+001) (23, -4.72068968130823750000e+000) (0, -2.73562543302519150000e+001) (1, 4.94864416024940560000e+000) (2, -2.36181000566531760000e+001) (3, 2.77783771043926950000e+000) (4, -1.04185573064659980000e+002) (5, 5.50943126241527810000e+000) (6, 7.75813806332867560000e+001) (7, 2.04212678967623490000e-001) (8, 2.99442943302374150000e+001) (9, 4.95761094267481270000e+000) (10, 3.93052034282108660000e+001) (11, -2.34296468868781820000e+000) (12, 2.12282276926728630000e+001) (13, 4.78305546597400610000e+000) (14, 5.11911176273644200000e+001) (15, 1.56334457193934620000e+000) (16, 5.53295057496556740000e+001) (17, 3.73267558621567510000e+000) (18, -3.14947776919772050000e+001) (19, 1.54424212873418650000e+000) (20, -2.22330795826519570000e+001) (21, 2.13823946718561600000e+000) (22, 1.47639322716359680000e+001) (23, -9.86292564700466330000e-001) (0, -2.11437392555964760000e+001) (1, -5.61420619240781880000e+000) (2, -2.06572311637302270000e+001) (3, -5.36088195006927130000e+000) (4, 6.82157489639261310000e+001) (5, -2.03155589732470790000e+000) (6, -7.55713008863331040000e+000) (7, 2.33298938903349960000e+000) (8, 4.63351271373699160000e+001) (9, 2.94635255954027060000e+000) (10, -1.04866906525258160000e+002) (11, 1.15960793032638890000e+000) (12, 1.03328257869739380000e+001) (13, -2.19597666100297630000e+000) (14, 3.43354619669359740000e+001) (15, -5.25176659914375770000e+000) (16, -1.10967453305608440000e+002) (17, -3.99422105302054890000e+000) (18, 2.96765087065222130000e+001) (19, 1.71425661548487350000e+000) (20, -6.11189202090826600000e+001) (21, 4.03882593359655080000e-002) (22, -5.57503514694744810000e+001) (23, -2.22696620649697370000e+000) (0, 2.17501097934680700000e+001) (1, -2.32115021483294280000e+000) (2, -3.10846380054109550000e+001) (3, 1.40470565846889590000e+000) (4, -4.67458270691618620000e+001) (5, -2.73573494541836770000e-001) (6, 6.09097223496593760000e+001) (7, -7.42059035526243860000e-001) (8, 5.42264668488489490000e+000) (9, 1.48587657142572850000e+000) (10, -1.02489898851049190000e+002) (11, -1.97098067085649010000e+000) (12, -2.88182100032402810000e+001) (13, 2.22846182604633400000e-001) (14, -3.55771621140913790000e+001) (15, -6.47006371123143160000e+000) (16, -2.88807670487801180000e+001) (17, -1.55607334022905340000e+000) (18, -8.23557302613114930000e+000) (19, -3.17957269946173820000e+000) (20, 4.86318789454133050000e+001) (21, 5.64777663878604060000e-001) (22, 4.95897229060670450000e+001) (23, 4.87045883321984400000e-001) (0, -1.50000000000000000000e+003) (1, 4.28189373283866030000e+001) (2, -4.23921372381420840000e+002) (3, 3.60488456650263490000e+001) (4, -1.44974909716490950000e+003) (5, 4.19091692515390780000e+002) (6, 9.18985369237422900000e+002) (7, 4.10636655060483090000e+001) (8, -2.02669535381430020000e+002) (9, 7.93434105695605750000e+001) (10, -1.50000000000000000000e+003) (11, 1.03826917065454670000e+001) (12, -2.29555123514264440000e+002) (13, 1.37952945128322990000e+002) (14, -1.49995485769097630000e+003) (15, 4.27039166804808020000e+001) (16, 9.33210076064048960000e+002) (17, 7.15815298796812130000e+001) (18, 1.09356382510057320000e+003) (19, 3.61491943723436380000e+000) (20, -9.62061773707159090000e+002) (21, 6.93963867299040520000e+001) (22, 7.92385980238473050000e+002) (23, 1.71832072918319520000e+001) (24, -1.60309839669781250000e+000) (25, 1.72882446150805700000e+000) (26, -1.99377623987016480000e+000) (27, -1.84804746652142220000e+000) (28, -1.73774214278218350000e+000) (29, 1.78109130306321830000e+000) (30, -1.39002538492938560000e-001) (24, -1.51215287154304960000e-001) (25, -1.73693446120807840000e+000) (26, 1.93652318299242700000e+000) (27, 1.71536981986977500000e-001) (28, 7.73384291456228750000e-002) (29, -1.69493674223981430000e+000) (30, 1.70079269627744360000e+000) (24, 1.45767020892358980000e+000) (25, -2.16415643163988640000e-002) (26, -2.24790359719278820000e-003) (27, 1.41004583333181350000e+000) (28, 1.39353500803072520000e+000) (29, -4.96426146990230910000e-003) (30, 1.33534564230984200000e+000) 

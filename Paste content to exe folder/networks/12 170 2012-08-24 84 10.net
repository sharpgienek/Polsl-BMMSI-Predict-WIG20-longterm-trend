FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.63598439176507070000e-002) (1, 1.65544500746376610000e-001) (2, 1.35237691634683020000e+000) (3, 4.47874306657828180000e-001) (4, 3.12132327485137310000e+000) (5, 2.98603233045267760000e-001) (6, 1.17774858583187970000e+000) (7, 1.08559350933305000000e-001) (8, 3.12949588239502940000e+000) (9, 4.87425297372304720000e-001) (10, -3.80506832516487430000e-001) (11, -4.79999404359275850000e-001) (12, -3.17303836351261290000e+000) (13, 4.91774595632001270000e-001) (14, -3.06092898684205310000e+000) (15, 1.23857725738397000000e+000) (16, -6.13291321374512480000e-001) (17, 3.93823781377312890000e-001) (18, 5.18118392702257680000e-001) (19, -5.20761852289189700000e-001) (20, -1.27018174462248950000e+000) (21, 1.93103677079432270000e-002) (22, -4.98738035450144610000e-001) (23, 5.70035993105710290000e-002) (0, 3.08166262972913340000e+000) (1, -9.12829456198510290000e-003) (2, 3.48198380389363740000e-001) (3, 3.70466162619687180000e-001) (4, -4.35355260201786830000e-001) (5, -5.42306571404883860000e-003) (6, 1.60758675882456380000e+000) (7, -1.06235229602741160000e-001) (8, -2.53496471618231520000e-001) (9, 1.84732615754138190000e-001) (10, -3.01879031433913790000e+000) (11, 4.62798159157591370000e-002) (12, -2.76707430574875460000e-001) (13, -7.12985858378222260000e-002) (14, 1.34766907452251670000e-001) (15, -3.60310018687523270000e-001) (16, -7.96059881344906910000e-001) (17, -4.01730992122621200000e-001) (18, 1.60659094449246730000e-001) (19, 1.70096385067291360000e-001) (20, 1.18105238933471850000e+000) (21, 1.71342550115886840000e-001) (22, -1.60142353986456750000e+000) (23, -1.26459214408803870000e-001) (0, -7.95154014183010020000e-001) (1, 2.31737197013331900000e-001) (2, -3.89570273029785030000e-001) (3, 4.04290076315480530000e-002) (4, -9.46209562289434650000e-001) (5, 2.20183705922898570000e-001) (6, -4.05887486325182790000e-001) (7, 3.50090498731769400000e-001) (8, -2.79620541387372580000e-002) (9, 4.14841885158983180000e-001) (10, 5.63647207089807560000e-002) (11, 1.66100453163870320000e-001) (12, 8.05764971710168590000e-001) (13, 2.50871718782833490000e-001) (14, 7.69468164972180620000e-001) (15, 3.84984298079852520000e-001) (16, 3.91921118663621920000e-003) (17, 5.49810847136304790000e-001) (18, 4.72982303494713980000e-001) (19, 5.74822874828336130000e-002) (20, -2.16437895131602890000e-001) (21, 2.88878311146050840000e-001) (22, -1.28369404784543230000e-002) (23, 6.07127180843168860000e-001) (0, 1.78626138755904440000e-001) (1, 4.09385664993907880000e-001) (2, -2.01389539320083080000e-001) (3, -4.15866734520760170000e-001) (4, 8.32641386603585330000e-002) (5, -4.49475366600644850000e-002) (6, -3.11481082358245500000e+000) (7, 1.31014708266919340000e+000) (8, -4.87478906183427710000e-001) (9, 2.74686860529346970000e-002) (10, 7.24440588987643850000e-001) (11, 8.44356132997726380000e-001) (12, 1.43175012023332380000e+000) (13, -6.12379005402005210000e-002) (14, 3.19190433059061270000e+000) (15, 8.27310382187470220000e-001) (16, 6.19136632340367640000e-001) (17, 3.48952760630904860000e-001) (18, 2.80111148021026930000e-001) (19, 5.33474332192402260000e-001) (20, -9.32516995773685740000e-001) (21, 3.13989548699040550000e-001) (22, 3.15646731834381010000e+000) (23, -1.94231673645316600000e-001) (0, -5.17580086783284930000e-001) (1, 1.83324110354420730000e-001) (2, -3.06849324531521860000e-001) (3, 4.07524939644933750000e-002) (4, 1.23286167847748710000e-002) (5, 5.14476643509154950000e-002) (6, 3.00707750046704390000e-002) (7, 2.42784588929661820000e-001) (8, 5.42577046903699010000e-001) (9, 3.88822597661890590000e-001) (10, -1.07569664846628720000e-001) (11, 2.33428335026508920000e-001) (12, 1.89481660820941480000e-001) (13, 2.27916424645608910000e-001) (14, 9.00612872862584850000e-001) (15, 3.20164961176469140000e-001) (16, -5.75737096515547000000e-002) (17, 1.24688099031153230000e-001) (18, 3.51320924728693250000e-001) (19, 2.16161489066087870000e-001) (20, -1.56360989939512250000e-001) (21, 3.48759903835231090000e-001) (22, -5.81555446693791390000e-002) (23, 5.76017561238974410000e-001) (24, -4.80751640259923510000e-001) (25, -3.73633750709146950000e-002) (26, 4.28834011112720790000e-001) (27, 2.82208083632418010000e-001) (28, 4.14747096840309410000e-001) (29, 4.43403103126692180000e-001) (24, 3.62503289204065330000e-001) (25, -3.20720804901796390000e-001) (26, 9.94029873311304820000e-002) (27, 1.26141186775590030000e-001) (28, 1.44770419647782890000e-001) (29, 4.53272488039382470000e-001) (24, -1.35379232932377250000e-001) (25, 1.82040965323404470000e-001) (26, 3.32730667364995070000e-001) (27, -5.94333729564580750000e-001) (28, 3.71866410135663070000e-001) (29, 3.34409134186881170000e-001) 

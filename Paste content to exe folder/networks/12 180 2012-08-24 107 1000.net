FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.21873019332186110000e+000) (1, -6.20369695505353590000e-001) (2, -3.11753571441630580000e+000) (3, -5.31107186908905790000e-001) (4, -1.58539546586964790000e+000) (5, 1.96069579815443040000e-001) (6, 3.57071586822682900000e+000) (7, 1.87431767018054860000e-001) (8, -1.83493889026986710000e+001) (9, -4.60558752058028210000e-001) (10, -3.55002987928229530000e+001) (11, 3.36648070615423120000e-001) (12, 1.65726528484595260000e+001) (13, 1.89607938008122840000e-001) (14, -2.02327057067012350000e+001) (15, -1.80366145555148240000e-001) (16, -7.72569943462119600000e-001) (17, 3.13338417216497970000e-001) (18, 3.32655953006086590000e+000) (19, -4.24184604921134190000e-001) (20, -4.56518895773388600000e+000) (21, -3.20763392952748750000e-001) (22, 4.74661211092070800000e+000) (23, -7.02891399199880200000e-001) (0, -4.51800419450000850000e+001) (1, 5.24950089857525800000e+000) (2, -1.26954285239813030000e+001) (3, 5.22680783636217510000e-001) (4, 1.66433715633969830000e+001) (5, 1.27349015337620890000e-001) (6, -4.29364361794760900000e+001) (7, -4.75221224980404030000e-001) (8, 4.29133380914406570000e+001) (9, 7.23918505011472750000e+000) (10, -3.38097673489566120000e+001) (11, 4.87089557588654350000e-001) (12, -4.72880186100636450000e+001) (13, 5.90183182878286060000e+000) (14, 7.84930831911466530000e+001) (15, 1.31723367756891310000e+000) (16, -1.89530934256654930000e+001) (17, 1.74745542928573250000e+000) (18, 2.65367436465011260000e+001) (19, 4.52086427889661380000e+000) (20, 1.46066087283590450000e+000) (21, -3.39295193726226410000e-001) (22, -3.39249146105515680000e+001) (23, 2.49754671445551100000e+000) (0, -4.92398753749721010000e+001) (1, 2.47716797340870400000e+000) (2, -2.77138110070436920000e+001) (3, -7.83261697331006370000e-001) (4, 1.46919189862280280000e+001) (5, 1.56903163361282250000e+000) (6, -3.07009927170843650000e+001) (7, 5.21260757692051250000e+000) (8, -4.52707390939652330000e+001) (9, 6.35823214330229810000e+000) (10, -1.51482546897893810000e+001) (11, 4.41970797105971420000e+000) (12, 1.42085400360546540000e+002) (13, 3.03267661525785080000e+000) (14, -6.64714022349093490000e-001) (15, 7.96068402645321440000e+000) (16, 3.68855441035860280000e+001) (17, 2.50174440503896770000e+000) (18, 2.90513148560047090000e+001) (19, -2.46032992768635910000e-001) (20, -2.74085656133861660000e+001) (21, 1.93343931392206540000e-002) (22, 1.73211215011116910000e+001) (23, -6.57683292455672360000e-001) (0, -3.21482182014911690000e+001) (1, 1.76545330509912190000e+000) (2, -2.23114981127333150000e+001) (3, 2.29883338343863300000e+000) (4, -4.57170339645879620000e+001) (5, -2.96842558545454070000e+000) (6, 4.16969602212482680000e+001) (7, 3.69168788441159790000e-002) (8, 4.18143830231034240000e+001) (9, 6.07164382677946700000e-001) (10, 3.41139354554695730000e+001) (11, -6.27847545793948080000e-001) (12, -1.39668266521018070000e+000) (13, 5.35076336945974480000e-002) (14, -3.48166000075731530000e+000) (15, 7.01716677292911320000e+000) (16, -1.52884731189566810000e+001) (17, -4.13043246977092220000e-001) (18, 6.83369712641770730000e+000) (19, 6.10606812604550300000e-001) (20, 2.24820947841185230000e+001) (21, 2.64419379402742120000e+000) (22, 1.21492106235672890000e+001) (23, 1.37499219412308120000e+000) (0, -1.56665855279460220000e+001) (1, 7.50682313236410990000e-001) (2, 4.48441501439037000000e+000) (3, 1.37548232123985350000e+000) (4, 3.72285065544635700000e+000) (5, 1.05129856745407940000e-002) (6, -7.07328214309145050000e+000) (7, -6.59827134006040430000e-001) (8, 1.87644865434283190000e+001) (9, 2.94731910615068590000e-001) (10, 5.04344826853572240000e+001) (11, -2.47118505028915250000e-001) (12, -1.93115245281946850000e+001) (13, -1.69807540254278490000e-001) (14, -3.42639324869877000000e+000) (15, -7.61314370058914780000e-002) (16, -1.78025026242789910000e+000) (17, -4.11282334197961510000e-001) (18, -1.06448024778763380000e+001) (19, 9.21706767178135040000e-001) (20, 2.30162783697457550000e-001) (21, 4.31648448822126660000e-001) (22, -3.08709045775823430000e+000) (23, -1.19931547489077610000e-001) (0, -6.28726355074022580000e+001) (1, -4.93510999143068120000e-001) (2, -3.81474794838058530000e+001) (3, 1.11444005737511610000e+000) (4, -2.47549911465440750000e+001) (5, -5.25504937039200650000e-001) (6, -2.17453156405043050000e+001) (7, -7.30452661850608290000e+000) (8, -2.43238560376870830000e+001) (9, 4.01890582021775700000e+000) (10, -5.27099768216793120000e+001) (11, 1.10280310546259150000e+000) (12, -5.93782667149769590000e+001) (13, 4.17782927022960670000e+000) (14, -1.20664183219822040000e+002) (15, -1.05021092180403590000e+000) (16, -2.74380467978994390000e+001) (17, 2.73528158289442700000e+000) (18, -1.37410510820379970000e+001) (19, 9.89614579528062950000e+000) (20, -2.80785380307919080000e+001) (21, 2.22777137819623090000e+000) (22, -1.15963104946588520000e+001) (23, -6.20155134912003980000e+000) (24, -3.93966027985489520000e+000) (25, -2.02402295802226420000e+000) (26, 1.31324361108820860000e+000) (27, -1.16530143857523940000e+000) (28, -2.31858248309978480000e+000) (29, 1.35849273150152270000e+000) (30, 1.04614805469051820000e+000) (24, 4.05305795006868140000e+000) (25, 2.01164426140190940000e+000) (26, 3.20062565486888380000e-001) (27, 2.53520798807599260000e-001) (28, 3.86901971750653620000e+000) (29, -2.05098407813388880000e+000) (30, 4.68463380521858750000e-002) (24, 3.23948351825314060000e-001) (25, 1.94216637693419100000e-001) (26, -1.56437918522229770000e+000) (27, 6.99050865097566640000e-001) (28, -7.12714601517497660000e-001) (29, 3.12431647086611200000e-001) (30, 1.42813420242723590000e+000) 

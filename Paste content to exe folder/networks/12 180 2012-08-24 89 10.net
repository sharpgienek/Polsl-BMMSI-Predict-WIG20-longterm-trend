FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.33617906005905110000e+000) (1, 1.92167803602811720000e-001) (2, 3.02215335149862610000e+000) (3, 5.45176405357354480000e-002) (4, 3.06154544192936400000e+000) (5, 1.19107119943020520000e-001) (6, 1.19220936645764150000e-001) (7, 5.49937147615795070000e-002) (8, 3.16300418367559200000e+000) (9, -1.02871078422192360000e+000) (10, 1.17206284190765730000e+000) (11, -1.48429069275517990000e-001) (12, -5.89811774859173470000e-001) (13, 3.46561510582546200000e-002) (14, -2.25681895523388400000e+000) (15, 3.64663366111095680000e-001) (16, 1.06267777970806830000e-001) (17, 7.03867813972040570000e-002) (18, 3.12656009133565770000e+000) (19, -9.85906828505970000000e-001) (20, -1.43147429201242020000e-001) (21, -1.67771110579361870000e-001) (22, -1.20104722210792980000e+000) (23, 5.08494275904498170000e-002) (0, 1.10449692293209670000e+000) (1, -3.17369420669882000000e-001) (2, -1.10836158344092380000e-001) (3, -4.30304915930144970000e-001) (4, -3.19107425245324360000e+000) (5, 8.48972885079563170000e-002) (6, -2.21941224786999030000e-002) (7, -2.34532505373015810000e-001) (8, -3.19196536574777220000e+000) (9, 2.91552727903779290000e-001) (10, 2.98432850915848590000e-001) (11, 1.97320000609516930000e-001) (12, 1.17014023445713320000e+000) (13, 1.23016776548516430000e-001) (14, 1.10686508702988510000e+000) (15, -6.54931532881847020000e-001) (16, 1.04647690253628100000e+000) (17, -3.80376743248945210000e-002) (18, -1.63209685359567920000e-001) (19, 1.98824403826361630000e-001) (20, 1.07823959832208200000e+000) (21, 3.97308560861004690000e-001) (22, 6.53172505554910020000e-001) (23, 9.74735632772679020000e-002) (0, 3.75470070626865720000e-001) (1, -2.07630866186897020000e-001) (2, 3.19974124476989190000e+000) (3, 8.72702228566986430000e-001) (4, -3.06922366470002840000e+000) (5, -9.89201303091687410000e-002) (6, 3.03222415242994270000e+000) (7, -9.33329792959409100000e-001) (8, -4.53724834430252470000e-002) (9, -4.63767475934304010000e-001) (10, -2.59972646218296350000e-001) (11, -2.43118697816168520000e-001) (12, -7.58114324138849160000e-001) (13, -4.60569233699146490000e-001) (14, 5.67965838464153720000e-001) (15, -1.79282527295263310000e+000) (16, -7.56490788958406600000e-001) (17, -6.02634665503586350000e-001) (18, 4.03306482739051290000e-001) (19, -1.54733686733504210000e-001) (20, 5.00110786063494350000e-001) (21, -5.97123624610116090000e-002) (22, -9.51153410019353720000e-001) (23, 1.21198962238940440000e-001) (0, 1.52811852987244980000e+000) (1, -5.73438213786026550000e-001) (2, 1.49941237356978510000e-001) (3, 3.76174931711255710000e-001) (4, -3.51449851422061870000e-001) (5, 4.50142552865504880000e-002) (6, 3.10806033520061490000e+000) (7, -1.22147568920921270000e+000) (8, 1.51086389094346060000e+000) (9, 5.93913393998602160000e-002) (10, -3.09353396779665510000e+000) (11, -7.41609363417216950000e-001) (12, -1.93926502656007140000e-001) (13, 1.43900955971195120000e-001) (14, -1.09591049225452730000e+000) (15, -2.30259818862202790000e-001) (16, -3.83208732039032110000e-001) (17, -1.50920218070575650000e-001) (18, -1.14376866543372870000e-001) (19, -6.48423359285402600000e-002) (20, 1.57620499357746050000e+000) (21, 2.85265401894825990000e-002) (22, -3.08375613561970410000e+000) (23, 1.37650906008526810000e-001) (0, -5.67839481139347010000e-001) (1, 1.82272574310625990000e-001) (2, 7.90339070613834020000e-001) (3, -4.21876531789077970000e-001) (4, 3.18633792425766680000e+000) (5, -6.18325558010980600000e-003) (6, 1.97823155004196320000e+000) (7, 5.76998185480973040000e-002) (8, 1.03309434030001720000e+000) (9, -3.38124032193896700000e-001) (10, 3.23763725115592760000e-001) (11, -2.20239712195096360000e-001) (12, -6.04509403560771430000e-001) (13, -2.21180671076304850000e-001) (14, -4.50272854367217310000e-001) (15, 2.73017812157467570000e-001) (16, -5.52619328140193660000e-002) (17, -1.48941450319068160000e-001) (18, 5.87484881723760120000e-001) (19, -2.47059577711930600000e-001) (20, -5.38921023677178420000e-001) (21, -2.01959682625827700000e-001) (22, 3.59826461993701940000e-002) (23, -2.55165046582711500000e-001) (24, -4.17728017755435670000e-001) (25, 2.53972436956179210000e-001) (26, -2.63972628635950560000e-001) (27, -5.67832495822246710000e-001) (28, -3.92089073688348500000e-001) (29, 5.18635393111877340000e-001) (24, 3.75721097313009460000e-001) (25, -1.66564019405371490000e-001) (26, -2.99519295290516300000e-001) (27, 2.17413322502141070000e-001) (28, -3.86783732518247850000e-002) (29, 6.11732939194574500000e-001) (24, 1.73538288566146700000e-002) (25, -1.65882236497263800000e-001) (26, 1.94663443639390370000e-001) (27, 4.67622142124214770000e-001) (28, -2.11871792148529640000e-001) (29, 6.64042144981369150000e-001) 

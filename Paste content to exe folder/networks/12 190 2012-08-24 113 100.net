FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.05375296429750890000e+001) (1, 7.68285333166946250000e-001) (2, -4.56862399586242600000e+000) (3, -3.82270346357963090000e-001) (4, 1.45392389162919960000e+001) (5, 1.56274358656517760000e-001) (6, -3.34538595483618760000e+001) (7, 1.70671375252327050000e+000) (8, -4.80826859133379080000e-001) (9, 1.60566019668494890000e+000) (10, -3.06457720639942680000e+000) (11, 1.65142430161704960000e-001) (12, 4.76771729770874850000e+000) (13, 4.73783722418001150000e-001) (14, 3.82873628471320780000e+000) (15, 2.74405991823518390000e+000) (16, 2.09536194192310270000e+000) (17, 3.05969125380051440000e-001) (18, 9.57068189078385960000e+000) (19, -1.31350235561840780000e-001) (20, -2.00105978208096820000e+001) (21, -3.90214389716186160000e-001) (22, -1.59842580066698100000e+001) (23, 6.11694786705793030000e-001) (0, 7.91793312584822310000e+000) (1, -3.38440627786727730000e-002) (2, 1.18048831431418010000e+001) (3, 8.93313431847933880000e-001) (4, 6.80820443115319220000e+000) (5, 7.40806314887487300000e-002) (6, 1.62507278986029710000e+001) (7, -1.16325330863503950000e-001) (8, -1.18971914113445520000e+001) (9, 3.19168786922853220000e-001) (10, 1.76085537606614400000e+001) (11, 1.05676397280676220000e+000) (12, 1.05267257586115420000e+001) (13, 8.84065684782561870000e-001) (14, 8.10619561372105930000e+000) (15, 5.88258590318896490000e-001) (16, 2.23676397706802210000e+001) (17, 8.61672142334321540000e-001) (18, 4.36061525175905370000e+000) (19, 4.54733420934174960000e-001) (20, 4.32670121202410400000e+000) (21, -4.63892897841573640000e-002) (22, 6.48868658509934270000e+000) (23, -7.84736157641595320000e-001) (0, 1.80264090628500040000e+001) (1, 4.95065129976649030000e-001) (2, -2.17391677067547610000e+000) (3, 4.59664950452638980000e+000) (4, 1.50340154849359050000e+000) (5, -1.88710748145741570000e-001) (6, 7.69779358614163640000e+000) (7, 2.29734936921307750000e-001) (8, 5.04650468885253670000e-001) (9, 1.74179348884039760000e+000) (10, -1.29419690663388000000e+001) (11, 4.38399409766625640000e-002) (12, 1.97708054355317770000e+001) (13, 1.10646131474515960000e+000) (14, 1.93460900873935490000e+001) (15, 3.44092399076424420000e-001) (16, -4.24638749633787160000e+000) (17, -8.20365594716389590000e-001) (18, 1.08282676725392030000e+001) (19, -6.27549928406647470000e-001) (20, -9.93936422950941890000e+000) (21, -7.25543009615079780000e-001) (22, -1.68674391233834410000e+001) (23, 5.65649752392074270000e-001) (0, -4.26148901832111240000e+001) (1, 3.35593691473672440000e+000) (2, 1.63191315868649940000e+001) (3, 1.21118214908658710000e+000) (4, -1.83924006883142290000e+001) (5, 5.69621707609280770000e-001) (6, -3.05137972215496870000e+001) (7, 4.40987911976430890000e-001) (8, -1.44958367634477840000e+001) (9, 1.21445438720618020000e+000) (10, 1.84406111127022570000e+001) (11, 4.34338112742959030000e-001) (12, 5.85833673553438050000e+000) (13, 5.40997982560620040000e-001) (14, -5.27821277373327930000e+001) (15, 5.65169770840926460000e-001) (16, 8.30163213228090240000e+000) (17, 2.48656281655837220000e+000) (18, 4.86081295506197290000e+001) (19, 1.46811838028148720000e+000) (20, 1.49703760850921910000e+001) (21, -9.08108880511587560000e-001) (22, -7.86249473197874150000e+000) (23, 6.18309618610173640000e-001) (0, 2.88720996642757130000e-001) (1, -5.72096970165566270000e-001) (2, 5.60378005869893060000e+000) (3, 2.04361533367528380000e+000) (4, 1.09414042625543520000e+001) (5, -6.31351760896693200000e-001) (6, -1.90802047616689220000e+000) (7, -2.56207215519882570000e-001) (8, -6.29438774420114470000e+000) (9, -4.16052165840832340000e-002) (10, -2.09812871643655820000e+001) (11, -1.39486259294424350000e-001) (12, -1.03977531694508980000e+000) (13, 1.24048942197960210000e-001) (14, -4.60162436047115970000e+000) (15, 1.05698140682912590000e+000) (16, -1.76145360982202790000e+000) (17, -2.58773136216998930000e-001) (18, 2.02789246626191750000e+001) (19, 2.99895446692337380000e-002) (20, -1.18307050549298600000e+001) (21, -5.05920890121970060000e-001) (22, -1.46774063447634550000e+001) (23, 7.62164787283023060000e-001) (0, 3.75202838344422940000e+000) (1, -1.41925176484590490000e+000) (2, -3.57171319153978620000e+000) (3, -1.22317896176462430000e+000) (4, 2.15150605968015500000e+000) (5, -1.70518554836617990000e-001) (6, -1.78461546417362590000e+001) (7, 7.09233007861012900000e-002) (8, 6.22072617680490310000e+000) (9, -1.08531670893097720000e+000) (10, -1.01608774791946810000e+001) (11, -2.80281249964739410000e-001) (12, -3.97312071462716030000e+000) (13, -1.54226839437588530000e+000) (14, 3.22813845093711870000e+000) (15, 4.40000504907690770000e-001) (16, -1.66709506763207610000e+001) (17, -3.50687145748846910000e-001) (18, 6.44122521747199620000e+000) (19, 4.45005202720434420000e-001) (20, -4.01642202048039470000e+000) (21, 5.89266938895266380000e-001) (22, -1.75519569835346490000e+000) (23, -8.37511123166928970000e-002) (24, 2.04346072548009710000e-001) (25, 1.20221757737952010000e+000) (26, 1.53210995180598530000e+000) (27, 8.54179501446813210000e-001) (28, -1.97761243719507940000e+000) (29, 1.98923235692136210000e+000) (30, 4.87973447507380420000e-001) (24, 9.96511723692249610000e-001) (25, 8.54657347661550710000e-002) (26, -1.19120302481435240000e+000) (27, -9.87890308686016680000e-001) (28, 1.14572738068385640000e+000) (29, -1.44682983353962810000e+000) (30, 5.79974102394691160000e-001) (24, -1.12605609044312180000e+000) (25, -8.98887250476571360000e-001) (26, 4.74280538862340150000e-002) (27, 1.73038361176018950000e-001) (28, 4.09092430803458200000e-001) (29, -1.77489027380478060000e-001) (30, 1.19118052393853090000e+000) 

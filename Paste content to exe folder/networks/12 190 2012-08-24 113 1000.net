FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -6.91345339960674470000e+000) (1, -3.27039096576753290000e-001) (2, -1.10877375879658340000e+000) (3, 2.10124472213540610000e-001) (4, -1.14165266850496270000e+001) (5, 1.24874178155757710000e-001) (6, -2.19371896828956570000e+001) (7, 3.73283691522745380000e-001) (8, -3.46609504990242030000e+001) (9, -9.26231105100851830000e-001) (10, -2.63101341216889080000e+001) (11, -2.68699647595539210000e-001) (12, 5.02076319952743510000e+000) (13, -1.06811843965406040000e+000) (14, -1.27286109165250780000e+001) (15, -1.17099158556336920000e+000) (16, -5.94817352678105320000e+000) (17, -9.50015573860479520000e-001) (18, -4.46490554258625050000e-001) (19, -1.97772755510751020000e+000) (20, -1.51389804854646110000e+001) (21, 2.23665397943056840000e-001) (22, -4.62804527994527040000e-001) (23, 1.83134637288213220000e+000) (0, 4.69531513881662210000e+000) (1, 9.26409973533965590000e-001) (2, 5.49653144320133790000e-001) (3, -2.18405296604362380000e-002) (4, -3.35215503136252480000e+000) (5, -6.73636136154867360000e-003) (6, 3.51091093202159570000e+001) (7, -1.12764168714230340000e-001) (8, 6.81060412408530740000e+001) (9, 2.99498433038056430000e+000) (10, 1.82444048270023170000e+001) (11, 5.78807693166445200000e-001) (12, -1.22812130934280090000e+001) (13, 1.38609542004782530000e+000) (14, 3.02422032542924870000e+001) (15, 1.96496134906473660000e+000) (16, 4.63807297833309560000e+000) (17, 1.08131013097825070000e+000) (18, 8.20671869731259560000e+000) (19, 3.14708468878222280000e+000) (20, 3.09119745845681460000e+001) (21, -5.90334752182061110000e-001) (22, -8.09767815469162320000e+000) (23, -2.66090073960741380000e+000) (0, -7.21791031544112090000e+001) (1, -3.52713394783781810000e+000) (2, -6.82376334575036300000e+000) (3, -2.33886667995956560000e-001) (4, 2.28987914504533310000e+001) (5, -3.15400128283930760000e+000) (6, -1.33054488581203540000e+001) (7, -9.29985367381020330000e-001) (8, -3.04571354146376690000e+001) (9, -4.21886670963765910000e+000) (10, -1.89952214412238970000e+001) (11, 1.11853748825895740000e+000) (12, 1.02853994808662890000e+000) (13, -3.70594648257264760000e+000) (14, -5.40024702890739330000e+001) (15, -3.17478377670876370000e+000) (16, -1.02252392774335870000e+000) (17, -2.24016427563830380000e+000) (18, 2.03331980092326990000e+001) (19, -1.09572869461296760000e+000) (20, 8.86585244907663570000e+000) (21, -8.44596556913017600000e-002) (22, -2.90314589487742860000e+001) (23, 4.18800392012465570000e+000) (0, 1.20039088486349210000e+001) (1, 5.45279151352691560000e+000) (2, -3.45775124584851670000e+001) (3, 5.83410001321735710000e-001) (4, -3.14938019935887890000e+001) (5, 4.72622065611333130000e+000) (6, -3.12307443010456150000e+001) (7, 5.54456808099332310000e+000) (8, -3.64690525734237670000e+001) (9, 1.27906171900032570000e+001) (10, -1.02008827335326160000e+001) (11, 6.51117736746285570000e+000) (12, 4.84096207902616130000e+001) (13, 3.70755736386628550000e+000) (14, 1.33824712004315160000e+002) (15, 3.24522163831526100000e+000) (16, 3.42359875600623550000e+001) (17, -7.11462802622667480000e-001) (18, 1.06461140403958920000e+001) (19, 1.98811074625987740000e-001) (20, 4.26161422401539800000e+000) (21, 1.18946764686742460000e-001) (22, 1.81753629828463690000e+001) (23, -2.90884023913275100000e+000) (0, 1.38064037887465640000e+002) (1, 2.95592000224907740000e+001) (2, 5.29998871061293810000e+002) (3, 3.46127248960030090000e+000) (4, -2.91286265568344300000e+001) (5, 3.63674489621286990000e+000) (6, 1.33535591174880890000e+002) (7, -1.52078488403264630000e+000) (8, 2.11369217626976820000e+002) (9, 1.27832230290670970000e+001) (10, -1.55769365134531400000e+002) (11, -9.82853210383373720000e+001) (12, 1.03859829189090140000e+002) (13, 1.76499397572421700000e+000) (14, 2.68447264927404830000e+002) (15, 1.09550905330363550000e+001) (16, -4.82400715899835430000e+001) (17, 1.06823743255746220000e+000) (18, 3.94032175237073400000e+001) (19, -2.06494037426022460000e+000) (20, 7.47172030711921130000e+000) (21, -1.47138104552742260000e+001) (22, 1.94708774341705410000e+002) (23, -9.47741682776568870000e+000) (0, -6.23529921724183740000e+002) (1, 2.60027813592395600000e+000) (2, 8.31869852951409600000e+002) (3, -9.06344992204926920000e+000) (4, 4.22353278086143120000e+002) (5, -2.31732405101826490000e+002) (6, -1.19939619732400170000e+002) (7, -4.26378270003164350000e+001) (8, 3.96770638773970290000e+002) (9, 1.32527551123894960000e+001) (10, -3.88817130976154670000e+001) (11, -5.27744971319141150000e+000) (12, -6.80869962313452870000e+000) (13, -5.95677116818041550000e+001) (14, 1.99877347362846710000e+002) (15, -4.56462807494677760000e+000) (16, 3.42427575032602250000e+002) (17, -2.37010413595610140000e+001) (18, 5.78856271621601430000e+000) (19, -3.87832491262600070000e+000) (20, 1.93595446489425630000e+002) (21, -3.98178582266853100000e+001) (22, -2.65272874206952850000e+002) (23, 9.03541138980057390000e-001) (24, -2.82849289433998540000e+000) (25, -1.95978997800821890000e+000) (26, 1.61493691358100460000e+000) (27, 1.44936243108816540000e+000) (28, 8.55084097346258900000e-001) (29, -1.08737586324025900000e+000) (30, 2.97310440415368140000e-001) (24, -2.66360527802423090000e-001) (25, -6.35958591330967100000e-001) (26, -1.36912618673198240000e+000) (27, 1.06806157400706730000e-001) (28, -9.77489524106362250000e-001) (29, 1.24353793546331000000e+000) (30, 1.12798942284904300000e+000) (24, 2.80849460072616170000e+000) (25, 2.51849185143887720000e+000) (26, -2.59241620613791070000e-002) (27, -1.45977694481880090000e+000) (28, 1.81953304349612490000e-001) (29, -2.45391747562264870000e-001) (30, 1.16028902030714050000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.61608417656503010000e+002) (1, -2.61691645775602380000e+001) (2, 3.81741864036942900000e+002) (3, -4.50018053022680960000e+001) (4, 6.63484322714980860000e+002) (5, 9.59282448576943950000e+001) (6, 3.06604906989034300000e+002) (7, -1.40242966969880030000e+002) (8, 1.50000000000000000000e+003) (9, -3.93707502233541290000e+001) (10, 1.27110312702510670000e+003) (11, -4.14217631151513220000e+001) (12, 1.50000000000000000000e+003) (13, 9.71829649687473700000e+001) (14, -4.82213469040416160000e+002) (15, -9.42674235597721830000e+001) (16, -1.12711968690641380000e+003) (17, 2.22908651728453440000e+001) (18, 9.24936708535421840000e+001) (19, 1.72200975024597940000e+002) (20, 1.50000000000000000000e+003) (21, 1.76714604804178180000e+002) (22, -1.50000000000000000000e+003) (23, -3.82523151022434650000e+001) (0, 3.09324341629438800000e+000) (1, 2.75346785359078390000e+000) (2, -3.11662389317627880000e+001) (3, -6.90668705997442120000e-001) (4, 1.17959151594301140000e+001) (5, 8.58266452390936800000e-001) (6, -6.69825846340692270000e+001) (7, 4.93341972435590300000e+000) (8, -5.76374497410945780000e+001) (9, 7.09807694721657970000e+000) (10, -2.11631081092011680000e+001) (11, 3.46059060012629870000e+000) (12, 4.53204982156906620000e+001) (13, 2.75533656923149820000e+000) (14, 7.49297545307283170000e+001) (15, 4.31845087231173790000e+000) (16, 2.29295821076393410000e+001) (17, 1.85230751829885750000e+000) (18, -1.98652439351070530000e+001) (19, 1.38288485621570770000e+000) (20, -8.17630245449334300000e+001) (21, -1.10941225614843180000e-001) (22, -2.59082329045598880000e+001) (23, -3.95252437757754370000e-001) (0, 2.09985804898646080000e+002) (1, -1.25317869640354850000e+001) (2, 2.84211446480460270000e+002) (3, 1.15352995700807080000e+001) (4, -4.88840528958758060000e+002) (5, 5.37202254490475890000e+001) (6, -1.50000000000000000000e+003) (7, 4.65399865679368290000e+001) (8, -1.00612627703448690000e+003) (9, 3.22321124635351170000e+001) (10, -4.57089714496816040000e+002) (11, 4.89185644786619990000e+001) (12, 3.65187145066427210000e+002) (13, -4.53483286596985720000e-001) (14, 1.50337083583280530000e+002) (15, 3.16467526424716330000e+001) (16, 1.26246594317666220000e+003) (17, -8.92179725608376730000e+000) (18, -4.86036153335367830000e+002) (19, -2.17047131132494900000e+001) (20, -1.13813682071195420000e+002) (21, -1.36589938177750160000e+000) (22, 5.57623663206201400000e+002) (23, 3.95502527672269300000e+001) (0, -1.08093216078463800000e+003) (1, 2.91498735155630830000e+001) (2, 1.01125704514851260000e+001) (3, -3.98756645931990180000e+000) (4, -1.40685088471480440000e+002) (5, 3.07859681627100810000e+001) (6, 1.21179298646287910000e+003) (7, 1.52059035825611060000e+001) (8, 1.54907634972859650000e+002) (9, 2.05731356175539410000e+001) (10, -6.09782362537233100000e+002) (11, 9.16409002491788630000e+000) (12, 8.56790537172708470000e+001) (13, 3.44889105753466740000e+000) (14, -2.42443854103676100000e+002) (15, 1.77262099075282900000e+001) (16, -1.11098954842159370000e+002) (17, 4.90579091920703480000e+001) (18, 2.17902711310875220000e+002) (19, -2.63253028764243670000e-001) (20, 1.12404281151078170000e+002) (21, -1.12548934864845480000e+001) (22, 5.95590570943874470000e+002) (23, -5.28113854752751430000e+000) (0, 4.93005051628705250000e+002) (1, -6.30069129795051880000e+001) (2, 1.18563595432486140000e+002) (3, 1.82036513469388270000e+001) (4, 2.72012636940210900000e+001) (5, -3.89489656550564330000e+001) (6, -5.74875398293231340000e+002) (7, 1.82831715711736860000e+001) (8, 3.72671927539744270000e+001) (9, -5.01820698738380670000e+001) (10, 6.38726144110596810000e+002) (11, 2.83124656156956170000e+000) (12, -5.08163324392436320000e+002) (13, -4.70778200392412600000e+001) (14, 5.32117397551669030000e+001) (15, -6.68239406894027880000e+000) (16, 6.71855360731149860000e+002) (17, -3.89938008912742400000e+001) (18, 4.62853624260302470000e+001) (19, -1.89793358328145030000e+001) (20, 6.98054335891805070000e+002) (21, -1.42982809816998870000e+000) (22, -7.26563400374623000000e+001) (23, 8.70874158418212830000e+000) (0, 7.06808943290717340000e+001) (1, -6.43308120615091130000e-001) (2, -4.49060926156766340000e+001) (3, -9.46779663109841630000e-001) (4, -1.31619139875165050000e+002) (5, 1.76212767425261490000e+000) (6, 2.36786605711979630000e+001) (7, -5.34108408065521800000e+000) (8, 1.28609814051496360000e+002) (9, 2.52453081111251620000e+000) (10, -7.96684454631318180000e+001) (11, -2.06459933684267940000e+000) (12, 7.26611713960680130000e+001) (13, 5.95044139337185920000e+000) (14, -9.22848794719783290000e+001) (15, -1.57898057209977250000e+000) (16, -1.75831548577056140000e+002) (17, 8.86506801863881200000e-001) (18, -1.87916941581904000000e-001) (19, 6.46623176729825210000e+000) (20, -1.18275868672705450000e+001) (21, 6.91738929196668460000e+000) (22, -1.88589644671205750000e+002) (23, -2.28177425172366140000e-001) (24, 1.41010455059636610000e+000) (25, 1.52657196020414630000e+000) (26, -2.58703613595913480000e-001) (27, 1.40674995620550350000e+000) (28, 1.44175933211784880000e+000) (29, 2.45895476822472480000e-002) (30, 1.55464014251323200000e-001) (24, 1.48616903510237570000e-001) (25, -4.20571258147451640000e-003) (26, 3.85883242129739960000e-001) (27, -1.19411495799432690000e+000) (28, -1.40630410359380350000e+000) (29, -1.41055600987489370000e+000) (30, 9.46082724573127140000e-001) (24, -1.46947815749868790000e+000) (25, -1.65656041641138540000e+000) (26, -2.70676182686892750000e-001) (27, 4.43127813699314070000e-002) (28, 3.61203971450887240000e-002) (29, 1.42920819001239120000e+000) (30, 1.85495693925789750000e+000) 

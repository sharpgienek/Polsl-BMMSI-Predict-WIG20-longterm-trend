FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.57540347045742380000e+000) (1, 2.37577371742397100000e-002) (2, 3.62838885934218150000e-001) (3, 5.99272374815363330000e-002) (4, -2.85147449373581270000e-001) (5, 5.52712184504555730000e-001) (6, 3.18761355904230030000e+000) (7, 1.24227709374483950000e-001) (8, 6.86700287132847030000e-001) (9, -1.78247996856737230000e-001) (10, -3.83529583930557360000e-001) (11, 2.31229715397809660000e-002) (12, -5.26474996399968860000e-001) (13, 4.28531102724417690000e-001) (14, 1.24694517743053670000e+000) (15, 2.91575377307763530000e-002) (16, -1.41248923585207620000e+000) (17, -9.38539443955127150000e-002) (18, 4.39797947747923130000e-001) (19, 6.54799588369526680000e-001) (20, 1.32932549908705950000e-001) (21, 1.26230709813530180000e-001) (22, 1.19311426686152990000e-001) (23, 5.96219955211588010000e-002) (0, -1.32313218724882330000e+000) (1, 2.13385125513214040000e-001) (2, -3.02965810921444370000e-001) (3, -1.32660436539478730000e-001) (4, 3.19554202595731860000e+000) (5, 7.59292691825817350000e-002) (6, -3.12848269878618180000e+000) (7, 7.14676745607138340000e-001) (8, -2.99606678104665570000e-001) (9, 1.25281772725609640000e-001) (10, 1.43417589245956420000e+000) (11, 6.30912095921447700000e-001) (12, 5.13573244517808500000e-001) (13, 5.03826813385296200000e-002) (14, -5.92869040358067200000e-001) (15, 9.43926364550336630000e-001) (16, 4.90355470734336660000e-001) (17, 4.14138878088874810000e-002) (18, 5.78335916468680320000e-001) (19, 1.21677848416535390000e-001) (20, -2.15111827006507110000e+000) (21, 4.54218415047789450000e-002) (22, 1.18373716867616400000e+000) (23, 1.42939113534366540000e-002) (0, -3.44420889664173170000e-001) (1, 5.29694236449920200000e-002) (2, 5.42033587883186120000e-001) (3, 7.46388768585098670000e-002) (4, 3.41299164800874240000e-001) (5, -4.25998016505378220000e-001) (6, 2.82084641564384400000e-001) (7, -1.60629997191700990000e-001) (8, -4.36129380291911810000e-002) (9, 1.91164745566319850000e-001) (10, 1.06605698095304690000e+000) (11, 9.89158369077328130000e-004) (12, -1.76533806734410490000e-001) (13, -3.03108996035510450000e-002) (14, 5.55261814290614190000e-002) (15, 5.25289000428279750000e-001) (16, 3.65492766670484300000e-001) (17, -6.60583388434816230000e-001) (18, 1.00618832836873720000e+000) (19, -1.58225211999616890000e-001) (20, -4.05354910620799700000e-001) (21, -3.72085662186396490000e-001) (22, 1.93245910043745250000e-001) (23, -7.64991365630534880000e-002) (0, -2.25678973717838960000e-001) (1, 2.09388087021954490000e-001) (2, -9.08587491416322110000e-001) (3, -3.49228260875334760000e-001) (4, -4.23807119408521340000e-001) (5, 1.88123438267586540000e-001) (6, -3.20919559061389760000e+000) (7, 6.63669664768948510000e-001) (8, -3.10279300113775050000e+000) (9, 1.03736362248308000000e-001) (10, 3.01855227722621590000e+000) (11, 7.43442615176408190000e-001) (12, 4.76488283027699470000e-001) (13, 1.39848014702916970000e-001) (14, 2.54671832316310540000e+000) (15, 2.35966994003704330000e-001) (16, 4.07970104783492990000e-001) (17, 5.69189075303945910000e-001) (18, 2.17114699075564970000e-001) (19, 2.01648829094130570000e-001) (20, 5.25211415588387190000e-002) (21, 1.78619499995165850000e-001) (22, 3.05801150632982920000e+000) (23, 3.78032685329754700000e-002) (0, 9.99761415935027320000e-001) (1, 1.95874339919178460000e-001) (2, 2.04212709268324800000e-001) (3, -3.04273415991435090000e-003) (4, 7.47228504292286820000e-001) (5, 2.11767894843510880000e-001) (6, -3.58190359717638520000e-001) (7, 4.46389989709285840000e-001) (8, 1.91647285381145170000e-001) (9, 3.50471904072231830000e-001) (10, -6.63036155506778190000e-002) (11, 4.64145643895837960000e-001) (12, 1.19441860962601200000e-002) (13, 1.10338689566227860000e-001) (14, 2.68058322148074900000e-001) (15, 4.38070897788446710000e-001) (16, 2.70060173278514120000e-001) (17, 1.13010809756484410000e+000) (18, 3.80025484139272840000e-001) (19, 5.44444033419550080000e-002) (20, -9.91336964183043010000e-002) (21, 7.12901067179755460000e-002) (22, -4.49707265317398350000e-002) (23, 5.28315727253319660000e-001) (24, 1.49565664257966910000e-001) (25, 1.19989453487661050000e-001) (26, -3.82906110837307880000e-002) (27, 1.68335401473696800000e-001) (28, 4.41301572381873730000e-001) (29, 4.22240292800963530000e-001) (24, -2.19427224013780510000e-001) (25, 1.64606753504316060000e-001) (26, 2.35547705391345120000e-001) (27, -7.33882841454829290000e-002) (28, 2.23401530048109750000e-001) (29, 5.58430936447187780000e-001) (24, 5.11245947706964850000e-001) (25, -5.15524385026925100000e-001) (26, 5.95230189381095590000e-002) (27, -5.14907929939614210000e-001) (28, 4.51169042514874270000e-001) (29, 4.04403905099269430000e-001) 

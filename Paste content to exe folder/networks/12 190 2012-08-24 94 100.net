FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.11413913580633150000e+000) (1, -5.67108307493703450000e-001) (2, -2.47045567532948280000e+001) (3, 7.50278866335862160000e-001) (4, -1.69845333860913430000e+001) (5, 2.29753040846457650000e+000) (6, -1.35528846142444480000e+001) (7, 1.14942220428041430000e+000) (8, -3.65302407311572490000e+000) (9, -7.41655575738340620000e-001) (10, 4.89190359700976710000e+000) (11, 6.02092151046436720000e-002) (12, 7.74800968967374890000e+000) (13, 2.70849779598613650000e+000) (14, -2.91158311200742510000e+001) (15, 2.03907094480001380000e-001) (16, -1.35516282596426320000e+001) (17, -7.69900385143843510000e-002) (18, 5.49152758219465480000e+000) (19, 5.54305477687573740000e-002) (20, 2.96772447173275750000e+001) (21, 1.05667928784039460000e+000) (22, 7.14772324199218370000e+000) (23, 1.97242033299012130000e-001) (0, 4.29833867057732190000e+000) (1, 1.28820974238835410000e+000) (2, 9.37374594377574420000e-001) (3, -4.24857481261902480000e-001) (4, 2.65725071305990670000e+001) (5, -6.58194941798180940000e-001) (6, -1.72552901812047390000e+000) (7, 3.75236415111795840000e-001) (8, -8.22961920363939110000e+000) (9, 1.38455089276801970000e+000) (10, 6.70124857150192380000e+001) (11, 2.20932631186656760000e+000) (12, 2.21739778850102770000e+001) (13, 4.31676561072730640000e-002) (14, 3.61718809429989960000e+001) (15, 1.34040671448884540000e+000) (16, 4.00226263340070700000e+000) (17, 1.92696309493580380000e-001) (18, -7.61699165462454350000e+000) (19, 5.42271609746575960000e-001) (20, -7.28663399963595460000e+000) (21, -1.24327048758904770000e-001) (22, -1.96868345329555840000e+000) (23, -9.07501315712641370000e-001) (0, -1.13050717552747560000e+000) (1, 1.02986356031669100000e+000) (2, 3.26358112563274090000e+000) (3, 4.59317555403969850000e-001) (4, -3.80087225878237620000e+001) (5, -5.81399127339879080000e-001) (6, -1.07844496389346280000e+000) (7, 9.77409147220675510000e-001) (8, -1.88329308735010700000e+001) (9, -8.25636919649271550000e-001) (10, 1.49536568661938620000e+001) (11, 5.47101930787478490000e-001) (12, 1.87715342084573460000e+001) (13, -5.51893159698784610000e-001) (14, 1.20598072105338990000e+000) (15, -9.22530527625569860000e-001) (16, -8.17753662996469370000e+000) (17, -8.30622138574219400000e-001) (18, 6.88623062963896420000e-001) (19, 1.70140728069842900000e-001) (20, -1.39762967992708500000e+001) (21, 8.56698116565246110000e-002) (22, -1.20492448875470670000e+001) (23, 5.46204042882641680000e-001) (0, 1.91949273579101700000e+000) (1, -3.61594253025929400000e-001) (2, -1.10516572990520600000e+000) (3, -4.74696018713340000000e-001) (4, 2.81178094107013910000e+001) (5, -3.78560969607404040000e-001) (6, 6.89449460583094980000e+000) (7, -1.82592506467765190000e+000) (8, 9.76727939589622980000e+000) (9, 2.53365123241124090000e-001) (10, 5.07044808888004740000e-001) (11, -3.23820543518990310000e-001) (12, -1.77860142139812740000e+000) (13, -1.87935890686623530000e-001) (14, 1.29813747980258380000e+001) (15, 5.20106960954689450000e-001) (16, 1.51057960473387740000e-001) (17, 1.40649074250968500000e-002) (18, -4.29006938055267910000e+000) (19, -2.35950061769436950000e-001) (20, 2.85875820816488970000e+000) (21, -2.29197639823724040000e-001) (22, 5.62805730354181400000e+000) (23, 1.83126741457469070000e-001) (0, 1.08066080034623480000e+001) (1, 1.44090129271599080000e+000) (2, -6.84200909490277630000e+000) (3, 1.15993109215911040000e+000) (4, 1.04475956135050650000e+001) (5, 8.83544129874002880000e-001) (6, -8.55373615611349790000e+000) (7, 2.54429283313022970000e+000) (8, -5.49178951412610560000e+001) (9, -1.28843706016615770000e+000) (10, 5.00522186617611600000e+001) (11, 4.54604567639349980000e-001) (12, 2.52688725024571570000e+001) (13, 1.50852369041977140000e+000) (14, -4.71193203746152370000e+000) (15, 1.25301729041525900000e+000) (16, -8.90462134079139570000e+000) (17, -5.27754920271513380000e-001) (18, -5.35556390736135950000e+000) (19, 3.09112031173029270000e-001) (20, 2.20506735148812800000e+000) (21, 8.38564795860825000000e-001) (22, -6.61373043637187050000e+000) (23, 8.34897150970884350000e-001) (24, 1.31880053664481060000e+000) (25, 1.36283703414162430000e+000) (26, -1.66729416671202280000e-001) (27, -5.48739994350136980000e-001) (28, -1.13941236654065590000e+000) (29, 6.53020338632911760000e-001) (24, -1.07541735451485980000e+000) (25, 1.54137817839843340000e-001) (26, -1.33745458175814070000e+000) (27, -9.09707305246278520000e-001) (28, 1.02207371200710440000e+000) (29, 5.00823930354351130000e-001) (24, -1.66369489073811190000e-001) (25, -1.34365974230096570000e+000) (26, 1.39249111541097290000e+000) (27, 1.31393275525150100000e+000) (28, 7.53044952631855700000e-002) (29, 1.12316543289134740000e+000) 

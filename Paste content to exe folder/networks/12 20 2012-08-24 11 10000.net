FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.00036803524199860000e-001) (1, 2.61019265298320810000e-001) (2, 1.31417749377167210000e+000) (3, -4.19569778339571040000e-002) (4, 6.19379411546003670000e+000) (5, -5.62226650793174780000e-003) (6, -1.94513564873046860000e-001) (7, 1.88534671731679720000e-002) (8, -5.83669542963100430000e+000) (9, -1.27142399179154710000e-001) (10, 3.29513647557246400000e+001) (11, -8.22196322731693520000e-001) (12, -2.35592562033864720000e+001) (13, 1.78016355416591910000e+000) (14, 2.60509083725782360000e+000) (15, 5.72879619799342880000e-001) (16, 1.59602195482664390000e+000) (17, 5.40928792564901560000e-001) (18, -5.80578556810974610000e+000) (19, -6.13188140521272460000e-001) (20, 7.26361807754067450000e+000) (21, 4.42127338333112440000e+000) (22, 3.38468082107274530000e+000) (23, 3.51874863204087450000e-001) (0, 3.09338187781447170000e+000) (1, 7.83914391275833510000e-001) (2, 6.15804590227600720000e+000) (3, 1.72245759784637460000e-001) (4, 8.50974348109820870000e-001) (5, 1.78368133332167940000e-001) (6, 2.60226529841355750000e+000) (7, 5.05265035639270610000e-001) (8, -4.82995089259599290000e+000) (9, 3.68127873054985330000e+000) (10, 7.93735336808422450000e-001) (11, 1.47207799729641820000e-001) (12, 5.78438721345426470000e+000) (13, -1.27456422981045090000e-001) (14, 6.82762928765706210000e-001) (15, -4.89656668451574520000e-001) (16, 4.74629223194043380000e-001) (17, -6.91737759955226710000e-002) (18, 1.08246020809784740000e+000) (19, -3.62495885782622710000e-001) (20, -8.99649688861046820000e-002) (21, 1.99621890206729740000e+000) (22, 4.01748991538998550000e+000) (23, -6.28490872153726790000e-001) (0, -1.82417419394105340000e+001) (1, 4.74148234559577610000e-001) (2, 3.77780049895748920000e+000) (3, 2.17806046109239700000e-002) (4, 1.04797287088350500000e+000) (5, 1.11733376076294740000e+000) (6, 2.32356815129065200000e+001) (7, 9.81368343885964060000e-001) (8, -9.79090263621003490000e+000) (9, 8.33022737493770870000e-001) (10, 3.59700158852483800000e+001) (11, 3.47509620814086870000e-001) (12, 3.08647542408462150000e-001) (13, -1.65757265117231410000e+000) (14, 1.76741387603272450000e+000) (15, 6.00183610915774660000e-001) (16, -5.77554532713009830000e-001) (17, -7.80465370264994740000e-001) (18, 9.64478110226377190000e-001) (19, 1.76263749445510350000e-001) (20, 1.03851903144527120000e+000) (21, 5.74852108739015750000e+000) (22, 4.98585907392857400000e+000) (23, -1.13237835729817290000e+000) (0, -2.84596885522582890000e+000) (1, 1.30781989419327170000e+000) (2, 1.34262309907168920000e+000) (3, 1.57770642270010560000e+000) (4, 1.46660091219787090000e+000) (5, 2.41427028157235620000e+000) (6, -8.96014540699901050000e-001) (7, 1.93002874115692990000e+000) (8, 1.25561301360857590000e+000) (9, 3.95898939548730950000e-001) (10, -1.01323626589931040000e+000) (11, 5.04436830014404650000e-001) (12, -4.65087811491372700000e+000) (13, 5.43674192329651170000e+000) (14, -1.04554214409674100000e+001) (15, -3.92097113272946830000e-001) (16, 7.20085039188599560000e+000) (17, 5.02969274282681680000e-001) (18, 5.74937896831151480000e-001) (19, 3.30151125129007130000e-001) (20, 5.66974608582758940000e+000) (21, 6.19657806970474570000e+000) (22, 3.05211603464095590000e+001) (23, 7.93315568067550550000e-001) (0, 1.00032498116039350000e+001) (1, 2.88861477144678410000e-001) (2, 1.71084159135857140000e-001) (3, -6.14339128944481730000e-001) (4, -1.62274804585739570000e+000) (5, 3.87106989872499030000e-001) (6, -1.37793843142633030000e+000) (7, 1.85700864019191130000e+000) (8, 1.84097518763936740000e+001) (9, -3.71103601152265430000e-001) (10, -5.50568179334210490000e+000) (11, 1.68794655173406040000e+000) (12, 2.07701078622227200000e-002) (13, 2.13138621008857140000e+000) (14, -4.85535032611180920000e+000) (15, -2.24470171303342130000e-001) (16, 9.51676284162234150000e+000) (17, 6.64433390017742380000e-001) (18, 9.37225932792577150000e+000) (19, 3.68352817389068010000e-002) (20, -7.51002557289872460000e+000) (21, -1.75892125815086750000e+000) (22, -1.57013189163584920000e+001) (23, 1.86926070196891780000e+000) (0, 4.94114690404107910000e+000) (1, 1.17113809215844040000e+000) (2, 3.82755377312214900000e+000) (3, 7.43569776127209200000e-001) (4, 5.56364093861121310000e+000) (5, 5.65155904006152680000e-001) (6, 1.01766103330464590000e+000) (7, 9.98045727426053910000e-001) (8, -3.96077069169978260000e-001) (9, 2.02759653367722550000e+000) (10, 7.76056352856306030000e-001) (11, 1.83199179189395740000e+000) (12, -1.43534698742583020000e+000) (13, 4.76675190630707290000e-001) (14, 8.66041938902532890000e-001) (15, 2.66883021702930880000e-001) (16, -3.71691118204972470000e-001) (17, 4.95360655362799000000e-001) (18, 4.66795761316031070000e-001) (19, -1.33246269812178270000e-001) (20, 2.12726632832774270000e-001) (21, -5.26175798534905930000e-001) (22, -4.94649432958361770000e+000) (23, 7.23410296135540530000e-001) (24, 9.45347111015143570000e-001) (25, -8.63471911983901830000e-001) (26, 4.87302533548517050000e-001) (27, -8.84552563641922470000e-001) (28, -2.76423591685003430000e+000) (29, 6.51368046515058860000e-001) (30, 1.97238930951564260000e+000) (24, -2.47513625299010310000e+000) (25, 2.47467965329808810000e+000) (26, 2.93246562008055770000e+000) (27, 1.50385665834024240000e+000) (28, 6.52559083955073230000e-001) (29, 3.77042548665408360000e+000) (30, 1.07093059187092890000e+000) (24, 1.90351120522995370000e+000) (25, -2.61102614956483330000e+000) (26, -3.38078317278041850000e+000) (27, 5.79462041153454640000e-002) (28, 2.10547649909532320000e+000) (29, 2.71839740624112420000e-001) (30, 9.45657835821987260000e-001) 

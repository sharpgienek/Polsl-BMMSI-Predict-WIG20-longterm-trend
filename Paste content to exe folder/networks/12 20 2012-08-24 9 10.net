FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.05068832838028610000e+000) (1, -2.89558369200966110000e-001) (2, -5.80247928589872290000e-001) (3, -2.07978778141585500000e-001) (4, -1.88960223170686950000e-001) (5, -1.47489146547416240000e-002) (6, -1.18768662620571640000e+000) (7, 5.96509395360615420000e-002) (8, 3.16363284579433480000e+000) (9, 1.42974321486526950000e-001) (10, -9.63769377004221270000e-001) (11, 2.64027706838070030000e-002) (12, 1.56316447937968980000e-001) (13, 7.36989649868090460000e-001) (14, -6.62170302520963090000e-001) (15, -2.02769730592115060000e-001) (16, 1.93935607319647540000e-001) (17, 2.87575228099750670000e-001) (18, 1.69392152108833070000e-001) (19, 1.60039386938149980000e-001) (20, -1.27773743251211380000e-001) (21, -1.03447860657349590000e+000) (22, -4.34641737166665680000e-002) (23, 2.97422776558565420000e-001) (0, 3.88404090616133680000e-001) (1, -4.83259700250492200000e-001) (2, -4.00556380330607250000e-001) (3, 1.46638614482142160000e-001) (4, -1.32774218788835000000e-001) (5, 6.19925604360871410000e-003) (6, -3.56529373626046640000e-003) (7, -5.83070492753413940000e-001) (8, 4.37134560092274250000e-001) (9, -2.26802604439959730000e-001) (10, 1.71802198400356100000e-001) (11, -1.05265487637559340000e+000) (12, 7.60294580851108570000e-001) (13, 6.45272753742182630000e-002) (14, -3.38262239675309050000e-003) (15, 3.18834621564665850000e-001) (16, 5.25430534225864050000e-001) (17, 4.78193363085455960000e-001) (18, -2.67217519373128380000e-001) (19, 1.74098505283942830000e-001) (20, 1.21790459821256190000e-001) (21, -3.39806543950550160000e-002) (22, 3.48706800999518780000e-001) (23, -1.79242869918436990000e-001) (0, 5.46977786031199950000e-001) (1, -3.75437372674831180000e-001) (2, -3.08302371373379010000e+000) (3, -3.72601419521639480000e-002) (4, -3.66425531524965930000e-001) (5, -3.23268208813202620000e-001) (6, -1.04656356769107580000e+000) (7, -4.46074096586779320000e-003) (8, 5.94047473812976730000e-001) (9, -1.65947369937129970000e+000) (10, -4.08383535194317030000e-001) (11, -6.18856348895801540000e-001) (12, 1.25343105633778100000e-001) (13, 6.34603340036624000000e-001) (14, -3.24073156823242170000e-001) (15, 1.13890244344797280000e-001) (16, 1.07614072198923410000e+000) (17, 4.51475735206367690000e-001) (18, -1.50820264543196910000e-001) (19, 2.43282295966813150000e-002) (20, 1.22666280314541900000e+000) (21, -1.06433318756545890000e-001) (22, 3.74874094802683730000e-002) (23, 1.95054722130940860000e-001) (0, 2.96983323427017050000e-001) (1, -2.24687534523189320000e-001) (2, -1.06231674175394140000e+000) (3, 7.16882917277281570000e-002) (4, -6.63727115525875160000e-001) (5, -3.28020469218026910000e-001) (6, 1.34798076897409300000e-001) (7, -1.98633379842957010000e-001) (8, 3.44502006461253060000e-003) (9, -2.03895327978429820000e+000) (10, 9.46892497540271220000e-002) (11, -4.08183296716251920000e-001) (12, 9.18276703473248520000e-001) (13, 1.15054479877744000000e-001) (14, -4.87416194453053790000e-001) (15, 2.13056624993333070000e-002) (16, 5.34564443463228400000e-001) (17, -1.78726341204789780000e-001) (18, -4.90614436688211310000e-001) (19, 1.28138659607974990000e-001) (20, 2.03792267866912290000e-001) (21, 1.07968990791409370000e-001) (22, 3.65653869529743330000e-001) (23, 2.12354969456645780000e-001) (0, 3.19650638144043860000e+000) (1, 5.36538009241070530000e-001) (2, -5.20879031220831790000e-001) (3, 5.54726344690819050000e-001) (4, 7.85465712947339470000e-001) (5, 4.11458233105998940000e-001) (6, 4.04451397064088950000e-001) (7, 6.04515003265830080000e-001) (8, 6.75630958423056200000e-001) (9, 8.98197648220926180000e-001) (10, -3.16047732816918890000e+000) (11, 5.41640406995823390000e-001) (12, -2.57013394383691920000e-001) (13, 1.56527359693019500000e+000) (14, -1.54805442341902990000e+000) (15, 7.33991960667267070000e-002) (16, 3.33269714862194980000e-001) (17, 1.71111100144709160000e+000) (18, 7.98257647379550740000e-001) (19, 4.45259503140927100000e-001) (20, -1.14614976821746990000e+000) (21, -5.06266255864460170000e-001) (22, 2.93672586819606060000e-001) (23, 5.91477446634446120000e-001) (24, -8.02415030769977780000e-001) (25, 4.85652620022129170000e-001) (26, -1.16866406975273120000e-002) (27, 2.73005088132575680000e-001) (28, -2.04266456075753100000e-002) (29, 2.25163710587254320000e-001) (24, -2.81775527866543360000e-001) (25, 1.00834499209919590000e-001) (26, -1.23713248960983830000e+000) (27, -3.53429895698341990000e-001) (28, 6.52665191686839340000e-001) (29, 5.73124174876586070000e-001) (24, 3.66395333975192810000e-001) (25, 8.37681096300443300000e-002) (26, 1.19927231496936000000e+000) (27, 2.20409605758573380000e-001) (28, 8.10095064362197360000e-001) (29, 7.57161106375662700000e-001) 

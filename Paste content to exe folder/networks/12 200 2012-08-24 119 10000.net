FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.26707904320058230000e+001) (1, 2.71376028134233230000e+000) (2, 9.60999895426959090000e+001) (3, -1.13113750273806150000e+001) (4, -2.81570282230631680000e+002) (5, -1.61131367517942060000e+000) (6, -2.29347878917181360000e+002) (7, -1.05054318642348510000e+001) (8, -2.64876003838564710000e+002) (9, 5.70282318352287590000e+001) (10, 3.63518145668263460000e+002) (11, 2.35050178186514100000e+001) (12, 3.44484538182853040000e+002) (13, 4.19233947446594790000e+000) (14, -1.95169391813262280000e+002) (15, 3.41626837580336900000e+000) (16, 3.69919828060640100000e+002) (17, 1.86342404600054760000e+001) (18, -1.50167370270455990000e+002) (19, -5.17208701700793410000e+000) (20, 2.37980553848989060000e+000) (21, 1.13931322439660780000e+000) (22, 4.00619091306165670000e+002) (23, -2.83414550254371060000e+000) (0, -9.79306201717054250000e+002) (1, -2.56347988853575600000e+002) (2, -2.37483636196126040000e+002) (3, -8.07229544095139850000e+000) (4, 1.37992996097881390000e+002) (5, -5.40640647423671440000e+001) (6, -1.49336126109693400000e+003) (7, -1.50991438922488750000e+002) (8, -1.05898433366698650000e+003) (9, -7.95844270607970400000e+001) (10, 1.50000000000000000000e+003) (11, 2.95380466426251580000e+001) (12, -6.22143648982864080000e+002) (13, -1.86172500322359050000e+001) (14, -1.31055642233500340000e+003) (15, -1.66466515850676070000e+002) (16, -1.29290960315402440000e+003) (17, 1.24056450587740830000e+002) (18, -7.07309714687700310000e+002) (19, -2.08735193601774680000e+002) (20, -3.37789514138352390000e+002) (21, -1.23993647605052750000e+001) (22, 1.47392916863760770000e+003) (23, -4.29568528472763870000e+001) (0, -1.35667312540203400000e+002) (1, 1.72528296347248380000e+000) (2, 6.76965950847962290000e+001) (3, 3.00736710357885830000e+000) (4, 1.47469568858994220000e+002) (5, -1.04407834332613670000e+000) (6, 3.86029618373556150000e+001) (7, 1.88984324786255950000e+000) (8, 7.18773506153871440000e+001) (9, -7.39008374996707930000e+000) (10, 6.05292950350047360000e+001) (11, 3.72223036947820550000e+000) (12, 1.31044954282841300000e+002) (13, -3.48853236059720120000e+000) (14, 7.43831214760549100000e+001) (15, 4.11271312162537320000e+000) (16, -1.08368780645160880000e+002) (17, 2.31622734122801300000e+000) (18, 8.65749388780866270000e+000) (19, -5.43487507930253420000e+000) (20, -3.41241022844192620000e+000) (21, 1.41050109729878530000e+000) (22, -1.11421177181582420000e+002) (23, -3.41335360375768990000e+000) (0, 1.41008368460203560000e+003) (1, -3.17348241457866570000e+001) (2, -1.50000000000000000000e+003) (3, 6.23996010216952260000e+000) (4, 1.50000000000000000000e+003) (5, 1.57155689557831410000e+002) (6, -1.48160103772958150000e+003) (7, 1.23883547758078540000e+002) (8, 3.14889173330061230000e+002) (9, 7.73007767660164970000e+001) (10, 3.19066023517068000000e+002) (11, 4.02350101802870770000e+001) (12, 7.95157396687149230000e+002) (13, 2.26425490157345930000e+002) (14, 3.09783376980524000000e+001) (15, 7.04558556846868240000e+001) (16, -1.37797286482307600000e+003) (17, -1.27481755099009020000e+001) (18, -2.16735978582488930000e+001) (19, -4.06699439958119270000e+001) (20, -8.79137296084805480000e+002) (21, 7.43235779851901980000e+001) (22, -1.06673798806448670000e+003) (23, 2.29920891760531310000e+001) (0, 1.11288186533060410000e+002) (1, -8.37678547108085250000e+000) (2, -6.57586572592119440000e+001) (3, 1.43803445414120270000e+000) (4, 1.43067206610931980000e+002) (5, 3.77158385973373060000e+000) (6, 3.86460141952851830000e+001) (7, -7.22170309249568600000e-001) (8, -4.58845061600825660000e+001) (9, 5.54560513022327050000e+000) (10, -1.24399187941995900000e+002) (11, -5.75674355461360140000e+000) (12, -9.66307289932272230000e+001) (13, 6.16367256868732570000e+000) (14, -7.64443019653796800000e+001) (15, -3.17412433449751790000e-001) (16, -6.52707463896521180000e+001) (17, -1.27665253905443680000e+000) (18, -1.25767121997500730000e+001) (19, -6.81341546067533610000e+000) (20, -5.37840347623607900000e+001) (21, 5.58192225635093520000e-001) (22, -2.94181453812576270000e+001) (23, 2.31194985464325060000e+000) (0, 1.32703615170039060000e+002) (1, 2.78062532491438110000e+002) (2, 8.22110846462846210000e+002) (3, -1.67450995550496770000e+001) (4, -4.91258566082463460000e+002) (5, 3.00869759483513590000e+001) (6, 1.48539227300502350000e+003) (7, 1.41982494856086170000e+001) (8, 1.50000000000000000000e+003) (9, 2.08325442427738640000e+001) (10, -6.95759000897203580000e+002) (11, 3.19599284657153220000e+001) (12, 1.50000000000000000000e+003) (13, -2.16696700912734310000e+002) (14, 9.76781857912174250000e+002) (15, 4.72518775504567970000e+001) (16, -6.86673713474682020000e+002) (17, -6.81855882720746960000e+001) (18, -2.86040080500657720000e+002) (19, -1.83796110400582560000e+002) (20, -2.04742883810393660000e+002) (21, 1.15518938892258160000e+001) (22, -1.50000000000000000000e+003) (23, -6.57787981975283880000e+001) (24, 4.67287095488257070000e-002) (25, 5.23143382718300520000e-001) (26, -3.03746807578769150000e-001) (27, 1.12340455207976580000e+000) (28, -9.95479462425121640000e-001) (29, 1.68317615315972140000e-001) (30, 5.68724430192859790000e-001) (24, 1.53443195177473450000e+000) (25, -1.64318375128015750000e+000) (26, 1.63310345134882300000e+000) (27, -1.15258625301574370000e-001) (28, -5.81793522753737850000e-003) (29, -1.55001661156461660000e+000) (30, 4.95357073050687050000e-002) (24, -1.10702527025559450000e+000) (25, 7.65179699333698120000e-001) (26, -8.99204023444948540000e-001) (27, -9.20726307088160170000e-001) (28, 8.65253360368504090000e-001) (29, 1.02260326951381250000e+000) (30, 1.74579708360552810000e+000) 

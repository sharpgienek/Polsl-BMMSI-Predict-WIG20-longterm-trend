FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.14726932015987430000e+000) (1, 1.55656754090987560000e-002) (2, -1.75961108031903480000e+000) (3, -3.16189529323708920000e-001) (4, -2.81098896418660150000e-001) (5, 1.27268734234403660000e-002) (6, -3.12598025734264250000e+000) (7, 2.40939248078037740000e-001) (8, -3.19328982865813330000e+000) (9, 2.53871590634508690000e-002) (10, 3.06172854740084240000e+000) (11, 2.76238459460057590000e-001) (12, 3.03481814660922120000e+000) (13, 2.08256515464259630000e-001) (14, 1.32580220891958620000e+000) (15, 2.58496335703856990000e-001) (16, 3.14845340220876850000e+000) (17, 2.16055214504111750000e-001) (18, 6.90526843291116240000e-001) (19, 2.26862402527549020000e-001) (20, -1.35689559947016480000e-002) (21, 1.19006587531547820000e-001) (22, 3.06397464118431180000e+000) (23, -1.57460273914639090000e-002) (0, -3.21130740705161610000e+000) (1, -2.28511005010039510000e-001) (2, -1.07922958380283740000e+000) (3, -2.34638874040804380000e-002) (4, -2.82154804637519410000e-001) (5, -1.07361053145370210000e-001) (6, -3.07211062763367250000e+000) (7, 7.31157250947863100000e-002) (8, -2.30148448324320220000e+000) (9, 7.22910832953912590000e-002) (10, 3.19579837361738850000e+000) (11, 3.06884211869839880000e-001) (12, 3.17167117599224020000e+000) (13, -2.12248599587278260000e+000) (14, 1.20169447948605960000e+000) (15, 2.01825192281266160000e-001) (16, 1.98777384470525660000e+000) (17, 7.23283715674288290000e-002) (18, 1.99147257522912200000e+000) (19, 1.94835473184344830000e-001) (20, -3.74183736915653100000e-001) (21, 4.75542012763899290000e-002) (22, 3.08073489534030910000e+000) (23, -1.80475067906728930000e-001) (0, -3.97110341666958360000e-001) (1, 5.01553564750037100000e-001) (2, -6.98530752731119090000e-002) (3, 5.09475928149339510000e-001) (4, 9.78624941010694300000e-001) (5, 4.80282812479953250000e-001) (6, -1.78960872017032770000e+000) (7, 3.76260594133026430000e-001) (8, -1.76751923319999750000e-001) (9, 7.56350425409606510000e-001) (10, 3.09863650693518890000e+000) (11, 7.69927479239902900000e-001) (12, 9.24642414236277910000e-001) (13, 5.71110014690322740000e-001) (14, 1.99904703823261530000e+000) (15, 5.58278348554289040000e-001) (16, -1.02106108571971690000e-001) (17, 4.13900975553286810000e-001) (18, 9.38191162771380820000e-001) (19, 4.66238622817553520000e-001) (20, -2.53645777653457580000e-002) (21, 4.82846289080652020000e-001) (22, 5.79302593846367180000e-001) (23, 4.56131200791941190000e-001) (0, -2.44403530914540310000e-001) (1, -2.76676309002519410000e-002) (2, -1.54470520992774360000e-001) (3, 1.93387076429369980000e-001) (4, -8.74114597501219670000e-001) (5, 1.29762194788417550000e-001) (6, -3.22939983418326970000e-001) (7, -1.49664703030649960000e-001) (8, -1.66633405103602690000e+000) (9, -1.37021284125818850000e-001) (10, 6.21632619088184900000e-001) (11, 3.84391993972367060000e-001) (12, 5.39717799545299300000e-001) (13, 2.99195791063174840000e-001) (14, -1.20090202218871040000e-001) (15, -3.41667930358889930000e-001) (16, 7.04372343014468160000e-001) (17, -1.13684534826050510000e-001) (18, 4.07084044541062450000e-001) (19, 3.04743886848972910000e-001) (20, 1.79316197358910300000e-001) (21, 1.55431958696431530000e-001) (22, 2.13946741469614200000e-001) (23, -2.73889615338292200000e-001) (0, -2.20969371039103810000e+000) (1, 4.49916684852019800000e-001) (2, -8.63750827815537470000e-001) (3, -2.79592849090875890000e-001) (4, -8.05655769244408400000e-001) (5, 1.61591203621007650000e-002) (6, -3.03541629114938430000e+000) (7, 4.09462582686706710000e-001) (8, -2.28163585013493450000e+000) (9, 7.75948120825875610000e-001) (10, 3.08402469031120590000e+000) (11, 5.51809762165633040000e-001) (12, 3.08011233673728220000e+000) (13, 1.36720032481355500000e-001) (14, 3.13194339219712510000e+000) (15, 3.69057308647121220000e-001) (16, 1.17943588889252430000e+000) (17, 3.19495166988480240000e-001) (18, -8.21062042759985590000e-002) (19, 2.58790889358457680000e-001) (20, -1.26850938131631930000e+000) (21, 2.53905532247382490000e-001) (22, 3.14687259163833750000e+000) (23, -1.57035026435006750000e-001) (24, 5.21222783527788280000e-001) (25, 2.28122916794225360000e-001) (26, 5.06253271851318190000e-001) (27, 2.18421864078299550000e-001) (28, 2.09137792888431760000e-001) (29, 3.65835789290184730000e-001) (24, 2.46448404436830710000e-002) (25, -3.55537347102440340000e-002) (26, 4.93136816577742720000e-001) (27, -3.39376751241378890000e-001) (28, 1.96421567296111150000e-002) (29, 4.20138768614987170000e-001) (24, -4.73006911754777220000e-001) (25, -1.86779280956142300000e-001) (26, 1.90770399527879080000e-001) (27, -8.55866071127402710000e-002) (28, -4.18701488639502570000e-001) (29, 6.65541662328731460000e-001) 

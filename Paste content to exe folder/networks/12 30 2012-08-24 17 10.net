FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.17036092261441530000e-001) (1, -1.67708510670132430000e-001) (2, -3.45524989429021320000e-002) (3, 2.82496085563128440000e-001) (4, -9.68953643879157110000e-003) (5, 2.34266757136323890000e-001) (6, 3.50722486334421100000e-001) (7, -2.41044302069022140000e-002) (8, -2.55769001504740750000e-001) (9, -1.35040865073770280000e-002) (10, 2.70252823668194480000e-001) (11, -2.35395213100869640000e-002) (12, 4.52327573559819840000e-001) (13, -7.46614612350736530000e-002) (14, 7.63370598824735510000e-002) (15, 3.48924698759561720000e-001) (16, 4.71950376586597390000e-001) (17, 2.83515372687692000000e-001) (18, -7.33760771140510300000e-002) (19, 5.66334233539482310000e-001) (20, 7.91302339472788940000e-001) (21, 2.04157461348916960000e-001) (22, -4.14251219596471540000e-001) (23, 1.95703240484108420000e-001) (0, 6.67799963143632770000e-001) (1, 5.59900137200134650000e-001) (2, -3.63942285481491520000e-002) (3, 3.37625008296386860000e-001) (4, 3.55650207271302140000e-001) (5, 3.92702486281299890000e-001) (6, -8.45062848310172140000e-002) (7, 2.21393652446058300000e-001) (8, 1.57739266657776180000e+000) (9, 1.02936875880284790000e+000) (10, 6.37732192577900450000e-002) (11, 1.51396808684365530000e-001) (12, 4.10994939033847370000e-001) (13, 2.41888420523098450000e-001) (14, 3.44798782734799300000e-001) (15, -2.47008155045457230000e-001) (16, -6.49208678563232280000e-002) (17, 5.79478163680990500000e-002) (18, 3.06218459894282700000e-001) (19, -5.44663123158725890000e-001) (20, 1.97368723113906410000e-001) (21, 3.79370112024860260000e-001) (22, 5.45136007684783540000e-001) (23, -2.54942725476191570000e-001) (0, -2.31378306741084040000e+000) (1, -4.90048932358749110000e-002) (2, -5.08725690449554490000e-002) (3, -1.51255635104034350000e+000) (4, 1.82393215323773560000e-001) (5, 1.52275693173588360000e-001) (6, 6.19796729726988960000e-001) (7, 5.31159667456290730000e-002) (8, -3.03329837119594980000e+000) (9, -1.40775451753804990000e+000) (10, 3.03523318567790580000e+000) (11, -2.11848777137355450000e-001) (12, 9.10542743501811190000e-001) (13, -2.76442100693214900000e-001) (14, 7.31682849763763520000e-001) (15, 3.20854885266645130000e-001) (16, 6.46066009501251590000e-001) (17, -1.15310167261793640000e+000) (18, -4.53557252873909130000e-001) (19, -7.05041708152731820000e-001) (20, 6.91072853184408360000e-001) (21, 3.08303345962681390000e-001) (22, 2.66829889007794210000e+000) (23, -1.06760537838007230000e+000) (0, -2.17865494241324450000e-001) (1, 8.42812510994865180000e-002) (2, 1.20578859062238020000e-001) (3, 5.46509756827560980000e-001) (4, 5.07314146644808560000e-001) (5, 5.18084628906866910000e-002) (6, -1.93035987158406140000e-002) (7, 1.02553541338346810000e-001) (8, -2.24770568562763230000e-002) (9, 5.51882018402671590000e-001) (10, 1.18018662132558600000e+000) (11, -2.73785500080417560000e-002) (12, 1.47788985266348210000e-001) (13, 1.09960273641709360000e-001) (14, 9.39904266540173010000e-002) (15, 3.35631241530223780000e-001) (16, -7.47168912525254520000e-002) (17, 2.35697379797718650000e-001) (18, -2.46161084192530800000e-001) (19, 1.02068997707750740000e-002) (20, 1.48040193831966150000e-002) (21, 8.46589598906411170000e-001) (22, 1.89104893155534140000e+000) (23, -5.15484722432016580000e-002) (0, 1.61028757824017270000e-001) (1, 6.97664579242639690000e-001) (2, -3.27236683276065140000e-001) (3, -5.13558569664334520000e-002) (4, 3.11976077482809000000e+000) (5, -2.85062636655906530000e-001) (6, -3.56659227935528180000e-001) (7, 7.59512046550468330000e-001) (8, 2.71049859773801670000e+000) (9, 2.77674139489034190000e-001) (10, 1.95474772116625410000e+000) (11, 7.02192637905926900000e-001) (12, 2.86071498279982960000e-001) (13, -1.11164224427064750000e+000) (14, 7.20032171409556780000e-001) (15, 8.23740862633288160000e-002) (16, -3.93214421986979260000e-001) (17, -1.66953425549045380000e+000) (18, 5.20748801680471770000e-001) (19, 1.22791300844047010000e+000) (20, -1.26220397825980290000e+000) (21, -1.49789337331329820000e-001) (22, 2.66535699550285440000e+000) (23, -5.10233146068949230000e-002) (0, 5.56661955507130270000e-001) (1, -1.06140793558237360000e-001) (2, -2.55219429666704440000e-002) (3, 1.30374575486280900000e-001) (4, -4.95457006462517950000e-001) (5, -7.12440855457214110000e-002) (6, 1.93749234381992570000e-001) (7, -1.13421129147707280000e+000) (8, -1.02433227482337310000e-001) (9, -1.05908124873644960000e+000) (10, 5.76184952496027750000e-002) (11, -4.06213694957895390000e-001) (12, 7.67935315184191390000e-003) (13, -1.96559443274730540000e-002) (14, 1.20069223043123840000e-002) (15, 1.71044751897830280000e-001) (16, 6.70461752254765790000e-001) (17, -1.79408992794713310000e-001) (18, 3.12369118801850370000e-001) (19, -6.86904077471087060000e-001) (20, 7.98356874782002900000e-001) (21, -2.56007686348078380000e-002) (22, -1.28562120584263130000e+000) (23, 3.12202524341209320000e-001) (24, 4.04027512391023520000e-001) (25, -2.64075829453225330000e-001) (26, 8.05880704981279510000e-001) (27, 3.96015407108060490000e-001) (28, -5.28617723176180720000e-004) (29, 7.61343223991695070000e-003) (30, 3.25511886221049540000e-001) (24, -4.62982471707367950000e-001) (25, 4.81358888569027140000e-001) (26, 9.68983858294293200000e-002) (27, 2.04316495482448260000e-001) (28, 7.86015566004353070000e-001) (29, -4.52624022902645860000e-001) (30, 6.53718516089856210000e-001) (24, 9.78169678653613290000e-002) (25, -2.83393680432765580000e-001) (26, -1.08735273353272750000e+000) (27, -6.57216215632863560000e-002) (28, -1.34425964354502760000e+000) (29, 6.59301381334223890000e-001) (30, 1.20908555342725290000e+000) 

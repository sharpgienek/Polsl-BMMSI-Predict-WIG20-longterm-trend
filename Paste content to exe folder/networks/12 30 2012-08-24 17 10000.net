FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.60683331460149410000e+000) (1, 7.96626222823455300000e-001) (2, 7.60790517964204580000e+000) (3, 1.92312996860667830000e+000) (4, 2.51752936121736040000e+001) (5, 7.01902589771348670000e-001) (6, 2.63405610301515610000e+000) (7, 9.66861946815133380000e-001) (8, 6.52402602274180230000e-001) (9, 1.11807305954612700000e+000) (10, 4.41009582769050750000e+001) (11, -2.25419926276533840000e-002) (12, 1.26544097526765030000e+000) (13, -7.11571666939167510000e-001) (14, -1.54342995438734840000e+001) (15, 2.71867799653070910000e+000) (16, 1.26866601023995920000e+000) (17, -2.27466521051548700000e+000) (18, -3.69646089527844830000e+000) (19, -6.42335091922326520000e-001) (20, 8.82878739878393710000e-001) (21, 5.15069536489872170000e+000) (22, 3.72360780638666280000e+001) (23, -1.29783560757535630000e+000) (0, -4.09861339684156650000e+001) (1, 1.81518750799744390000e-001) (2, 9.11969830303212880000e-001) (3, -1.84312502144866960000e+000) (4, -1.20424103053666900000e+001) (5, -9.95716952484861810000e-001) (6, 2.61539583655520590000e+000) (7, 2.02231785293612280000e+000) (8, -7.97401854363072890000e+000) (9, 6.18751734638622520000e+000) (10, 6.92636798770695780000e+001) (11, 5.61496413292489780000e-001) (12, 3.41356632134806120000e+001) (13, 1.15692080171033980000e+000) (14, 2.87202334279088700000e+001) (15, 4.00271801850201560000e-001) (16, 1.52899261338588440000e+000) (17, -6.22775004925243450000e+000) (18, 2.87900011391016370000e+001) (19, -1.15099893673214430000e+000) (20, 2.87020012413389790000e+000) (21, 1.65755515300415010000e+000) (22, 6.73911394174846950000e+001) (23, -4.15176657880912800000e+000) (0, -1.01209993498475900000e+001) (1, 9.22511657650103340000e-001) (2, 6.90392082946398530000e-001) (3, 1.95684025343090330000e+000) (4, 7.18155781312047600000e-001) (5, 1.51826761831934970000e+001) (6, 7.24544757110449780000e+001) (7, -1.61050768003161690000e+000) (8, 9.15038915217195950000e+001) (9, 1.40053122137112900000e+000) (10, 3.81304681120038720000e+000) (11, 6.41435726173505750000e-001) (12, -2.39505132628461120000e+001) (13, 2.38138235329287040000e+000) (14, 6.64968718598305970000e-001) (15, 3.98827027290458380000e-001) (16, 1.13432921775107380000e+001) (17, 7.11494601766363120000e+000) (18, 8.28660227014736390000e+001) (19, -3.20109583345962900000e-001) (20, 1.27612267197123460000e+000) (21, 3.93621747369159890000e-001) (22, -7.41887578035234880000e+000) (23, 2.57385162139853830000e+000) (0, -1.40401036986789610000e+000) (1, 1.97985300233804690000e-002) (2, 3.26630729019915190000e-001) (3, -7.38078521806214000000e-002) (4, -4.76638792441263260000e+000) (5, 1.32487476392114580000e-001) (6, 2.77275957097916640000e-001) (7, 1.96963238381169220000e-001) (8, -2.30967118362050710000e+000) (9, -7.11389126982150510000e-001) (10, -1.21380079183636660000e+001) (11, -1.78897903027203320000e-001) (12, 7.06149361819150470000e+000) (13, -5.88375476140729600000e-001) (14, 8.35565291062594360000e+000) (15, -1.88071190462853560000e-001) (16, 2.55249105731950320000e+000) (17, -8.10693811289421310000e-001) (18, 9.06100397016727510000e-001) (19, -4.66794141191659520000e-001) (20, 7.47631290309150740000e+000) (21, 3.00986697203581570000e-001) (22, 1.65678700569130650000e+001) (23, 3.89786769176615200000e-001) (0, -1.84808307439306260000e-001) (1, -2.96792722116924870000e-001) (2, -2.94993778465977960000e-002) (3, 2.69080514581318120000e+000) (4, -1.21583033550358850000e+001) (5, -3.20419896284846960000e-001) (6, 1.44703153559288020000e+000) (7, -1.06202964210393500000e+000) (8, -9.19515127506451590000e-001) (9, -1.66541175811182600000e+000) (10, -6.55868575836907390000e+000) (11, -1.49500698857315610000e+000) (12, 2.68532565146402200000e+000) (13, -3.89757637181122770000e-001) (14, -5.82114076494698910000e+000) (15, 8.24050510121552840000e-001) (16, -1.25366351889337630000e+001) (17, 8.30063054506037790000e-001) (18, 3.68788731056401490000e+000) (19, -3.81255902960967810000e+000) (20, 7.28865187946022530000e+000) (21, 2.37590477013250560000e+000) (22, 4.30445417356373740000e+000) (23, 1.60014737304167220000e+000) (0, 6.21899406240419150000e+000) (1, -5.68562331968784250000e-001) (2, -1.73981936793662870000e+000) (3, 1.81811534272097620000e+000) (4, -7.12214377121709230000e+000) (5, 6.73147614933425790000e-001) (6, 1.43999849454266830000e+000) (7, -1.24322176281837240000e+000) (8, -9.51592574201859500000e-001) (9, -4.90361466704048880000e+000) (10, -3.31960239219855910000e+000) (11, -1.73051478465902430000e+000) (12, 5.27533118573633290000e+001) (13, -2.14013417947342300000e-001) (14, -6.00193498001032830000e+000) (15, 9.21139866485549800000e-001) (16, 1.06352000500002510000e+000) (17, 2.66278313616348640000e+000) (18, 2.57634155060198040000e+001) (19, 1.01136493225886630000e+000) (20, 2.38218152409023750000e-001) (21, 1.05927542501618130000e+000) (22, -6.12451765132199100000e+001) (23, 2.18730649296099070000e+000) (24, -1.67525709699233440000e-002) (25, 2.89082838771506930000e+000) (26, -2.64782633419499370000e-001) (27, 1.46353008995946390000e-002) (28, 9.14476371195507930000e-004) (29, 6.75548114810204520000e-002) (30, 3.08681202218581600000e+000) (24, 3.33619515995464160000e+000) (25, -3.71400464248093420000e-001) (26, 1.03629678512711170000e+000) (27, -5.15958073150245240000e+000) (28, -1.34611319261510310000e+000) (29, -2.98538884540808660000e+000) (30, 1.14586342898384540000e+000) (24, -4.00281830604628120000e+000) (25, -1.79134937060276010000e+000) (26, 1.39862994412471720000e+000) (27, 4.24212605699738620000e+000) (28, 2.84618803514285810000e+000) (29, 2.09034223570066450000e+000) (30, 2.06073252692990130000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.14551711979430930000e-001) (1, -1.04832138021726930000e+000) (2, 3.46928849120446250000e-001) (3, 1.53070954372153010000e-001) (4, -3.10218465206725970000e-001) (5, -1.69080093123740340000e-001) (6, 1.33059638023746210000e-001) (7, -9.91308439914585390000e-001) (8, 1.05298782154051530000e-001) (9, -5.48653158780853630000e-001) (10, -3.43384759697256680000e-001) (11, -2.71193077177498350000e-001) (12, -8.25491834296400160000e-001) (13, 1.01094296711146180000e+000) (14, -4.47857768299296450000e-002) (15, 3.56303283452908740000e-001) (16, 3.13339602893752110000e+000) (17, 5.08305285035318580000e-001) (18, -4.00226801559894100000e-001) (19, -3.55789829328669540000e-001) (20, 1.21098496162826710000e+000) (21, 2.86772141634233590000e-001) (22, -1.00573715106708980000e+000) (23, -4.00550255016484110000e-002) (0, -5.95789059791539950000e-002) (1, -9.56567228459400900000e-001) (2, 1.99730360598892900000e-001) (3, 2.79386379500369130000e-002) (4, -1.22211900214985960000e+000) (5, 1.20024428888265620000e-001) (6, 4.90683583362590880000e-001) (7, 1.63783021165875510000e-001) (8, 3.29691954931369050000e-001) (9, -8.93251666469489950000e-001) (10, -1.08648666398910130000e+000) (11, -4.69056638523482340000e-001) (12, -3.01633670102132620000e+000) (13, 1.21783920977727830000e+000) (14, 2.74474437153496120000e-001) (15, -7.47423239816486840000e-001) (16, 1.05849199225794300000e+000) (17, 7.03171618482573590000e-001) (18, -1.00468421931518890000e-001) (19, -2.56220966360450110000e-001) (20, 1.10015121974234060000e+000) (21, 3.22135911692444820000e-001) (22, -9.11785733651479640000e-001) (23, 3.91968005791500870000e-001) (0, 6.89556384292280280000e-001) (1, 1.35513251341557890000e-001) (2, -4.05810862920642720000e-001) (3, 4.03396090437951600000e-001) (4, 2.12185615765315140000e-001) (5, 5.18087875123677930000e-001) (6, 2.05360228946377510000e-001) (7, 5.07322894006581480000e-001) (8, 1.51736396114551590000e-001) (9, 1.71290381071048660000e-002) (10, -2.97525290071648410000e-001) (11, 2.42264328952730700000e-001) (12, -1.46037973923225150000e-001) (13, 3.41072543350047770000e-001) (14, -6.66853506165341340000e-002) (15, 4.72858669971864320000e-001) (16, -3.95316197105158310000e-001) (17, 3.20254633215460770000e-001) (18, 4.67621597693362370000e-001) (19, 2.62698928040190850000e-001) (20, -3.14780435674062110000e-001) (21, 1.34080142546480490000e-003) (22, 2.30524123103505950000e-001) (23, 1.00798814324987700000e+000) (0, -6.56491072327225370000e-001) (1, 2.86047572874961800000e-001) (2, 1.89897347698798000000e+000) (3, 2.56303596197303250000e-001) (4, -1.09976791418700740000e+000) (5, 3.72774686331906080000e-001) (6, 3.20635745580598110000e+000) (7, 2.63777626409079480000e-001) (8, -1.04699319768303710000e-001) (9, 5.29770090277878190000e-002) (10, 3.77550248066584160000e-001) (11, -5.14303681883735210000e-001) (12, -3.04855105697010750000e+000) (13, 6.90752790819604280000e-001) (14, 1.15516831040590920000e+000) (15, 1.41361314801253050000e+000) (16, -1.20827988823132990000e+000) (17, 1.61355153542684320000e-001) (18, 5.24146732910839570000e-001) (19, 8.15801916438602890000e-001) (20, -3.20382610333344140000e-001) (21, 3.07342765442484710000e-002) (22, -8.46360373953643910000e-002) (23, 6.89011476785786670000e-001) (0, 1.72150624934477940000e-001) (1, -4.05102049538263290000e-001) (2, -1.05237411465265970000e+000) (3, -1.92456469605828520000e+000) (4, 1.14474960907878340000e+000) (5, -3.17290488589387740000e-001) (6, -1.77269701801403050000e+000) (7, -2.32321299919198230000e+000) (8, -1.21925438503270980000e-001) (9, -1.56861962461365740000e-001) (10, 4.56175678428718370000e-001) (11, -5.27618283210551380000e-003) (12, 1.07296005722778580000e+000) (13, -8.87524021529160660000e-001) (14, -7.84518133126046570000e-001) (15, 2.01134358253637760000e-001) (16, 1.95216343441914340000e+000) (17, -4.60090643686637600000e-001) (18, -5.36485720906514580000e-001) (19, -4.67348629371078680000e-001) (20, 1.18202988307180280000e+000) (21, 2.47082424683839230000e-001) (22, 6.88156277929197870000e-001) (23, -5.90677878216041340000e-001) (24, 1.71488496490322440000e-001) (25, -2.85014847147746720000e-001) (26, 5.31410677344602460000e-001) (27, -2.96435342792324030000e-001) (28, 6.34391114643754860000e-001) (29, 3.78853302024445390000e-001) (24, -4.47708776010868560000e-001) (25, -4.55338170655805400000e-001) (26, 3.08934463788660800000e-001) (27, 2.78582130043848600000e-002) (28, -2.56267188386552600000e-001) (29, 2.16008437013330110000e-001) (24, 3.20475977394944210000e-001) (25, 8.73463378603736680000e-001) (26, 4.00973729266905830000e-001) (27, 1.76407606155747850000e-001) (28, -2.01005017829978260000e-001) (29, 6.99391631907040790000e-001) 

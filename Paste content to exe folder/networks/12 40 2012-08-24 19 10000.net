FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.71533662888463460000e+001) (1, 1.28674358352128310000e+001) (2, 2.41955036296900120000e+000) (3, -3.66826244945521650000e+001) (4, 1.65542040941407010000e+002) (5, 4.31672146550438170000e-001) (6, -1.52095893922168710000e+000) (7, 9.51939369760798650000e+000) (8, 1.43428486062075020000e+002) (9, -1.01614165349200980000e+001) (10, -4.40182515737601700000e+002) (11, 1.54693174225418860000e+001) (12, 2.78890281872854700000e+002) (13, -1.09779407683793010000e+002) (14, -2.30065426679703900000e+002) (15, 6.33834925546139160000e+001) (16, -1.47680187389710250000e+003) (17, 9.71661104748141930000e-001) (18, 7.63287411846662390000e+002) (19, 1.26542188270725740000e+001) (20, -1.50000000000000000000e+003) (21, -1.59175303648833730000e+001) (22, 1.33700552242587490000e+002) (23, -9.83237916571857110000e-001) (0, 9.62198117070055400000e+000) (1, 1.50150806682436230000e+000) (2, 1.98658774663027840000e+001) (3, 1.85834278356556030000e-001) (4, 8.00763458260764520000e+000) (5, -9.04401987166530750000e-001) (6, -1.85612624185892550000e+001) (7, 5.04452425498092440000e-001) (8, -5.36679058987243970000e+000) (9, -3.33524869278274270000e+000) (10, -1.24164607631133150000e+001) (11, -9.78049808636391680000e-001) (12, -5.86314947978765060000e+001) (13, 1.49544863751849390000e+000) (14, 1.36182912857343470000e+002) (15, -1.40295147216743970000e-001) (16, 5.04408033087881830000e+001) (17, -1.09054422393231310000e+000) (18, -4.64818070267567550000e+001) (19, 3.45513867245597740000e-001) (20, 1.37266849289365920000e+001) (21, 1.30892358779631150000e+000) (22, 1.10654593810327240000e+002) (23, -5.19335910146263750000e+000) (0, -9.21478263684238640000e+000) (1, -1.97385731746138030000e+000) (2, -1.07865274711389300000e+001) (3, -1.81516432570359810000e+000) (4, -5.97719011929284250000e+001) (5, 6.86391681414503130000e-001) (6, 2.22289969303247890000e+000) (7, 5.63823626505212120000e-001) (8, 9.61425113603829540000e-001) (9, -1.08317049600515420000e+000) (10, 1.04395304022112030000e+002) (11, -1.22173036309247760000e+000) (12, 1.42741189056045190000e+002) (13, -5.22389689719342080000e-001) (14, 1.20509979459115330000e+001) (15, 9.71344735483012920000e-001) (16, 2.36238459401476780000e+001) (17, 6.06446741691972550000e-001) (18, 1.66468883696613230000e+001) (19, -3.30938582599224480000e-002) (20, -3.69294665826879940000e+001) (21, 1.79079419583225260000e+000) (22, -1.07795085132596480000e+001) (23, -2.00093529859360460000e+000) (0, -3.15524828007154240000e+001) (1, -2.03150120589163260000e+000) (2, -8.88799247943689790000e+000) (3, -1.08095224491167350000e+000) (4, -6.35128613871642860000e+001) (5, -1.60421193012174480000e+000) (6, 2.06236696217568220000e+000) (7, -7.62647386435944990000e-001) (8, 3.68755132104324760000e-001) (9, -1.38799868450392160000e+000) (10, 6.59339011034153230000e+001) (11, 1.07016866097586250000e+000) (12, 9.09467094043093310000e+001) (13, 1.25826005130386130000e+000) (14, -1.41065864565197470000e+002) (15, 2.97076103120023140000e-001) (16, -8.47801925572039890000e+001) (17, 1.57412904840996710000e-001) (18, -2.83881978160406450000e+001) (19, -9.01520692776353940000e-001) (20, 6.01142067533935030000e+001) (21, 2.95016801656101530000e+000) (22, 2.31972735609898600000e+001) (23, 2.36606541978596940000e+000) (0, 7.93196784297904060000e+000) (1, 7.33563830192049690000e+000) (2, 1.20620147116602140000e+000) (3, 5.07084157254489810000e+002) (4, 3.19042181453057300000e+001) (5, 2.12594256434685520000e+000) (6, 1.76184858011000700000e+000) (7, 6.80619428150944740000e+000) (8, -5.91535949724064470000e+000) (9, -5.41044152419969660000e+000) (10, 2.14252957292732750000e+000) (11, 2.69734090261588800000e+001) (12, 4.49718816372210950000e+001) (13, 8.65994611205488240000e+001) (14, -4.36078009398863800000e+002) (15, 3.91827841419635270000e+000) (16, 4.35864238314621040000e+000) (17, 8.06561873781182470000e+001) (18, -1.33676168631816290000e+003) (19, 4.14457969121073780000e+000) (20, 3.41381942760803550000e+001) (21, 3.98976303619554920000e+000) (22, -6.98072750151102350000e+001) (23, 8.83048278713688010000e+001) (24, 2.61171949204536920000e+000) (25, -6.42238583463020540000e-001) (26, -8.58924408027257470000e-002) (27, 2.64535240196122420000e+000) (28, 9.54481999600611740000e-003) (29, -6.87941951409775320000e-001) (24, -5.12468938290991240000e-002) (25, 3.49003901745656900000e+000) (26, 1.24580460602438950000e-001) (27, -3.28851402412426270000e+000) (28, 3.19315845892912040000e+000) (29, 3.52982474762030840000e+000) (24, -2.52930535609767080000e+000) (25, -3.14269849095320590000e+000) (26, -9.44152813985102310000e-001) (27, 9.07389563283619750000e-001) (28, -2.71063021136534400000e+000) (29, 2.07776919077486120000e+000) 

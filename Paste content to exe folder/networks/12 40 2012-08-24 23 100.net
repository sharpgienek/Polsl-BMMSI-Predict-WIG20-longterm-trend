FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.00122660007423510000e-001) (1, 5.84625242348987610000e-001) (2, 1.23533447925643180000e+000) (3, 4.24829639225497990000e-001) (4, 2.51826938413463890000e+001) (5, 4.88064167079440000000e-001) (6, -2.08674285868751540000e+000) (7, 4.67167305993421710000e-001) (8, -5.37504450375811960000e+000) (9, -8.67732025329824410000e-001) (10, 6.87186625323849110000e+001) (11, 7.89377554472400660000e-001) (12, 1.65930731627364350000e+001) (13, 1.13438589926860780000e+000) (14, 1.34462046677869830000e+000) (15, 5.12488105693604480000e-001) (16, -4.19178839183070700000e-001) (17, 3.24977217988795970000e+000) (18, 7.32694062886924780000e+000) (19, 8.53655989473763640000e-001) (20, -2.18176127841229640000e+001) (21, 2.57817187320693270000e-003) (22, 3.64812692951729800000e-001) (23, 6.94242019267563460000e-001) (0, -9.38987118089179010000e-001) (1, -3.95050190503539600000e+000) (2, -1.56507974380267230000e+001) (3, -1.48998118226617790000e-001) (4, -4.27581280210451300000e-002) (5, -4.54737665158427220000e-002) (6, 1.10403924809877850000e-001) (7, 1.80568350010738650000e-003) (8, -1.11862145678172940000e+000) (9, -6.41315268198948240000e-001) (10, 1.80497702871769870000e+000) (11, 3.80708659962824130000e-002) (12, 2.70924166413186210000e+001) (13, 3.93856893041886310000e-001) (14, 4.26075096907462920000e-001) (15, 6.00744026847330410000e-001) (16, 2.58321117005046950000e-001) (17, -1.44533762359872890000e-001) (18, 4.59450360766278880000e-001) (19, 1.00361413200815740000e-001) (20, 3.35839485038767240000e+000) (21, 6.06239995820275100000e-001) (22, 7.49698499830241530000e-002) (23, -2.91302372753687090000e-001) (0, 4.45321805196602860000e-001) (1, 1.47653099632858510000e+000) (2, 1.52785831980180430000e+000) (3, 1.96280151236045900000e-002) (4, 6.32181159132659040000e-001) (5, -6.50053688774149150000e-001) (6, -1.97971615008289410000e+000) (7, 7.73099996272833430000e-001) (8, -1.34511433746296940000e+001) (9, 1.63810836625344660000e+000) (10, 2.77034195993992930000e+001) (11, 2.22984556193846340000e+000) (12, 2.03318916501728180000e+001) (13, 6.71999016473130760000e-001) (14, 4.43611226320505030000e+000) (15, 4.49148613836113760000e-001) (16, -1.06512541026540430000e+001) (17, -1.85789576161237310000e-001) (18, 1.69085405786056260000e+000) (19, -1.12699125469243280000e+000) (20, 1.11737367010480120000e+000) (21, -3.75629107305085060000e-002) (22, 3.44475111146142370000e+001) (23, -1.85701759645167130000e+000) (0, 1.66860380141471580000e+000) (1, 7.00437200607763320000e-002) (2, -8.63387634100853170000e-001) (3, -2.61410292260830460000e-001) (4, -2.26919536018210130000e-001) (5, 4.82273038934737500000e-001) (6, -1.43993454965258350000e+000) (7, -6.57246847129429930000e-001) (8, 2.72020156559728000000e+000) (9, 7.76618168239909700000e-001) (10, 1.19584358964574960000e+001) (11, -1.41287071927188900000e-001) (12, 1.01964193035093900000e+000) (13, 2.00147406900952650000e+000) (14, -4.30026126746313300000e+001) (15, 2.65749196369146690000e+000) (16, -1.52796183202715530000e+001) (17, 1.01722603002408940000e+000) (18, 4.69353891828143420000e+000) (19, 1.85156121269547410000e+000) (20, 3.23894056477361310000e+000) (21, 1.08508594921279050000e-001) (22, -5.63567172439363660000e+001) (23, 2.19289875106290250000e-001) (0, 2.99492233562254120000e+000) (1, 1.04266581139067040000e+000) (2, 4.96950480691238190000e+000) (3, 7.04081016059345140000e-001) (4, 3.14175656889619900000e+000) (5, 3.51175002524622410000e-001) (6, 4.78779074621926080000e+000) (7, 1.54116700522664950000e+000) (8, -3.22119152892476630000e+001) (9, -1.06651315900749970000e+000) (10, 5.08196388600435820000e+001) (11, 3.40946416128340760000e-001) (12, 4.40020398122476130000e+000) (13, -1.45225826474012410000e+000) (14, 1.95780641794728500000e+001) (15, 4.74647915448339900000e-002) (16, 1.33720146757317610000e-001) (17, -1.15933972559761880000e+000) (18, -2.10506865539234810000e+000) (19, -4.59620201312094130000e-001) (20, -3.74354435011447430000e+000) (21, 4.13371378852073760000e-001) (22, 5.42000356841128690000e+001) (23, -3.56288886543887710000e+000) (0, 1.44576257590155600000e+000) (1, 1.28579599087998790000e+000) (2, 9.79698176158996680000e+000) (3, 1.53824271909720830000e+000) (4, -3.37151444149440450000e+000) (5, 4.30164787838536660000e-002) (6, 1.25921021241850920000e+000) (7, 1.63672172522493580000e+000) (8, 2.19766023512576990000e+000) (9, 7.44528649168170300000e-001) (10, -2.19809326802207540000e+001) (11, 6.28161970948178660000e-002) (12, -4.12985452469211010000e+001) (13, 2.06944569971464880000e-001) (14, 3.95147062430346720000e+000) (15, -2.28267565485889500000e-001) (16, 2.41890688738245870000e-001) (17, 1.30661934832061410000e+000) (18, 3.28150849713748590000e+000) (19, 8.43221108348068520000e-001) (20, -1.59272096629309650000e+001) (21, -5.84515424837592220000e-001) (22, -3.04907982043550480000e+001) (23, 7.78917983947495780000e-001) (24, 6.92599633023761600000e-001) (25, 2.37382814423403890000e-001) (26, 6.11639767791968820000e-001) (27, 3.93753065262293980000e-001) (28, -4.58005881651373680000e-001) (29, -1.70785948985908640000e+000) (30, 7.77946962202448410000e-001) (24, 7.43450802106021440000e-001) (25, 1.69971179674679360000e+000) (26, 1.27994540268189020000e+000) (27, -8.38859869658673430000e-001) (28, 1.10664149628420390000e+000) (29, 2.41059413210346960000e+000) (30, 5.30476742354492050000e-001) (24, -3.47284884300888270000e-001) (25, -1.27303211402442340000e+000) (26, -1.14792099331118510000e+000) (27, 1.00481170926309950000e+000) (28, -1.20455468574969670000e+000) (29, -1.05543995529802660000e-001) (30, 5.51455209369290930000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.43405373593934640000e+000) (1, 1.96996369160498360000e+000) (2, 9.19605051906692390000e-001) (3, 1.27248100677390500000e+000) (4, 4.91795456883566210000e+000) (5, -5.48386441325582340000e-001) (6, -2.48253458868762920000e+001) (7, -8.45796853317929530000e-001) (8, -4.54733844082165910000e+000) (9, -3.64518135572353240000e-001) (10, -7.65242798153060730000e-001) (11, 1.24562623083455680000e-001) (12, -2.19546147406640240000e+001) (13, 2.88263218235002940000e+000) (14, 2.08584588778306030000e+000) (15, 8.64853002679617230000e-002) (16, -2.27287282400688540000e+000) (17, 1.26308349884764630000e+000) (18, 1.23504800117525380000e+001) (19, 1.78240440301816090000e+000) (20, -1.99771479505609900000e+001) (21, -7.82129915045872260000e-001) (22, 3.09184329014518160000e+000) (23, 6.47300330091624910000e-001) (0, 3.20415870300362230000e-001) (1, -3.45267588448306300000e-001) (2, -3.85669932958011910000e+000) (3, -2.88083352215775920000e+000) (4, 1.55917488402323910000e+000) (5, -1.77004103104250550000e-001) (6, -1.54114576312777080000e+001) (7, -8.65359654507102060000e-001) (8, 2.59323249629146810000e+001) (9, 4.96041304373872500000e-001) (10, 3.78059582690697410000e+001) (11, 3.80906436063801420000e-001) (12, 2.25638494979552850000e+001) (13, 3.10856288295382250000e-001) (14, 1.82061936915496820000e+001) (15, 6.10244798866689590000e-001) (16, 1.25730184092999520000e+001) (17, -8.82850147292186690000e-001) (18, 2.36116652213512670000e+001) (19, 5.19895335064753610000e-001) (20, 7.17162149451985090000e+000) (21, 1.09465369488412920000e+000) (22, 3.49981111451807510000e+001) (23, -1.09262348039079420000e+000) (0, 9.98736680891142310000e-001) (1, 2.89313489660848470000e+000) (2, 7.63832660500316680000e+000) (3, 3.82694972149749280000e+000) (4, -9.80555121527722400000e-001) (5, 7.82543152793723330000e-001) (6, -4.77843257553990770000e+000) (7, 9.74836409446440120000e-002) (8, 2.01353800847511130000e+000) (9, -2.97754897715830140000e-001) (10, 7.07501690646604690000e+001) (11, 1.71662363804693740000e-001) (12, 3.24499789806462860000e+001) (13, 5.70822270930750550000e-001) (14, 9.09834290846902150000e-001) (15, 2.01715110491773910000e+000) (16, 1.20418279562847650000e+001) (17, 2.88728132464328450000e+000) (18, -3.12030397886119530000e-001) (19, 3.93671063903305580000e-001) (20, 2.98882410103743370000e+001) (21, 2.93815457746262480000e+000) (22, 3.28428439881346180000e+000) (23, 6.59308663128557290000e-001) (0, 5.72975676587982450000e+000) (1, -1.15898191049388790000e+000) (2, -1.30450124704642920000e+000) (3, -9.78314683496135930000e-001) (4, -3.10792515645080010000e+000) (5, 7.90311465916553050000e-002) (6, 6.78966524458038640000e+000) (7, 5.78565865991892760000e-003) (8, 1.82177832824454880000e+001) (9, -2.68530921776422790000e-001) (10, 1.60325223320293130000e+001) (11, 1.26812642350798810000e+000) (12, 3.19806299808930030000e+001) (13, -8.61957960680311160000e-001) (14, 2.04406224474482020000e+001) (15, -2.62508532857277330000e+000) (16, -1.37508161926171510000e+001) (17, -6.85185273021527870000e-001) (18, 2.73644191548870130000e+001) (19, -2.23719281960341390000e+000) (20, -3.79441717420633890000e+001) (21, 2.35952803380858580000e-001) (22, 2.57032055439330770000e+001) (23, 1.05476425858040180000e-001) (0, 4.07748114714878260000e-001) (1, -1.63551450421387410000e+000) (2, -5.04244705576633480000e-001) (3, 3.29072629150251090000e-001) (4, -5.29828367045963140000e+000) (5, 9.57708737638181980000e-001) (6, 5.70350586724616710000e+000) (7, -4.63993713587747330000e-001) (8, 3.20171581512433210000e+000) (9, 2.28493191402849540000e-001) (10, 1.40399825897201410000e+001) (11, -1.12058981890057060000e-002) (12, 1.59136716336348600000e+000) (13, 8.28696415488775480000e-001) (14, -2.74520658612184860000e+001) (15, -1.45938964321748380000e+000) (16, -1.73466492586283470000e+001) (17, 6.92015713456643810000e-001) (18, -9.10883280526871890000e+000) (19, -2.64091110805588560000e+000) (20, 1.04728334408055870000e+001) (21, 8.85866067908049120000e-001) (22, -5.93586200619493950000e+001) (23, 4.39531027479965750000e-001) (0, -4.12799542388989150000e+000) (1, 4.98001151315218770000e-001) (2, 1.54495402803949200000e+000) (3, 3.75513993177217480000e+000) (4, 1.71492481953824670000e+000) (5, -5.53172144980148830000e-002) (6, 1.16214233514126750000e+001) (7, 8.89301476316856300000e-001) (8, -1.59404685410963380000e+001) (9, 2.03983170434544550000e+000) (10, -2.02117617213081810000e+000) (11, -2.51273037945360770000e-001) (12, -1.86033301168390000000e+001) (13, -1.38076282364524600000e-001) (14, -1.25519179555683650000e+001) (15, 2.55396975995807910000e+000) (16, -1.58152700985864000000e+000) (17, 8.95101138846281840000e-001) (18, -5.61363813592411060000e+001) (19, -5.08234087570367050000e-002) (20, 3.74326806537807310000e-001) (21, 2.68614523002459650000e+000) (22, 9.01045762850990070000e+000) (23, 1.16667744826022510000e+000) (24, -1.68128058941802830000e-001) (25, 1.05356593302744560000e+000) (26, 1.07680149157663970000e+000) (27, -3.82645468789863660000e-001) (28, 2.42020336211083540000e-002) (29, -1.34472797974916270000e+000) (30, 1.04337103923595360000e+000) (24, 1.90759829275106540000e-001) (25, -1.48964658666898080000e+000) (26, 1.23066999113657860000e+000) (27, 2.17784285397042290000e+000) (28, -1.64260459218362610000e+000) (29, 7.49181129255291790000e-001) (30, 1.19089911824332280000e-001) (24, 7.96767891594993280000e-001) (25, 6.67776130413157310000e-001) (26, -1.75861501714564320000e+000) (27, -1.81444976041021740000e+000) (28, 2.19413347474927490000e+000) (29, 4.97236442621722450000e-001) (30, 1.54514099403232930000e+000) 

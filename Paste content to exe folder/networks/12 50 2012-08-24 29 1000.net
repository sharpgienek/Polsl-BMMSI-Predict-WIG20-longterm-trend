FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.73551686282152980000e+000) (1, 2.31045209261772190000e-001) (2, -3.47268783408838880000e-001) (3, 4.52947398232828570000e+000) (4, 1.13831091220102000000e+000) (5, -1.11980810640521370000e-001) (6, 7.83919505842551970000e+000) (7, 1.46803991467542660000e+000) (8, -4.71257841647523820000e+001) (9, 1.46359941142697130000e-001) (10, -9.22871774640578200000e+001) (11, 6.91374464362046750000e-001) (12, -8.64848815766770970000e+001) (13, -3.33817630965408560000e-001) (14, -2.89564401085995260000e+001) (15, -1.68342938244969460000e-001) (16, -2.72650004295131400000e+001) (17, 1.23597986400778880000e+000) (18, -4.46408451475051680000e+001) (19, -2.75735879634555810000e-001) (20, -4.16940251794742030000e+001) (21, -3.02085869296678130000e-001) (22, -3.76670713614418130000e+001) (23, 8.87359513204135640000e-001) (0, 7.35948189684047650000e-002) (1, 1.43900766174939940000e+000) (2, -2.56792215022906830000e-002) (3, -1.99968712768908040000e-001) (4, -2.07301744845267170000e-001) (5, 4.71288338074696110000e-001) (6, -4.15462047527240500000e+000) (7, 2.07031131667460230000e+000) (8, -1.32297627156467800000e+001) (9, 4.65272650519705790000e-001) (10, 6.54837782312953550000e+000) (11, 6.88708340420540850000e-001) (12, 2.87914418957199770000e+001) (13, 1.03702497833200050000e+000) (14, 7.08896686671269020000e+000) (15, 7.03311432347042410000e-003) (16, 1.48833343581537210000e+001) (17, 3.11300074277254650000e-001) (18, 5.68275191478327100000e+000) (19, 2.97387873665531210000e-001) (20, 1.20640965590017450000e+001) (21, -8.06974424573447540000e-002) (22, -1.66814733421027460000e+000) (23, -7.25204259382895460000e-001) (0, 1.39877835796347520000e-001) (1, 6.17083464534102700000e+000) (2, 1.91572411490172030000e+000) (3, 3.87067715582427920000e+001) (4, 1.40903057111950290000e+001) (5, 5.36335065590634040000e+000) (6, 4.10030876228871930000e+000) (7, 2.11412388925678350000e+000) (8, 5.97476843693238490000e+001) (9, 2.49157399624176360000e+000) (10, 5.04647760697519820000e-001) (11, 1.26826662495949400000e+001) (12, -1.74341352914620130000e+001) (13, 5.13433710238037120000e+000) (14, 5.62326522487248860000e+000) (15, 1.73050457777002450000e+000) (16, -1.30624383365666500000e+001) (17, 1.45602950828217550000e+001) (18, 1.20153867039306090000e+001) (19, -1.85681165905069920000e-001) (20, -1.77868534312178820000e+001) (21, -8.59758745365660220000e-001) (22, -9.16131892717750130000e+001) (23, 4.21395342313605960000e+000) (0, -1.32109023622403130000e+000) (1, 2.65175304600581410000e+000) (2, 7.20808857146009510000e-001) (3, -2.05072767527109790000e+000) (4, -2.30543969485735080000e-001) (5, -9.48195447073900550000e-002) (6, -1.09316928858547930000e+000) (7, 1.03292781475752340000e+000) (8, 2.76767514465233080000e+001) (9, 5.52411972629944130000e-001) (10, -3.56252026162717290000e+000) (11, 8.14576359655439060000e-001) (12, -4.48962773371853970000e+000) (13, 4.79587575584650420000e+000) (14, -6.42223342489714270000e+000) (15, -1.10491152282447210000e+000) (16, -8.98589888004391210000e+000) (17, 1.31261452615349580000e+000) (18, 1.91173149690381870000e+001) (19, -8.66774473565732890000e-001) (20, -2.57360470845060550000e+001) (21, -5.48114959447005210000e+000) (22, -1.68000119500018310000e+001) (23, 2.35251787776241760000e+000) (0, -2.77323464636627910000e+000) (1, -1.72203003557959660000e+000) (2, -2.50545360389707250000e+000) (3, 5.54223021218042230000e-001) (4, -6.04096275966011120000e+000) (5, -6.05276455558114050000e-001) (6, 5.00652812831048520000e+000) (7, -1.07394177538642970000e-001) (8, 3.62261271961992380000e+000) (9, -2.85089138507472250000e-001) (10, 4.67580050048552210000e+000) (11, -4.71383134596965460000e-001) (12, -2.76588166801076210000e+000) (13, -5.09628979880094150000e-001) (14, -2.14823142088364630000e+001) (15, -1.25463111738471220000e+000) (16, 8.53373918117576460000e-001) (17, 5.23836164590465860000e-002) (18, -3.08874999032015190000e+001) (19, -3.22538600270853190000e+000) (20, 4.57648191785163410000e+001) (21, 1.64623033493998670000e+000) (22, -3.29882192844176390000e+001) (23, -7.22339682624273730000e-001) (0, -1.02614037524082600000e+001) (1, -1.52926953045985800000e+000) (2, -1.23151522636673630000e+001) (3, -3.66816647036377450000e-001) (4, -1.58946190565625930000e+001) (5, 1.92468504258149710000e-001) (6, 1.12647687493629420000e+001) (7, -2.46126385502065940000e+000) (8, -1.95050198856705530000e+001) (9, -1.41989050517843700000e+000) (10, 4.80622227971526500000e+001) (11, 4.17231189512279610000e-001) (12, 2.53222786277997900000e+001) (13, -2.66998867292959190000e-001) (14, 3.35579441813079350000e+000) (15, 4.96378569579640660000e-001) (16, 3.11594113808359200000e+001) (17, 6.07603095437962450000e+000) (18, 3.35018365761565300000e+000) (19, -2.73138909671387520000e+000) (20, 1.76112741715837300000e+001) (21, 3.60573344918243280000e-001) (22, -5.76695312959425860000e-002) (23, -1.05400732119188900000e+000) (24, -2.90524437904544320000e+000) (25, 6.19883062254802940000e-003) (26, 1.72730481058667330000e+000) (27, -1.33453435136187790000e-002) (28, 2.21764446606916650000e-002) (29, 1.49351696467764120000e-002) (30, 1.14901754936862570000e+000) (24, 2.90344609190154430000e+000) (25, 3.18689438032567860000e+000) (26, -6.44978779825382430000e-001) (27, -2.25285678906569360000e+000) (28, -2.61445232080462550000e+000) (29, 9.61076803511464290000e-001) (30, 2.03147022044361050000e-001) (24, -8.45067168261785520000e-002) (25, -2.75487549996907080000e+000) (26, 6.84875334163017930000e-001) (27, 2.39303069253553470000e+000) (28, 2.79610033581331050000e+000) (29, -6.94412872916362560000e-001) (30, 1.80487299476585640000e+000) 

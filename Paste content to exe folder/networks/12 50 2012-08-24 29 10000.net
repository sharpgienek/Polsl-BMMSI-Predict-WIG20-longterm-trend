FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.60597848642151410000e+000) (1, 2.09678752460019790000e+000) (2, -2.30289627575492520000e+001) (3, -1.13443888751898040000e+000) (4, -4.58893297802051590000e+000) (5, -4.55295433689176400000e+000) (6, -6.71311379071525400000e+000) (7, 2.57752258709528140000e+000) (8, 3.90709315809113140000e+001) (9, -3.74781309921531090000e+000) (10, 9.24206728954226550000e+001) (11, -3.34315117569209040000e+000) (12, -8.29944454863229320000e-001) (13, 9.18837685683992490000e-001) (14, -4.41636327918471210000e+001) (15, -4.68572006708829980000e-001) (16, 1.22515595203440260000e+001) (17, 2.27902215341830830000e-001) (18, -2.06080650839449090000e+000) (19, -6.77443172400739920000e-001) (20, 2.50973675797644980000e+001) (21, -6.35521737533121130000e-001) (22, -2.04770791104667290000e+001) (23, 2.91516409027820670000e-001) (0, 7.95574285495458880000e+000) (1, 1.32742509998585030000e+000) (2, 1.07371129314633610000e+001) (3, -6.32027890355412960000e-001) (4, 2.97125355194948930000e-001) (5, -1.02440117115969190000e+000) (6, -1.73289912624689070000e+000) (7, -2.62157300257407580000e+000) (8, -1.12881993350543690000e+001) (9, 1.62252117419525320000e+000) (10, 2.21622615357072660000e+001) (11, 1.77114238594548730000e+000) (12, 3.50158067095839770000e+001) (13, 8.26582456095948940000e-001) (14, 2.31557107930819090000e+001) (15, 1.39194861875883950000e+000) (16, 1.81942147193236710000e+001) (17, -4.83309520556508000000e-001) (18, -1.07360993639908100000e+000) (19, -1.08356315404944060000e+000) (20, -2.90458079244204900000e+000) (21, -9.28193726693992360000e-001) (22, 4.64652429652042830000e+001) (23, -2.06435308916611240000e+000) (0, 8.14965033710661980000e-001) (1, 1.51562335804679640000e+000) (2, -1.00306457345990730000e+001) (3, -2.72991418149987150000e+000) (4, -2.13229105657281480000e+000) (5, 5.86990738109341210000e-001) (6, -1.94344968493610890000e+001) (7, -7.67049292952328090000e+000) (8, 4.93231267942003480000e+001) (9, -8.92202605485797660000e-001) (10, 3.45350682369987820000e+001) (11, 3.77898349051676340000e+000) (12, -8.76583950537097500000e+000) (13, -6.29552214763891090000e+000) (14, -9.64489228571167420000e+001) (15, 2.35950248859380900000e+000) (16, 8.91969010016099340000e+000) (17, -4.89486810361552950000e-001) (18, 1.52191448151848900000e+001) (19, -1.63511962172998590000e+000) (20, 4.24843366412767550000e+001) (21, 1.05422927743979680000e+000) (22, 2.09013842247608320000e+001) (23, -5.02012275069930290000e-001) (0, 3.64174491468100570000e+001) (1, -8.99076896543220090000e-001) (2, -4.84389541921829970000e+001) (3, 1.41317109724683940000e+000) (4, -1.98691581098334320000e+001) (5, 1.01270701847610690000e+000) (6, 5.12103048009266540000e+000) (7, -1.24758200657356340000e+000) (8, 6.65982717272565680000e+000) (9, 3.40124474784131660000e+000) (10, 6.57959288646909980000e+000) (11, -8.27829346697324560000e-003) (12, 5.08767753964899110000e+001) (13, 3.86201204714580770000e+000) (14, 3.68949486745751610000e+001) (15, 3.34134394826758020000e+000) (16, 1.31958307376455440000e+001) (17, 1.44032645821795600000e+000) (18, -8.00556250547879780000e+000) (19, 2.16795680967004230000e+000) (20, 4.48487743182742090000e+001) (21, -4.58715744939830030000e-001) (22, -3.53264861988306010000e+001) (23, 2.09252407020144690000e+000) (0, -4.26820621415059520000e+000) (1, -3.99526306459693350000e-003) (2, 4.31937414348763580000e+001) (3, 1.13654823773468890000e+000) (4, -1.49696729092191890000e-001) (5, -1.91281800062280020000e-001) (6, -3.30115433958888090000e+000) (7, 5.18124130621492450000e+000) (8, -7.34970806854950180000e+000) (9, -4.15987493051207080000e-001) (10, 2.37299796203725710000e+001) (11, -2.21768855132522570000e-002) (12, 7.47653656333583290000e+001) (13, -4.47650945487564400000e-001) (14, 4.25228703885786350000e+000) (15, 9.59250568025146190000e-001) (16, 1.35634472400802300000e+001) (17, 1.05343226781924360000e+000) (18, -2.36272324137201330000e+001) (19, 2.60901007992322580000e-001) (20, 1.79608268611051840000e+000) (21, 3.61426036939938950000e+000) (22, -4.93919702451161910000e+001) (23, 3.31768080944538820000e+000) (0, -1.13313265329421000000e+001) (1, 6.39232010205445730000e-001) (2, 2.69827762061955560000e+001) (3, 4.22943480592971810000e-002) (4, -8.37611632310551180000e+000) (5, -8.36169784757338050000e-001) (6, 1.57032848578546780000e+000) (7, 2.48385600332892170000e-001) (8, -6.05753658588369250000e+000) (9, 1.64599147537352900000e+000) (10, -1.92614344806681070000e+000) (11, 1.69863592557825790000e+000) (12, -1.17606005616169140000e+000) (13, 4.34062231656459520000e-001) (14, -4.00855313519277060000e+001) (15, 1.42762755738356530000e+000) (16, -1.27945377448767260000e+001) (17, 7.48524354935695800000e-001) (18, -1.31730281046132180000e+001) (19, -9.21937131808008290000e-001) (20, -6.90729764194761400000e-001) (21, -2.11348005638269170000e-001) (22, -1.58597808859393970000e+001) (23, 1.41479071029392190000e+000) (24, 2.69629234407567250000e+000) (25, 3.57855824355822350000e+000) (26, 2.53314217662491710000e+000) (27, 3.79649366503341580000e+000) (28, -1.93577209331847940000e-001) (29, -2.78620935429069410000e+000) (30, 2.66257331471815650000e+000) (24, -4.10444678473284250000e+000) (25, 6.04484498590880310000e-002) (26, -3.99598458030979490000e+000) (27, -4.35187198986248980000e+000) (28, 3.39602809955384370000e+000) (29, 4.00457668992652210000e-002) (30, 7.85671510366441780000e-001) (24, 1.37402357532407880000e+000) (25, -3.65241879031353410000e+000) (26, 1.28385555273203940000e+000) (27, 1.07268931620030440000e+000) (28, -3.95346489856318020000e+000) (29, 4.51698109198859220000e+000) (30, 2.08689791828910210000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.93435934541962260000e-001) (1, 4.00584072446525220000e-001) (2, 6.48174547738142870000e-001) (3, 3.85878398740454710000e-001) (4, 3.48667810049871630000e-001) (5, 5.44095854131530280000e-001) (6, 5.75263650144176460000e-001) (7, 5.33888942036567560000e-001) (8, -3.87845115636268560000e-001) (9, 7.63982620179404210000e-004) (10, -1.65517884438642900000e-001) (11, 7.58189153792100530000e-002) (12, -8.57458103112393570000e-001) (13, 3.22900489765392980000e-001) (14, 2.14661716938645050000e-001) (15, -1.80095385841177900000e-001) (16, 3.72215173682004690000e-001) (17, 3.34753517285766860000e-001) (18, 2.13087009883930090000e-001) (19, 4.63437109103932710000e-001) (20, -3.51083005883553230000e-001) (21, -1.71619578789216100000e-001) (22, -2.94442668540558890000e-001) (23, 6.03824858927811900000e-001) (0, -2.99222067440682360000e-001) (1, -2.30286571850922410000e-001) (2, 3.02798831252307380000e+000) (3, 7.95831148134023450000e-001) (4, 6.00807774645371500000e-001) (5, 4.63417926074675690000e-002) (6, 2.05626139455392560000e+000) (7, 4.74527197159812900000e-001) (8, -9.46020353302240210000e-001) (9, -2.05732128125657690000e-001) (10, -1.50063782645858850000e-001) (11, 1.05388826104411580000e-001) (12, -9.37451017237047160000e-001) (13, -2.93769238812512770000e-001) (14, -6.64230330255049290000e-001) (15, 1.58806161204924150000e+000) (16, -3.91218389070728870000e-001) (17, 2.56969551126197900000e-001) (18, 6.18971566870078700000e-001) (19, 3.42094323623794050000e-001) (20, -5.05294147138297400000e-002) (21, -2.94031689988298590000e-001) (22, -2.97408977178510340000e-001) (23, 4.77609472596367380000e-001) (0, -3.17937991634148440000e+000) (1, 1.69740250514906910000e+000) (2, 2.73427179145163990000e+000) (3, -5.32319578919298600000e-001) (4, 5.46877342347696360000e-001) (5, -1.63035287806914540000e-002) (6, -1.10110756040809180000e+000) (7, -9.01009284271125090000e-002) (8, -3.19163577589911100000e+000) (9, 1.31661641776708230000e+000) (10, 1.02193548853107160000e+000) (11, 8.78867330753928530000e-001) (12, 3.05469729729606860000e+000) (13, 1.04028559964607830000e-001) (14, 3.01910159364065130000e+000) (15, 1.09580461764743740000e+000) (16, 1.57699282765141780000e-001) (17, -8.43628169624777160000e-002) (18, 3.06102664309350820000e+000) (19, 6.09172260758630290000e-001) (20, -7.37808212210820050000e-001) (21, -2.52586479351145980000e-001) (22, 3.02512576365229350000e+000) (23, 3.46913450260663840000e-002) (0, -1.03905013984474200000e+000) (1, -1.95972568976894690000e-001) (2, -3.14441287480480990000e+000) (3, -3.85329636297436270000e-001) (4, -3.17510135182460380000e+000) (5, -5.09765012135589970000e-002) (6, -6.47869464266740000000e-002) (7, -1.16913672967278530000e-001) (8, 6.70461209696653020000e-001) (9, 4.72078686577070000000e-002) (10, 5.95586185193021530000e-001) (11, 4.20483775207041670000e-001) (12, 3.08071048127744530000e+000) (13, 1.53589878616183280000e-001) (14, 2.08894572121283510000e+000) (15, -3.87093260988179700000e-002) (16, -5.16194090397760100000e-001) (17, -5.65479229292428440000e-001) (18, 8.21003864263301080000e-002) (19, 1.04948660468885920000e-001) (20, 3.91566164528985130000e-001) (21, 1.89821975966845550000e-001) (22, 1.35025473398103910000e+000) (23, -5.10497434021503910000e-002) (0, 1.13116148429897520000e+000) (1, -2.43954674003402370000e-001) (2, -3.10602176095148770000e+000) (3, -3.62821624248170600000e-001) (4, -4.44588768174012380000e-001) (5, 3.11551317699425150000e-002) (6, -1.22258652906951550000e+000) (7, -1.63190250621119330000e-001) (8, 3.15597293357081820000e+000) (9, 1.34789085570833910000e-001) (10, 3.23664041459323320000e-001) (11, -1.06812047482432740000e-001) (12, 3.09538943657430380000e+000) (13, 1.61908970537022410000e-001) (14, -5.91672118600952700000e-002) (15, -2.74398729827384920000e-002) (16, -3.62035971275795120000e-001) (17, 1.47521019354304510000e-001) (18, -3.07636477808768930000e+000) (19, 1.34518170419546780000e-001) (20, 3.02391726754053550000e+000) (21, 1.21727561938702060000e-001) (22, -2.05901833187236480000e-001) (23, 1.44930768230956570000e-001) (24, 1.84163504112350080000e-001) (25, -1.19652397612583870000e-001) (26, 5.58454738071839650000e-001) (27, 4.84489877508311020000e-001) (28, 6.02300052480565950000e-001) (29, 3.28523857825986980000e-001) (24, 4.20692852384230490000e-001) (25, 3.90242412477358580000e-001) (26, 3.28670205501054250000e-001) (27, -1.56467399473423450000e-001) (28, -1.10310043376791580000e+000) (29, 4.01088359904600790000e-001) (24, 3.28220169250908410000e-001) (25, 3.50296585595497640000e-001) (26, -8.38894639498375170000e-001) (27, -9.42378938311663190000e-002) (28, 2.63799359693397910000e-001) (29, 6.39326312879062160000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.74400583871480650000e+000) (1, 5.25263175898218580000e-001) (2, 3.55523270066334970000e+001) (3, 1.04927992036814180000e+001) (4, 4.35183009016697040000e+001) (5, 2.81283544204390780000e-001) (6, 3.70012152300654980000e+000) (7, 1.26155241849328110000e+000) (8, 5.39900793903632610000e+000) (9, -1.24349360004547130000e+000) (10, -7.34341977849026220000e+001) (11, 1.92786058222212680000e-001) (12, -7.87288419979359160000e+001) (13, -7.40870810515692480000e-001) (14, 9.60917788943786880000e-001) (15, -2.95172056252675440000e-002) (16, -4.71458658039430740000e+000) (17, 1.09519138890119220000e+000) (18, -2.77575146825486420000e+001) (19, -2.51801682171789330000e-001) (20, -3.92956498468291850000e+001) (21, -7.15009571110031940000e-001) (22, -4.31373369526296950000e+001) (23, 9.83850444014220950000e-001) (0, 1.49684733354591160000e+000) (1, -9.70493141405037170000e-002) (2, 4.28832088385855230000e+000) (3, 1.86492299846850610000e+000) (4, 7.96856243392378970000e+000) (5, -5.06008636096637380000e-001) (6, -1.88981337175949430000e+000) (7, -4.95497098178931880000e-002) (8, -1.02008596552877600000e+001) (9, -4.28852348325482020000e-001) (10, 5.64493738736441930000e+000) (11, 1.26611485441897650000e-001) (12, 1.73721839532390600000e+000) (13, -4.80538402692292420000e-001) (14, 2.76230123435100840000e+001) (15, -2.25120478552937130000e-001) (16, 8.82817929581532770000e-002) (17, 4.91121177897377030000e-001) (18, 1.84321065541857450000e+000) (19, -2.10527132721431180000e+000) (20, 3.39469798368155120000e+000) (21, -2.43194973971135740000e-001) (22, -4.10956626350690790000e+000) (23, -1.83974219489476070000e-001) (0, 2.26755147036983190000e+001) (1, 7.12431901526476620000e-001) (2, -5.81763595719353610000e+000) (3, -2.21673826429873390000e+000) (4, -2.56645131211274950000e+001) (5, 1.01001857856661470000e+000) (6, 9.36114397310938170000e+000) (7, 1.54881697397743400000e+000) (8, 8.45596340833191680000e+001) (9, -1.65939266284665490000e+000) (10, 3.24045630139290990000e+001) (11, -1.79910882612526880000e-001) (12, -1.54396445783054940000e+001) (13, 1.21154574287345800000e+000) (14, -5.69364988556476350000e+001) (15, 9.15521680210636680000e-002) (16, -1.56294709305732700000e+001) (17, -9.99344092314575330000e-001) (18, -8.34543765703918080000e+000) (19, 3.03932318883322280000e+000) (20, 2.14197276266801100000e+001) (21, 7.07348844575386160000e-001) (22, 2.30403091474651660000e+001) (23, -1.99216842094086130000e-001) (0, 1.76169732756282860000e+001) (1, 9.63387754037416850000e+000) (2, 4.74321464656648930000e+001) (3, -4.41029024213511000000e+000) (4, 1.58097330397985960000e+001) (5, 6.24585187267300060000e+000) (6, 1.32172441341907110000e+000) (7, 1.23148017990083480000e+001) (8, -9.56675027334522630000e+000) (9, -8.78535757812216820000e-001) (10, -7.63310979047284730000e+000) (11, 1.40648137173108560000e+000) (12, 1.57637158102065030000e+002) (13, 3.68324105478914860000e-001) (14, 3.19485531762983930000e+001) (15, 7.02907580673810630000e+000) (16, 1.03714805196399720000e+002) (17, -1.36265237444360920000e-001) (18, 2.12056381800962300000e+002) (19, 3.81939817246004410000e+001) (20, -1.31957971653881800000e+001) (21, -1.85345920057401250000e-001) (22, -1.12729633412222970000e+001) (23, 5.90348099068323970000e-001) (0, -7.25758859357312500000e+001) (1, -4.33004251850760360000e-001) (2, -1.03167987940587600000e+001) (3, 2.20969376127384680000e+000) (4, -2.29162359419687430000e+000) (5, -2.01753627297586960000e+001) (6, -3.27301301624859260000e+002) (7, -2.41194088139735640000e+000) (8, 1.84547131210479060000e+001) (9, -2.18808729179857140000e+000) (10, -1.79672931382846080000e+000) (11, -3.23284137097070210000e-001) (12, 2.31418856614689940000e+001) (13, 1.66590206677144410000e-001) (14, -3.78651031544570740000e+001) (15, -1.71138366235116310000e+001) (16, 2.08355315036909160000e+002) (17, 2.84937375083855860000e-001) (18, -1.22386915055164560000e+001) (19, -2.92490259161327230000e+001) (20, -6.49189897250996640000e+001) (21, -5.34187371534060180000e-002) (22, 2.57984416941905790000e+001) (23, -7.58772588718846210000e+000) (0, 1.73216900647412150000e+001) (1, 2.06496974041242620000e-001) (2, -3.48048487083960510000e+001) (3, 3.41523804039451220000e+000) (4, -5.11703955769639480000e+001) (5, -5.93086549254492560000e-001) (6, 2.94988972975404840000e+001) (7, 4.98697534241618330000e-001) (8, 5.28699270868206380000e+000) (9, -1.26601703402095780000e-001) (10, 1.43606570572699840000e+001) (11, 1.78524432171852760000e+000) (12, -1.67208417954489730000e+001) (13, -4.63638429283806000000e-001) (14, 4.54788775131868520000e+001) (15, 1.21383936347823560000e+000) (16, 8.55295055967030220000e+000) (17, 8.67505101174239620000e-001) (18, 4.76424038367403480000e+000) (19, 1.47176859371805180000e+000) (20, 1.09736817780508970000e+000) (21, -5.92945574934866660000e-001) (22, -6.01522858238102100000e+001) (23, 2.07858821692578570000e+000) (24, -2.65158126089525890000e+000) (25, -9.11740093778881320000e-001) (26, -9.03756724713386860000e-001) (27, 1.53654457084142440000e-001) (28, 2.22194469577478990000e-001) (29, 1.86285921035210530000e+000) (30, 7.51428329037017400000e-001) (24, 6.94252845415639590000e-001) (25, 1.93829463058856110000e+000) (26, -4.26083117795743390000e-002) (27, 1.56779692208729380000e+000) (28, -8.31856907560177940000e-001) (29, -2.09401286151757080000e+000) (30, 1.79013501703741510000e+000) (24, 7.63890406860592840000e-001) (25, -3.78663890949109900000e-001) (26, 5.14231588657388720000e-001) (27, -2.01060279351357310000e+000) (28, 8.77315225002657240000e-001) (29, 8.11369549235771870000e-001) (30, 1.96369675633232400000e+000) 

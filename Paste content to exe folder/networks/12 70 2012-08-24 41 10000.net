FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.27306827393851170000e+001) (1, -3.85197616805166550000e+000) (2, -1.93919706609876100000e+001) (3, 4.97119304143253670000e-001) (4, -1.84053375549339260000e+001) (5, 8.72092491553200010000e-001) (6, 8.11474105010073290000e+000) (7, 1.72439942218050120000e+000) (8, 8.38634409080257190000e+000) (9, 2.49139168587348940000e-001) (10, 2.49901828232647320000e+001) (11, 3.53860786407554830000e+000) (12, 3.45176443596335280000e+000) (13, 6.57566950673416440000e+000) (14, -1.46449343151563400000e+002) (15, -1.43279858160893210000e+000) (16, -3.56901105733300100000e+001) (17, 6.65517953230620570000e-001) (18, 2.61974608990382480000e+001) (19, 1.13587476794288270000e+001) (20, -6.61051658857203110000e+001) (21, 2.64592005133506940000e+000) (22, -2.43323297095776140000e+001) (23, 6.39996699746797630000e-002) (0, -7.52593110562851300000e+000) (1, 1.15102464175238350000e+000) (2, -1.62382206919862160000e+000) (3, 4.68137158312872110000e-001) (4, 1.09894099140778270000e+001) (5, -5.92773621377769570000e-002) (6, -1.46593217640133470000e+001) (7, 3.62690283491518940000e-001) (8, -2.16894326533564480000e+001) (9, 5.13000349863300790000e-001) (10, -4.38076291109352100000e+001) (11, 5.84725136111671100000e-001) (12, -2.34658649845172530000e+001) (13, -4.63795304173348800000e-001) (14, 1.19981332471481250000e+001) (15, -6.28505716022677020000e-001) (16, -2.17265056064872830000e+001) (17, 7.00465507150392910000e-001) (18, -1.32713547757413830000e+001) (19, 1.44147472844365100000e-001) (20, -5.47548263531494040000e+001) (21, -1.14419406225111020000e+000) (22, -4.35853227875776380000e+001) (23, 2.32741786383766460000e+000) (0, -7.49498751489760760000e+001) (1, 5.24184785557176910000e+001) (2, -3.86882125399280310000e+002) (3, 1.03179838923527640000e+001) (4, -1.79725865050533120000e+002) (5, -2.91853584015697230000e+000) (6, 6.42239324738932990000e+001) (7, 2.30700081088504290000e-001) (8, -1.54502062569268560000e+002) (9, 3.13776253993713580000e+000) (10, -1.21356021760288810000e+002) (11, -3.69187431300116660000e+000) (12, 2.43599920853193850000e+002) (13, -1.50149459863726250000e+001) (14, 3.69866371901640950000e+002) (15, -1.02048116674458740000e+000) (16, 4.76279044152435560000e+001) (17, -5.32122653999044190000e+000) (18, 5.95699659457349640000e+001) (19, 8.65095232075976740000e+000) (20, -2.06718042515234470000e+001) (21, 4.58620792735882880000e+000) (22, -6.24698243032383760000e+001) (23, 3.16069632592323340000e+001) (0, 1.22349849242069690000e+001) (1, -1.35427271830499940000e+000) (2, -1.92889551339214090000e+001) (3, 7.09510927106272170000e-001) (4, 3.01103187218053030000e+001) (5, 3.13868532716015600000e+000) (6, 6.46356767791732100000e+001) (7, -1.78785718123546820000e-001) (8, 4.85436941349976860000e+001) (9, 1.79431869676388470000e+000) (10, -1.97666398510664680000e+001) (11, 3.42285640958035400000e+000) (12, -5.86487215954202840000e+001) (13, 2.29310002562888560000e+000) (14, 6.61045386127295700000e+001) (15, -8.18179386982907380000e-001) (16, 4.87311211331383870000e+001) (17, 3.13611422899046530000e-001) (18, 3.10236266999187150000e+001) (19, 4.95725526265973490000e-001) (20, -3.87261528623766950000e-001) (21, 1.73712504422513180000e-001) (22, -6.17085848261764270000e+000) (23, -1.56555821701941130000e+000) (0, -4.60858513523995670000e+000) (1, 7.18527889695520950000e-001) (2, 1.32789730603458750000e+001) (3, -1.72642450788079540000e-002) (4, 5.16320646576166540000e+000) (5, -1.95100826920067800000e-002) (6, -7.50728610373064330000e+000) (7, -2.42555265059804290000e-001) (8, 9.89420170852146090000e+000) (9, -2.02746216544473810000e-001) (10, 1.28375826232092720000e+001) (11, -3.04365007963960410000e-002) (12, 2.40291719479607590000e+001) (13, -4.50953316606860550000e-001) (14, 2.15480799879990350000e+001) (15, 3.90251643408828350000e-003) (16, -1.08584098903851940000e+000) (17, 3.17596742866787020000e-001) (18, 3.66758417757690710000e+000) (19, -2.43157354109976690000e-001) (20, -6.41296145921369480000e+000) (21, -5.27308179791051930000e-001) (22, -1.39540812717438690000e+001) (23, 1.60603695508611780000e+000) (0, -9.19635334047240040000e+001) (1, 2.16514581839563910000e+000) (2, 7.78120226915811490000e+000) (3, 1.87869716934016960000e+001) (4, 1.53804558093489080000e+002) (5, 4.91671072763285510000e+001) (6, 4.31130013967132230000e+001) (7, 7.78855797857043530000e+000) (8, -7.12262873405457380000e+001) (9, 2.44632618532237830000e+000) (10, -6.17040451783792390000e+001) (11, 7.54142045419976630000e+000) (12, -8.01907449617482550000e+000) (13, 6.12985198717937240000e+000) (14, 1.21808394091281560000e+002) (15, -2.20264890946642030000e-001) (16, -3.61230668511329480000e+000) (17, 6.26802335059478200000e+000) (18, 9.05028248048347450000e+001) (19, 1.17294505871137770000e+000) (20, -2.86477661971092420000e+001) (21, 1.16332584625994100000e+000) (22, -1.90917813625236700000e+002) (23, 1.82064664309322110000e+000) (24, 1.45550794414979980000e+000) (25, -4.52761754862841850000e+000) (26, 3.95855280441861250000e-001) (27, 1.80472867288224600000e+000) (28, 5.73915153332532580000e+000) (29, -1.91737077118029680000e+000) (30, 1.76723787707311920000e+000) (24, -4.62081174780510120000e+000) (25, 4.83300352484655970000e+000) (26, 1.70211179699038830000e+000) (27, 1.00438853319808730000e+000) (28, -5.13577248438291090000e+000) (29, 1.83274300962555260000e-001) (30, 1.88639445635271130000e+000) (24, 1.86803114201275930000e+000) (25, -3.05030539197968020000e-001) (26, -1.93574917399695720000e+000) (27, -2.96618957875381990000e+000) (28, 3.29251781708745310000e-001) (29, 2.38732271688289320000e+000) (30, 6.16541791885079520000e-001) 

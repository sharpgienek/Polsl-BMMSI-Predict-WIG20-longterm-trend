FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.01168074892291140000e+000) (1, 2.20528571339892950000e-001) (2, -1.29718233054315930000e+001) (3, -2.80675723153994190000e-001) (4, -1.79623384440537030000e+001) (5, -4.94152412213286600000e-001) (6, 9.60105522459924290000e+000) (7, -9.44555891524351270000e-001) (8, -1.49531502662654600000e+001) (9, -7.13803229954498520000e-001) (10, -1.57913151475897460000e+001) (11, -6.85229980212454290000e-001) (12, 3.63619620981032630000e+001) (13, 8.29326530795716830000e-001) (14, -5.58432837984709090000e+000) (15, 2.97327713234037340000e-001) (16, -2.61892402861724940000e-001) (17, 3.40086511305602470000e-001) (18, -2.73809256343650310000e+001) (19, 2.84523121978646200000e+000) (20, -3.27041100505155880000e+001) (21, 1.02018905863672440000e+000) (22, -7.03358832938410360000e+001) (23, 3.23160274332007360000e+000) (0, 7.25687792530696210000e+001) (1, 1.00420833941235250000e+001) (2, -1.18345946584285020000e+002) (3, 8.19221286094411800000e-001) (4, 9.57886230597131320000e+001) (5, 2.24411238986265230000e+000) (6, 2.14331098412227020000e+002) (7, -6.42750709993978430000e-001) (8, -1.10139821118896760000e+002) (9, -3.91209047405551620000e+000) (10, -2.25741476659913860000e+000) (11, 1.67277590156649900000e+001) (12, -6.24241450960233520000e+001) (13, -2.98021755780257360000e+000) (14, 1.32365484832694160000e+002) (15, 1.00575957867704310000e+001) (16, 1.29537720814853230000e+002) (17, 2.83551258143610110000e+000) (18, 7.31421945685498540000e+001) (19, 5.78032102739258940000e+000) (20, -6.23555735765755590000e+001) (21, -6.14809651546549320000e+000) (22, -2.51669509660536900000e+002) (23, -1.60969775089186990000e+000) (0, 9.95337370036035910000e+001) (1, 2.87907372064146760000e+001) (2, -1.10118567377498960000e+002) (3, -9.06794533208257290000e+000) (4, -2.89796232588001740000e+001) (5, 1.68915141511259750000e-001) (6, 2.29381896767355470000e+002) (7, -8.38865023552624710000e-001) (8, -1.79990819598647760000e+002) (9, -6.21587529610830530000e+001) (10, -1.53626349430700910000e+002) (11, -2.07789061179314530000e+002) (12, 1.22541546535469860000e+002) (13, -9.70001751666285020000e+000) (14, 3.60426057191206440000e+001) (15, -6.20536727611198420000e+001) (16, -1.01054919806902160000e+001) (17, -6.66537854170608880000e+001) (18, 5.07792134333461220000e+001) (19, 1.24943675815488660000e+000) (20, 6.66123286431613480000e+001) (21, 7.90241269952775390000e+000) (22, 1.32165699563664070000e+003) (23, -2.60632984039736120000e+001) (0, 4.39044408503018870000e+002) (1, -3.03457242158942900000e+001) (2, -2.24044659739532850000e+002) (3, 1.50600853210366690000e+002) (4, 1.49681109928458890000e+003) (5, -5.46453388089650150000e+001) (6, -1.49804211366046710000e+003) (7, -1.94182734112583940000e+001) (8, 5.48418782472787750000e+000) (9, 2.71386324581783240000e+002) (10, -1.78982453962004140000e+002) (11, -9.85158661373833700000e+001) (12, 1.50000000000000000000e+003) (13, 1.46251292763140610000e+001) (14, -4.53350631217873140000e+001) (15, -1.50000000000000000000e+003) (16, -8.33742491963579940000e+002) (17, 4.86337093037566720000e+002) (18, -1.46208264460154440000e+003) (19, 1.54012913123078930000e+002) (20, 1.49763101158973680000e+003) (21, -3.37819549065980880000e+001) (22, -1.50000000000000000000e+003) (23, -7.99690747048299360000e+001) (0, -1.32956016280143440000e+001) (1, -2.66684619323134630000e+001) (2, -3.27314709168811760000e+002) (3, 6.44361953981828490000e-001) (4, -3.62409717880493500000e+001) (5, -2.87554991384736450000e+001) (6, 1.17755437515159800000e+002) (7, 1.12484219214343360000e+001) (8, -2.28006800114348320000e+002) (9, 2.17636205663950210000e+000) (10, 2.00132648770824180000e+002) (11, 1.67702994977442120000e+001) (12, 1.45497488214448630000e+001) (13, -1.06838576991644860000e+002) (14, 3.27713002352835870000e+002) (15, 8.22369430050968480000e+000) (16, -1.02800769177931300000e+002) (17, -2.00241553435569090000e+000) (18, 1.77968440211690280000e+002) (19, -1.14211432623443440000e+002) (20, -1.41957081354644150000e+003) (21, -3.51574374889321590000e+000) (22, 9.38051210464842100000e+000) (23, -6.03585024905562540000e-001) (0, 4.48421706203651030000e+001) (1, 2.87116779541155020000e+000) (2, -2.49014422306170640000e+001) (3, 6.37630856607956380000e-001) (4, -2.31897294432846730000e+001) (5, 5.28744458052851750000e-001) (6, -1.34152617538404580000e+001) (7, -2.10997978877337600000e+000) (8, -1.49577174563488010000e+001) (9, 1.74226443441878740000e+000) (10, -1.04072006834873600000e+001) (11, 5.83827745437050890000e+000) (12, -4.14481331616719970000e+001) (13, -7.75688482185330210000e-002) (14, -2.26250880401954570000e+001) (15, -8.60812774250154340000e-001) (16, -3.44124755305366320000e+001) (17, 3.90612820672762370000e+000) (18, 3.53713259673852600000e+001) (19, -3.14178390406421200000e-001) (20, -1.28308782228183360000e+001) (21, -1.69857059939232440000e+000) (22, -9.91476385738091610000e+001) (23, 2.11373237513664500000e+000) (24, 2.29600330830831640000e+000) (25, 1.96446306103435290000e-002) (26, 2.14698174594320880000e+000) (27, 4.48053993833902150000e-003) (28, 2.21507804164417310000e+000) (29, -1.88529135793664550000e-003) (30, 2.06112188155941340000e+000) (24, -4.51298544651579550000e+000) (25, 2.25617995890399530000e+000) (26, -2.16338567463629290000e+000) (27, 2.23492541410507030000e+000) (28, -2.19994414958330960000e+000) (29, -2.20412484742195370000e+000) (30, 2.18864013109172490000e+000) (24, 2.27705786780999110000e+000) (25, -2.21164545594187520000e+000) (26, 3.09093641518854850000e-002) (27, -2.17135718732309880000e+000) (28, 8.29132809119993570000e-002) (29, 2.16427930696657090000e+000) (30, -8.01337648685138680000e-002) 

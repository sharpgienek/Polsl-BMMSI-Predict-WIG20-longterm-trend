FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=24 7 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (24, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (7, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.76898583682377670000e+000) (1, -2.94121941767423230000e-001) (2, -3.39641490369517920000e+000) (3, -3.95380633135820110000e-001) (4, 2.40447471919045250000e+000) (5, -8.09446619904289790000e-001) (6, -4.96380601350462760000e+000) (7, -9.70029268763564070000e-002) (8, -8.42489578207193550000e+000) (9, 1.14673477204475870000e+000) (10, 8.03057866452931200000e-001) (11, 9.49346972106504650000e-001) (12, 3.46089857708577140000e-001) (13, 5.23385828499518760000e-001) (14, 1.62640828516214350000e+001) (15, 7.79618696194907090000e-001) (16, 6.71453385140851380000e+000) (17, -7.35977075224046320000e-001) (18, 2.20088210684056090000e+001) (19, -1.21471583647646820000e-001) (20, 4.17359914310687690000e+000) (21, -4.08328523643135320000e-001) (22, 6.51962724461505340000e+000) (23, -6.28629673885606310000e-001) (0, -2.17511383219931670000e+001) (1, 3.57128612177742170000e-001) (2, 2.66176415861793860000e-001) (3, 9.26477037370894930000e-001) (4, -7.09305668741936790000e-001) (5, 1.75273119856896350000e+000) (6, 1.41951254634419100000e+001) (7, 2.99111444289825010000e+000) (8, -2.17031706298089280000e+000) (9, 3.59827133246391870000e-001) (10, 7.34080001426336450000e-001) (11, 1.98191750570328650000e-001) (12, 1.43286544395004380000e+001) (13, 9.80224471137309710000e-001) (14, 1.66128262381916760000e+001) (15, -7.34353948614129500000e-001) (16, 1.67281098035283760000e+001) (17, 4.74002806136053940000e+000) (18, -1.28671287303596810000e+001) (19, -1.15896233254292870000e-001) (20, -2.83190941310933120000e+000) (21, 3.69761692530353160000e+000) (22, 1.77508186826278060000e-001) (23, 1.40503344395077100000e+000) (0, 5.09987320722968540000e-002) (1, 4.93777864633210660000e-001) (2, 1.18314978654419820000e+001) (3, 8.53414443466799070000e-001) (4, 2.57580903485078980000e+000) (5, -2.43703070927408870000e-001) (6, 2.63277070745866650000e-001) (7, -2.58375286035562700000e-001) (8, -1.01191665112393440000e+001) (9, 1.02460699520867380000e+000) (10, 1.12565634352275480000e+001) (11, 1.00086845974884110000e+000) (12, -2.16113034830792510000e+001) (13, -5.66487689321821110000e-002) (14, -3.28369102475709870000e+000) (15, -5.44803892949252360000e-001) (16, -1.27203261798810330000e+001) (17, -7.02042105369309220000e-001) (18, -8.75636103453969380000e+000) (19, -6.75021856376365470000e-001) (20, 2.21781105837728280000e+000) (21, 1.30051687178965650000e+000) (22, -6.62709624025214910000e+001) (23, 5.97630485953880460000e-001) (0, 8.44948530752532890000e+000) (1, -1.45004901138484020000e-001) (2, -3.23426848351754170000e+000) (3, -9.76328320873780800000e-002) (4, 9.58819473068469820000e+000) (5, 5.29387807059275710000e-002) (6, 2.84544640246354740000e+001) (7, 7.54179841362533080000e-002) (8, 9.96584553510183050000e-001) (9, -4.93855535928973350000e-001) (10, -6.18060197160343530000e+000) (11, -1.54221440093082450000e-001) (12, -6.09129907593561890000e+000) (13, 1.05895656605384250000e+000) (14, -7.79976702857912760000e+000) (15, -4.08665312363848510000e-001) (16, -1.04918680697824840000e+001) (17, 8.09732811943658310000e-001) (18, -6.88427156706723760000e+000) (19, -2.88709772893495530000e+000) (20, 5.12717893379781400000e+000) (21, 7.75845204373437350000e-002) (22, 8.13442144608782950000e+000) (23, 3.85978021524645500000e-001) (0, 1.41286926237041700000e+001) (1, 7.41200833077895530000e-001) (2, 5.06398486796059450000e+000) (3, -4.02932361823341410000e-001) (4, 1.34983847169563040000e+001) (5, -4.32410552272693200000e-001) (6, 5.18858269659561880000e+000) (7, -6.07067836778124370000e-001) (8, 1.34584845129949460000e+000) (9, -3.65871915555079630000e+000) (10, 1.57478597170370400000e+001) (11, -4.59374131970915820000e-002) (12, 1.57475711791175790000e+000) (13, -1.11857686170023190000e-002) (14, 1.70506851433042780000e+001) (15, 1.21610489570327500000e+000) (16, -1.11640237631926360000e+001) (17, -7.80718658512996490000e-001) (18, 2.25366533082710030000e+001) (19, -5.90155663591237720000e+000) (20, 5.62327229207954030000e+001) (21, -1.79380968938225080000e+000) (22, 4.18269090631858590000e+001) (23, 5.33949566010983420000e-001) (0, -1.30646517258503340000e+000) (1, -1.48007850910899100000e+000) (2, 3.68660938738408510000e+000) (3, -4.51348545985652380000e-001) (4, 2.15437076008964610000e+001) (5, -1.53966941796203520000e+000) (6, -7.24679824594918200000e+000) (7, -6.21696451516174480000e-001) (8, 3.81053681867525370000e+000) (9, 7.29510125965799670000e-001) (10, -8.63115280127202670000e+000) (11, 1.29790280849980070000e-001) (12, -1.58667419311003940000e+001) (13, 5.08742279247618170000e-001) (14, 3.93845978130333660000e+000) (15, 2.10156862583173560000e+000) (16, 7.84014236037252840000e-001) (17, -1.26667106573688050000e+000) (18, 2.45597946575049870000e+001) (19, 1.63228349594586990000e-001) (20, 4.02935911169413630000e-001) (21, -1.71441914299696970000e+000) (22, 4.79540062147397970000e+000) (23, 3.68335959180400800000e-001) (24, 1.46749253886537810000e+000) (25, -1.15198754921497120000e-001) (26, -6.88341786230338370000e-001) (27, -7.18162788738041960000e-001) (28, -1.44699506759525640000e-001) (29, -1.86976938145402570000e+000) (30, 5.57549325588005630000e-001) (24, -1.07052458961832150000e+000) (25, 1.61891538880294190000e+000) (26, 6.16729814194230900000e-001) (27, -9.13586137555383540000e-001) (28, 1.53223628850383410000e+000) (29, 1.48345227649770450000e+000) (30, 5.06660604471243950000e-001) (24, -5.43812910424905540000e-001) (25, -1.31738335974288860000e+000) (26, 4.05960525177329500000e-001) (27, 1.68421928685680820000e+000) (28, -1.26029510963295550000e+000) (29, 7.05687724627012240000e-001) (30, 1.42928240201335480000e+000) 

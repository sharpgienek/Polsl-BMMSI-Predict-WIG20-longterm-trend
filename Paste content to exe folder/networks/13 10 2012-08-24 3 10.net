FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.09248576032808580000e+000) (1, -2.75520653086140320000e-001) (2, 2.38821946088935200000e-001) (3, -2.87590752645116300000e-001) (4, -2.53368340025787620000e-001) (5, 1.26836996307275300000e+000) (6, 4.00053851420563040000e-001) (7, 8.22353300478325000000e-001) (8, 4.08241424478243410000e-001) (9, -1.31822789602278980000e+000) (10, -1.22684806562846350000e+000) (11, 2.91153489837485960000e-001) (12, -5.40000133825862430000e-001) (13, -4.18629461428192850000e-001) (14, 1.75926577788468560000e+000) (15, 7.70772489162836030000e-001) (16, -3.16224124421109830000e+000) (17, 7.02903866988062620000e-001) (18, 1.19636704148856810000e+000) (19, -1.89003317812556580000e-001) (20, -3.55934147993959890000e-001) (21, 1.49476327081523790000e+000) (22, 8.19051298475996340000e-001) (23, -1.21295394835701910000e-001) (24, -9.05525148266647230000e-002) (25, 8.61491522985826930000e-002) (0, 9.49686400221699390000e-002) (1, -4.11325340595526170000e-001) (2, -1.64824637534508660000e-001) (3, -1.62883334383484930000e-001) (4, -3.21763951985365610000e-001) (5, -9.49850967008870620000e-001) (6, 5.33834973524685230000e-001) (7, -1.51590110331678430000e-001) (8, -2.55809361158815700000e-001) (9, 1.14062678896964040000e+000) (10, 2.39035223086286940000e-001) (11, 6.14004652453681520000e-001) (12, 1.16031673066929340000e+000) (13, -2.26665073615156950000e-001) (14, 4.53970470381486360000e-001) (15, -6.97146757952085140000e-001) (16, 1.18307674077406900000e+000) (17, 4.86273211244605040000e-001) (18, -1.42193412443879910000e+000) (19, -1.29936393584965910000e+000) (20, 3.59059746952882180000e-001) (21, 1.16041371877603770000e-003) (22, 1.71625504149528820000e-001) (23, -2.77172647192787500000e-001) (24, 1.06236062334487880000e+000) (25, -1.25611442348644120000e+000) (0, 8.17185253428848180000e-002) (1, 4.10726524942015700000e-002) (2, -1.06397079451296370000e+000) (3, -8.02823737952207850000e-001) (4, -2.23896735569902360000e-001) (5, 4.99888318745009410000e-002) (6, 1.63523567639034110000e-002) (7, -8.11946807461823020000e-002) (8, 4.63034677661180840000e-001) (9, 2.32752432478140230000e-001) (10, 5.97679796646020670000e-002) (11, 2.99771654028406610000e-001) (12, 3.13255813514772440000e-001) (13, -3.44300790098437560000e-001) (14, 7.81066743617141680000e-001) (15, 7.36948869152486700000e-002) (16, 2.93573966587576730000e-001) (17, 7.31451199395426470000e-001) (18, 7.78025529920826630000e-002) (19, -7.49751982316297920000e-002) (20, 3.85454300918738720000e-001) (21, 2.09177865194336150000e-002) (22, 8.09513177637313510000e-002) (23, 3.02983596564829480000e-001) (24, 3.94847611605584960000e-001) (25, -1.15691751572728710000e-001) (0, -1.05680255900522970000e+000) (1, -5.04666881346230940000e-001) (2, -9.61588027730641450000e-001) (3, 3.50874932377793940000e-001) (4, 2.89113456848101250000e-001) (5, -8.81807977944472740000e-001) (6, 3.52100581988353980000e-001) (7, -7.86642608895052220000e-001) (8, -9.25695241798401710000e-002) (9, 1.26625020607906720000e+000) (10, 1.45375869943206350000e+000) (11, 8.77157858605973060000e-002) (12, 1.94783604177653520000e+000) (13, 2.35402518547745910000e-001) (14, 6.28383857522071490000e-001) (15, -9.51443984610733430000e-001) (16, 1.56319717209896330000e+000) (17, 7.56603787660854230000e-001) (18, -9.14572646170682680000e-001) (19, -1.41394795113346380000e+000) (20, 5.42158858033936260000e-001) (21, -2.75967326468379850000e-001) (22, -1.48773589736121340000e-001) (23, -1.24204952921055710000e-001) (24, 6.46821543330833300000e-001) (25, -7.88015251937477230000e-001) (0, -1.17216412115161570000e-001) (1, 3.06893822556170480000e-001) (2, 3.00608983750359830000e-001) (3, -1.11680687062275170000e-001) (4, -8.80722882729826210000e-002) (5, -1.19389263710039580000e-001) (6, 1.94994842142863640000e-001) (7, -9.18248952624943350000e-002) (8, 8.16466672513284360000e-002) (9, 3.45981579635056210000e-001) (10, 3.34295100950168960000e-001) (11, 5.09027959127321240000e-001) (12, 1.59727798620516920000e-001) (13, -8.85475779567443390000e-003) (14, 9.88231018944850520000e-002) (15, -1.61568906911810390000e-001) (16, 4.85709364920287430000e-001) (17, 1.95782454067467970000e-001) (18, -3.12995354947544270000e-001) (19, 1.07378767943605780000e-001) (20, 4.00534803104212580000e-001) (21, 3.75565394098851120000e-002) (22, -3.70144616964295380000e-002) (23, 2.93761003742767310000e-001) (24, 3.80527478587330210000e-001) (25, 1.57012557745706850000e-001) (26, 6.40620302725923630000e-001) (27, 2.18322995261477580000e-001) (28, 3.86558377534313820000e-001) (29, 7.98618306120624900000e-001) (30, -1.54418890392035770000e-001) (31, 3.00481122992532100000e-001) (26, -3.21052498736386030000e-001) (27, 7.52123319007801110000e-002) (28, -7.96597484555968900000e-001) (29, 5.22956653768308130000e-001) (30, -6.83144598830568440000e-002) (31, 9.63869074231732960000e-001) (26, 8.94943991149739440000e-001) (27, -1.25215324178679000000e+000) (28, 9.77789422300203230000e-003) (29, -8.73275910967239000000e-001) (30, 2.51638983039722600000e-001) (31, 8.73786637786371220000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 5.25207977826734230000e+000) (1, 1.03239143281039400000e+000) (2, 3.01101366420884860000e-001) (3, 9.74390886844162200000e-001) (4, 4.99496142367456490000e-001) (5, 2.63660096075690190000e-001) (6, -1.42756417652314420000e-001) (7, 1.61052609472158890000e+000) (8, 7.66782419857050980000e+000) (9, 6.67467421956784100000e-001) (10, -1.82730332258242040000e+001) (11, -1.92830925990312820000e-001) (12, -6.34102656179752370000e-001) (13, 5.46727400212644650000e-001) (14, 2.31578743662688550000e-001) (15, 7.52332326224051770000e-001) (16, 2.83174774980013750000e-001) (17, -5.28574916254924810000e-001) (18, 1.05238599844804440000e+000) (19, 3.37366813020907820000e-001) (20, 5.83682581927137050000e-002) (21, 5.40868739835756340000e-001) (22, 6.70559461471363030000e-001) (23, 2.52010062847806970000e-002) (24, 8.53352144319127870000e-001) (25, 4.90369730759919460000e-001) (0, 4.65774657610527140000e+000) (1, 3.78662993951819520000e-001) (2, 8.55966376557171340000e-001) (3, 4.97950665158033930000e-001) (4, 2.01903325375994060000e-001) (5, 3.82702253476905270000e-002) (6, 3.52237046668126720000e-001) (7, 2.91213389756310900000e+000) (8, 7.17135752179827790000e+000) (9, 8.24276496795848910000e-001) (10, -6.14884228899937660000e+000) (11, 9.46824397736172440000e-001) (12, -1.26801091109889920000e+001) (13, 1.48230486370585670000e-001) (14, 7.20772363036623730000e-001) (15, 8.60161425314456270000e-001) (16, -1.66264919903720750000e-001) (17, -6.94433858595775890000e-001) (18, 5.19820210999749310000e+000) (19, 7.22312284088469370000e-001) (20, -7.85435984532705580000e-001) (21, 4.70450413134623930000e-001) (22, 6.79019735785465260000e-001) (23, 6.32281935896860880000e-001) (24, 1.32033811347810800000e+000) (25, 1.35230848593277430000e+000) (0, 1.34151041909846850000e+001) (1, 8.07314220848641540000e-002) (2, 1.27357001667454920000e+000) (3, -5.61509111553939990000e+000) (4, 8.51320473548808350000e-002) (5, 2.85287000987042920000e+000) (6, 7.62270771925054660000e-001) (7, 2.66087540423265170000e+000) (8, 3.66196962412106760000e+001) (9, -1.57497124146504320000e+000) (10, -3.88750226802782390000e+000) (11, 8.57031292386372990000e-001) (12, -8.94551819480460590000e-001) (13, -1.66090681771364240000e-001) (14, 1.12185524442943300000e+000) (15, 2.27694831891960890000e+000) (16, -3.96481242066118120000e+000) (17, 1.00639332825126290000e+000) (18, -1.90506590932688670000e+000) (19, 1.64731393918865130000e+000) (20, 2.65357456487718370000e+001) (21, 5.62601575277127710000e+000) (22, 1.54572136398971740000e+000) (23, -2.07241111692685950000e+000) (24, 4.75678857271686490000e-002) (25, 1.26630180581226390000e+000) (0, 3.40285264802882370000e+000) (1, -3.93636008897005950000e-001) (2, 2.60062567337477620000e-001) (3, -1.54552737787698220000e+000) (4, -8.75176160520246270000e-001) (5, 2.76207181793479750000e-001) (6, 3.72694034493779800000e-001) (7, 1.12986905975904790000e+000) (8, 3.38655829990370090000e+000) (9, 1.89487842424501450000e-001) (10, -7.55215977630731050000e+000) (11, 8.43747109089393880000e-001) (12, 4.36386299183865580000e+000) (13, -3.13931252089479810000e-001) (14, -2.79282624184981180000e-001) (15, 5.96895048584390020000e-001) (16, 3.87469875606339440000e-001) (17, 6.12962346284612990000e-001) (18, 8.45000562532834180000e-001) (19, 6.35983484681496290000e-002) (20, 5.46737124899356550000e-001) (21, 2.35262139618275050000e-001) (22, -5.11679180758551550000e-002) (23, 1.03216276037094170000e-001) (24, 1.09832520551831260000e+000) (25, 1.84820222169859410000e-001) (0, 1.50121200444015530000e+000) (1, 6.18989059237581850000e-001) (2, 1.95789622941058750000e+000) (3, 2.14782674299594550000e-001) (4, -2.33470885171572130000e-001) (5, 7.91954165060697820000e-001) (6, 5.16619088141507370000e-001) (7, 2.10028689679006810000e+000) (8, 3.00993138034905180000e-001) (9, -8.20935682084890760000e-001) (10, 1.40466667563951870000e-001) (11, 8.02065865788205490000e-001) (12, 1.88617104824963500000e+000) (13, -4.33927678992904330000e-002) (14, 9.22179644420771940000e-001) (15, 2.07467140442333080000e+000) (16, -9.05427464517891580000e-001) (17, -2.49366408768555090000e-001) (18, 7.33035014011791940000e-001) (19, 1.89862169987337600000e+000) (20, -6.23078257957374040000e-001) (21, 3.54794234816060870000e-001) (22, 8.34602621986136000000e-001) (23, 6.40932692250626430000e-001) (24, 1.32570593599856190000e+000) (25, 9.70637176717840110000e-001) (26, -7.20657813515155570000e-001) (27, -1.03190220205583220000e+000) (28, 4.29346032873097470000e-001) (29, 1.51459601782398520000e+000) (30, -1.43643145176813890000e+000) (31, 1.40276883947327380000e+000) (26, 6.75739108289849840000e-001) (27, -4.06169433110845430000e-002) (28, -7.09874395906065380000e-001) (29, -2.30136170941347110000e+000) (30, -7.97997179663732740000e-001) (31, 2.84422324736167730000e+000) (26, 1.01451019936360170000e+000) (27, 1.42753237471585260000e+000) (28, 1.66192905187124040000e+000) (29, 3.08024538690288400000e-001) (30, 2.74977387348280540000e+000) (31, 3.11304080805844440000e+000) 

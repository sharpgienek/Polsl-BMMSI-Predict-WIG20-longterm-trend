FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.23639377269856040000e+001) (1, -2.80621197075043350000e-001) (2, -5.42491253814955330000e+000) (3, -2.90434967892311660000e-001) (4, 3.46195963747263310000e+000) (5, 5.14146118136145860000e-001) (6, 1.27460434752592380000e+001) (7, 1.94577423569794730000e+000) (8, 2.74865827223828880000e+001) (9, 1.16843930447948300000e+000) (10, 2.48586288358615410000e+001) (11, 1.40028766134628310000e+000) (12, -7.45854230995016240000e-001) (13, 1.54369845776650280000e-001) (14, 7.24871076256992650000e-001) (15, 2.77036529833942390000e-001) (16, 3.22638647627040150000e+000) (17, -5.74280574921778420000e-001) (18, 1.95270792980761850000e+001) (19, -2.55851198730965620000e-001) (20, -2.61717448490333690000e+000) (21, -2.02336188133679960000e-001) (22, 6.79558276335150160000e+000) (23, 2.53301503804982290000e-001) (24, 5.44101883837950150000e+000) (25, 1.49651313622829330000e+000) (0, -1.40406487626097360000e+001) (1, -1.45586707281607560000e+000) (2, -1.52905511240658010000e+000) (3, 1.34020453953838400000e-002) (4, -2.91962871924893220000e+001) (5, 3.83360761908578430000e-001) (6, -2.52988211348071810000e-001) (7, 1.68559922223890710000e+000) (8, -5.44764835105307470000e+000) (9, -1.01995682398293000000e+000) (10, 3.27097808991172160000e+000) (11, 9.93769249615675480000e-001) (12, 6.96533319540344480000e+000) (13, -7.33849204861713140000e-003) (14, 2.80285429935239080000e-001) (15, -4.24875251481396990000e-001) (16, -3.15289835479189910000e-002) (17, 1.07993987454849450000e+000) (18, -3.87195803504556750000e-002) (19, -1.16576983444504680000e-001) (20, -3.61289055713550990000e+000) (21, -6.47912320444077760000e-001) (22, 2.32247382063304140000e+001) (23, 1.11784370220977470000e+000) (24, 4.72470824078663830000e+000) (25, -6.02292550470916730000e-002) (0, 1.95034671368343670000e+001) (1, 6.29384551730880480000e-001) (2, 2.48656130659053820000e+001) (3, -6.94839806848783210000e-001) (4, -4.16860241050866340000e+000) (5, 2.31142706755151310000e-001) (6, 4.94969030825197440000e-001) (7, 2.26227299062805090000e-001) (8, 1.35273523995243340000e+001) (9, 1.05988206515930640000e+000) (10, 1.75838460502816720000e+001) (11, 4.08075955414009870000e+000) (12, -1.73683580782513050000e+001) (13, 3.78489986600403390000e-001) (14, 5.32549897508668990000e-001) (15, 1.97860058986270080000e+000) (16, -2.21856334679723840000e+001) (17, -6.68555088624859570000e-001) (18, -5.17230789042902120000e+000) (19, 2.54045180743559460000e-002) (20, -1.25639722908628570000e+001) (21, 1.71795648225134890000e+000) (22, -3.45097446930890110000e+001) (23, 8.65979275481684520000e-001) (24, -1.19856844929130690000e+001) (25, 4.06129014830757140000e-001) (0, 2.47927770306320240000e+001) (1, 8.82536596502364490000e-001) (2, 5.65533038153233300000e-001) (3, 3.55796055391880920000e-001) (4, -7.45669959004999770000e-001) (5, -4.09784664188562690000e-001) (6, -2.32807208171569610000e+001) (7, -3.35928739183295190000e-001) (8, 4.38329601418966690000e+000) (9, 1.33923164528440310000e+000) (10, -3.94253058537205940000e+000) (11, -1.69101976685215450000e-001) (12, 3.26434005679280550000e-001) (13, 9.90337959717157550000e-001) (14, 1.70781333081610750000e+001) (15, -5.34300237224063950000e-001) (16, -7.04455338458609060000e+000) (17, -9.78394394937442070000e-001) (18, 2.36053714758089160000e+001) (19, -8.86282376866994740000e-001) (20, 5.39529248432008850000e+000) (21, 4.52214246511263570000e-001) (22, 2.03754288750667700000e+001) (23, -1.08092617886599090000e-001) (24, 2.07398051894843190000e+001) (25, -1.00624087859713310000e+000) (0, 4.34259944339952050000e+000) (1, -5.65343226567141780000e+000) (2, -3.23248407097049220000e+001) (3, -1.31124489934183420000e+000) (4, -8.37653919439459390000e+000) (5, -4.81901994294758160000e-001) (6, -5.00084039528112890000e+000) (7, -5.39831440547775680000e-002) (8, 2.83188924473814690000e+001) (9, -2.95333642612271730000e+000) (10, 3.37921501855807450000e+001) (11, -3.56604326238570200000e-002) (12, -1.78818614908985080000e+001) (13, -2.20716867092211990000e+000) (14, -3.27228333746217930000e+001) (15, -4.29567317098913050000e-001) (16, 1.16943688289932340000e+001) (17, -3.75321080101035380000e-001) (18, -4.33280453158483600000e+000) (19, 1.18171677427609950000e-002) (20, -7.14383627433331460000e+000) (21, -6.70603349059788910000e-001) (22, -1.17712981748425190000e+001) (23, -1.29506702299512390000e-001) (24, -1.26918589455225150000e+001) (25, -3.84420888888250270000e-002) (26, -1.80978083097700890000e+000) (27, 1.65875872268031510000e+000) (28, 7.55027282928714900000e-001) (29, 1.11817572831849850000e+000) (30, -4.90506979198206130000e-001) (31, 8.53355642354975630000e-001) (26, 2.03732901907133310000e+000) (27, -1.07489440402876960000e+000) (28, -1.70164076549734000000e+000) (29, -4.99855123009448340000e-001) (30, -5.14925412212658970000e-001) (31, 6.62041004053235290000e-001) (26, -1.69085050323757800000e-002) (27, -4.60719786516344270000e-001) (28, 4.61464627885212480000e-001) (29, -2.90982255543385140000e-001) (30, 1.45422818743245210000e+000) (31, 1.49753901565756230000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.17013919354753690000e+000) (1, 2.47423459346196580000e-004) (2, -3.32628897300958790000e-001) (3, -1.74436134687002000000e-002) (4, 3.16555687934518490000e-001) (5, 2.74999448996838330000e-002) (6, 1.47153283566988250000e+000) (7, -3.29221293243480570000e-002) (8, 1.30939561716269330000e+000) (9, 1.18766368755078000000e-001) (10, 1.45412218181928710000e+000) (11, -1.80966896503067940000e-002) (12, 3.41943897791742390000e-001) (13, -4.42685650402981220000e-002) (14, 1.94214775284922620000e-001) (15, -2.45961540757856640000e-001) (16, -5.22458250382085710000e-002) (17, -1.50922555592129110000e-002) (18, 2.71406625295803060000e-001) (19, -1.62255627345317340000e-001) (20, 2.63450763649385520000e-001) (21, -3.14045580125354380000e-001) (22, 3.69632286094195130000e-001) (23, -2.38453537983320200000e-001) (24, -3.12052981780829960000e+000) (25, -1.25974219902363210000e-002) (0, 3.15114505263950220000e+000) (1, -8.39158225408823540000e-002) (2, 6.64146977230281820000e-001) (3, -6.00937805565430750000e-001) (4, -3.10721805003181380000e+000) (5, 4.63952111010433460000e-002) (6, -3.01713626158011560000e+000) (7, -1.32966940024424500000e-001) (8, 1.14490660169129340000e+000) (9, -8.21318796855958430000e-001) (10, -4.52274555841171160000e-001) (11, 7.76009193271700810000e-001) (12, -1.32341905248747290000e+000) (13, -9.23584622946750090000e-002) (14, 2.52524360424485340000e-002) (15, 3.32222730199378260000e-001) (16, 3.79787149622131060000e-001) (17, -8.06273630616142990000e-001) (18, -5.96649516656018040000e-002) (19, 6.69806156997849320000e-002) (20, -5.55634133059848270000e-002) (21, 4.69160159825850740000e-001) (22, 2.46428864785204590000e-001) (23, 4.53945379126983680000e-001) (24, -1.81871292780704070000e-001) (25, 2.69954662865261760000e-001) (0, 7.01271933525226540000e-002) (1, -4.71941650143625930000e-001) (2, 5.30707710347549040000e-001) (3, -4.91081333535327850000e-002) (4, 3.88210052165248230000e-001) (5, 2.84330415360547140000e-002) (6, 2.52409028166131410000e-002) (7, -1.47020732468794160000e-001) (8, 1.39310265871993180000e+000) (9, 1.12752584305460980000e-001) (10, 2.58686756573585700000e-001) (11, 2.06302440294303610000e-001) (12, -7.71400952417059530000e-002) (13, -1.82060332836806140000e-002) (14, 5.09778754957558310000e-001) (15, 1.14880274276373680000e-001) (16, 3.63479788456737620000e-001) (17, -8.04413433641948670000e-002) (18, 6.75238421784762900000e-002) (19, -7.70596019682817930000e-002) (20, 4.32699760191320560000e-001) (21, -1.50533724156881520000e-001) (22, 9.73844974492814370000e-001) (23, 2.69040478338548220000e-001) (24, -5.54259158671359440000e-001) (25, -4.77051406268472260000e-001) (0, -9.25182950647988720000e-001) (1, 1.77149695327724340000e-001) (2, -1.05646304451147730000e-001) (3, -2.85112403660129800000e-001) (4, 3.18281619568956400000e+000) (5, 4.71449433232616120000e-001) (6, 4.28400881874740180000e-001) (7, 3.82682622295136720000e-001) (8, 1.03979321210977500000e-001) (9, -6.25327536935486480000e-001) (10, 4.25129397450991260000e-001) (11, 1.44804046093942320000e-002) (12, -2.44384712045130880000e-001) (13, -5.48035294044964650000e-001) (14, 3.88923448646057930000e-001) (15, 1.96755797950509180000e-001) (16, -6.83114323021262070000e-001) (17, -3.54648600330644050000e-001) (18, 7.36770346992840610000e-001) (19, 1.54165884438678680000e-001) (20, 1.85867843737357620000e-001) (21, -6.06479919721431280000e-002) (22, 1.40458366274511910000e-001) (23, 7.58652445463153520000e-002) (24, -7.82320867468304760000e-001) (25, -1.96896773299283150000e-001) (0, -9.35168302359282060000e-001) (1, 4.49730575691405510000e-002) (2, -1.46243566184352790000e+000) (3, 2.83161401520154840000e-001) (4, 6.01164173137773820000e-001) (5, 8.45168242224544120000e-001) (6, -7.17728498653141810000e-002) (7, 3.58014918260559150000e-001) (8, 1.19727036181452860000e+000) (9, 6.65114529929481280000e-001) (10, 7.33341455449475710000e-001) (11, 2.77605391366562200000e-001) (12, 7.41785914450092120000e-002) (13, 1.33165123773819620000e-002) (14, -3.17920291438572190000e+000) (15, 1.11701429837986850000e+000) (16, -3.52841453005298340000e-001) (17, 6.45064367101720990000e-001) (18, -5.64579245014641410000e-001) (19, 4.95736870505646690000e-001) (20, -9.62792577338249520000e-001) (21, 3.98798610274533450000e-001) (22, -4.43582799386886720000e-001) (23, 3.20801782940415230000e-001) (24, -6.09185682590805630000e-001) (25, 8.84940024681695860000e-001) (26, -1.69047420020862480000e-002) (27, 3.27294372976280450000e-001) (28, -1.22584687075981040000e-001) (29, -5.25718160451191130000e-001) (30, 1.15642020003229390000e-001) (31, 4.81098771458788150000e-001) (26, 5.39901803003815630000e-001) (27, -4.02582747548302480000e-001) (28, -1.46440898475778960000e-001) (29, 3.24391938388393420000e-001) (30, 3.96467067271040750000e-001) (31, 7.73318929268411950000e-001) (26, 4.14613949950968060000e-001) (27, 5.82278512619652800000e-001) (28, -8.59349363314932250000e-002) (29, -8.24350159011977280000e-003) (30, 4.05860377957886990000e-001) (31, 3.37848902335062100000e-001) 

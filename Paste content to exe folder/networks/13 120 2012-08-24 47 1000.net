FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.48354874626713450000e+001) (1, 7.52413690757720020000e-001) (2, 1.54809516156636080000e+001) (3, 2.69554060419269260000e+000) (4, 4.05362831704415780000e+001) (5, 1.78826456170071530000e-001) (6, -8.30333589112203190000e+000) (7, 1.12287609514089180000e+000) (8, 2.75024136618801260000e+001) (9, 2.42371022462349870000e-001) (10, 5.12813691648517440000e+000) (11, -6.96375100139953410000e-001) (12, -8.08299225249288970000e+000) (13, -6.62233701662872540000e-001) (14, -2.58674515544052460000e+001) (15, 6.87835560774613720000e-001) (16, -5.37576342893649530000e+000) (17, -1.08355130235498160000e-001) (18, 1.96681250917142210000e+000) (19, -9.60070038694500060000e-002) (20, -4.08067545546773670000e+000) (21, 3.35606546813898810000e+000) (22, 4.82915489586773280000e+000) (23, -6.01219479558494290000e-002) (24, -3.14288589431875990000e+001) (25, 2.40427943485780560000e+000) (0, 3.34558909175410970000e+001) (1, 1.94097767635133090000e+000) (2, 1.49576127760539120000e+001) (3, -1.67608822659907510000e+000) (4, -7.60566169811574470000e+001) (5, 9.16495310254089480000e-001) (6, 3.44535114387351340000e+001) (7, -1.83140183094262830000e+000) (8, -2.17538263339069250000e+001) (9, 8.04432496211197940000e-001) (10, -1.34432226109736990000e+001) (11, 4.77367260113563670000e+000) (12, 5.67425174476863460000e+001) (13, 5.41936064398039540000e-001) (14, 5.05609454771392630000e+001) (15, -2.56575833437086140000e+000) (16, 4.39078967054109130000e+001) (17, 1.43872563498035300000e+000) (18, 2.87471719829755750000e+000) (19, 1.75890708266615330000e+000) (20, -3.06199032505224200000e+001) (21, 2.75577457273197360000e+000) (22, -2.41941824898857940000e+001) (23, 1.15722822912682610000e+000) (24, -7.59574535571506450000e+000) (25, -1.07838051070334420000e+000) (0, 2.76017172892961040000e+001) (1, -3.74191051369820030000e+000) (2, 1.88986054188339520000e+001) (3, -1.37043423776416040000e+001) (4, 7.69996486570944860000e+000) (5, -8.84340007349249340000e-001) (6, -6.03733639421907280000e-001) (7, -3.00528149551184230000e+000) (8, 5.46700953742113500000e+001) (9, -2.94969987664422990000e+000) (10, 4.44838628287359800000e+001) (11, -5.30958442815548540000e+000) (12, -8.92395254880855900000e+001) (13, 5.66865900171486250000e-002) (14, -1.78885294995086000000e+001) (15, 1.27597068717641200000e+000) (16, 2.56790403381129090000e+001) (17, -1.00374868388379550000e+000) (18, -4.76566299401030240000e+000) (19, -1.39645897082000500000e+000) (20, -2.47125902885881890000e+001) (21, -9.04546932630041490000e-001) (22, -6.41929377368166600000e+001) (23, -1.68155685663758200000e+000) (24, -1.23937264279809650000e+001) (25, -2.13570136712123080000e+000) (0, -3.69623540872685230000e+001) (1, -2.40131902817015020000e+000) (2, 8.28817044355865380000e+000) (3, 3.14613060980844360000e+000) (4, 6.70325814507890530000e+001) (5, -5.12817283512371660000e-001) (6, -4.06630896017359260000e+001) (7, 1.58891549866943250000e+000) (8, 1.73905549155830350000e+001) (9, -1.14248033988243720000e+000) (10, 1.28612548416292880000e+001) (11, -1.85096406424551560000e+000) (12, -3.96565003831663110000e+001) (13, -3.10536641881096690000e+000) (14, -3.77658139702542360000e+001) (15, 1.36693872496051210000e+000) (16, -3.11958168144822420000e+001) (17, -1.29248602506718610000e+000) (18, -6.00879433443941660000e+000) (19, -1.33266994602024240000e-001) (20, 1.69522470299885980000e+001) (21, -2.76759450186345780000e+000) (22, 3.28359260208895950000e+001) (23, -1.39782465394033520000e-001) (24, 2.77919911531055600000e+001) (25, 5.36532706108837080000e-001) (0, -1.59244219184652810000e+001) (1, -1.12664755195156040000e+000) (2, -4.29214728814136920000e+001) (3, -1.07724480653269670000e+000) (4, 3.19127359760466330000e+001) (5, -3.81137990604852040000e-001) (6, -2.73529932402198920000e+000) (7, -1.35031467466768060000e+000) (8, -4.88223405943279760000e+001) (9, -1.32995624230578310000e-001) (10, 1.06637749982882840000e+001) (11, 3.84664169596834960000e+000) (12, -2.83498547233466280000e+001) (13, -5.21306447718609460000e-001) (14, 2.02603381414583980000e+001) (15, -2.53079750676574910000e+000) (16, -5.61991549024459050000e+001) (17, 4.02640952135759180000e-001) (18, 3.65297780265462530000e+001) (19, 1.66523937961402630000e+000) (20, 1.82816922647969450000e+001) (21, -5.17880904272205100000e+000) (22, 3.25761438552352440000e+001) (23, -4.08647321642608840000e-002) (24, 6.54527346886295900000e+001) (25, 3.74471749016862180000e+000) (26, -3.25135614817295520000e+000) (27, 1.47042976058821720000e-001) (28, -1.33728083408168170000e+000) (29, 1.10709865621253510000e+000) (30, -1.53695656565430560000e+000) (31, 2.30401224562870110000e+000) (26, 2.05474061828979560000e+000) (27, -1.82280085853783280000e+000) (28, -3.49527659454475500000e-001) (29, -2.23877993962182090000e+000) (30, 1.53718443192828350000e+000) (31, -4.33847443263158440000e-001) (26, 2.85021763865463960000e-001) (27, 1.87075023031432690000e+000) (28, 1.87428998684731170000e+000) (29, 1.70875442566853500000e+000) (30, 3.73551601141124960000e-002) (31, 1.82063957699409970000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.75925432186399530000e+001) (1, 2.95192938046726110000e+000) (2, 9.19940648137134960000e+000) (3, 1.71047177008469120000e+000) (4, 1.81819475889157300000e+001) (5, -1.46209330045974780000e+000) (6, -2.94399274356789920000e+001) (7, 1.07289157951366800000e+000) (8, -1.48346564007678480000e+001) (9, 3.74816738896239610000e+000) (10, 1.46859774345785880000e+001) (11, -1.71043545519927060000e+000) (12, 5.45554364808170790000e+000) (13, 3.35887204804722510000e-001) (14, 9.86059570564049360000e+000) (15, -9.79925466492675700000e-002) (16, -3.18789095755177810000e+001) (17, 3.19940011475061190000e+000) (18, 8.20542763296228110000e-001) (19, 1.86210338472011210000e+000) (20, -3.95751671871640820000e+000) (21, 1.39902332307701080000e+000) (22, -6.40838918449776430000e+000) (23, 8.99159257772166760000e-001) (24, 4.57163509129785780000e+000) (25, -1.58251237452528630000e+000) (0, 1.38436280717910220000e+002) (1, -5.31769034449495750000e-001) (2, -8.19573287752942110000e+000) (3, -4.87697246653149170000e-001) (4, 1.20717661837857940000e+001) (5, 1.78422614197024810000e+000) (6, 3.70654221471361040000e+001) (7, -1.31636121823892080000e+000) (8, 9.60746246589768590000e+001) (9, 4.21262871343608180000e-001) (10, 8.71754877789972230000e+000) (11, 2.16136474146069670000e+000) (12, -3.27731520404122490000e+001) (13, 5.45755781354714360000e-001) (14, 9.96465105245281710000e+000) (15, -1.72797980784275110000e-001) (16, -1.06907031972309240000e+000) (17, -1.82871987335183150000e+000) (18, 3.71090508630386400000e+001) (19, -2.07495347226699160000e+000) (20, 6.97951235960845510000e+001) (21, 4.07971501358152020000e-001) (22, 1.14027182468614910000e+001) (23, -1.70192960446751560000e+000) (24, -5.10624432137694550000e+001) (25, -5.14230216391024370000e-002) (0, 1.60546122266689930000e+001) (1, -5.38405241883349390000e-002) (2, 2.72023456473397150000e+001) (3, -9.52278162811678430000e-001) (4, -4.95593283544613850000e+001) (5, -3.37606904185354790000e+000) (6, -7.75379565799603800000e+001) (7, -5.85198270283662560000e-001) (8, 3.33018081620761490000e+001) (9, 8.81188987806681200000e-001) (10, -4.98084130220186340000e+001) (11, -3.17303427194221330000e-001) (12, -4.85755772579465980000e+001) (13, 4.16362931675480050000e-001) (14, 9.35936129387996530000e-001) (15, 1.05218672672651260000e+000) (16, 4.39525725696021960000e+001) (17, 1.87553753275068980000e+000) (18, 1.53022652986064430000e+001) (19, 8.91543300642816950000e-001) (20, 3.70219693732529930000e+001) (21, 1.10238447450015720000e+000) (22, -2.86325992454806550000e+001) (23, -1.30264056987523920000e+000) (24, -9.37949470348287800000e+001) (25, 1.68385456339947130000e+000) (0, -8.28084027948274580000e+001) (1, 2.18237407374513160000e+000) (2, 1.74723171014331310000e+001) (3, 2.84506601759321460000e-001) (4, 1.52468996975219040000e+001) (5, -2.19120079815921320000e+000) (6, 8.76688191960146490000e+000) (7, -7.00805068058101830000e-001) (8, -5.49871349600449480000e+000) (9, -1.44608535067752950000e+000) (10, -3.07103004599083040000e+001) (11, -4.13806902103191820000e+000) (12, -1.67936531855138900000e+001) (13, -5.55958099740490260000e-001) (14, -2.40683299699447310000e+001) (15, -1.18259039038006920000e+000) (16, -1.51840281516808580000e+001) (17, 8.48841828872804680000e-001) (18, 1.02253171419260700000e+001) (19, 1.16484834358833540000e+000) (20, -1.04283910755622140000e+001) (21, -5.65276711738326610000e-001) (22, -1.37740321269659840000e+001) (23, -2.36085043022884630000e-001) (24, -1.66533512674562760000e+001) (25, 2.37580315148385070000e+000) (0, -1.79064280961272080000e+001) (1, 1.46141739695230320000e+000) (2, 3.73565732491899500000e+001) (3, 1.04744329219750810000e+001) (4, 9.40515413029292090000e+000) (5, 4.74297704839817420000e-001) (6, -2.96206057373477590000e+001) (7, 1.82640212817009460000e+000) (8, 9.35982272831831490000e+001) (9, 7.12557199924533520000e+000) (10, 2.07319857697178040000e+002) (11, -3.60312245625724790000e+000) (12, -4.20599071479636990000e+001) (13, -1.80944694632925970000e+000) (14, 3.79329636914138180000e+001) (15, 1.98901535777315990000e+001) (16, 3.00462666126217240000e+002) (17, 2.44029731692822230000e+001) (18, -2.02341827141554940000e+001) (19, -5.58897259551635490000e-001) (20, -9.26881040191525470000e+001) (21, 1.28592584577505630000e+001) (22, -1.07139344535739950000e+002) (23, -6.00381921706157060000e-003) (24, 6.10557668548691090000e+000) (25, 1.62425721075113540000e+001) (26, 1.77555028176751460000e+000) (27, -6.97078724093586180000e-001) (28, 3.88441760317373100000e-001) (29, -2.10146737825200080000e+000) (30, -2.13788573620889320000e+000) (31, 1.91136948890335770000e+000) (26, 1.12917097937179660000e-001) (27, 2.03592269538563330000e+000) (28, -1.83044501053768130000e+000) (29, 1.98700350154797320000e+000) (30, 3.14315273403252990000e-001) (31, 1.58266447180114380000e+000) (26, -1.45331200722009580000e+000) (27, -9.58353927837078180000e-001) (28, 8.70727988611642360000e-001) (29, 1.66240854622357830000e-001) (30, 9.79441511928183850000e-001) (31, 7.24657135065960580000e-002) 

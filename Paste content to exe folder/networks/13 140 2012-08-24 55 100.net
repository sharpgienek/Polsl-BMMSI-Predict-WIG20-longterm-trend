FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.66275587469751310000e+000) (1, 1.15028931648606860000e+000) (2, -1.78420086862407360000e+000) (3, 2.84466654019761660000e+000) (4, 2.44910631154647870000e+001) (5, -8.89462507831683570000e-001) (6, 9.53332881301173710000e+000) (7, -7.70589097058538730000e-001) (8, 3.09394854471641030000e+000) (9, 1.42173168026995390000e-001) (10, 6.52714630334166210000e+000) (11, -1.51902321752463920000e+000) (12, 2.91827076161706850000e+001) (13, 9.55988305372591050000e-001) (14, 3.15983264454596910000e+001) (15, -1.77639717463651410000e+000) (16, 2.09151315519928020000e-001) (17, 1.65273212300911410000e+000) (18, 8.40975896016745320000e+000) (19, 4.77233282878568800000e-002) (20, 1.51477343281878630000e+000) (21, 7.71397534938466740000e-001) (22, 6.90116632055144750000e+000) (23, 8.19778976069999830000e-001) (24, 3.00830645754768880000e+000) (25, 4.21260521989901830000e-001) (0, -2.79094985375641150000e-001) (1, 2.34793061947742960000e+000) (2, 3.11938839985816120000e+001) (3, 1.41750018396236950000e+000) (4, 2.21414252885310710000e+001) (5, 3.43133768496052700000e-001) (6, 2.30579362586156480000e+000) (7, 1.68016419826281680000e+000) (8, -2.73249836131600540000e+001) (9, 7.28849683686464100000e+000) (10, 2.78425807353656330000e+001) (11, 3.52653570962733200000e-001) (12, 2.98601423273181440000e+001) (13, 2.22406194698318240000e+000) (14, 2.49988766266933060000e+001) (15, -3.14658190850269640000e-001) (16, 6.13753833812291560000e+000) (17, 2.00522156385154200000e+000) (18, 1.38459620315432360000e+001) (19, 1.66923603077222090000e+000) (20, 1.92805151463440240000e+000) (21, 9.03480477989503480000e-001) (22, -2.21068534103372420000e+000) (23, 2.04382028369512390000e-001) (24, 7.92208651999348420000e-001) (25, 1.59546267865947720000e-001) (0, -8.30387822020266600000e+000) (1, -1.36074344758737340000e+000) (2, 4.70686484356383050000e-001) (3, 2.07105813789744820000e-001) (4, 1.51604881440351990000e+001) (5, -2.24087742427281050000e-001) (6, 4.56890210517911370000e+001) (7, 2.38071364093623310000e+000) (8, 1.72291959583823020000e+001) (9, -1.10970043914045410000e+000) (10, -8.19496345549375960000e+000) (11, -3.25026661039068240000e-001) (12, -3.92253525035978840000e-002) (13, -7.04350333473770960000e-001) (14, 1.14232871702650790000e+001) (15, -9.62965241894208180000e-001) (16, 6.83659820709383250000e-001) (17, -5.09962402059555010000e-001) (18, -8.30501908874005770000e-001) (19, -5.69818717102761770000e-001) (20, -1.63234054174469140000e+001) (21, 5.97014227973790670000e-001) (22, 2.00933726479050280000e+000) (23, 1.00546950025098570000e+000) (24, 2.95800116462496160000e+001) (25, -2.15671426387626460000e-001) (0, 1.14218939961833830000e+000) (1, -4.83279842296556570000e-001) (2, 2.95091790053761720000e+001) (3, -8.03043089050313850000e-001) (4, -1.98743960196956660000e+001) (5, -8.66122408261126440000e-002) (6, -5.81091421522569100000e+000) (7, 2.16946150786301620000e+000) (8, -1.64564396400529310000e+001) (9, 1.43677697922583850000e+000) (10, -2.55848436690350980000e+000) (11, 7.49922927762124880000e-001) (12, -6.79968180670428880000e+000) (13, 3.32157357639768360000e-002) (14, -2.09542433210323380000e+000) (15, 4.30943488313104970000e-001) (16, 9.79528301582207740000e+000) (17, -5.13225296558891130000e-003) (18, -5.70227696223528910000e+000) (19, 5.14975513851561710000e-001) (20, 4.15403284904993870000e+000) (21, 2.02820985597111520000e+000) (22, 1.65541897539747960000e+001) (23, -4.72114963096908130000e-002) (24, 2.15688000260301570000e+001) (25, 2.52412243609866420000e-001) (0, -2.24408085053257180000e+000) (1, 3.63755065958748620000e-001) (2, 1.55693349822839180000e+000) (3, 2.33975120393367320000e-001) (4, 5.39233750653299100000e+000) (5, -3.88597762668014600000e-001) (6, 9.27201739213835020000e+000) (7, -3.46196190869831890000e-001) (8, 6.72132913589857160000e-001) (9, 2.27397767117092610000e-001) (10, 3.95533479913678270000e+000) (11, -5.21257285041055280000e-001) (12, 9.88800773799957790000e+000) (13, 1.86656188289291510000e-001) (14, 2.97118433894661170000e+000) (15, -4.73968658962156120000e-001) (16, -5.15253160044181070000e+000) (17, 7.28306653558696390000e-001) (18, 1.09122411477032100000e-001) (19, 5.47378411554269510000e-002) (20, 1.12446632924594510000e+000) (21, 8.91907687765897960000e-002) (22, 8.51265185771704740000e-001) (23, -7.79934219157133250000e-003) (24, -1.48006819898527770000e+000) (25, 3.40767248691596140000e-001) (26, 1.67755085998675570000e+000) (27, 1.88964731712166300000e-001) (28, -7.00102179265076340000e-001) (29, 9.42902528192297360000e-001) (30, -1.85420801289733460000e+000) (31, 2.26390450892466760000e-001) (26, -1.94334249191774360000e+000) (27, 1.19288593558974430000e+000) (28, 8.60404792427041150000e-001) (29, -1.34284351595038820000e+000) (30, 1.89391277410885460000e+000) (31, 9.63228200027692050000e-001) (26, 1.33055751622638910000e-001) (27, -1.56201366286296620000e+000) (28, -1.89519807851849520000e-001) (29, 3.11663264550201990000e-001) (30, 4.98249265891320330000e-002) (31, 1.44203473627452610000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.02317528964530580000e+002) (1, -1.27884512892773290000e+002) (2, -9.41440740244411700000e+002) (3, -6.32438300267738430000e+001) (4, -7.63157745864105890000e+002) (5, 8.90376289102991870000e+000) (6, -1.50000000000000000000e+003) (7, -1.07258649961240200000e+001) (8, 1.26452359037278570000e+003) (9, -2.30146085699191790000e+002) (10, 1.50000000000000000000e+003) (11, -2.37283598116227520000e+000) (12, 8.46335070062234390000e+001) (13, -2.15849916746285340000e+002) (14, -1.93365660011892800000e+002) (15, 1.92794467538973710000e+001) (16, 7.04301553809162100000e+002) (17, -3.00116589986533630000e+001) (18, -1.40407001517643470000e+002) (19, -2.90311659043422620000e+000) (20, -3.23814050021062770000e+002) (21, 1.30566183399305820000e+001) (22, -7.90039553257601940000e+002) (23, 4.06695627423594170000e+000) (24, 1.86290746831007740000e+002) (25, -4.46082736321834790000e+000) (0, 1.99088543312096900000e+002) (1, 1.51607685455727450000e+000) (2, -1.57871257372632750000e+002) (3, 4.07394348103405330000e+000) (4, -2.78831170498082710000e+002) (5, -3.51103519760112230000e+001) (6, -1.53005941329814310000e+002) (7, 3.78929485993223810000e+001) (8, 6.21956127095637270000e+002) (9, 2.12167506633424360000e+000) (10, 6.00133378872638450000e+002) (11, 5.68784713406878150000e+000) (12, 2.72739928926750150000e+001) (13, -2.29324038136037740000e+000) (14, -6.24373611827007040000e+002) (15, -1.48569116862107840000e+001) (16, 1.70466541989412690000e+002) (17, 1.98301475797232530000e+001) (18, -8.53927462014092950000e+001) (19, -3.87240791467751590000e+000) (20, -5.99773666217760630000e+001) (21, -4.42846792640271330000e+001) (22, -8.03068063740564980000e+002) (23, -2.09238621198749220000e+001) (24, -1.24098427624664150000e+002) (25, 5.09499947321688130000e+000) (0, -1.49335999467087350000e+001) (1, -3.84819840553468270000e+000) (2, 4.33648979261713730000e+001) (3, -6.16148402992048540000e+000) (4, -4.58864252821152690000e+001) (5, 4.66935403090760760000e-001) (6, 7.13723305958766620000e+001) (7, 1.39899585753394450000e+000) (8, 2.24617450524666290000e+001) (9, -3.42829990433870140000e-001) (10, -1.64235997278775160000e+001) (11, 2.58577176658651280000e+000) (12, 4.84200362551555760000e+000) (13, -1.03421998329061940000e+000) (14, -4.77782095778068200000e+001) (15, 4.36293178194297940000e+000) (16, -1.36254151883678600000e+001) (17, 1.04388154807149320000e-001) (18, -2.66028603608279610000e+001) (19, 1.49141812411336080000e+000) (20, 5.69054913985411840000e+000) (21, 8.93407567533389010000e-001) (22, -3.19109600234027870000e+001) (23, -4.85646314073396590000e-002) (24, -2.27469740995894090000e+001) (25, -1.66340343096007890000e+000) (0, -1.35461396381224710000e+001) (1, 3.48282988953258950000e+000) (2, -3.68499776063419520000e+001) (3, 6.19095715446845050000e+000) (4, 6.07393086994814840000e+001) (5, 4.16951661825023570000e+000) (6, -2.17056109044022420000e+001) (7, -5.72093117523423000000e+000) (8, -1.93101846290160740000e+001) (9, -2.95262008188619920000e+000) (10, -3.94338181540347460000e+001) (11, -2.99375827711486230000e+000) (12, -1.58905892053739150000e+000) (13, 4.58843258790992970000e-001) (14, 8.92647446051903870000e+001) (15, 7.26223154465959060000e-002) (16, -3.47684417003285230000e+001) (17, -2.76485891433042590000e+000) (18, -5.72495544857941670000e+000) (19, -9.52918473018431580000e-001) (20, 1.73601311720094880000e+001) (21, 2.61955986351343520000e+000) (22, 7.79494648634593120000e+001) (23, 5.17664675399133680000e+000) (24, 6.27869327844465630000e+000) (25, 5.29798022093102540000e+000) (0, -1.56208976201559930000e+000) (1, 1.56292269045649810000e+000) (2, -9.77225569182852110000e+000) (3, 1.28227026596971160000e+000) (4, -1.66357633898901990000e+000) (5, 2.93669023787196000000e-001) (6, -3.86087930379833600000e+000) (7, -6.64026914498577980000e-001) (8, -1.96119408116891730000e+001) (9, 4.42365174307223720000e-001) (10, -2.64962322256752320000e+001) (11, -4.01363696364040960000e-001) (12, -1.07966877487017160000e+001) (13, 1.27502477276222610000e+000) (14, -2.28235457446041500000e+000) (15, -4.79950833453396230000e-001) (16, -1.36033456112008860000e+001) (17, -2.37189459535892570000e-001) (18, 1.04695046981661390000e+000) (19, -2.41209449929648930000e-001) (20, -2.62560380307157000000e-001) (21, 1.59133384362968140000e-001) (22, 1.00140471597985210000e+001) (23, 9.70894859703571310000e-002) (24, -1.09272522465486180000e+000) (25, 3.34566705864027280000e+000) (26, -1.29285024210765630000e-001) (27, -2.48439997933923530000e+000) (28, -2.53866035026471650000e+000) (29, -1.44449433397105790000e+000) (30, -4.27687340944433990000e+000) (31, 5.44128929336571950000e+000) (26, -1.70777828155611560000e+000) (27, 1.69795814116096810000e+000) (28, 1.73283595335707830000e+000) (29, 2.24677986642397710000e+000) (30, -8.17643066501159480000e-001) (31, 1.66702308155604520000e-001) (26, 1.77743458277013850000e+000) (27, 3.10219501330675320000e-002) (28, 1.08774541936648040000e-001) (29, -6.42148716134948170000e-001) (30, 3.97515788567659590000e+000) (31, -1.47442652631527740000e+000) 

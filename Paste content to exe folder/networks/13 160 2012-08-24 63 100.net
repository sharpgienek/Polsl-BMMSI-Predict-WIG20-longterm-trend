FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.94135894979359060000e+000) (1, -6.74815228886758490000e-001) (2, 1.16501955855275630000e+001) (3, -3.69674210388644900000e-001) (4, 1.40707404562810560000e+001) (5, -3.71326140377332580000e-001) (6, 1.04987071633112660000e+001) (7, 1.15837734329923670000e-001) (8, -5.90720925545357910000e+000) (9, -4.60769841946594870000e-001) (10, 3.46183230643676780000e+000) (11, 9.75049812510678020000e-001) (12, 3.34776768065058050000e+000) (13, -7.74718161290791190000e-001) (14, -2.07322898416520790000e+001) (15, 1.07423940851260040000e+000) (16, -1.16422366558901300000e+001) (17, 1.17136568722784570000e+000) (18, -5.09843331478684190000e+000) (19, 6.65945384612460560000e-001) (20, -2.25438605765506670000e+000) (21, 1.68903965366299420000e-001) (22, -2.05352099017990670000e+001) (23, -2.70986286594205710000e-001) (24, -1.51844600988435910000e+001) (25, 3.93806980412241550000e-001) (0, -9.45768620373774200000e+000) (1, 1.18521952125817260000e+000) (2, 1.34397600677642210000e+001) (3, 1.63210595670489480000e+000) (4, 8.54786416299162940000e-002) (5, -5.51164794117489860000e-001) (6, 1.91982274953608470000e+001) (7, 1.34981605782954440000e+000) (8, -5.07562900816736400000e+001) (9, 1.09488925349721030000e+000) (10, 8.33257800506538640000e-001) (11, 1.60526852196507090000e+000) (12, 4.73164107160396410000e+001) (13, 4.63468928377384350000e-001) (14, 9.14470895875127980000e-001) (15, 4.70726400209679980000e-001) (16, 4.90280964249804540000e+000) (17, 2.31480600099752640000e+000) (18, -4.73124971598222730000e+000) (19, 5.26331470790878280000e-001) (20, 5.01604362033316780000e+000) (21, -4.10100903504755370000e-001) (22, -1.64802341641696940000e+001) (23, -1.26423682742013570000e-001) (24, 1.47380343661779650000e+001) (25, 4.01619423668904410000e-001) (0, 3.89415563588341260000e+000) (1, -5.88389824480659460000e-001) (2, 1.67348584218935020000e+001) (3, 4.49014280923955960000e-001) (4, -8.75896793619268800000e+000) (5, 4.21503354449390910000e-001) (6, 2.31992145991554020000e-001) (7, 1.48263195955796930000e+000) (8, -6.38085769351403440000e+001) (9, 9.76951610457801320000e-001) (10, -1.58310848010864440000e+000) (11, 1.10232988071031430000e+000) (12, 1.07352211940363060000e+000) (13, 1.64308714898881460000e-001) (14, 1.06450087169778540000e+001) (15, 3.30705900926629660000e-001) (16, -4.09926638778491450000e+000) (17, 3.36100150724224280000e-001) (18, -8.34601752820361580000e+000) (19, 1.65263894313018870000e+000) (20, 1.07239022427588230000e+000) (21, 3.08364156784610530000e+000) (22, -3.09086593290903300000e+001) (23, 8.98204088401547560000e-002) (24, 3.71967750981830750000e+000) (25, 1.05277228423606140000e+000) (0, -3.83560474865074050000e+000) (1, 3.95251895843196310000e+000) (2, 4.79431792651339560000e+001) (3, 1.06526330392789540000e+000) (4, 1.64838810803927810000e+001) (5, 2.39176587275145820000e-001) (6, 7.20661623317996900000e+000) (7, 3.01112679559384640000e-001) (8, -1.41736377246513200000e+001) (9, 3.11283581800457960000e+000) (10, 1.80435458409323670000e+001) (11, -6.97559013621107170000e-001) (12, 2.56111281550281900000e+001) (13, 2.09266882701487370000e+000) (14, 1.77635785639236270000e+001) (15, -8.22536217064120830000e-001) (16, -1.82955888156307150000e+001) (17, 3.69594090181428250000e-001) (18, 1.75777557935516490000e+001) (19, 5.83345590774572490000e-001) (20, 1.64872931465087010000e+001) (21, 6.83364853881014760000e-001) (22, -6.99754974411269660000e-001) (23, -7.61449457395714930000e-002) (24, -9.32347173144865950000e+000) (25, 7.83073218408170010000e-001) (0, -1.44600262931538430000e+001) (1, 1.15677839748236800000e+000) (2, -2.08670109457813770000e+001) (3, 1.05008403627695120000e+000) (4, -2.42825693315918940000e+001) (5, -8.96496915193785020000e-002) (6, 1.01818867146546830000e+001) (7, 1.04418840237474680000e-001) (8, -2.24431312510289340000e+001) (9, 5.94821756356915140000e-001) (10, -8.14034506740707540000e+000) (11, -4.44625612779361650000e-002) (12, 4.31481921355005850000e+000) (13, 5.54523183234046260000e-001) (14, -6.03560278425424550000e+000) (15, -5.00295368675263590000e-001) (16, -1.97270790836912300000e+000) (17, 6.77267622296983120000e-002) (18, -3.59521971689022290000e+000) (19, 9.74263320076343770000e-003) (20, 2.80198923608957040000e+000) (21, -4.11231704655571350000e-001) (22, -1.47946079238396050000e+001) (23, -1.00779881594276640000e-001) (24, 1.79313266144953020000e+000) (25, 1.17269616277034680000e-001) (26, -1.61861881247918850000e+000) (27, 1.97491277715844270000e+000) (28, 1.06442111414739290000e+000) (29, -1.42675515140621410000e-001) (30, -1.90651971678130150000e+000) (31, 1.31056212471479360000e-001) (26, 1.03989850413531840000e+000) (27, -4.32011317689355300000e-001) (28, -1.10539162478961250000e+000) (29, 8.99355464807115480000e-001) (30, 6.24249340978625390000e-001) (31, 1.02259492557934180000e+000) (26, 3.31876518993896590000e-001) (27, -1.31114071402594350000e+000) (28, 2.97469438361188220000e-001) (29, -7.04709187795770300000e-001) (30, 1.02151021877871220000e+000) (31, 1.04817588315178890000e+000) 

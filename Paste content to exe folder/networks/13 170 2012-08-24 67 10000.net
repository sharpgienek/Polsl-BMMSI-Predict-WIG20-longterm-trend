FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.48833994270527140000e+002) (1, -7.70176200097477090000e+000) (2, -1.74404334252889500000e+002) (3, -5.33042299293166800000e+000) (4, 1.80502646960141190000e+002) (5, -1.46331569737486980000e+000) (6, 2.84078054982039300000e+002) (7, 6.33593332581709670000e+000) (8, -2.35808136097481590000e+002) (9, 6.67564439222792180000e-001) (10, -6.03155216196278590000e+001) (11, -6.08277892410396430000e+000) (12, 1.51123527492085060000e+002) (13, -2.32640919458021590000e+000) (14, -2.60870068065913260000e+001) (15, -8.36902283324355700000e+000) (16, -1.77255116419595370000e+002) (17, -1.47823977354829020000e+000) (18, 6.69286992585777510000e+001) (19, -2.64081248453297680000e+000) (20, -4.32369942875853330000e+001) (21, -2.35818439536922100000e+000) (22, 7.19237549862573640000e+001) (23, 5.08180174281109290000e-001) (24, -6.32120121287208820000e+000) (25, 1.82120076599845540000e+001) (0, 4.30863134429124130000e+001) (1, -2.95152006931205600000e+000) (2, 2.54455874924876540000e+001) (3, -3.07896708495501590000e+000) (4, -1.18828319501419680000e+001) (5, 1.80170492730596870000e+000) (6, -9.88240113473682410000e+001) (7, 6.55457744681872570000e-001) (8, -7.54017681958829370000e+001) (9, 1.18141237332760070000e+001) (10, -4.82856532822557580000e+001) (11, -8.49465823667745390000e+000) (12, -1.10709153549583900000e+002) (13, -2.06999483865003110000e+000) (14, 2.90393591411446370000e+001) (15, 1.14888362969410180000e+000) (16, 5.74285512722068600000e+001) (17, -4.41320491480864430000e+000) (18, 8.45856762617285090000e+001) (19, 1.43537465050611510000e+000) (20, -1.22455623454217070000e+001) (21, -5.56941208825024870000e+000) (22, 7.68585155926900400000e+001) (23, 4.19919686190122830000e+000) (24, 2.44561683731574670000e+001) (25, -6.74575475693737440000e-001) (0, -1.50000000000000000000e+003) (1, 1.03698333683453060000e+002) (2, -1.50000000000000000000e+003) (3, 2.00169873519316180000e+001) (4, -3.49302074692353700000e+002) (5, 6.36810944905440210000e+000) (6, -4.59284397092624490000e+001) (7, -5.13542256636789140000e+000) (8, -1.50000000000000000000e+003) (9, 2.96855533154255850000e+002) (10, -4.99265607788341640000e+002) (11, -1.55085503405115300000e+002) (12, 1.50000000000000000000e+003) (13, -2.05330963709170330000e+001) (14, -1.84072987727082650000e+002) (15, 1.15483546394046520000e+001) (16, 3.68074457000631270000e+001) (17, 2.46796358044641160000e+001) (18, 6.77913641348414440000e+002) (19, 4.30706881336730230000e+001) (20, -5.90419342190568050000e+002) (21, -7.49287100007731510000e+001) (22, -4.81671752653635450000e+002) (23, 3.19480908634226200000e+000) (24, -5.19695165060868590000e+002) (25, 3.98371010707748920000e+001) (0, 1.12206716888273570000e+001) (1, 1.41094705568869010000e+000) (2, 2.03365919070800350000e+001) (3, 7.44993441910706820000e-002) (4, -1.87358074718523430000e+001) (5, -3.79686720057224310000e-001) (6, -2.64948923414039220000e+001) (7, -1.32081798715204020000e+000) (8, 5.24471541730966850000e+001) (9, -9.45783666277125040000e-002) (10, 1.07359893140108620000e+001) (11, 4.64043242089947790000e-001) (12, -2.53969062579043520000e+001) (13, -9.86731665922368490000e-002) (14, -1.47251536834901150000e+001) (15, -3.28360134181172880000e-001) (16, 1.02198532495218310000e+001) (17, 1.88875031272833140000e-001) (18, -2.35377254682066180000e+000) (19, 9.33441941715623390000e-002) (20, 5.53883437749517250000e+000) (21, -3.79391378011440960000e-001) (22, -2.30225164359764530000e+001) (23, -6.66791851139633680000e-001) (24, -5.94386722590376590000e+000) (25, -2.39808368684355330000e+000) (0, -1.50000000000000000000e+003) (1, -3.61454731862387520000e+002) (2, 1.49781896858406210000e+003) (3, 3.13338731492317040000e+002) (4, 1.50000000000000000000e+003) (5, 1.57272311424460980000e+002) (6, 1.50000000000000000000e+003) (7, 3.30398159209550140000e+001) (8, -8.97333564048156970000e+002) (9, -1.13046226010842500000e+002) (10, 8.20857023032850750000e+001) (11, -1.09129742375699610000e+002) (12, 9.26649808056061600000e+002) (13, -1.01046039148828000000e+002) (14, -1.50000000000000000000e+003) (15, 1.50000000000000000000e+003) (16, -1.14900966960366300000e+003) (17, -2.20037237192174250000e+000) (18, -1.50000000000000000000e+003) (19, 4.51018823707166590000e+001) (20, -1.50000000000000000000e+003) (21, 9.27492329824429620000e+000) (22, 1.50000000000000000000e+003) (23, 1.46107101427380740000e+002) (24, 1.50000000000000000000e+003) (25, 7.25050650779296010000e+001) (26, -2.76149039499932680000e+000) (27, 3.65507288795901720000e-001) (28, -6.79102178821752440000e-002) (29, -3.77167685667269750000e+000) (30, -1.15310786522174860000e+000) (31, 2.83259203457510320000e-001) (26, 7.40161973032633200000e-001) (27, -9.13039195040655120000e-001) (28, 9.16576441263958760000e-001) (29, 5.48575506990019220000e-001) (30, 5.46794306245128370000e-001) (31, 6.33034468177534950000e-001) (26, 6.79551710119614130000e-001) (27, 4.62946142859549990000e-001) (28, -6.64660099536948160000e-001) (29, 1.36566141820161160000e+000) (30, 3.28026948412667500000e-001) (31, 1.15852461740950920000e+000) 

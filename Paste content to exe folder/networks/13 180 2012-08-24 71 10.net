FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.03812625212726580000e+000) (1, -3.23169836497281650000e-001) (2, 1.57374132877742740000e-001) (3, -1.57807285205062650000e-001) (4, -3.09209353808769110000e+000) (5, -1.39136630629973220000e-001) (6, -3.19459598102134650000e+000) (7, -3.25746466073800200000e-002) (8, 5.63938761512323250000e-001) (9, -1.61530429791791830000e-001) (10, -3.11261355792471320000e+000) (11, 4.33555528062085420000e-001) (12, 5.98442630548085890000e-001) (13, 5.44117571225966380000e-001) (14, 4.95140627055641050000e-001) (15, 1.89134789505648020000e-001) (16, 5.72929934855417100000e-001) (17, -3.56430409420155140000e-001) (18, 5.75975589197675890000e-001) (19, -3.03414060522512460000e-002) (20, -4.55503315654908430000e-001) (21, 5.67152104645419540000e-001) (22, 1.30791856635943350000e+000) (23, 6.77142762508730480000e-002) (24, 5.31913604309650400000e-001) (25, -2.28022130001345360000e-001) (0, -3.17098147871633800000e+000) (1, 1.42186082749994000000e-001) (2, -1.10671981858747380000e+000) (3, 7.16741893767441070000e-002) (4, 1.14934114414068670000e-001) (5, -3.75080118861250350000e-002) (6, 1.06234596767346030000e-001) (7, 1.52527462065926710000e-001) (8, -3.18464725040434880000e+000) (9, 5.67755075141114510000e-002) (10, -3.04247805883273780000e+000) (11, 1.59145974508911990000e-001) (12, 4.86791017556222170000e-001) (13, 1.64478145837755770000e-001) (14, 5.92644290617933890000e-001) (15, 1.43230435737178590000e-002) (16, 4.62103345461776390000e-001) (17, 2.21865702006008750000e-001) (18, 6.15642337835631380000e-001) (19, 4.95769503490419980000e-002) (20, 6.26646976671488280000e-001) (21, 1.12015944593666410000e-001) (22, 6.76456535029615060000e-002) (23, -2.63177554428246360000e-002) (24, 2.92889475752793280000e-001) (25, -4.46857463680816120000e-002) (0, -5.59300662652733700000e-001) (1, 2.85241149693388600000e-001) (2, -3.39603016591282450000e-001) (3, 2.99376892091527570000e-001) (4, -1.20819443901130660000e+000) (5, -5.64175940342612310000e-001) (6, -3.78530754478273450000e-002) (7, 3.87630798912910750000e-003) (8, -3.20039432095149850000e+000) (9, 1.43749620500904070000e+000) (10, -9.27176406124118340000e-001) (11, 4.51446771496051700000e-002) (12, 3.03240115438570520000e+000) (13, 6.68268680656686430000e-001) (14, 3.12768313822739240000e+000) (15, 2.37069026155346250000e-002) (16, 2.35912066411768300000e+000) (17, 5.30205324843770810000e-001) (18, 1.19882675832209570000e+000) (19, 5.80711917393252670000e-001) (20, 2.46804756906180530000e-001) (21, 1.74580820804429270000e-001) (22, -8.08849314248273670000e-001) (23, 1.63298372947252250000e-001) (24, 3.19268558060225430000e+000) (25, -3.23253897161260410000e-001) (0, -3.69169378466443760000e-001) (1, -2.41818648968671280000e-001) (2, 4.14523534156313660000e-001) (3, -2.34555465266691410000e-001) (4, 7.68135770373545860000e-001) (5, -2.81690925884227890000e-001) (6, -1.02052460207527020000e-001) (7, -1.64430181949406650000e-001) (8, 1.18054463839570480000e+000) (9, -2.38852340330719840000e-001) (10, 2.40128596427926500000e-001) (11, -5.48737383557264650000e-001) (12, -1.16943303896106020000e-001) (13, -1.60159712204983290000e-001) (14, 1.50299722318183000000e-001) (15, -1.78854780842936520000e-001) (16, 8.72223837459012110000e-001) (17, -1.89450484125824800000e-001) (18, 4.90046497027908650000e-001) (19, -2.27829390947715090000e-001) (20, 5.26588245619298070000e-001) (21, -1.41676484235470970000e-001) (22, 2.92001878522002930000e-001) (23, -8.49888126473496150000e-002) (24, 8.85061258967890920000e-002) (25, -1.22806196023372530000e-001) (0, -3.15474002339619640000e+000) (1, 9.38848830670842150000e-002) (2, -1.09924301183543570000e+000) (3, 6.42192845516047770000e-002) (4, 5.20213869616761530000e-001) (5, -3.25998280060431080000e-001) (6, 3.05945803955450920000e+000) (7, -1.60057181097352010000e-001) (8, -2.16339854368556140000e+000) (9, -4.15302287429357360000e-002) (10, 6.63173067865756800000e-001) (11, -2.21531791388395040000e-001) (12, 5.33666018254714160000e-001) (13, -1.19203569744108700000e-001) (14, 5.21430303062130560000e-001) (15, 1.59110979024726370000e-003) (16, 1.41476002855836890000e-001) (17, 1.08651588990862020000e-001) (18, 5.18205812946214150000e-001) (19, -7.67780320025439330000e-002) (20, 6.51341801258219830000e-001) (21, -1.33686191095630350000e-001) (22, -2.02245005096508330000e-001) (23, -3.74336294549257320000e-003) (24, 1.72942535565173000000e-001) (25, 5.04497530964227730000e-002) (26, 4.51253943573270810000e-001) (27, 6.53117910962077580000e-003) (28, 5.98886345867315930000e-001) (29, -2.60811007495088730000e-001) (30, -3.64437035168407860000e-002) (31, 5.33747669554106800000e-001) (26, -4.43158252661964070000e-001) (27, 5.76182265194377790000e-002) (28, 1.88762222881288550000e-001) (29, -2.92921394801574920000e-001) (30, 3.03253167531254420000e-001) (31, 5.62154081033916950000e-001) (26, -3.09261253096224650000e-002) (27, -9.82601106879770200000e-002) (28, -7.20209456207463460000e-001) (29, -1.46591596768427620000e-001) (30, -6.26155789068321140000e-002) (31, 7.01327231230322260000e-001) 

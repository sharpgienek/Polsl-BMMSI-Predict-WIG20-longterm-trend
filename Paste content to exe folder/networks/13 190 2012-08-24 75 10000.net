FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.62621651980575850000e+002) (1, -2.93820872921910100000e+000) (2, 1.33038780519482320000e+000) (3, 1.01670480572435660000e+001) (4, 1.06027566292483040000e+002) (5, 1.31372247327782040000e+001) (6, 7.03661218579867140000e+000) (7, 2.24599032827723330000e+000) (8, 1.77449066683770550000e+001) (9, -4.22692513940286130000e+000) (10, -2.38777863226291830000e+002) (11, 9.70201414604397350000e+000) (12, 4.84957483227724940000e+002) (13, 1.32449732340763870000e+000) (14, -2.52039197606439930000e+002) (15, 5.59935571202546980000e+000) (16, -1.93733883052836210000e+002) (17, -6.86540233144562070000e+000) (18, -9.04370924633990820000e+001) (19, -3.27981931080885000000e+000) (20, -1.93362293960616710000e+002) (21, 2.74440406647372400000e-001) (22, 1.14573534621263380000e+002) (23, 3.63453158689491930000e+000) (24, 3.01065698340741560000e+002) (25, 1.65057271513041750000e+001) (0, 4.47509177808674750000e+001) (1, 4.37766507435184950000e+000) (2, 5.54807977426533090000e+001) (3, 3.31441112004618120000e+000) (4, 5.96440776829196300000e+001) (5, 1.83330480947843140000e+000) (6, -3.31570028471235860000e+001) (7, 1.29696642110649610000e-002) (8, -4.60596059723297840000e+001) (9, 1.84010538129512400000e+000) (10, 1.54941963438889460000e+001) (11, 2.35835825352568750000e+000) (12, 2.12824802455628090000e+002) (13, 1.05625947199076540000e+000) (14, 8.01729592177312970000e+000) (15, -3.82856480835497100000e+000) (16, 6.92768842570662000000e+001) (17, -1.71487883538070210000e+000) (18, -4.04602588644246030000e+001) (19, -2.37038211193768780000e+000) (20, -1.18509817981035370000e+002) (21, -9.22861264551956050000e-001) (22, 1.66959296665044580000e+002) (23, 6.51158043775190490000e-001) (24, 4.67342601646617550000e+001) (25, 8.35604163223296050000e+000) (0, -3.15351310284001390000e+002) (1, -9.10031550903020660000e+000) (2, -1.09482832750575240000e+003) (3, 1.52310124264161870000e+001) (4, 1.73478409207818200000e+002) (5, -7.43535169248755600000e+000) (6, 5.60972946488161380000e+001) (7, -8.71014720414704340000e+000) (8, -5.74682677239850140000e+002) (9, -1.17952154408119070000e+001) (10, -4.53881943054553500000e+001) (11, -2.43392340425052040000e+001) (12, 8.66020289099678620000e+002) (13, 6.02416659332231940000e+000) (14, -5.96428150603609650000e+002) (15, -2.91727606276415760000e+000) (16, -3.62354480098975330000e+002) (17, -7.93903619947746900000e+000) (18, -5.83041988934826010000e+002) (19, -1.64889654009285880000e+001) (20, -4.81749197324118710000e+002) (21, -1.37811904554029560000e+000) (22, 1.70040867758385780000e+000) (23, -3.42268285723659680000e+000) (24, 1.31483119414461640000e+002) (25, 1.44495625018239280000e+001) (0, 6.48815732583225890000e+001) (1, -6.42298369607387730000e-001) (2, 1.29366718210548300000e+002) (3, -1.78860530828759320000e+000) (4, -5.25497710234537580000e+001) (5, 4.11412586077039940000e+000) (6, 1.95954762850896490000e+001) (7, -1.96441373266251480000e+000) (8, 1.54002581372562620000e+002) (9, -1.13151465848665000000e+000) (10, 2.49392268295867370000e+001) (11, 1.38558080679382070000e+000) (12, -7.96797885539959200000e+001) (13, -2.99117427377719380000e+000) (14, -2.48560533637396900000e+001) (15, -5.09730537979221630000e-001) (16, 3.22287801496060600000e+001) (17, -6.43390707330385950000e+000) (18, -1.34941427275490560000e+001) (19, -1.09556628178503450000e+000) (20, -1.37295168429276690000e+001) (21, -2.08861673571506670000e+000) (22, 3.44282190509822000000e+001) (23, -3.88180022539691280000e-002) (24, -1.43524237501160920000e+000) (25, 1.24508470961519760000e+000) (0, 3.16179978919932410000e+002) (1, 1.02919152883720590000e+002) (2, -2.67516682805383250000e+002) (3, -6.01787799032325310000e+000) (4, 1.50000000000000000000e+003) (5, -1.78223968347557790000e+001) (6, 1.50000000000000000000e+003) (7, -1.15013116525755910000e+001) (8, -1.50000000000000000000e+003) (9, 1.04284159738068720000e+002) (10, 1.50000000000000000000e+003) (11, -1.27747455044863790000e+001) (12, 1.07872302425538510000e+003) (13, 5.31577993781942200000e+001) (14, 1.50000000000000000000e+003) (15, -6.69056368835989450000e+001) (16, 1.50000000000000000000e+003) (17, 1.10325435059095600000e+002) (18, 1.45525601168374370000e+003) (19, 7.78441078806794450000e+000) (20, 3.13255033386534880000e+002) (21, -6.10256051886089780000e+001) (22, 9.08313568441238200000e+002) (23, -1.14786170058734350000e+001) (24, -7.13758510449209210000e+002) (25, 6.86029024418967310000e+001) (26, 9.52166246062429310000e-002) (27, 1.96803585636994870000e+000) (28, -2.06462813274798450000e+000) (29, -2.02717717623560350000e+000) (30, -2.01618468018909700000e+000) (31, -1.43901785208981680000e-002) (26, 1.16885562493476590000e+000) (27, -8.88986730241401290000e-001) (28, 9.09506837256292140000e-002) (29, 1.10737975447667190000e-002) (30, 1.25847720394837690000e+000) (31, 8.32516665548410530000e-001) (26, -1.26508158990231250000e+000) (27, -3.00256888313691740000e-001) (28, 1.38778824798051790000e+000) (29, 1.44997408291390180000e+000) (30, 9.13774719510404290000e-002) (31, 1.67595446593905400000e+000) 

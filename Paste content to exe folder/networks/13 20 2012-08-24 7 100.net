FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.52243384914036140000e-001) (1, -2.92595174717434630000e-004) (2, -4.67518403243798730000e-001) (3, 5.51682728787309060000e-001) (4, 1.56739933322544480000e+000) (5, 5.74274161258757520000e-001) (6, 5.29158341075763090000e-001) (7, 7.26280317142391720000e-001) (8, 1.00530268719704910000e+001) (9, 1.90610279318907060000e-001) (10, -5.08043049253622980000e-001) (11, 8.98340432822334000000e-001) (12, 1.04937353457752570000e+000) (13, 4.69054397714062380000e-001) (14, -2.51849637381938380000e-001) (15, 9.70016446439785350000e-001) (16, 1.90650016920263680000e-002) (17, 1.60789143289678660000e+000) (18, 6.95096124548320590000e-001) (19, 6.33364782986526210000e-001) (20, 2.11131522660386900000e-001) (21, 5.70324258513885350000e-001) (22, 3.14078188626103390000e+000) (23, 9.42573163199539320000e-001) (24, 1.13793258670258710000e+000) (25, 2.60431995511666290000e-001) (0, 6.84782631679119100000e+000) (1, -1.60140663973519120000e-001) (2, -4.41320332090671030000e+001) (3, 3.61871895079151680000e-001) (4, 1.36124842393710570000e+001) (5, 1.23703103435978570000e+000) (6, 6.68253310084601650000e-001) (7, -1.41440324562878560000e-001) (8, 2.16305590118514810000e+001) (9, -5.49410135383749720000e-001) (10, -6.23559670924082980000e+000) (11, 4.26895994908295150000e+000) (12, 2.62503646080883080000e+001) (13, 3.33569677957120450000e-001) (14, 6.59166635193846550000e-001) (15, -2.85685830073654850000e+000) (16, 9.06033765999882410000e+000) (17, 1.58713587957302570000e+000) (18, -3.13844621878635310000e+000) (19, -4.17553674719498450000e-001) (20, 6.98403144617690330000e+000) (21, 6.10083628367300910000e-002) (22, -3.79343423781304700000e-001) (23, 5.42850282635827330000e+000) (24, 5.63625545651707240000e+000) (25, -4.37520071790135410000e-001) (0, -1.77179384241072580000e+000) (1, -1.73153897307662200000e-001) (2, -3.03793196001221940000e+000) (3, 1.80790532202868180000e-002) (4, 5.59413924493639250000e-001) (5, 2.33359864516712980000e-001) (6, 8.09054596992382020000e-001) (7, -1.19662056969389730000e-003) (8, 7.58593975429485370000e-001) (9, 3.88686150304991040000e-001) (10, 7.20735125952308600000e-001) (11, 3.81439414402075850000e-001) (12, 1.48186961191174530000e+001) (13, 1.24713286980381310000e-001) (14, -1.02208489083051140000e+000) (15, -3.15756063932961630000e-001) (16, 3.67401208272349790000e-001) (17, 3.89912420731657160000e-001) (18, 1.33144337525571120000e-001) (19, 1.54466905398596370000e-001) (20, 1.56885029136380140000e-001) (21, -2.25776540694761050000e-002) (22, 8.35116015236234800000e-001) (23, 1.18329003026594770000e+000) (24, 6.08291348064757910000e+000) (25, -5.18255859638619750000e-001) (0, 1.22020490685118730000e+000) (1, 1.78276016605406710000e-001) (2, -1.69755035870680950000e+000) (3, 2.31688738688349670000e+000) (4, 1.48072837489665470000e+000) (5, 5.53908220825544100000e+000) (6, 1.73648420475900190000e+000) (7, 3.77807373050423940000e-001) (8, 2.77985119995248690000e+000) (9, 1.70900659684677850000e-001) (10, -3.81669950714553120000e+000) (11, -5.55107624153627560000e-003) (12, 1.98077872906486320000e-001) (13, 8.71126575100159230000e-001) (14, -9.92152431893897120000e-001) (15, -3.91942873277222120000e-002) (16, 2.62649555287517820000e-001) (17, 1.35400408097241030000e+000) (18, -7.63771175648821240000e-001) (19, 1.69269787094733930000e+000) (20, 1.68329785541996930000e-001) (21, 5.08398272378800640000e-001) (22, 1.24981998771641180000e+000) (23, 6.46089002546145760000e-001) (24, -2.84993479656019240000e+001) (25, 7.05870804790325270000e-001) (0, 1.61402467406310950000e+001) (1, 3.25262315304063120000e-002) (2, 2.17317434379964420000e+000) (3, -1.12557431219262760000e+000) (4, -9.82855374134393720000e-001) (5, 2.21823335161707960000e-001) (6, -5.81820268968398780000e-001) (7, 4.04245301627616400000e-001) (8, 8.67489897305364520000e-001) (9, -2.16111379467661150000e+000) (10, -3.88392714210792130000e+000) (11, -1.66138395029432150000e+000) (12, 4.62646538386670870000e+000) (13, -6.07290431367007780000e-001) (14, 3.06317933717048020000e-001) (15, 1.03022206642194770000e+000) (16, 1.12610914986261370000e-001) (17, 9.23102323370919020000e-001) (18, 7.67376220148597100000e+000) (19, 3.49338030100065370000e-001) (20, -1.48778929832326810000e+000) (21, 3.48839977714043350000e-001) (22, 1.50715575042938780000e+000) (23, -2.99175164968848730000e+000) (24, -1.35649809260158770000e+000) (25, 2.02372728609954760000e-001) (26, -1.19676700618804450000e-001) (27, -3.52961904043381460000e-001) (28, 2.78940757807595490000e+000) (29, 1.41110353783516050000e-001) (30, 9.19890804519543080000e-001) (31, 1.62806809343029270000e-001) (26, 8.27512816437422140000e-001) (27, 1.60692524902974570000e+000) (28, -2.44000035851429510000e+000) (29, 1.02308308248654910000e+000) (30, -1.97976794629841990000e+000) (31, 4.61078381752472010000e-001) (26, 2.54534203528878120000e-001) (27, -2.26851521130246200000e+000) (28, 3.33122145188857260000e-002) (29, 5.82214539765514740000e-001) (30, 5.69107696130915880000e-003) (31, 1.41698042717613020000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.23423855504804500000e+000) (1, 3.74750797536657350000e-002) (2, -9.96750656100541120000e+000) (3, 1.17397540457633400000e+000) (4, 1.06870117608937800000e+001) (5, 8.43440044987648570000e-001) (6, 2.94348005223367350000e+000) (7, 1.03839706954915000000e+000) (8, 2.12875391161324750000e+001) (9, 4.39254048429497110000e-001) (10, -5.44120552857671310000e+000) (11, 3.97508390771581420000e+000) (12, 1.87650063081702530000e+001) (13, 7.95377981381388150000e-001) (14, 1.85094852182601600000e+000) (15, -1.11087431895444120000e+000) (16, 1.11148094568732120000e+001) (17, 3.44639672306992880000e-001) (18, -1.49915477451255530000e+000) (19, -1.37268779923959090000e+000) (20, 1.57897394755982410000e+000) (21, 1.90750054650003580000e-001) (22, 3.04707367569428870000e+000) (23, 6.17890483580626170000e+000) (24, 1.03232973720060280000e+001) (25, -4.33025456534276270000e-001) (0, 5.28217733477705090000e-002) (1, 5.28649918351491440000e-001) (2, 1.68216827999071210000e+000) (3, 1.69021052902758460000e+000) (4, 5.52283616356222250000e-001) (5, -1.67954551728126480000e-001) (6, -1.11255764015414100000e+001) (7, 6.05810740426533490000e-001) (8, -1.47550547000517620000e+000) (9, 1.83844371709563780000e+000) (10, 1.01894115451426760000e+001) (11, 2.53142947080518880000e+000) (12, -4.43629292042937350000e+001) (13, 2.47494649717678780000e+000) (14, -1.53162396058884880000e-001) (15, 6.64820206878964040000e-001) (16, 4.87114846517778920000e-001) (17, -5.24057751150025620000e-001) (18, 3.77735457776082860000e-001) (19, 1.06147389797902740000e-001) (20, 7.34640204080134080000e-001) (21, 1.35246867609415640000e+000) (22, 7.23225068315162910000e+000) (23, -3.11697496986384510000e+000) (24, -2.31174411263873230000e+001) (25, 1.15094981625102080000e+000) (0, 2.95590653861407660000e+000) (1, 2.68278775799590980000e+000) (2, 2.17868149636274350000e+001) (3, -3.06947956713306050000e-001) (4, 5.75164186286566200000e-002) (5, 4.21152655723445350000e-001) (6, 2.63023483697217130000e+000) (7, 1.61621807085629540000e-001) (8, -1.55043380812946690000e+000) (9, 1.22027850482572140000e+000) (10, -4.75526194872323950000e+000) (11, -7.02254685814543310000e-001) (12, 3.26032923343120110000e+000) (13, 2.63173989627142610000e-001) (14, -9.14370389093251860000e-001) (15, 2.71652973931081480000e+000) (16, -6.35543060146036980000e-002) (17, 1.05528828260528780000e+000) (18, 2.34431668086689000000e+000) (19, 1.22151974140476290000e+000) (20, 2.16827952522834440000e+000) (21, 1.16211567769411930000e+000) (22, 5.36036069264749940000e+000) (23, -1.00603828941697150000e+000) (24, -4.82841758343779850000e+000) (25, 7.40148167560427670000e-001) (0, -2.60238638133062180000e+000) (1, 9.10726018798181600000e-001) (2, 1.84556793108975550000e+001) (3, -9.83467585042495930000e-002) (4, 1.34250216926334850000e+000) (5, -3.31181701736049990000e-001) (6, -2.19592175101765370000e-001) (7, -5.12214409872807970000e-001) (8, 8.37801156516285170000e-001) (9, 3.58461481913118290000e-002) (10, 4.53812044806841540000e+000) (11, -1.44412573395334090000e+000) (12, -1.76297915540394710000e+001) (13, -5.12031385704651630000e-002) (14, 1.60878523308327530000e-001) (15, 1.87592769978658720000e+000) (16, 1.69527815049040750000e+000) (17, -6.50432679869586970000e-001) (18, 6.33292526631872970000e-001) (19, 9.37195679620334230000e-001) (20, 1.51204625536148550000e+000) (21, 1.31285458352950660000e-001) (22, 1.40260787856758360000e-001) (23, -1.38649503535420780000e+000) (24, -9.73966219070611320000e+000) (25, 1.11416480010184690000e+000) (0, 2.87404423923033380000e+000) (1, -2.21674851030217220000e-001) (2, -9.38064992144804770000e-001) (3, 1.96866253708732390000e+000) (4, 4.17335295091503070000e+000) (5, 4.51729945493509420000e-001) (6, -4.36100550699937250000e-001) (7, 2.83330454886715430000e-001) (8, 8.94981079858259500000e+000) (9, 1.03728735749833900000e+000) (10, 5.12413174225494220000e+000) (11, 3.01216464521768180000e+000) (12, 1.77843862804903650000e+000) (13, 1.54463948739204080000e+000) (14, 3.07771084139681280000e+000) (15, -1.66132297674137760000e-001) (16, 6.74306051431358130000e-001) (17, 5.46940582396250320000e-001) (18, 2.94198661549939190000e+000) (19, 4.37838888460493900000e-001) (20, 9.00794999201408040000e-002) (21, -2.12704696821193600000e-003) (22, 6.68995705368280120000e-001) (23, -7.63016995907136120000e-001) (24, -6.21894672759463150000e+000) (25, -4.69376792495080350000e-002) (26, -3.96493794954839220000e-001) (27, -3.14641117378647460000e+000) (28, 1.72488240255070860000e+000) (29, -8.66143279169438670000e-001) (30, 8.82975164154911060000e-001) (31, 1.20877325392020720000e+000) (26, 4.40951990603673850000e+000) (27, 3.15255853152027090000e+000) (28, -3.94260540536046370000e-001) (29, -1.20193558762718710000e-001) (30, 2.05649530969791530000e+000) (31, 3.17035899238025000000e-001) (26, -1.59742818105462740000e+000) (27, -4.80442838519257840000e-001) (28, 2.73764954313726520000e+000) (29, 4.09223140828186600000e+000) (30, -6.95086469031545810000e-001) (31, 1.88366316003746290000e+000) 

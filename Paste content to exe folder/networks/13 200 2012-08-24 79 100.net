FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.78614926443578420000e+001) (1, -7.72398048738082570000e-002) (2, -1.23164082140526750000e+001) (3, 7.99650816895930210000e-001) (4, 1.79065613626361890000e+001) (5, -1.12624662485896640000e+000) (6, 2.61263738969736470000e+001) (7, -8.78855134147816350000e-001) (8, -5.68912941085761140000e+000) (9, 5.12852431941892670000e-001) (10, -2.32209471985591250000e+000) (11, 1.07825099217618890000e+000) (12, 6.35101425476955300000e+001) (13, 1.24392809183889260000e+000) (14, 1.94678394306696310000e+000) (15, -1.52065997117139790000e-002) (16, 3.18099578925264790000e+000) (17, 1.08866720783885510000e+000) (18, 1.07248163595091340000e+001) (19, 7.10865046771598340000e-001) (20, 1.80469797620674850000e+000) (21, 6.53408714086941680000e-001) (22, 7.48732770993412620000e-001) (23, -3.40850351959560820000e-001) (24, -1.45782331692805610000e+000) (25, -4.62775571248244090000e-001) (0, 7.71650653577711320000e+000) (1, -3.88020434375451970000e-001) (2, -1.71866152082404290000e+001) (3, -1.10217105786600690000e+000) (4, -1.44513003809000940000e+001) (5, 1.33142551618591170000e+000) (6, -1.92557756769306330000e+000) (7, -3.20427816396752940000e-001) (8, 5.04390053377548050000e+000) (9, -4.02701501925720010000e-003) (10, 2.00097722684947010000e+000) (11, -2.83624771839159750000e+000) (12, 1.08390576636814430000e+001) (13, -6.27342694722286650000e-001) (14, 2.60832365560221290000e+001) (15, -1.47983195888137800000e+000) (16, -1.15821221821157860000e+001) (17, -5.19555608094551590000e-001) (18, -6.60303545637699880000e-003) (19, -1.19601642675169530000e-001) (20, 4.37051515401873810000e-001) (21, -2.70571153578303360000e-001) (22, 1.28516674697417810000e+001) (23, 1.11175335200150200000e-001) (24, 8.91376208396197710000e+000) (25, -2.90117826688692850000e-001) (0, -5.69689800563713080000e+001) (1, -8.68207094015197020000e-001) (2, 9.59228941247181940000e+000) (3, -9.74616133772011620000e-002) (4, -8.22140917155439330000e+000) (5, 2.61866845667892770000e-002) (6, -2.39848081147488940000e+001) (7, 1.25866601006500780000e+000) (8, -3.82967685420308540000e+001) (9, -1.51894191964045100000e+000) (10, -5.82937604270688300000e-001) (11, 1.50775282398103920000e-001) (12, -1.16622394851053100000e+001) (13, -8.44932921277720410000e-002) (14, -1.38604547202859920000e+001) (15, 9.44844760136910320000e-001) (16, 2.45145477620589000000e+001) (17, -1.54169455506843670000e+000) (18, -1.59153296239854760000e+001) (19, 2.80975109152071520000e-002) (20, 1.40954602069647610000e-001) (21, 4.31036275008126580000e-001) (22, 1.60595360504105390000e+001) (23, 2.44705140571331770000e+000) (24, -6.83621607615286830000e+000) (25, -6.92760389297675110000e-002) (0, -6.66065905532272050000e+000) (1, 1.08364886050124220000e+000) (2, 1.45406653828021180000e+001) (3, 1.70975306427903310000e+000) (4, 1.27072438733747680000e+001) (5, -1.60003341852490350000e-001) (6, 1.04558019107773600000e+000) (7, 1.64312876155567620000e+000) (8, -1.56620318947082050000e+001) (9, 2.63876188325076640000e+000) (10, -6.96660394278858420000e+000) (11, 3.27253719250757320000e+000) (12, -9.36309298543294940000e+000) (13, 1.47063023082720230000e+000) (14, 4.09367794263435910000e+001) (15, 1.30399817840084960000e+000) (16, 1.76367493077136960000e+001) (17, 2.56148290503006800000e+000) (18, 1.54778280222839740000e+001) (19, 9.01070370261750740000e-001) (20, 7.21577050400193890000e+000) (21, 1.60189714244733490000e-001) (22, -2.15676216833276480000e+001) (23, -2.93582089838795910000e-001) (24, 7.18728170081855830000e+000) (25, 4.01480307536432050000e-001) (0, 1.58249433501726690000e+001) (1, 3.65773986013328940000e-001) (2, 1.19101150863740980000e+001) (3, -5.79854150070466260000e-002) (4, -3.95142972416734790000e+000) (5, -2.31684332814084600000e-001) (6, -9.48172740845902060000e+000) (7, 1.27251227159809590000e-002) (8, 1.11465376162895480000e+001) (9, 4.06256249306349850000e-001) (10, 9.53569589280984080000e+000) (11, 4.69132096769603100000e-001) (12, -1.58128882845153670000e+001) (13, -8.39615757972337340000e-002) (14, -3.86572839143293700000e+000) (15, 1.74743994133312400000e-001) (16, -3.20182054686678930000e-001) (17, 2.16919196215517470000e-001) (18, -6.62983338275483360000e-002) (19, -1.59381776342283620000e-001) (20, -1.64654333872409950000e+000) (21, -3.52054708438388490000e-002) (22, -4.32039305697262590000e+000) (23, -6.44453835054553670000e-001) (24, -1.79365248745850530000e-001) (25, -3.02301962091085450000e-001) (26, 1.53067589436210680000e+000) (27, 1.54843683002645040000e+000) (28, 1.53180448805757960000e+000) (29, 9.85929200255528990000e-001) (30, 1.22069049139353410000e+000) (31, 5.24996998702644710000e-001) (26, -9.36616980821920690000e-001) (27, -1.07450714926275870000e+000) (28, -1.31627532806887730000e+000) (29, 4.15316937317739220000e-001) (30, -1.63730671378980160000e+000) (31, 2.39925243769928460000e-001) (26, -3.70453273010147690000e-001) (27, -2.31501854995636550000e-001) (28, -4.75200322367459600000e-002) (29, -1.51042330853577770000e+000) (30, 4.36492716992672560000e-001) (31, 1.71783928838602070000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -5.60109156746804260000e+000) (1, 2.49313360084480770000e-001) (2, -1.75947697260977900000e+000) (3, -9.99831965104352350000e-001) (4, -2.51713881192701050000e+001) (5, -7.55624447674371310000e-001) (6, -1.35433135450727600000e+001) (7, 1.63607814885272650000e-001) (8, -2.10758587459954400000e+001) (9, -6.30736706036215260000e-002) (10, 8.77059973597451050000e+000) (11, -1.15803193844502300000e-001) (12, -9.81999553516306630000e+000) (13, -7.80583317159107800000e-003) (14, -1.51991631622176530000e+000) (15, -1.28534730045051870000e+000) (16, -1.27430113658445110000e+001) (17, -6.52049317938724200000e-002) (18, -1.33095369540194920000e+001) (19, 1.45955372888088770000e-001) (20, -9.62595988938617530000e+000) (21, -4.39187952066739660000e-001) (22, -5.38730492610554010000e+000) (23, 4.95314566696339440000e-001) (24, 1.89731172462469610000e+001) (25, -9.62964255374240410000e-002) (0, 7.81964734779952550000e+001) (1, -9.05368808725833850000e+000) (2, -2.89758887293253690000e+001) (3, -9.54718709704108550000e+000) (4, -2.40017760499254540000e+002) (5, -2.42814544554304710000e+000) (6, 9.09405635623865290000e+001) (7, -1.17236888856317670000e+000) (8, -4.44270185795137800000e+000) (9, -4.00256764564148870000e+000) (10, 3.26830774958727160000e+001) (11, -4.72515938014854520000e+000) (12, -3.25870898439681440000e+001) (13, 5.61316475627373190000e+000) (14, -3.99476424008557630000e+000) (15, -5.45714795201202390000e+000) (16, -6.78142731649279400000e+001) (17, -2.98538522094913890000e+000) (18, -3.05625965262441640000e+001) (19, -3.23957252885651710000e+000) (20, -1.38551331209727040000e+002) (21, 2.71064421047082730000e+000) (22, -8.39877131566356460000e+000) (23, 6.83787375665411720000e+000) (24, 4.68440436091260610000e+001) (25, 2.19498061491160580000e-001) (0, -5.37167281700920110000e+001) (1, 1.48159644802955290000e+000) (2, 2.23939924067930140000e+001) (3, -1.06954444126843430000e+000) (4, -1.92244644031838770000e+001) (5, -1.00837603761400470000e+000) (6, -9.37890095877092730000e+001) (7, -4.26873321758314110000e-001) (8, -7.14052849851027640000e+000) (9, -7.81073464347467270000e-001) (10, 6.79083573404419810000e+001) (11, 2.55358486049427070000e-001) (12, -8.28965115664746430000e+001) (13, -3.13113446020413070000e+000) (14, -7.04651636759377170000e+001) (15, -1.92403781000537410000e+000) (16, -1.64160448684380360000e+001) (17, 4.18907395189040300000e-001) (18, -2.15443751782999730000e+001) (19, -1.03950774378556860000e+000) (20, 2.18069045203978100000e+000) (21, -2.56792498751854080000e+000) (22, -3.86774014757247780000e+001) (23, -5.23060260192473870000e-001) (24, -6.98705295172948660000e+000) (25, 2.55822370575735060000e-002) (0, -3.00006059383184830000e+001) (1, 1.30431365520887790000e+001) (2, 6.11010348915426820000e+001) (3, -1.01239649660716590000e+000) (4, -9.27709127061948780000e+001) (5, -2.98068907587140370000e+000) (6, 3.61995538575302900000e+001) (7, 2.68793102540713670000e+000) (8, -1.73931643342413050000e+002) (9, 4.22872165983494240000e+000) (10, -8.55243206013958710000e+001) (11, 5.27042688862823550000e+000) (12, 2.14765647030184030000e+002) (13, 2.06025697597956730000e+000) (14, 5.09510027641204390000e+001) (15, -3.58508424641987800000e+000) (16, 3.92674321266235470000e+001) (17, 1.74770608817575400000e+000) (18, -3.87269089414827120000e+001) (19, 1.10699936821124980000e+001) (20, 1.65274656076519050000e+001) (21, -3.36232114964714590000e+000) (22, 2.75015776393722930000e+001) (23, 1.48003541992518730000e-003) (24, 1.23436424201641070000e+002) (25, -4.56309741783971830000e+000) (0, -1.38990231777395140000e+002) (1, 2.96037514034058760000e+000) (2, 5.38891887662598850000e+001) (3, 1.27225903304763060000e+001) (4, 9.86340221330732590000e+001) (5, -2.85282974749797940000e+000) (6, -1.12903348348387280000e+001) (7, 1.57940523192617930000e+001) (8, -1.43913793568359490000e+002) (9, 2.22303153745832490000e+001) (10, 1.59135560069976290000e+002) (11, 2.81227035276976030000e+001) (12, -2.25016618319695540000e+002) (13, 2.03683305338418830000e+000) (14, 4.36212574969502140000e+001) (15, 1.44370056440638340000e+001) (16, 1.77347338311401270000e+002) (17, 3.87438213286049230000e+001) (18, 2.50713230627035330000e+002) (19, 9.50002679231723950000e+000) (20, 7.78966971204964840000e+001) (21, 1.76540766386345660000e+000) (22, -3.31696671251299050000e+002) (23, 2.29993393760468480000e+000) (24, 1.29770316997733000000e+002) (25, 5.78759060662267010000e+000) (26, 2.26201259947360000000e+000) (27, -8.83381326563364880000e-001) (28, -1.64027712613339420000e+000) (29, -8.68330353768997700000e-001) (30, 9.11118035238737410000e-002) (31, 4.06018368214549010000e-001) (26, -3.18538588667057220000e+000) (27, 1.40271929972644620000e+000) (28, 1.27283817886895470000e+000) (29, 1.58204094797256590000e+000) (30, 1.39408089770835590000e+000) (31, 3.10126910696644600000e-002) (26, 3.83823420979183040000e-001) (27, -2.64967289778462730000e-001) (28, 3.86854109054575120000e-001) (29, -3.54256429173251730000e-001) (30, -1.86915284626028800000e+000) (31, 2.34490026196885060000e+000) 

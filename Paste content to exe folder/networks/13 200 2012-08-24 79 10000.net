FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.25229415559434670000e+001) (1, 5.74923398873536410000e+000) (2, -1.07169697233893030000e+002) (3, 9.57528181797552770000e+000) (4, 1.18155963458164150000e+001) (5, 3.18275682077131710000e+000) (6, -7.80592189400882290000e+001) (7, -3.48616918260202980000e+000) (8, 9.78318812348713180000e+001) (9, -8.91537734633458980000e-001) (10, 1.89330176248121060000e+001) (11, -6.56420352607088380000e+000) (12, 5.13912783785111100000e+001) (13, 3.81498914835590200000e+000) (14, 5.17889122321899080000e+001) (15, -6.35932900672511710000e+000) (16, -9.12258779277611750000e+001) (17, -8.16103779359402930000e-001) (18, 3.76652009030131860000e+001) (19, -2.19173603022238160000e+000) (20, 8.47619029616938630000e+001) (21, -2.99220341682216780000e+000) (22, 4.97467948253397410000e+001) (23, -1.89538572043331070000e+000) (24, 7.54725500891841870000e+000) (25, 6.63362049921960930000e+000) (0, 8.47378767881387350000e+001) (1, 3.17256400318963960000e+000) (2, 3.64457474780917680000e+001) (3, 9.27459560262791640000e-001) (4, 1.81141713569275030000e+001) (5, -1.18639179806775190000e+000) (6, -7.59648631130869630000e+001) (7, -9.61009619241334790000e+000) (8, 7.57597976237565400000e+001) (9, 1.13331073903371740000e+000) (10, 1.38867481385922160000e+002) (11, -3.96729788802403820000e+000) (12, -5.75612326852687060000e+001) (13, -4.71324442290693660000e+000) (14, -1.16694378834461080000e+002) (15, -3.54535281103408550000e+000) (16, -7.10163266705444720000e-001) (17, -3.49513987987319030000e+000) (18, -5.57429782892374850000e+001) (19, 9.59556885521350880000e-001) (20, -4.49079817088015080000e+001) (21, 1.85555876014114050000e-001) (22, -4.22098438097604070000e+001) (23, -4.45512143892710990000e+000) (24, -1.65566926650975180000e+001) (25, -2.35512384923264010000e+000) (0, -5.22845743019068290000e+001) (1, -4.22490868659468790000e+000) (2, 2.15519042048901320000e+001) (3, -8.56169718082476370000e+000) (4, -2.31585084073239750000e+001) (5, -3.73500220009827470000e-001) (6, -1.05072755503325870000e+002) (7, -1.70923512876228760000e+000) (8, 3.68604252021490310000e+001) (9, -9.16133409230434200000e+000) (10, -4.04408964209670070000e+001) (11, -5.86837094773099380000e+000) (12, -2.69406020069268210000e+002) (13, -9.59149451687078520000e+000) (14, -7.34458267373450300000e+001) (15, -1.03474331802273410000e+000) (16, -6.88487944179683500000e+001) (17, -4.61776983288102020000e+000) (18, -3.59973559238773360000e+001) (19, -4.58686944754513880000e+000) (20, -5.12264021786465590000e+001) (21, -3.20144768104022150000e+000) (22, -3.04374537883665720000e+001) (23, 2.93947406488597300000e-001) (24, -2.62366589060991480000e+001) (25, 1.01048663836758820000e+001) (0, 2.14514436685588210000e+002) (1, 1.97003956464188190000e+001) (2, -3.14827419530546140000e+002) (3, 2.93031560571157430000e+001) (4, 3.56719182199214290000e+002) (5, 2.92685578567979730000e+001) (6, -1.80597188698902600000e+000) (7, -5.33285316758111920000e+001) (8, 1.21246819950816960000e+003) (9, 6.33453338184959240000e+001) (10, -6.22744473695814350000e+002) (11, -5.05465576080559270000e+001) (12, -1.91772479274740160000e+002) (13, 6.26478230764599410000e-001) (14, 5.52881049829860670000e+002) (15, -9.23348992757257040000e+000) (16, -1.76668564695091020000e+002) (17, 4.79782116979297510000e+001) (18, -2.57272876786770330000e+001) (19, 1.26463064636415940000e+001) (20, 2.84612282210832010000e+002) (21, 2.07075732336837640000e+001) (22, -9.80686046440649900000e+001) (23, 1.87225682795168890000e+000) (24, -4.99127328767212430000e+001) (25, -2.02586462650962990000e+001) (0, 1.23554741802122250000e+003) (1, -3.39238559287452400000e+001) (2, 8.85287671244470860000e+002) (3, -8.88815959915569210000e+001) (4, -2.24278704143809850000e+002) (5, 4.01072913353949900000e+001) (6, -5.16261177907378620000e+002) (7, -6.57663241516444120000e+001) (8, -3.92412832168676630000e+002) (9, 3.34867486938859780000e+001) (10, 5.54589466319138980000e+002) (11, -3.11019522058857060000e+000) (12, -1.50000000000000000000e+003) (13, -4.56648328257386000000e+001) (14, 3.74539304260293870000e+002) (15, 1.85831686530375210000e+002) (16, 8.74218941554200800000e+002) (17, 1.02011021588448630000e+002) (18, -8.31469680149566560000e+002) (19, 6.99828106059606940000e+001) (20, -1.46986965266735590000e+003) (21, 7.65206970589154030000e+001) (22, -7.27016784344964890000e+002) (23, 7.98879651369453400000e+001) (24, 1.48285579966890050000e+003) (25, -3.71615544722646900000e+001) (26, 1.18479892559909450000e+000) (27, -1.68725178587535750000e-001) (28, -1.10957233439454230000e+000) (29, -1.29271424414026440000e+000) (30, 1.12925353834793470000e+000) (31, 7.21747073184898500000e-002) (26, -1.45173591453256680000e+000) (27, -3.74665555426330840000e-001) (28, 2.22154223261308990000e-001) (29, 1.51968073738479540000e+000) (30, -1.40598641723892540000e+000) (31, 1.40338489693634960000e+000) (26, 9.76539198194306680000e-002) (27, 4.70786544182872800000e-001) (28, 7.28817984709540960000e-001) (29, -9.40876646234049540000e-002) (30, 4.86647533021837900000e-002) (31, 1.04428249286074440000e+000) 

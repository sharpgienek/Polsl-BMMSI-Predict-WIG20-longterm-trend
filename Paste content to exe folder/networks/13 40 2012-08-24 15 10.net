FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.36418575144256040000e-001) (1, 4.45749120559111140000e-001) (2, 4.61713114364004310000e-001) (3, 8.55928837154676520000e-002) (4, -1.41535175974813220000e+000) (5, 7.90171576143675750000e-002) (6, 2.63578781913625600000e-001) (7, -6.52638503949619640000e-002) (8, -3.08321073892123400000e-002) (9, -1.16690123201218770000e-001) (10, -2.29627948386058270000e-001) (11, 9.02980487025734770000e-002) (12, 4.12065003033823100000e-001) (13, 4.99936133085310430000e-001) (14, 3.12392337254636750000e+000) (15, 1.41312390789038400000e-001) (16, 2.26267337199619060000e-001) (17, 4.13749355845828230000e-001) (18, 6.32366559480831650000e-001) (19, -1.54541229629659630000e-001) (20, -6.45184431395942890000e-002) (21, -4.05018871353549640000e-002) (22, 2.05884928521748820000e+000) (23, 1.72805374150778430000e-001) (24, 3.23291761558305250000e-001) (25, 9.16209175678032310000e-002) (0, 1.77474921888710500000e-001) (1, 9.00839503688842520000e-003) (2, -1.08633289518987870000e-002) (3, -6.68900969429681860000e-002) (4, 2.77315118656223800000e+000) (5, 3.11391125577436590000e-001) (6, -3.18335931199000060000e-001) (7, 1.33034189325961230000e-001) (8, 3.87686248732261870000e-001) (9, 3.18494398205568960000e-001) (10, 4.23973522990712500000e-001) (11, -2.36371304232350810000e-001) (12, -1.18533066913935990000e+000) (13, -4.27296453744841100000e-001) (14, -3.05397097892587070000e+000) (15, 1.92765781881960630000e+000) (16, 4.92277452765235270000e-001) (17, -7.64835495964158170000e-002) (18, 3.95907811222667770000e-001) (19, 5.44854351145548370000e-001) (20, 1.63023949272816160000e-001) (21, 1.87827506037526960000e-001) (22, -4.90965700696963440000e-001) (23, 1.07747295244321250000e-001) (24, -3.20760257301203480000e+000) (25, 3.33884637120197720000e-001) (0, 2.65058716164079280000e-001) (1, -9.64965262476752960000e-002) (2, 2.87177482117261680000e-001) (3, -6.29305652701712540000e-002) (4, -1.02680038380283150000e+000) (5, 6.50217960776954400000e-002) (6, 1.79215987687772030000e-001) (7, 5.31565615258896700000e-002) (8, -5.01309296924478790000e-001) (9, 3.00082123171067470000e-001) (10, -2.55421206642683090000e-002) (11, -2.39430316938920640000e-001) (12, 3.73277491853623080000e-001) (13, 8.90236780091022140000e-002) (14, 1.05353867021963450000e+000) (15, 1.49998674762469250000e-001) (16, -1.59405615563524560000e-002) (17, 7.67394835435895320000e-002) (18, 9.26174396680981230000e-001) (19, 1.77195492790870320000e-002) (20, 1.01985576408464950000e-001) (21, 3.98720659485611310000e-002) (22, 2.50730881331551970000e-001) (23, 4.79075380101731260000e-002) (24, 3.03470818307621510000e-001) (25, 5.07761903966693770000e-002) (0, -1.19995876621166840000e+000) (1, -1.80888970790704900000e-001) (2, 2.70986993561927390000e+000) (3, -5.14905426073878350000e-001) (4, -3.08963382125416340000e+000) (5, -4.80179190561030640000e-001) (6, 1.02596982280412940000e+000) (7, -3.65384266975453010000e-001) (8, -1.32009873993799640000e+000) (9, 3.61605073708537340000e-001) (10, 1.05134140456189270000e+000) (11, -3.35574696218755800000e-001) (12, -1.02089828410550830000e+000) (13, -3.29693679000311190000e-003) (14, 2.66825616546793040000e+000) (15, 4.24427040371667450000e-001) (16, -1.08557113663170890000e+000) (17, 1.16917991554533880000e-001) (18, 8.52227698231389330000e-001) (19, 3.64589674041058300000e-001) (20, -4.24787337722926650000e-001) (21, -7.80403813723963560000e-002) (22, 1.94140293621192450000e+000) (23, 1.97151927405416450000e-001) (24, -5.67907605803839370000e-001) (25, 1.03462228577229800000e-001) (0, 2.28306598653710150000e+000) (1, -1.53035513496994400000e-001) (2, 2.83590753515363050000e+000) (3, -1.37627258347518260000e+000) (4, -2.24866465823737550000e+000) (5, 4.87628085484279050000e-002) (6, -3.66858881140798340000e-001) (7, 1.09309859488032850000e-001) (8, -2.32027110461689470000e+000) (9, -1.53712910531275580000e+000) (10, 5.58867434645869520000e-001) (11, -1.54265240856802670000e+000) (12, -1.78404841735309770000e+000) (13, -2.38292467322350100000e-001) (14, 2.00129063241682030000e+000) (15, 1.06294615677759860000e+000) (16, -6.24003658821974280000e-001) (17, 1.89615836142300150000e-001) (18, 1.42445936639194760000e+000) (19, 1.17226255913017900000e+000) (20, -4.98844965550714450000e-001) (21, -3.75147444405109610000e-001) (22, 1.91808750617699750000e+000) (23, 4.94785937675589870000e-001) (24, -2.27675303756217500000e+000) (25, 2.47428337003773540000e-001) (26, 4.81582861327450480000e-001) (27, -8.34905999225931780000e-001) (28, 4.22513036228491510000e-001) (29, 2.64071556293069000000e-001) (30, 1.96106786834879640000e-001) (31, 3.59213474738379560000e-001) (26, -1.84518469151064150000e-001) (27, 5.02589856059449600000e-002) (28, 6.65997131215839700000e-003) (29, -7.40325821263696060000e-001) (30, -6.56279697921578590000e-001) (31, 8.07626310476041050000e-001) (26, -1.05953353858746850000e+000) (27, 7.20540675013606640000e-001) (28, -8.84199774131699810000e-003) (29, 2.73303293820311430000e-001) (30, 7.17977198412907860000e-001) (31, 1.37820273244437170000e+000) 

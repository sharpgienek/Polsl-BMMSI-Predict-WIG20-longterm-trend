FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.23514164379635150000e+001) (1, -4.41983944670954420000e-001) (2, 6.95353256830590640000e+000) (3, -1.66448038360487830000e+000) (4, 1.17399744289494000000e-001) (5, -4.42615349246331880000e-002) (6, -3.47561544604577670000e+000) (7, -2.54571693745123510000e-001) (8, -7.57296659523559620000e-001) (9, 9.72558446113111150000e-001) (10, 5.04303438633058930000e+000) (11, 8.43278856996568520000e-002) (12, -2.26761384031210940000e+001) (13, -1.25467417247369980000e-001) (14, -3.89579666670353720000e+001) (15, 3.08129258700663520000e+000) (16, -5.00671964427285010000e-001) (17, -9.42263244015552890000e-002) (18, -4.75842607179957790000e+000) (19, 3.12392243798651100000e-001) (20, -1.90242602378244000000e+001) (21, -2.21932963119457580000e+000) (22, 3.82518260125497920000e+001) (23, 1.10990714505129150000e-001) (24, -9.45010648733020990000e+000) (25, -4.20637871084121930000e-001) (0, 7.34855543631397490000e-001) (1, 6.86798925485009180000e-002) (2, 1.74560723435754440000e+000) (3, 1.25284447832018290000e+000) (4, 9.88733648425849940000e+000) (5, 1.73932508383892850000e+000) (6, -1.45587805936038900000e+001) (7, -8.16741786228635660000e-002) (8, 1.22100791517067590000e+000) (9, 5.53908174218080920000e-001) (10, 1.02003832062364770000e-001) (11, 2.77657987522338880000e+000) (12, -3.94240750511942960000e+000) (13, -3.53495506399716770000e-001) (14, -2.65682777531584620000e+001) (15, 2.89180471464272060000e-001) (16, -2.08826893530393750000e+001) (17, -2.51208944125391690000e-001) (18, 9.04759212573970850000e-001) (19, 1.45297691980581930000e-001) (20, -7.18880645832002600000e+000) (21, 5.36875142048837570000e-001) (22, 1.03320347622375230000e+000) (23, -8.06621365019477900000e-001) (24, -1.31404492249715760000e+001) (25, 1.59423633490888840000e+000) (0, 1.33012763693726390000e+000) (1, -2.93340635111950800000e-001) (2, -4.95259505512515740000e+000) (3, -4.07563683059807000000e-001) (4, -2.09034959453628490000e+000) (5, -1.37153554632241050000e-001) (6, -6.65247613569978920000e+000) (7, -2.38612332055355290000e-001) (8, -2.14780069102291190000e+000) (9, -1.03018273664532070000e+000) (10, 9.08547847867441760000e+000) (11, 1.04907793665068750000e+000) (12, -6.23303587341554250000e+001) (13, -3.73386578715985910000e-001) (14, 1.52069285192780000000e+000) (15, 8.01675763334882880000e-001) (16, -1.29804800267793290000e+001) (17, 1.77108296174892820000e-001) (18, 6.83507550806202780000e+000) (19, 5.91409357962415120000e-003) (20, 5.28359142586230050000e+000) (21, -8.11753981942365480000e-001) (22, 4.08932215609243460000e+001) (23, -4.11283282047766390000e-002) (24, -2.56445182121635040000e+001) (25, 1.25793066969930550000e-003) (0, -9.48151833789588010000e-001) (1, 7.79253560479675870000e-001) (2, -6.66818280801245170000e-002) (3, 4.38659001733454570000e-001) (4, 5.41069655676204950000e+000) (5, 1.89438801908177630000e+000) (6, 8.46446082340436060000e-001) (7, -5.03996165633205040000e-001) (8, 5.34696268880899160000e+000) (9, -3.70823395288449940000e-002) (10, -7.63943375847041610000e+001) (11, -9.68805197459886580000e-001) (12, -5.74769032987645370000e+000) (13, -7.04940054968524970000e-001) (14, -6.03512325763594370000e-001) (15, -1.79715394510249890000e+000) (16, 4.93756675625895090000e+000) (17, -2.02480664269098970000e-001) (18, 3.40694518718622730000e+000) (19, -1.35935354155245650000e-002) (20, -4.20496163761978630000e+000) (21, -4.83836479423265410000e-001) (22, 5.25289913043500920000e-001) (23, 8.40141823558814950000e-001) (24, -4.52451403427060160000e+001) (25, -2.35371344877899570000e-001) (0, 2.62025255166738450000e+000) (1, 4.24353151470418130000e-001) (2, -1.48817134491446780000e+000) (3, -8.95967887851764290000e-001) (4, -1.03269993303989980000e+001) (5, 3.83218175517122780000e-001) (6, -2.04230567752622250000e+000) (7, 8.33390804824308830000e-001) (8, 8.57785623644803710000e-001) (9, -1.14912253813257110000e+000) (10, 1.24686508480176740000e+001) (11, -4.67155863987911420000e+000) (12, -5.31076281974347440000e+000) (13, -1.80339948537666350000e+000) (14, -3.18953135951484760000e+001) (15, -1.74380228422879410000e+000) (16, -1.63646741256730930000e+000) (17, -5.63975892259534260000e-001) (18, -1.40303952353179700000e+000) (19, -1.52391490956036990000e-001) (20, 3.93389630493732190000e+000) (21, 2.32364715544859850000e-001) (22, -1.20290195708767950000e-001) (23, 8.20001777818226000000e-002) (24, -4.72091005387944310000e+001) (25, 1.91098107965605140000e+000) (26, -5.88273869731684720000e-001) (27, -9.26551347728442940000e-001) (28, 7.89857109119590730000e-001) (29, -1.10147766430256980000e-001) (30, -2.55144649449687290000e-001) (31, 8.20469809006866500000e-001) (26, 6.73992913553018050000e-001) (27, -5.19997394055854430000e-001) (28, -1.75188201276352800000e+000) (29, 1.42213102448055580000e+000) (30, -1.27240013078034160000e+000) (31, 1.43736780159670950000e+000) (26, 7.33878508150290900000e-002) (27, 2.56997065824437730000e+000) (28, 1.50922742190798690000e+000) (29, -1.79364098527767360000e+000) (30, 1.29778925473742920000e+000) (31, 9.37497439059225890000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.02322757026463320000e+000) (1, 1.33920603867062230000e-001) (2, -1.47274589277407840000e+000) (3, 7.80261014575874380000e-001) (4, 1.96786896100747730000e+000) (5, 2.92296340546202020000e-001) (6, 7.16416247586183940000e-001) (7, 3.36390400596728310000e-002) (8, -1.57275957351683400000e-001) (9, 1.72175789817538720000e+000) (10, -3.15857303126581270000e+000) (11, 4.29137265559986440000e-001) (12, 6.07527403493599790000e-001) (13, 4.57480879735551900000e-001) (14, 7.57083105573765790000e-001) (15, -1.78270980048108730000e-001) (16, 3.10933596998524830000e+000) (17, 2.68095383543428210000e-001) (18, 6.04708105803723360000e-001) (19, -1.85889402316167380000e-001) (20, 2.83653009375665730000e+000) (21, 6.28013813773766310000e-001) (22, -1.42584980677956530000e+000) (23, -2.29996139026877160000e-001) (24, 2.71593683024092770000e+000) (25, 7.79757788146693690000e-002) (0, -2.79032658373301990000e-001) (1, -4.30321160902510940000e-002) (2, 6.35441792400076810000e-001) (3, 3.12316888369439380000e-001) (4, 4.43578015470342200000e-001) (5, 8.05317625635160850000e-001) (6, 1.41402145122495190000e-001) (7, 3.39084832510186670000e-001) (8, 1.41966783560275230000e+000) (9, 2.85894735925357470000e-001) (10, -1.39306310221604620000e+000) (11, 7.46820442911411140000e-004) (12, -4.05702806657351690000e-002) (13, -4.08805609525819620000e-001) (14, -3.15807254297710480000e+000) (15, -2.74062126628556450000e-001) (16, -3.11280276691190760000e+000) (17, -1.91687465675884740000e-001) (18, -1.25273179319058990000e+000) (19, 4.39178540432670180000e-001) (20, 3.09776292367647140000e-001) (21, 1.97074221530232740000e-001) (22, -3.40821797699225710000e-001) (23, -1.10679603724302360000e-001) (24, -1.28859605153750900000e+000) (25, 1.14780519132086020000e-001) (0, 3.04424132940776750000e-001) (1, 1.05997019466593390000e-001) (2, -2.21558360305692940000e+000) (3, 4.06082900092704260000e-001) (4, 2.03190704789921920000e+000) (5, 5.29184580990641250000e-001) (6, 9.92617268764807160000e-001) (7, -5.68089593349823540000e-002) (8, -3.27307443782100640000e-001) (9, -6.93819201407773890000e-002) (10, -3.10784060863484070000e+000) (11, 8.48367286621506070000e-001) (12, 2.85226495727237510000e+000) (13, 4.51475020271057630000e-001) (14, 1.22236191492279690000e+000) (15, -2.52805337094311190000e-001) (16, 3.12268435885602980000e+000) (17, 3.01550535564164560000e-001) (18, 3.36237862822686470000e-001) (19, -1.53427534370291020000e-001) (20, 2.74477594199878890000e+000) (21, 3.95049771388260750000e-001) (22, -1.44943379150599410000e+000) (23, -2.78651375057685060000e-001) (24, 2.80631769096270740000e+000) (25, -3.07762550482018230000e-001) (0, -3.35009268430179090000e-001) (1, 7.03268033207473800000e-002) (2, 3.03632571499106070000e+000) (3, 1.73335023261336430000e-001) (4, -3.11627566735428290000e+000) (5, -1.69243197759504280000e-001) (6, 3.90037975610033500000e-001) (7, -8.24622714175361200000e-002) (8, -1.00864852806359770000e+000) (9, -7.85184283703464080000e-003) (10, 1.28287584137689280000e+000) (11, 1.45861125516547540000e-001) (12, -1.61097080175959420000e-001) (13, -2.13081901110505320000e-001) (14, 6.67906742911306690000e-001) (15, 1.08649121287426930000e-001) (16, -2.18628062410465600000e+000) (17, 2.29011945488805270000e-001) (18, 3.03144290241830120000e+000) (19, 1.10876140221061080000e-001) (20, -6.26158210947652560000e-001) (21, 2.19519035424143640000e-001) (22, 3.20466067843694710000e+000) (23, 1.47957544879758820000e-001) (24, -3.69814138606825940000e-001) (25, 2.03996433482595660000e-001) (0, 9.13673142129507010000e-001) (1, 3.67503795586748060000e-001) (2, -1.26538584297976600000e-001) (3, 6.01408996642660120000e-001) (4, 2.53611041284878520000e+000) (5, 1.65911515106291810000e+000) (6, -9.63940275444267860000e-001) (7, 3.19394094440434590000e-001) (8, 3.04833743392004930000e+000) (9, 2.45011187641105770000e+000) (10, -2.63844841320057030000e-001) (11, -3.25183397388376760000e-001) (12, 4.66941329095273580000e-001) (13, 1.16910646116952390000e-001) (14, -3.08851077436242870000e+000) (15, 4.72092274491808790000e-001) (16, 9.20290607530805940000e-001) (17, 1.55639068510456250000e-001) (18, -3.07631594996196170000e+000) (19, 4.18715313292262860000e-001) (20, 9.17287677798558800000e-001) (21, 1.40776816257243100000e+000) (22, -9.34429776957652170000e-001) (23, -1.85112475759688370000e-001) (24, 1.39788721913163470000e-001) (25, 6.53213650455387150000e-001) (26, 3.13239953588855330000e-002) (27, -1.29305900411508330000e+000) (28, 1.71063191245484140000e-001) (29, 3.72416270718048670000e-001) (30, -2.23371571869474190000e-002) (31, 8.26285542861023850000e-001) (26, 6.42162113621431830000e-001) (27, 1.44759719435990610000e-001) (28, 5.36699465565541050000e-001) (29, -3.84610341480693840000e-001) (30, 4.14862437232652200000e-001) (31, 2.24512035658413380000e-001) (26, -1.27860826628500530000e+000) (27, 3.00108935088885530000e-001) (28, -5.51142027311473550000e-001) (29, 2.16914461955879550000e-001) (30, 6.39283588269050520000e-001) (31, 1.14264466885066310000e+000) 

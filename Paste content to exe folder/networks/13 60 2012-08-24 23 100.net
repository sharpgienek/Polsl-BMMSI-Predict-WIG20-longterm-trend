FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.39535880592202770000e+000) (1, 1.48455105894998880000e-001) (2, -3.94218480438443150000e-001) (3, 3.18555884713103630000e+000) (4, -3.66399606868438220000e+000) (5, 1.50785020245657940000e+000) (6, 3.04329739915399210000e+001) (7, 2.47341794995928980000e-001) (8, -1.29048035678034620000e+000) (9, 3.05764898861330850000e+000) (10, 4.83918090282747660000e+000) (11, -1.14132689411684640000e+000) (12, 1.88473838332086530000e+000) (13, 6.01046135786326490000e-001) (14, 6.65180648841842360000e+000) (15, -2.44224940356282980000e-001) (16, 8.51988940179188140000e-001) (17, -3.78179175976714630000e-001) (18, 1.28531681213030300000e+001) (19, 9.46616707025298990000e-001) (20, 1.54613170439972290000e+000) (21, 1.67963143251575690000e+000) (22, -1.10280360811072790000e+001) (23, 6.77386858619957950000e-001) (24, -7.44556329837914530000e+000) (25, 1.17655015574536210000e+000) (0, 1.46969853562753030000e+000) (1, -4.98075679688939830000e-002) (2, -2.35298613010105730000e+001) (3, 9.81443583348814320000e-001) (4, 2.49230496808763320000e+001) (5, 1.18503897697684990000e+000) (6, 9.52392940483802700000e+000) (7, -6.05457696100713760000e-001) (8, -1.23314907947906250000e+000) (9, 5.61574043149555060000e-001) (10, -3.03201575819776670000e+000) (11, 1.00971790130269940000e-001) (12, -1.23784866568965110000e+001) (13, 2.34536554690149000000e-001) (14, 8.40281599860775330000e+000) (15, -1.44710566970030550000e+000) (16, 1.27765798526727660000e+001) (17, 3.06312882213357280000e-001) (18, 2.02561369027874600000e+001) (19, -4.43281736732908380000e-001) (20, 1.66116132856987060000e+001) (21, -2.99268999061926030000e+000) (22, -6.33712235351153290000e-001) (23, -2.07003817551763850000e+000) (24, 8.10383065464050820000e+001) (25, -1.08195344556756940000e+000) (0, 6.31961241330965070000e+000) (1, 3.01070485591315940000e-001) (2, 1.12856967617908650000e+001) (3, -2.61676458143246380000e+000) (4, 4.43296796715903430000e+000) (5, 6.75081694368551260000e-001) (6, 1.04263322119726960000e+001) (7, 5.42551314497778270000e-001) (8, -1.05975366408922830000e+001) (9, -6.91582707952217430000e-002) (10, 3.83433188610288320000e+000) (11, -1.29813114377572790000e+000) (12, -4.26184380236681040000e-001) (13, -4.93415619359362960000e-001) (14, -4.69332428437528650000e+001) (15, 3.41442861743778360000e-001) (16, -3.04217898936869880000e+000) (17, -1.03496270664377500000e+000) (18, -1.58667038433458330000e+001) (19, 6.00170726742804360000e-001) (20, -1.02800990011167330000e+001) (21, -2.29173608499021960000e-001) (22, -1.95249048618471030000e-001) (23, 3.70965234726493180000e-001) (24, -3.37379088036304320000e+001) (25, 1.15161676787595440000e-001) (0, -1.72107227330085720000e+000) (1, -4.55426651029831820000e-001) (2, 6.84815381022971460000e-001) (3, -1.79910308257010990000e-001) (4, -2.67506311201752970000e+000) (5, 1.26307957618693020000e+000) (6, -2.79820395290810890000e+001) (7, -4.17300674283272170000e-001) (8, -9.69032906496993010000e+000) (9, -1.69372709564066740000e+000) (10, 3.64117305234741410000e+001) (11, -2.19078787768223830000e+000) (12, 4.72942715335952570000e+001) (13, -6.07203943829690450000e-001) (14, 2.93044701880010460000e+000) (15, -9.33006149817935950000e-002) (16, 1.20565239036118380000e+000) (17, -1.86114601255052900000e+000) (18, 1.88407209259982340000e+001) (19, 6.34041434148269630000e-001) (20, -1.53777370124485380000e+000) (21, -5.52446838404180070000e-001) (22, -1.50454772100809020000e+000) (23, -1.75712669526388060000e-001) (24, -3.29366224218925740000e+000) (25, -3.71840465655486230000e-001) (0, -4.50314779568568730000e+000) (1, 7.02529554291635660000e-001) (2, 6.08678279283043190000e-001) (3, -1.14504019255792570000e+000) (4, -8.07343157822332990000e+000) (5, -2.60516645058004700000e-001) (6, 3.45307225255968130000e+000) (7, 3.29063687580964980000e+000) (8, -9.16193661030838270000e-002) (9, -6.19927057898013790000e-002) (10, -3.06374675939184600000e-001) (11, 4.63803939441514490000e-001) (12, -1.21795213847476670000e-001) (13, 1.71544123015392460000e-001) (14, 2.32337290041842470000e+000) (15, 1.03529898311432890000e+000) (16, 3.99497032873617640000e+001) (17, 4.12079537285723830000e-001) (18, -8.75475032695492670000e+000) (19, -7.97435598676504290000e-002) (20, 3.75242198539591600000e+001) (21, -4.36466850573766290000e-002) (22, 2.67744693420263720000e+001) (23, 3.07174048860658850000e-001) (24, -9.37257374067927710000e+000) (25, -1.96792625662266100000e-001) (26, -1.85370930085944300000e-001) (27, -3.06517760647227970000e-001) (28, -1.81970552397399700000e+000) (29, 1.37120204261710630000e+000) (30, 1.43001291499222890000e+000) (31, 1.23870140848031340000e+000) (26, 1.58519350853608240000e+000) (27, 2.24039482863963360000e+000) (28, 1.35291784070147790000e+000) (29, -1.08436499415170170000e+000) (30, 3.46445780516527630000e-001) (31, 5.71059957419408290000e-001) (26, -1.23761718040746430000e+000) (27, -1.50055599998464030000e+000) (28, 2.35982429568539260000e-001) (29, 3.31534013399435720000e-001) (30, -1.59641386381842510000e+000) (31, 1.58349865688587270000e+000) 

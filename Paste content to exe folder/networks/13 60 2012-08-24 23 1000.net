FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.00688030103138540000e+001) (1, -2.37770014600620970000e+000) (2, 2.92946011334475040000e+001) (3, 1.00484578801454320000e-002) (4, 6.86506079766142550000e+000) (5, 1.74040444823486080000e+000) (6, -1.06856499243889950000e+001) (7, 4.56891372853297110000e+000) (8, 9.28255824427429490000e+000) (9, -1.08113230849065100000e-001) (10, 1.50201399179883990000e+001) (11, 5.51282784040047710000e-001) (12, 8.36466267696232710000e+000) (13, 3.18576002127684930000e+000) (14, 5.47573401065672010000e+000) (15, 8.85320518886642870000e-001) (16, 1.44622890172531500000e+002) (17, 2.37289263280231640000e-001) (18, 2.98542457223721270000e+001) (19, -9.57182624558067570000e-001) (20, -2.29105792485359570000e+001) (21, 3.39026107875448620000e-001) (22, 1.80847864541335350000e+001) (23, 2.10109618546418760000e+000) (24, 2.13393618163470890000e+000) (25, 1.66846056245893020000e+000) (0, 6.88990282203671280000e+001) (1, 3.57688385705751610000e+000) (2, -1.18557255422661530000e+001) (3, 9.10339981029479440000e-001) (4, 1.14465774397320460000e+001) (5, 6.22859490850465660000e-001) (6, 6.50934399360750720000e+001) (7, 1.52099429322060660000e+000) (8, -3.74670034367892980000e+001) (9, -2.95783673446988860000e-001) (10, -4.48517341134922210000e+001) (11, -6.18233765417528680000e+000) (12, -1.25739783905260790000e+002) (13, -1.05830205378442850000e+000) (14, -9.89326724657799300000e+001) (15, -2.74977448965013860000e-001) (16, -2.63679004628623550000e+001) (17, -1.34623721243131360000e+000) (18, -1.96547619441601890000e+001) (19, 5.18302853832233730000e-001) (20, -6.07274500347689280000e+001) (21, -3.96428532705486260000e+000) (22, -6.30322983021147200000e+000) (23, -6.17305423394321150000e-001) (24, -4.29839287981346630000e+001) (25, -7.19144551421612600000e-001) (0, -4.82008687122244610000e+000) (1, 2.32115531687642610000e+000) (2, 1.45312931327008550000e+001) (3, 1.00684842341435800000e+000) (4, -2.58342481690856620000e+001) (5, -1.88921009254901410000e+000) (6, -4.66525628503622730000e+001) (7, 2.83661744451646320000e-001) (8, 7.22833201423489950000e+000) (9, -1.82918400991992640000e-001) (10, 5.64484918178500370000e+000) (11, -1.29622584236205580000e+000) (12, 4.64454803066029670000e+001) (13, -2.39371161296971830000e-001) (14, 5.33176060080638270000e+001) (15, -2.96606125278773780000e-001) (16, 1.43450638900921050000e+001) (17, 5.51253117815058370000e-001) (18, 2.36206427641288810000e+001) (19, -5.50223038775833670000e-001) (20, 8.70979619232212170000e+000) (21, -3.26583131674928640000e-001) (22, 5.02346888523692740000e+001) (23, 7.42688119717688110000e-001) (24, 1.53598647910443870000e+001) (25, -2.31417450264832290000e+000) (0, 4.09422243010799840000e+000) (1, 1.22028195171079440000e+001) (2, -1.77592932577498140000e+001) (3, -3.67080677261613860000e-001) (4, 5.39175643687677120000e+000) (5, 1.45077487799876640000e+000) (6, 4.12480182615759890000e+000) (7, -3.00947169311477310000e+000) (8, 4.39067499702178040000e+000) (9, -6.88150228033513220000e-001) (10, -2.39424503900301250000e+001) (11, 1.37558421644356890000e+001) (12, -5.48738766122214110000e+000) (13, -1.28986753129487790000e-001) (14, -5.58244964386558710000e+001) (15, -7.64243965484154140000e+000) (16, -1.50219958150373320000e+002) (17, 5.72834171765556400000e-001) (18, 5.08614336779865360000e+000) (19, -7.90390014305365710000e-001) (20, 8.33466670865814620000e+001) (21, 1.40091825606017960000e+000) (22, 3.04853297775596420000e+001) (23, -2.03705644485115880000e-001) (24, 1.54076881183760360000e+001) (25, -2.44794303814031090000e+000) (0, 3.24986955154739760000e+001) (1, 5.22710148513994550000e-001) (2, -2.56327518221786700000e+000) (3, 4.05384503534668480000e-001) (4, 4.03189926122027700000e+001) (5, 1.09981239224728370000e+001) (6, 2.94484145950388100000e+000) (7, 4.96472304552073200000e-001) (8, -1.11620219247458100000e+001) (9, -2.26384713700287100000e+000) (10, 8.64694222984703910000e+001) (11, 3.30790664193060650000e+000) (12, 5.45348996877044240000e+001) (13, -5.36944970993693090000e-001) (14, -1.87424710327516380000e+001) (15, -1.34652687637936430000e+000) (16, -2.89503826043984210000e+000) (17, 1.03933913698197220000e+000) (18, 2.48668942580657630000e+001) (19, 1.51931842163407380000e+000) (20, -3.65957785810990010000e+000) (21, 5.06772357028345550000e-002) (22, -5.69226458498685800000e+001) (23, -1.28495392196136840000e+000) (24, 6.70713231380132840000e+001) (25, 5.50323415877369370000e+000) (26, 9.32174451567566060000e-001) (27, -1.21911066608119010000e+000) (28, 1.53463954262600640000e+000) (29, -7.09981910966337230000e-001) (30, 7.11150753399357400000e-001) (31, 4.04506468480332060000e-001) (26, 1.28817490690724750000e+000) (27, 1.26614938000796080000e+000) (28, -2.41363828731181980000e+000) (29, 3.49347155812959320000e+000) (30, -3.32520779456910680000e+000) (31, 1.91600828113835990000e+000) (26, -3.39846738229371060000e+000) (27, 9.18385535928475160000e-001) (28, 1.99415402101469040000e+000) (29, -2.87098010729806190000e+000) (30, 2.79257295708284040000e+000) (31, 2.51418846871316950000e+000) 

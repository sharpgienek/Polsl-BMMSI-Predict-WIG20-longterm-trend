FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.54987662375154040000e+000) (1, 9.10914627421194330000e-001) (2, 3.07082502265746770000e+001) (3, -2.72368988068395820000e-001) (4, -1.54516013437908020000e+001) (5, 6.47459223198097340000e-001) (6, -4.72501256282014670000e+001) (7, 1.10191562311367020000e+000) (8, 2.01827048871527420000e+001) (9, -1.40032778572348530000e+000) (10, 6.37708742420720750000e+001) (11, -2.49444557346630010000e-002) (12, 1.17655613097797470000e+001) (13, 5.96304348627240350000e-001) (14, 2.57038230022805830000e+001) (15, 6.34237754829760080000e-001) (16, 5.78030454868808690000e+001) (17, 5.69170395478988730000e-001) (18, -2.59742607003509710000e+001) (19, -1.51382789900576390000e+000) (20, -1.65400268936183360000e+001) (21, -6.70947228619708790000e-001) (22, 1.36403128351416300000e+001) (23, -6.78192364907925780000e-003) (24, 8.40999102260248680000e+000) (25, -2.10387673734819060000e+000) (0, 8.53292261144678040000e+000) (1, 1.16596008409500420000e-001) (2, -1.34896074770450060000e+001) (3, 3.74511210539959670000e-001) (4, 3.77397139726650990000e+000) (5, 1.54039754168037410000e+000) (6, 4.65740499867973860000e+000) (7, -5.36744461261741580000e-001) (8, -3.99445674497825330000e+000) (9, 1.84532481214543180000e+000) (10, -3.25545177829168960000e+001) (11, -1.13868436159531930000e+000) (12, 1.64666638803748310000e+001) (13, 1.04069278994059390000e-001) (14, 1.31671407957429950000e+001) (15, 1.12613434745315820000e-001) (16, -4.91283267082583830000e+000) (17, 6.50660640360564480000e-001) (18, 1.93821081527595640000e+001) (19, 3.81323246143531640000e-001) (20, -1.17736620827830760000e+000) (21, 1.22033527921669550000e+000) (22, -1.87722555116291440000e+001) (23, 5.01190745342963500000e-002) (24, 1.23027776731390370000e+001) (25, 1.20011132775505880000e+000) (0, 8.25070899474624220000e+000) (1, 1.76296754115295480000e+000) (2, 4.83270298440314680000e+000) (3, 5.12880561543854750000e-001) (4, 1.71965850675356720000e+001) (5, -3.33998787110351180000e+000) (6, 1.51699634299691650000e+001) (7, 4.30179112424595190000e+000) (8, -1.75915038918487840000e+001) (9, -2.81250505575443810000e-002) (10, 2.93291002702720820000e+000) (11, 7.53921509462463480000e+000) (12, -1.19514017415842710000e+000) (13, 1.94318413743343000000e+000) (14, 1.47790629752447820000e+001) (15, -6.74780605502498080000e-001) (16, -5.75496770626744870000e+000) (17, 3.81435942010925370000e+000) (18, -1.75096610944385740000e+001) (19, -6.35880318788558330000e-001) (20, -2.10343431207593490000e+000) (21, 3.28628397305097010000e+000) (22, -4.77275554238091000000e+001) (23, 1.17418006922990520000e-001) (24, -1.10257768385050030000e+001) (25, 1.39529432942295180000e+000) (0, 5.13756842487844740000e+001) (1, 7.70876302702250160000e-001) (2, 1.12193082001213600000e-001) (3, 7.54512899671681450000e-001) (4, -2.11732725588012980000e+001) (5, 1.17230215982828060000e+000) (6, 3.11769612692971130000e+001) (7, 1.36305091973499580000e+000) (8, -1.17330320039802520000e+001) (9, 5.17500326777659140000e+000) (10, 4.05493685212879430000e-001) (11, -6.74617256201027970000e-001) (12, 7.91877520867666100000e+000) (13, 4.46498745324651890000e-002) (14, 3.52008513468987230000e+001) (15, 2.23013445695551620000e+000) (16, 1.70116883498735310000e+001) (17, -1.19416118468614400000e+000) (18, 1.42514710008401010000e+002) (19, 1.09540808627600000000e+001) (20, 9.82073428082353100000e+001) (21, 3.02219285187851350000e-001) (22, -2.82835282582253740000e+001) (23, 4.79672240525719660000e+000) (24, -2.68864141103276180000e+001) (25, -7.04883728448697790000e-002) (0, -2.57815188014787750000e+001) (1, 2.00569212304963740000e+000) (2, 3.39180813398501970000e+000) (3, -4.88933055394883100000e+001) (4, 5.24584803993390560000e+000) (5, -2.55217167451312260000e+001) (6, -1.90525071663624430000e+002) (7, -2.50504882645357310000e+000) (8, 1.77649570615274610000e+001) (9, 4.49661859313732570000e+000) (10, 6.83255200753714220000e+000) (11, -1.70647325154605320000e+000) (12, -8.74494045159602430000e+000) (13, -1.24916879956248760000e+000) (14, -1.02087987967552110000e+001) (15, 1.12892343747043690000e+000) (16, 1.14130399952890950000e+002) (17, -4.60951745770812950000e+000) (18, -4.77187963099580340000e+000) (19, -1.38687594231433660000e+001) (20, 3.65176589824108080000e+001) (21, -5.44711645180181050000e+000) (22, 8.00790638276440770000e+001) (23, -3.23145028530352010000e+000) (24, -8.20785135912821180000e+001) (25, -5.50374652524510650000e+000) (26, 3.65588118718759160000e+000) (27, 1.93606909304874060000e-002) (28, -1.13364131150425660000e-002) (29, 8.06402251096699320000e-003) (30, -3.59669337257399310000e+000) (31, -2.82959833875551310000e-002) (26, -1.14352691986856740000e+000) (27, 3.43800051418402400000e+000) (28, 2.99268780319694420000e+000) (29, 4.01263035446274860000e+000) (30, 4.95853866957043810000e+000) (31, -5.99767860967594930000e-001) (26, -3.05573951115542290000e+000) (27, -3.73096860712394250000e+000) (28, -3.57734621810698620000e+000) (29, -3.55695925503521600000e+000) (30, -5.35129878310404170000e-003) (31, 6.74626364348737970000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.28051739111837030000e+000) (1, -2.40276042640962610000e-001) (2, 2.22027969209691600000e+001) (3, 4.89261350763911820000e+000) (4, -4.05047497512091890000e+001) (5, -6.78091889036866010000e-001) (6, -3.73286110692733220000e+001) (7, 8.13437270740841050000e-001) (8, 2.09939160804591940000e+001) (9, -1.84119116908943070000e+000) (10, 1.86034590797913530000e+001) (11, 1.05640088106748120000e+000) (12, 8.00518372559255550000e+000) (13, -9.66368762417272320000e-001) (14, -2.33548480948461620000e+001) (15, 2.47995330558172580000e+000) (16, -4.67828071542551380000e+001) (17, 1.61441629127313300000e+000) (18, -1.99290369686119460000e+001) (19, 8.65206693988535670000e-001) (20, -1.37884753078725120000e+000) (21, 7.23140123369173440000e-001) (22, -1.00292635832633130000e+001) (23, 6.70097296922019030000e-001) (24, -3.72386850656427060000e+001) (25, 2.51885578227496130000e-001) (0, 1.79528981005456220000e+000) (1, 7.82786339273560010000e-001) (2, 7.27095822644099030000e+001) (3, -9.71000822624674460000e-001) (4, -1.47143663870751580000e+001) (5, 5.95993107667404430000e-001) (6, -1.81524367469219320000e+001) (7, 1.19588823040302380000e+000) (8, -3.76302691198853480000e+001) (9, -1.47214258638438760000e+000) (10, -5.63443075366253510000e+000) (11, -1.00647858372473990000e+000) (12, 9.03257894290800460000e+001) (13, -2.32272383714007270000e+000) (14, 4.81048087913890900000e+001) (15, 2.13463023082849990000e+000) (16, -4.73674108881988510000e+000) (17, 1.18058572095399760000e+000) (18, 1.80254746296333440000e+001) (19, 1.97302010109662040000e+000) (20, 1.49444512088311980000e+001) (21, 6.53209565495364510000e+000) (22, -3.16629412117976020000e+001) (23, 5.23246683105901940000e+000) (24, -1.82553250758784150000e+002) (25, -3.41709957690915060000e-001) (0, 1.01216703063153910000e+001) (1, 1.77295055794308640000e+000) (2, -2.32352099186429340000e+001) (3, -1.55503028178681470000e+000) (4, -3.67084987152555940000e+001) (5, 2.00482663922810910000e+000) (6, 2.86282699964739780000e+001) (7, -1.40159987763400200000e+000) (8, -7.20115456737820820000e+000) (9, 1.83847340408389610000e+000) (10, -6.29907417868275270000e+001) (11, -5.85775371035613060000e-001) (12, -6.49680625030929090000e+001) (13, 4.35631150868021460000e-001) (14, -6.19444670990144810000e+001) (15, -1.36724685084144440000e+000) (16, 1.44375844172908110000e+001) (17, -6.32179369943391860000e-001) (18, 6.37801580086535670000e+000) (19, 1.62886587418888810000e-001) (20, -1.40334097370978640000e+001) (21, 1.32105588458924020000e+000) (22, -2.41356048510814140000e+001) (23, 1.22264892721362410000e+000) (24, -7.21673568883113750000e+001) (25, 1.27140627721712420000e+000) (0, 1.70425071903118310000e+001) (1, 1.10494726298971750000e+000) (2, 4.06754519281477300000e+000) (3, -2.41731583235432400000e-001) (4, -5.02630497095740480000e+000) (5, 2.02218391932721040000e+000) (6, 2.91981033036545060000e+000) (7, -4.06074079399413260000e-001) (8, -2.86573335307668130000e+000) (9, -4.05669987986517930000e-001) (10, -4.37135528709993350000e+000) (11, -1.83741598818908810000e+000) (12, -3.55419758289972880000e+000) (13, -6.91383308117280990000e-002) (14, -7.53651991372012020000e+000) (15, -7.24523680772335980000e-001) (16, 7.31482622023375660000e+000) (17, -2.98712000311255220000e-001) (18, 1.61846090972469340000e+001) (19, 8.31386888197104710000e-001) (20, 5.12800787366113300000e+000) (21, 9.65366744447453650000e-003) (22, -3.80442268771756350000e-001) (23, 6.27105186169755300000e-001) (24, -3.18947896162905560000e+001) (25, 2.73210608363711420000e-001) (0, 1.84180498046217700000e+001) (1, 5.36395442423354680000e-002) (2, 2.80168569923333060000e+001) (3, -1.19863566363572580000e+000) (4, 8.43214547000235370000e+000) (5, 2.26368953288426940000e+000) (6, -3.46943170155872740000e+001) (7, -1.23989097965666440000e+000) (8, 1.52772896697865970000e+001) (9, -3.43514137443369980000e+000) (10, 4.75540795493335580000e+001) (11, -1.91657897992982980000e+000) (12, 6.67098447789754890000e+000) (13, 5.30233733178694040000e-001) (14, -1.09921654611981750000e+001) (15, 4.13720348689603720000e-001) (16, -2.23602586080246230000e+001) (17, -1.32155210562007830000e+000) (18, -1.56136413196564860000e+001) (19, 1.84745427959738720000e-001) (20, -9.53908346467067680000e+000) (21, -2.72488362103058310000e+000) (22, 6.72673362057396850000e+000) (23, -1.94390527944052760000e-001) (24, 8.30748735583523160000e+000) (25, 2.02643697639708980000e+000) (26, -3.22862721849772520000e+000) (27, 3.13569821727494480000e+000) (28, -3.30380233809161970000e+000) (29, 2.35536986036875840000e-001) (30, -6.44681702178771100000e-002) (31, 3.13840130534727630000e+000) (26, -7.95990649177524960000e-002) (27, -4.53219336850172550000e+000) (28, -1.60490275780026080000e+000) (29, 7.29832620037420200000e+000) (30, -5.19823505108729740000e+000) (31, 4.07721830054834910000e+000) (26, 3.93899858690098940000e+000) (27, 6.95020298998890310000e-002) (28, 3.90885304490018640000e+000) (29, -7.29889961774543130000e+000) (30, 7.10128831716735930000e+000) (31, 9.53445694846329070000e-002) 

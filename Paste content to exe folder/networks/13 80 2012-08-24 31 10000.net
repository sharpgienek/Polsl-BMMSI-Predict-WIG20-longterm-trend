FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -4.46904529878711400000e+002) (1, 4.76193499548889250000e+001) (2, -1.50000000000000000000e+003) (3, 8.02352944006105990000e+002) (4, 1.50000000000000000000e+003) (5, 1.74579193850989870000e+002) (6, -1.26295863138177990000e+003) (7, 4.51325093681648970000e+001) (8, 1.50000000000000000000e+003) (9, 4.40067545222324330000e+002) (10, -1.50000000000000000000e+003) (11, 2.23644621854304940000e+002) (12, 1.08688045360357360000e+003) (13, 6.28975597142065010000e+001) (14, -1.12140712278051320000e+003) (15, 6.99604195427317560000e+001) (16, -4.15284012261980710000e+001) (17, 9.24898978196189600000e+001) (18, -1.50000000000000000000e+003) (19, 4.50771055588193900000e+001) (20, 1.43737122535642970000e+003) (21, 3.24221368520843640000e+001) (22, 1.49710892156930050000e+003) (23, 2.96518130259998750000e+001) (24, 1.50000000000000000000e+003) (25, 1.48301933497154550000e+002) (0, -8.05475059272091870000e+001) (1, 1.73172158158660320000e+000) (2, -3.47777149962815240000e+001) (3, 6.43422600790824980000e+000) (4, -2.49736709975096080000e+001) (5, 6.92067704033954350000e-001) (6, 4.94214178103857690000e+001) (7, 2.88342875265714500000e-001) (8, 1.16896432943596750000e+002) (9, 2.35576112684339110000e+000) (10, -1.77423462330590600000e+001) (11, 2.27830508354900270000e-002) (12, 6.74711467426721900000e+001) (13, 1.21504649605230860000e+000) (14, 4.36557029826258470000e+001) (15, -1.19705996350194680000e+000) (16, 1.09739402397014730000e+002) (17, 2.20329280943250350000e+000) (18, 1.40866281679108170000e+002) (19, 1.33552376163319030000e-001) (20, 1.41616173671446380000e+002) (21, 1.24128577589689890000e+000) (22, 1.27634726022200780000e+002) (23, -6.63242465727473470000e-001) (24, 1.86180995948676100000e+002) (25, -5.15323238664112450000e+000) (0, 1.49547078168480950000e+003) (1, -7.38772486018440650000e+002) (2, -1.47748658711287290000e+003) (3, -3.91924766546026380000e+002) (4, 1.49999933027312500000e+003) (5, 1.50000000000000000000e+003) (6, 3.53157813493847300000e+002) (7, 1.49680909841278480000e+003) (8, 1.48173097409366350000e+003) (9, -1.49320831489649460000e+003) (10, -1.47633402557934390000e+003) (11, -1.25598042156348900000e+003) (12, 1.49999720564914670000e+003) (13, -1.49817052774659960000e+003) (14, -1.48627706882869010000e+003) (15, 9.73011941612481110000e+002) (16, 9.54193864053706650000e+002) (17, 7.72878989586073290000e+001) (18, -4.90379667408999750000e+002) (19, 4.79829239920661110000e+002) (20, 1.48240698417416550000e+003) (21, 1.46470911164747580000e+003) (22, 1.50000000000000000000e+003) (23, 1.49913145176922560000e+003) (24, -1.48506242936404030000e+003) (25, 1.41190298564481510000e+003) (0, 7.80874202779924360000e+001) (1, 1.09309548791246320000e+001) (2, -2.83886295177102450000e+002) (3, 6.20815804919816380000e+000) (4, -3.15771488698167390000e+001) (5, 1.65957336841956470000e+001) (6, -1.92120132658165370000e+002) (7, -3.02731130988927400000e-001) (8, 2.34597203700230460000e+001) (9, 1.50567450135592010000e+001) (10, 5.87778754478392570000e+001) (11, -7.74584500933523380000e-001) (12, 5.53522033301693880000e+001) (13, 6.79841767706013660000e+001) (14, 1.26032194490952930000e+003) (15, -1.78172653588261620000e+001) (16, 3.77693119064196990000e+002) (17, 1.15667135101468990000e+001) (18, -7.65851209413970510000e+001) (19, -1.25420177521193580000e+001) (20, 4.13660881112265770000e+002) (21, 7.88208856695558510000e+000) (22, 2.70179969509376630000e+002) (23, -1.61459521091936010000e+001) (24, 7.65554660681571480000e+002) (25, 8.12796126633502420000e+000) (0, 1.08970758361466350000e+003) (1, 4.67968081917906250000e+001) (2, -1.30858536635853800000e+002) (3, 5.47480055059520080000e+001) (4, -9.49020741261288550000e+002) (5, 8.25729675724595500000e+000) (6, -2.73872029900475070000e+002) (7, -4.81334332928014630000e+001) (8, -8.13405474496153860000e+001) (9, 1.09180576355738240000e+001) (10, -3.49497909802210020000e+002) (11, -3.11837690268225600000e+001) (12, 3.14051181154271940000e+002) (13, -1.25261730926112430000e+002) (14, 1.50000000000000000000e+003) (15, 8.87293661236261410000e-002) (16, 5.48075224757429570000e+001) (17, 8.31970709591261230000e+001) (18, 1.45168553103170940000e+003) (19, 5.28194068259781280000e+001) (20, -7.32222346012627900000e+002) (21, -7.96376255628185170000e+000) (22, 5.10676398679003400000e+002) (23, 8.02108093443289860000e+000) (24, 7.68706800927645300000e+002) (25, 9.00254540883057430000e+000) (26, -1.19769269819368280000e+000) (27, -3.93340093274032950000e-002) (28, -4.72826886341482370000e-002) (29, 2.65364114316546160000e+000) (30, 2.63834206087865740000e+000) (31, 1.20721813610233220000e+000) (26, -1.40234569589631100000e+000) (27, 3.38355727823396800000e+000) (28, 1.29856394146079010000e+000) (29, -3.37622111758651040000e+000) (30, -3.29899695974082490000e+000) (31, 3.32813996460844970000e+000) (26, 2.29155826999590760000e+000) (27, -2.30099453857417610000e+000) (28, -2.30773377850160420000e-002) (29, 4.83906797911825420000e-002) (30, 4.56617369635250390000e-002) (31, -8.19854375992851020000e-002) 

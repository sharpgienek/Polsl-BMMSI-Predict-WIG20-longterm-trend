FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -9.59423673814465250000e-001) (1, -2.22720289649658730000e-001) (2, 4.57396375051251800000e-001) (3, -1.35806260769120210000e+000) (4, 1.44673300690305240000e+000) (5, 2.40466550278942260000e-001) (6, 3.11504275717966110000e+000) (7, 2.11648476157196230000e-001) (8, 2.63117908983365010000e-001) (9, -8.12624199439702930000e-002) (10, 1.06076523282731870000e+000) (11, 3.20321342091590830000e-002) (12, -6.95986637666199500000e-001) (13, -4.28647591231403220000e-001) (14, -1.02030013956534530000e+000) (15, 1.88228958364982740000e-001) (16, -3.95822234805723980000e-001) (17, -1.43797415230062590000e-001) (18, -9.36895597306895760000e-001) (19, 1.74594032245667000000e-001) (20, 3.49123401002513660000e-001) (21, 1.01933132038790490000e-001) (22, -1.31923814422204750000e+000) (23, -1.51661933984487090000e-002) (24, -9.15630948552527800000e-001) (25, 1.32135249836555110000e-001) (0, 2.30057697312616050000e+000) (1, 8.02882829284163600000e-002) (2, 3.63762340452871040000e-001) (3, 1.65855252131929310000e-001) (4, -5.49564945907969000000e-001) (5, 1.80731999372608750000e-001) (6, -4.75160154239431810000e-001) (7, 1.98947059952305380000e-001) (8, 1.26563559209511570000e+000) (9, 4.49923514152170970000e-002) (10, 3.08207156528210200000e+000) (11, 3.16723842610487250000e-001) (12, -3.12909305035777670000e+000) (13, 9.47553975568339170000e-002) (14, -3.83596892826677190000e-001) (15, 1.02454779325749800000e+000) (16, -3.14041507201086300000e+000) (17, 8.05647235172513990000e-002) (18, 1.65404693655975400000e-001) (19, 4.80771878578554520000e-001) (20, -1.48050679001589280000e+000) (21, 9.80141133210783000000e-001) (22, 1.20805928724320500000e+000) (23, 1.39666082581365040000e-001) (24, -3.14965579480481050000e+000) (25, 2.42877438986742300000e-001) (0, -1.34255113046650230000e+000) (1, 9.08989664944225010000e-002) (2, -8.28728464935121090000e-001) (3, 4.46960290273969270000e-001) (4, 1.21596715868508460000e+000) (5, 2.25491746104537620000e-002) (6, 1.40196496353949040000e+000) (7, 2.62812352421770420000e-001) (8, -1.31872772260623300000e-001) (9, 1.25307921072506590000e+000) (10, -3.59604237592448860000e-001) (11, 5.01309598520767170000e-002) (12, 5.29423369897543020000e-001) (13, 2.42351716286950350000e-001) (14, -1.41176902099759420000e+000) (15, -3.23502325992741700000e-001) (16, 5.27399541432329140000e-001) (17, 6.21337506582110950000e-001) (18, -3.97403310421323930000e-001) (19, -2.23408104237854010000e-001) (20, 6.66673832736684900000e-001) (21, -2.42536108988826130000e-001) (22, -1.69007179602907260000e-001) (23, -2.20574549086072160000e-001) (24, 5.32903078790220470000e-001) (25, 3.91840674656942220000e-001) (0, -3.03031985552656650000e+000) (1, -5.13734373564232460000e-001) (2, 2.08902212696480990000e-001) (3, 2.07840526254722880000e-001) (4, 3.17888553156849250000e+000) (5, 4.14505869049698270000e-001) (6, 3.03517215052074630000e+000) (7, 1.20872869221342420000e-001) (8, -2.23442554455851040000e-001) (9, -3.42355437134006620000e-001) (10, 3.15605838279084150000e+000) (11, -3.26482523737652690000e-001) (12, 3.32378067653622710000e-001) (13, -3.61964805188311480000e-001) (14, -1.27826890294612250000e+000) (15, -4.64096810509637750000e-001) (16, 1.09590927631975580000e+000) (17, -1.79383601581872030000e-001) (18, -1.31833238010561480000e+000) (19, 1.32291059571842620000e-001) (20, 9.18998429780881980000e-001) (21, -7.50616447188669600000e-001) (22, -1.21593614072960280000e+000) (23, -2.25320387344653210000e-001) (24, -1.40321935236738620000e+000) (25, 3.59592538153300890000e-001) (0, 3.18359744570120550000e+000) (1, -7.08185628120728610000e-001) (2, -6.81795963626616990000e-001) (3, -5.72757956074013700000e-001) (4, 9.90288759543873740000e-001) (5, 1.12918249377161690000e-001) (6, -8.56936347095786920000e-001) (7, -3.38368935910631150000e-002) (8, 3.03883425995031600000e+000) (9, -1.17528795224541270000e+000) (10, 1.09728425778451650000e-001) (11, 1.02215554958381640000e-001) (12, 5.68089846892669170000e-001) (13, -6.70465900996160990000e-001) (14, -4.70885133991489680000e-001) (15, 3.53725131429211030000e-001) (16, -1.25110316246307920000e-001) (17, -6.03020510242116230000e-001) (18, 1.95443394226547660000e+000) (19, -1.72069189085029610000e-001) (20, -9.97198332580476630000e-001) (21, -1.31378160117198870000e+000) (22, 1.41718415140487000000e-001) (23, -2.85308709287357410000e-003) (24, -3.08586184854170660000e+000) (25, 7.28818014099616440000e-004) (26, -4.17618642817244310000e-001) (27, 1.25960103794218130000e-001) (28, 3.66527044812567790000e-002) (29, -4.58798958868193610000e-001) (30, -1.04869852934447130000e-001) (31, 3.43065352142711550000e-001) (26, 2.59827838757757280000e-001) (27, 5.69004334484347620000e-002) (28, 6.65563588458788050000e-001) (29, 4.32509369231609490000e-001) (30, -4.71569335684953020000e-001) (31, 5.54522770022371160000e-001) (26, 3.22346261053185480000e-001) (27, 7.11476291241780910000e-001) (28, -1.69821891859920890000e-001) (29, 1.91037655809791600000e-001) (30, 3.63508371041548710000e-001) (31, 6.57570040438515190000e-001) 

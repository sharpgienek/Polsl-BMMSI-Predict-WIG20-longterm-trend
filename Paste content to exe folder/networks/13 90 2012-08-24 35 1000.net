FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=26 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (26, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.92377011170696260000e+001) (1, -4.87994097238029060000e-001) (2, -8.83059625019176590000e+000) (3, 2.05050684378733860000e+000) (4, 2.41144687306034240000e+000) (5, 1.97042883149430750000e-001) (6, -5.60234533415307910000e+000) (7, 2.14789435979474750000e-001) (8, 8.71028782346437890000e-003) (9, 1.62310284455248640000e+000) (10, 1.07465996171232000000e+001) (11, -1.68253597995543620000e+000) (12, 8.66005094830133610000e+000) (13, -4.94434337578552320000e-001) (14, -3.78754635814182380000e+001) (15, -2.74641965146686800000e+000) (16, -2.30564476223017500000e+001) (17, 7.84124229584767660000e-002) (18, 1.60805154939688750000e+001) (19, 6.95656571967854350000e-001) (20, -6.09626712121104750000e+000) (21, -5.29305986711924510000e-002) (22, -1.85081066521419400000e+001) (23, -2.42294710085348220000e+000) (24, 8.01390134729862600000e+000) (25, 1.34472056452728060000e+000) (0, -4.00181668522731540000e+001) (1, -9.72945290615938040000e-001) (2, -1.51429419511970970000e+001) (3, 5.42253516777681100000e+000) (4, -1.98183149148060980000e+001) (5, -8.35492361414225000000e-001) (6, 7.00611184271945130000e+000) (7, 2.63498123645617310000e+000) (8, -3.84242812757609610000e+001) (9, 1.09979604639480510000e+000) (10, -2.78625407428701880000e+001) (11, -4.80863561195058580000e-001) (12, 9.11710878647713660000e+001) (13, 1.55277574272707540000e+000) (14, 7.64806568447911560000e+001) (15, -1.58178090918420920000e+000) (16, 8.89492678615297340000e+001) (17, 1.63791542933073740000e+000) (18, 8.83163008684851580000e+001) (19, -2.32926848797948620000e-001) (20, 1.04600035726166270000e+002) (21, 4.21442931558452750000e-001) (22, 9.28948019844939240000e+001) (23, -2.27499265747312540000e+000) (24, 1.74936644193191370000e+002) (25, 9.99398352229973420000e-001) (0, -1.30441546606079900000e+001) (1, -8.37143211866395290000e-001) (2, 1.31874978259551820000e+001) (3, 2.08810505887859360000e-004) (4, 2.61518619621080890000e+001) (5, -1.69438781350619090000e+000) (6, 7.23311245141122110000e-001) (7, 5.89441895589168440000e-002) (8, -3.51895896158998200000e+001) (9, -4.82789967510584280000e-001) (10, -6.04578950068321590000e+000) (11, 1.90624168009940510000e+000) (12, 1.31816712354347880000e+001) (13, 8.92309467587779400000e-001) (14, 5.18722622040291800000e+000) (15, 1.88790407771988340000e+000) (16, 1.15348192598975600000e+000) (17, 3.63644664159367400000e+000) (18, -3.37091558669303910000e+000) (19, 4.69354978483076950000e-001) (20, 8.91861360405200900000e+000) (21, -5.93160630084757280000e-001) (22, -2.06692463063183670000e+001) (23, -3.92429599035397430000e-001) (24, -1.53078815903874400000e+001) (25, 1.39920499029463690000e+000) (0, 1.74019303790740180000e-002) (1, -2.52987498348134050000e-001) (2, 2.47236244151112760000e+000) (3, 1.50181823967477720000e+000) (4, 1.54963437913097170000e+000) (5, -6.33423648401179820000e-001) (6, -1.29908148272399600000e+001) (7, 1.79435182492470010000e-001) (8, -4.49684145243019010000e+000) (9, 8.74105537719707780000e-001) (10, 8.57289434748877530000e+000) (11, 1.49194560524453570000e-001) (12, 3.52181807364613210000e+001) (13, 5.49387742410940020000e-001) (14, 1.58514352188011860000e+001) (15, 1.30137910285060780000e-001) (16, -7.39392365950351320000e+000) (17, 1.46161322382837260000e+000) (18, 1.42440048658782260000e+001) (19, 2.02919855025701960000e+000) (20, 1.13454067931620270000e+001) (21, 1.49384896411221880000e-001) (22, -1.20309269538317200000e+001) (23, -1.25556583536003350000e-001) (24, 1.65848543936140020000e+001) (25, 7.13911669479131710000e-002) (0, 2.21917116065386680000e+001) (1, 3.42604441002058060000e-001) (2, -3.61838941386878190000e+001) (3, 8.35066522828626590000e-001) (4, -2.34965024736092230000e+001) (5, 3.00122031212788090000e+000) (6, -9.01232088215011730000e+000) (7, 1.23525969184863760000e+000) (8, 1.86986662345905050000e+001) (9, -1.98397135242046550000e-001) (10, 3.38559322001745710000e+001) (11, -6.03855740847228150000e-001) (12, 4.30720052445488410000e+001) (13, 5.90246679505102900000e-001) (14, 4.03009377308222130000e+001) (15, 2.14507504756184360000e+000) (16, 1.91781643629804820000e+001) (17, 1.39621409148647870000e+000) (18, 3.01775708719067590000e+001) (19, 9.44617412628661770000e+000) (20, 4.06421894560597890000e+001) (21, 1.19115838562783830000e+000) (22, 9.26709779984703990000e+000) (23, 8.62521635038754480000e+000) (24, -2.91196396035373190000e+001) (25, 3.62878019311433490000e-001) (26, -1.78931978850694760000e+000) (27, 9.78751993000215200000e-001) (28, -1.97223897336881390000e+000) (29, 2.60943093395407160000e+000) (30, -3.73135141218846940000e-001) (31, 4.27602464722802500000e-001) (26, 2.96838193855117630000e+000) (27, 1.27925369771553620000e+000) (28, 3.44132968226662680000e+000) (29, -5.07354566097672420000e+000) (30, 2.42007970970496400000e+000) (31, 2.43149409015869320000e-001) (26, -5.51767223360570340000e-002) (27, -1.86805652043034050000e+000) (28, -7.90734412207265980000e-002) (29, 5.66194582473113490000e-001) (30, -5.96618772526881220000e-001) (31, 1.95028843112713600000e+000) 

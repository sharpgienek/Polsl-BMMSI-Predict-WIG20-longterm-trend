FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 6.46086674226787340000e-001) (1, -3.40119729026419350000e-002) (2, -3.14324099978734760000e+000) (3, -4.52577807355843620000e-002) (4, 1.38722701723193370000e-001) (5, -2.76438609809255690000e-002) (6, 5.12444094110357850000e-001) (7, 1.11569083954184800000e-001) (8, 6.68734733145165850000e-001) (9, 2.98742121904763290000e-001) (10, 3.09939944639968260000e+000) (11, 1.05778346939838660000e-001) (12, 3.18940188914707350000e+000) (13, 1.84788960425695190000e-002) (14, 6.65902854834999890000e-002) (15, -3.62930653657641320000e-001) (16, -1.05164169276674580000e+000) (17, 7.87443764338085490000e-002) (18, -1.55242451569692520000e+000) (19, -3.83839671819204980000e-002) (20, -1.10670150804032600000e+000) (21, 3.64331430620306540000e-001) (22, -1.45445698494022050000e+000) (23, -3.14468738873002530000e-001) (24, -8.22768866117901790000e-001) (25, -1.26725881772551920000e-001) (26, -3.09603030572447850000e+000) (27, -5.33009595917010030000e-002) (0, 6.55602055227952560000e-001) (1, 2.03154853058671430000e-001) (2, -1.57203178292542840000e+000) (3, -6.23463698827381170000e-002) (4, 3.87281564755171890000e-001) (5, -1.16468325195138180000e-001) (6, 2.26857432911536480000e-001) (7, 5.86882237911985900000e-002) (8, 5.14551249916978870000e-001) (9, 1.34154067770688640000e-001) (10, 1.42235948603348610000e+000) (11, 1.52506863261147820000e-001) (12, 3.12957522809933670000e+000) (13, 3.40321222417433460000e-003) (14, -5.34828123878553830000e-001) (15, -6.65169437006837560000e-002) (16, -1.01531967074113050000e+000) (17, 7.10539466317122170000e-002) (18, -4.12143211701463400000e-001) (19, -2.32228341435020100000e-002) (20, -1.07072738641051980000e+000) (21, 3.28351948963215150000e-002) (22, -3.12841556011330630000e+000) (23, -1.28117483355788400000e-001) (24, -7.91732488702298840000e-001) (25, 3.71144407652983230000e-002) (26, -3.03798587126579900000e+000) (27, 1.50498806590600440000e-001) (0, -3.66771964215980180000e-001) (1, -8.77376710652343490000e-002) (2, -3.12776248393169980000e+000) (3, 1.33939811489877880000e-001) (4, 2.76123007264122370000e-001) (5, 3.21152171145865970000e-001) (6, 2.09451240724569780000e-001) (7, -2.91407640334897800000e-001) (8, 5.34245852247729360000e-001) (9, 8.18392215501587280000e-002) (10, -3.11698977869304890000e+000) (11, 5.26114127986050390000e-001) (12, -3.87758966501831890000e-004) (13, -7.36580570883446360000e-002) (14, 1.74630683565078050000e-001) (15, 2.16205664087501250000e-001) (16, 5.98454837579517780000e-001) (17, -2.15895501173913040000e-002) (18, 6.28252672441283800000e-001) (19, 1.61850317730820540000e-001) (20, 5.34807375693596710000e-001) (21, -1.45798057156232540000e-001) (22, 1.90302402939003420000e+000) (23, 1.12012729559135480000e-001) (24, 1.19394057628884330000e-002) (25, 2.82302938624366330000e-002) (26, 4.41999514889875600000e-001) (27, 7.78640836645377170000e-002) (0, -1.11696826677646520000e-001) (1, -1.09724965976616960000e-001) (2, -3.14584720099805800000e+000) (3, 8.82691667215941500000e-001) (4, 6.57570655419561720000e-001) (5, 1.62136978038767770000e+000) (6, -8.99819072677388030000e-003) (7, 5.80557382704542660000e-003) (8, 5.49276709144908780000e-001) (9, 4.67276220489264930000e-001) (10, -3.21142947736593510000e+000) (11, 2.46790972823876630000e+000) (12, 7.51082619703623560000e-001) (13, 3.35844823206074390000e-001) (14, -1.48011864673239010000e-001) (15, 8.34042076957927310000e-001) (16, 6.14009863754830350000e-001) (17, 1.31699597600753840000e-001) (18, 5.16696067245081330000e-001) (19, 6.41244408944746210000e-001) (20, 6.17746115836158570000e-002) (21, 4.02769915914160560000e-001) (22, 3.31185834999422890000e-002) (23, 7.61983970415427870000e-001) (24, -8.73213372521592920000e-002) (25, -1.30713594094586690000e-001) (26, 3.04775149641131820000e+000) (27, 6.12681984967384020000e-001) (0, 1.12140976498099270000e+000) (1, 3.05837004207865910000e-002) (2, 6.82592272860381930000e-001) (3, -3.97329803187563500000e-001) (4, 7.45713123022741400000e-001) (5, -1.92583238125604520000e-001) (6, -4.43642264706950730000e-001) (7, 1.55412431961364010000e-001) (8, -3.18275994960425970000e-001) (9, 4.22512116094354020000e-001) (10, 3.11596438805276940000e+000) (11, 1.23377747126289960000e-001) (12, 1.05861679529530450000e+000) (13, 6.76829239350384420000e-002) (14, -8.56695163647899880000e-001) (15, -6.80517470763107200000e-001) (16, 2.11504595945207600000e-001) (17, 2.99726468363977980000e-001) (18, -3.09426028616685310000e+000) (19, -6.32436213801532140000e-004) (20, -1.36429661866114270000e-002) (21, 1.64069886404525130000e-001) (22, -1.53343647830460640000e+000) (23, 2.37916164708557750000e-001) (24, 5.70374458985504650000e-001) (25, 1.90373369982322570000e-001) (26, -3.19398562944975150000e+000) (27, 5.12341913637672230000e-002) (28, -4.61590870124131470000e-001) (29, -9.36092317124235240000e-002) (30, 1.81329346314689500000e-001) (31, 4.00586313973046390000e-001) (32, -1.80463535542667090000e-001) (33, 4.21161265451512060000e-001) (28, 2.87158196588295670000e-001) (29, -2.11893297873339130000e-002) (30, 1.29222478720761310000e-001) (31, 6.62858062932474960000e-001) (32, 4.38114638829750350000e-002) (33, 4.05717871122263930000e-001) (28, 3.02177570867084910000e-001) (29, 4.72085790873433110000e-001) (30, -6.38905454522919690000e-001) (31, 6.29771183128523680000e-002) (32, 1.73196915926172650000e-001) (33, 5.98276763142013830000e-001) 

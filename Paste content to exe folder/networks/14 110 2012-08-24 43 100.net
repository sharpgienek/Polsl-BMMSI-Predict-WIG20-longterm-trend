FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.67195394683549100000e+001) (1, -1.99761940095991490000e-001) (2, -7.56027471859788940000e+000) (3, -1.99680978450122000000e-002) (4, -4.18493380230844640000e+000) (5, 5.52979065285037150000e-001) (6, 4.28713383934747140000e+000) (7, -4.11927813886879100000e-001) (8, 1.19214654768350710000e+001) (9, -6.70731624523324690000e-001) (10, -1.12695408845726540000e+001) (11, 1.14741103322718150000e-001) (12, 8.19262783677639920000e+000) (13, 7.28020831352991370000e-002) (14, 6.39960244610698230000e+000) (15, 1.16109621628917670000e+000) (16, 1.33337792886312020000e+001) (17, -2.95023609493086870000e-001) (18, 3.05776322570874190000e+000) (19, 3.28279281003440560000e-001) (20, 2.77675208275388210000e+001) (21, -8.16069320516929210000e-002) (22, 3.83348681915685600000e+001) (23, 5.89539218865372860000e-001) (24, 2.72506499373908650000e+001) (25, -4.09829889553982200000e-001) (26, 4.83030927400649190000e+001) (27, -1.93536612603532780000e-001) (0, 1.65918109132243060000e-001) (1, -2.82108051996689090000e-001) (2, -2.26758429375566180000e+000) (3, 1.16272173741635320000e+000) (4, 7.67414715824187520000e+000) (5, 7.60786689110556690000e-001) (6, -3.64409281952949150000e+000) (7, -7.40281746897532570000e-001) (8, 3.59234964020456940000e+000) (9, 2.36266735387572310000e-001) (10, -1.60709566146685460000e+001) (11, 2.54757338927789380000e+000) (12, 1.27916007210074200000e+001) (13, 1.03711354646684930000e+000) (14, -1.16462873556113080000e-001) (15, 1.39044242477472310000e+000) (16, 3.51676167385061780000e+000) (17, 2.17156686183324170000e-002) (18, -1.05787587805978640000e+001) (19, 1.13709197479690990000e+000) (20, 1.52145657366293770000e+000) (21, 5.95329536507884340000e-001) (22, -2.81385896468542370000e+000) (23, 2.80464950670853250000e-001) (24, -1.39993998484760440000e+001) (25, 8.75199705246697430000e-001) (26, 1.28689400317397620000e+000) (27, 3.34334954705779560000e-001) (0, -6.27317434569901520000e+000) (1, 9.86329435422784400000e-001) (2, -9.39719249563740710000e+000) (3, -3.89580541346812390000e+000) (4, -3.54786090868496990000e+000) (5, -1.65899139135772210000e+000) (6, -2.12682810302838150000e+000) (7, 6.92542065227475940000e-002) (8, -5.87631375331054700000e+000) (9, -4.95419777008283210000e-001) (10, 3.09692418314460550000e+001) (11, -2.77258562598041220000e+000) (12, -2.36208717298989350000e-001) (13, 2.87389905087218220000e+000) (14, -9.10672844062850830000e+000) (15, -2.37916662077006120000e-001) (16, -1.56042938956022970000e+001) (17, 3.21589010951648160000e-001) (18, 2.03512265318017000000e+001) (19, -8.28080028569174840000e-001) (20, 2.02795196454237930000e+001) (21, 3.46331360123510850000e-001) (22, 9.92389034963568760000e+000) (23, 2.00774522601004300000e+000) (24, -1.94580384162580170000e+001) (25, -1.59777212056322670000e-001) (26, -2.07307788746643670000e+001) (27, 1.25317929109489190000e-001) (0, -2.10850762853588810000e+000) (1, 2.37126421032628960000e-001) (2, 1.48300696525582920000e+001) (3, -5.92149470709310770000e-002) (4, 2.24085932205440980000e+001) (5, -1.11503181453324670000e+000) (6, -2.19236157752589840000e+001) (7, 1.07014815310181670000e+000) (8, -3.34091371567560990000e+000) (9, 4.99361144652597340000e-001) (10, 2.07194233387447650000e+000) (11, 6.83547112940959600000e-001) (12, -3.67329000377897400000e+001) (13, 4.91675673308690620000e+000) (14, 4.22962301737351890000e-001) (15, 1.20710540689146540000e-001) (16, -3.16383047821133800000e-002) (17, 1.89299259064730090000e+000) (18, -1.26515419352722930000e+001) (19, -1.59274342841855890000e+000) (20, 1.22871382994534470000e+001) (21, 5.96602868716860860000e-001) (22, 9.04983802051664380000e+000) (23, 2.10695312613434990000e+000) (24, -4.99695255424150630000e+000) (25, 1.33111680302148420000e+000) (26, -1.26945724365544400000e+001) (27, -1.08155158133225990000e-001) (0, 3.92352656439680430000e+000) (1, 2.66207019176435130000e-001) (2, 2.85713691657473400000e-001) (3, -6.06168048221606300000e-001) (4, -2.70756515873488370000e-001) (5, -1.24790248065946540000e+000) (6, -8.93752118715172020000e+000) (7, 1.27490481992015050000e+000) (8, 8.00735607268605930000e-001) (9, 6.37295379255567780000e-001) (10, 1.70639096030521280000e+001) (11, -4.78449979373125940000e-001) (12, -1.28570191244174960000e+001) (13, 6.23091492106593870000e-001) (14, 1.16777923723913340000e+001) (15, -7.62413688648708840000e-001) (16, -7.11559697783058990000e+000) (17, 9.71454087349563070000e-001) (18, 1.08944518103670870000e+000) (19, -8.18697449168712680000e-001) (20, 3.61482365542764980000e+000) (21, 2.97626427710029730000e-001) (22, -2.77111075127519290000e+000) (23, -1.82600648743416220000e-001) (24, 2.75704104621363260000e+000) (25, -8.02493467286271360000e-001) (26, -2.75859224970354010000e+001) (27, -4.95971404115676360000e-001) (28, 4.03529708337580170000e-001) (29, -6.46830950800705520000e-001) (30, -5.89885954332767800000e-001) (31, 1.09881137055120210000e+000) (32, -1.03565445504631650000e+000) (33, 3.07510731964659170000e-001) (28, 7.29035621098751090000e-001) (29, 1.89148202329056760000e+000) (30, -1.10525370110139990000e-001) (31, -1.35135783847379410000e+000) (32, 2.61949665596255520000e+000) (33, 1.00441093605865310000e+000) (28, -9.88789354030616740000e-001) (29, -8.44937702578039460000e-001) (30, 6.72320494998237540000e-001) (31, 1.53133276604629360000e-001) (32, -9.83314665730414480000e-001) (33, 1.18993025277766960000e+000) 

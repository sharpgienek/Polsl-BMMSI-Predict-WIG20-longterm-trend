FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.91613614804785370000e-001) (1, 2.04995017320605320000e-001) (2, 2.83494573330078380000e-001) (3, 3.96658729055209750000e-002) (4, 6.05686317520310210000e-001) (5, 1.16431394992416660000e-001) (6, 6.59182641633921710000e-001) (7, -2.05989229334430530000e-001) (8, -2.26955761867163180000e-001) (9, -5.23979283244295490000e-002) (10, 8.10996048433861860000e-002) (11, 9.54405027243641900000e-002) (12, 1.64849276209191240000e-001) (13, 1.31860254998145100000e-001) (14, 2.20421466700275030000e+000) (15, 8.45073056110656750000e-002) (16, 6.30415929383442260000e-001) (17, 4.46800831828780760000e-002) (18, 6.48550317256737730000e-001) (19, -1.26955421560352440000e-002) (20, 5.47390886985688050000e-001) (21, -1.32643954536947470000e-002) (22, 9.87926698961801300000e-001) (23, 3.43798956352689810000e-001) (24, 3.24054164985342560000e-001) (25, 2.06471674338878780000e-001) (26, 1.28149252592515240000e+000) (27, -6.11836679984692600000e-001) (0, -5.60699353743303040000e-001) (1, 9.78351315047032020000e-002) (2, 3.06301028570119180000e+000) (3, -3.48036015380386370000e-001) (4, 5.30418462075452850000e-001) (5, -1.87372634570786730000e-001) (6, -5.44959624070556060000e-002) (7, -4.67431145548265480000e-002) (8, -2.20788096622340110000e+000) (9, -1.22413822064128860000e-001) (10, 3.19714427324391200000e-001) (11, -2.93220340735444230000e-001) (12, -2.24204844720128630000e+000) (13, 2.70807126902927080000e-001) (14, 2.21242225384627620000e-001) (15, -1.13051766935760230000e-002) (16, 5.65203472542523900000e-001) (17, 2.11941763523023820000e-001) (18, 1.35850301553010460000e+000) (19, -2.79759155044862870000e-001) (20, 2.93794521292246420000e-001) (21, 1.57280371963440800000e-002) (22, -3.50772185306300940000e-001) (23, 4.12153555735419120000e-001) (24, 5.78857037199102860000e-001) (25, 2.46560904663889220000e-001) (26, 1.63544320455215720000e+000) (27, -7.50136593857641390000e-002) (0, 6.12724857323407530000e-001) (1, 8.86150960358976090000e-002) (2, -3.19855716272099770000e+000) (3, -2.51945433927281140000e-001) (4, 2.61537868837862510000e-001) (5, -4.80677719627413510000e-001) (6, 3.39128210605928070000e-001) (7, 1.72511646289344960000e-001) (8, 3.21246097152193060000e+000) (9, 1.12387207863214360000e-001) (10, 7.59828957724579150000e-001) (11, -1.79574169364247440000e-001) (12, 1.35550157488097560000e+000) (13, -2.90186437568290710000e-001) (14, -1.46343726831001550000e-001) (15, -4.04250174276212850000e-001) (16, 2.13217719213770750000e-002) (17, -1.62411100557004890000e-002) (18, -4.27701878499762820000e-001) (19, -1.27657664684381250000e-001) (20, 1.33412709603932030000e-001) (21, -6.84710609835251090000e-002) (22, 3.99243767421128550000e-002) (23, -1.55267101850555200000e-001) (24, 4.10971628410533580000e-002) (25, -8.81574137243826690000e-002) (26, -9.70049894675933280000e-001) (27, 1.29351170788884060000e-002) (0, 2.92040860904901830000e-001) (1, -2.22602999113244990000e-001) (2, -3.85755231935359240000e-002) (3, -2.02912498463695660000e-001) (4, 4.69091971032679630000e-001) (5, 1.38801239330336720000e-002) (6, 1.29604941090769190000e+000) (7, 2.48499121235319230000e-002) (8, 4.61021869907182250000e-001) (9, 4.50358694760204580000e-002) (10, 1.27006662329706980000e-001) (11, -1.90798195949183900000e-002) (12, 2.32367151900349710000e-001) (13, -4.25634189591299760000e-002) (14, 7.34072868884404930000e-001) (15, 3.98362277054432200000e-003) (16, 4.52230940548583320000e-001) (17, 6.47667534040677890000e-002) (18, 5.30294700260216740000e-001) (19, -1.54537659665649810000e-001) (20, 7.15041831044060490000e-001) (21, 8.69492290864795900000e-002) (22, 9.71483827623033420000e-001) (23, -5.27829626814137250000e-001) (24, 2.34020419818046610000e-001) (25, -3.75741184798195490000e-002) (26, 1.04896185612129590000e+000) (27, -4.70424324361859270000e-001) (0, 5.49569015294622650000e-001) (1, 4.69137173030578840000e-001) (2, 1.14700180637796880000e+000) (3, -4.40718015054328950000e-001) (4, 1.99407942402741960000e-001) (5, -2.02227150792353320000e-001) (6, 2.75080114318099810000e-001) (7, 3.60565967682268400000e-001) (8, -4.72447634014772740000e-001) (9, -8.88081266590354660000e-002) (10, 3.19184939894916920000e+000) (11, -1.58859394982964170000e+000) (12, -6.94161686467130610000e-001) (13, 3.00183886704380290000e-001) (14, -1.49590558169956970000e+000) (15, -1.38300889969778520000e-001) (16, -7.06527409307644240000e-001) (17, 1.20644956972619290000e-001) (18, 1.14981552712302150000e+000) (19, -8.01557370463618750000e-001) (20, -6.81112369866430640000e-001) (21, -2.92839945111339150000e-001) (22, 8.18365729524059420000e-002) (23, 8.65004962175735640000e-001) (24, -9.04654633295052250000e-002) (25, -1.96809168129525920000e-001) (26, 2.83491333626246680000e-001) (27, 7.62196376714139450000e-003) (28, -6.88552058319273910000e-002) (29, 6.48535785150241790000e-001) (30, -6.84344375117007520000e-001) (31, -3.05351401339641170000e-001) (32, -2.66344192572657290000e-001) (33, 3.73171656365742400000e-001) (28, -1.69803267036183450000e-001) (29, -2.57966948919994970000e-002) (30, 7.60685336839711960000e-001) (31, -1.79524385190073630000e-001) (32, -5.52505961352794280000e-001) (33, 8.61033795356961560000e-001) (28, -3.97802363400558250000e-001) (29, 1.13211158692286610000e-001) (30, 3.52507735231869900000e-001) (31, -3.64538202748633630000e-001) (32, 2.80804275017749630000e-001) (33, 5.46197485973148210000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.66523874042039390000e-002) (1, -5.25868149988303340000e-001) (2, -8.71866346706184240000e-001) (3, -1.34778549676816510000e-002) (4, -3.73037640414840220000e-001) (5, 9.15555232949784860000e-002) (6, 1.88764535181917780000e+000) (7, -3.25052115791684300000e-001) (8, 1.25293982101238080000e+000) (9, -5.69646346302734170000e-002) (10, -4.13602330190142920000e-001) (11, -1.54962372214060150000e-001) (12, 7.10407517286011370000e-002) (13, -3.49423454045470540000e-001) (14, 3.12410647801784600000e+000) (15, -9.81416835493695710000e-002) (16, 2.08338112006458080000e-001) (17, 8.33162723534185000000e-002) (18, 4.05947569249622220000e-001) (19, 1.27336356114988560000e-001) (20, 5.01604250198831590000e-001) (21, -1.78598256187476790000e-001) (22, 8.91249911217407930000e-001) (23, -1.57550880604070100000e-001) (24, 2.55184050485317420000e-002) (25, -9.03224590499183410000e-002) (26, 7.65934360355428500000e-001) (27, 1.36098980989977690000e-001) (0, 7.72400837924658520000e-001) (1, 1.35282561577061140000e-002) (2, -5.91721496834347050000e-001) (3, -4.82395445216178550000e-002) (4, 6.51833279731575230000e-001) (5, -1.33497773176098680000e-001) (6, 8.64378521969301870000e-001) (7, 5.46232274731938830000e-002) (8, 1.89416390660381180000e+000) (9, 5.53917436069678580000e-002) (10, 4.70386210196368500000e-001) (11, -2.49586642093457660000e-001) (12, 9.98421162780051660000e-001) (13, 2.00791109025372020000e-002) (14, -7.87331853871099270000e-001) (15, -1.74757539415917100000e-001) (16, 1.88876876985320710000e-001) (17, 2.56964016627961420000e-001) (18, -2.24209742567253840000e-001) (19, 1.39663511943517840000e-001) (20, 8.37915975619660140000e-001) (21, 9.83305035151080390000e-002) (22, 2.29044142382445530000e-001) (23, -3.92202679762921560000e-001) (24, 1.10374294273948610000e-001) (25, 3.61069431726205040000e-002) (26, -9.67744379339449120000e-002) (27, -9.28013127637649370000e-002) (0, 1.32979229214056360000e-001) (1, 7.63447815973244960000e-001) (2, 9.70125263920909920000e-001) (3, -2.31698842916237190000e-001) (4, 9.66327931255772650000e-002) (5, -6.31418763050882400000e-001) (6, -3.35574607044877400000e-001) (7, 1.02315083569748780000e-001) (8, -5.32502031752839060000e-001) (9, -8.63385660410297270000e-002) (10, 1.36718370396130280000e+000) (11, -1.17847031747463270000e+000) (12, 5.11884013549108950000e-001) (13, 4.22384099359809080000e-001) (14, -1.23692613127675300000e+000) (15, -1.02622774441644250000e-001) (16, -8.10116946074784240000e-002) (17, 6.11093980982568770000e-002) (18, 4.44240415236186790000e-001) (19, -3.20089957514617380000e-001) (20, -9.56786955025175080000e-001) (21, -9.85700400062538010000e-002) (22, -5.83771340510375330000e-002) (23, -1.33539649777524890000e-001) (24, 4.88647929218489320000e-001) (25, -5.50214553729543240000e-002) (26, -2.56694291942528630000e-001) (27, -2.50165721133467360000e-002) (0, 1.56032208073197480000e-001) (1, -8.80560590132360020000e-003) (2, -3.08307864537523370000e+000) (3, -3.38323385372862540000e-002) (4, -3.22604290053949750000e-001) (5, -1.12277425947508540000e-001) (6, 3.99623715352596160000e-001) (7, 3.64092385224300680000e-002) (8, 1.36668664270130250000e+000) (9, -3.52625959906793630000e-001) (10, 1.33785631094616560000e+000) (11, -1.88112186679139650000e-002) (12, 9.94633958408436710000e-001) (13, -5.43561721599158320000e-002) (14, 4.52201182111402200000e-001) (15, -2.68930288783528980000e-001) (16, -3.18155887145207840000e+000) (17, -2.51676159818673690000e-002) (18, -1.32286973607303750000e+000) (19, -1.18564047134936470000e-001) (20, 3.05326516504981770000e-002) (21, -3.89631055242912750000e-002) (22, 5.59541930626188180000e-001) (23, -1.64862892431777570000e-001) (24, 7.33967730153861630000e-002) (25, -2.77084585780037470000e-001) (26, -1.81922411831671330000e+000) (27, -2.69906822827619520000e-001) (0, -5.74479147505911450000e-001) (1, -6.80304666408739630000e-002) (2, -8.41068006403503210000e-001) (3, 9.17486960550797370000e-002) (4, 1.60782095474767910000e-001) (5, 4.38099474769462820000e-001) (6, 1.12233785469605270000e-001) (7, 2.90469896077299620000e-001) (8, 4.91772929265055450000e-001) (9, 3.15774652679953920000e-001) (10, -3.93626954214193190000e-001) (11, 6.53238064518250950000e-001) (12, 6.56332332269433880000e-001) (13, 1.91946945390443300000e-001) (14, 1.15332334986358780000e+000) (15, 6.39448383193381150000e-001) (16, -1.34421186430824370000e-001) (17, 2.46911605219976680000e-001) (18, -1.30028301274426740000e-001) (19, 5.41804310299160100000e-001) (20, 2.93867421843150960000e-001) (21, 5.04267688646070860000e-001) (22, 1.19078135815237590000e-001) (23, 3.19525521749521480000e-001) (24, 3.29769012534219950000e-002) (25, 2.24808274005115220000e-001) (26, 3.48765385461605510000e-001) (27, 5.17829729037372010000e-001) (28, 4.58488320487864310000e-001) (29, -2.52180636272736180000e-001) (30, 5.85896438884927480000e-002) (31, -2.33500545981288820000e-002) (32, 4.97334094792752310000e-001) (33, 5.19630237703115670000e-001) (28, 5.57359171570529720000e-001) (29, 8.92253650383709050000e-002) (30, 3.50301016953891360000e-002) (31, 5.72575236250391750000e-001) (32, 6.22382953251586430000e-001) (33, 6.14893939468116430000e-001) (28, 1.69916624977482420000e-001) (29, -7.06824673642828530000e-002) (30, 6.83084453185805130000e-001) (31, 3.56785566553855350000e-001) (32, 3.63302067229418210000e-001) (33, 4.40334567550877800000e-001) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.97686587379997490000e+000) (1, 1.28367475583971390000e+000) (2, -8.65551121121284870000e+000) (3, 4.62860335097663440000e-001) (4, 9.59236079931416910000e-001) (5, 1.54450942224498620000e-001) (6, 2.06769990040633720000e+001) (7, 3.22474255886290860000e-001) (8, 1.37134286125482770000e+000) (9, 2.06059045610371750000e-001) (10, 2.66992550569182250000e-001) (11, 5.25433191093124250000e-001) (12, 1.06484109072170290000e+001) (13, -8.19882823191449560000e-001) (14, 1.22348898599918490000e+001) (15, 7.14082439516516570000e-002) (16, -1.67232318383091150000e+001) (17, -7.70897202604372890000e-001) (18, -8.90753957079154830000e-001) (19, 1.38198190310374920000e+000) (20, -2.36023028245496960000e+001) (21, 2.03392506741177950000e-001) (22, -9.60673220375871040000e+000) (23, 1.76894309295441340000e+000) (24, -4.87554260101239210000e+000) (25, -5.39663233272983710000e-001) (26, -1.96532880670833840000e+001) (27, -1.75746356774730940000e-001) (0, 2.74366835153033610000e+001) (1, 2.09753398803518020000e+000) (2, 2.18472823978788600000e+001) (3, -9.67216925038814070000e-002) (4, 4.26190031977959550000e+000) (5, -8.72048895008008310000e-001) (6, 1.12406776454891850000e+001) (7, 1.00605858221749170000e+000) (8, -1.46978397057067300000e+001) (9, 1.19308449801067180000e+000) (10, 1.42449227518028910000e+000) (11, 1.57067929813117830000e+000) (12, -1.83131159619044470000e+001) (13, 4.31615540025319770000e-001) (14, -4.20718575139408290000e+000) (15, 2.41752828245854700000e-001) (16, 2.84645364472254240000e+001) (17, 2.22117404627774300000e-001) (18, -2.04760899484954880000e+000) (19, -1.98334229765223320000e+000) (20, -3.49855267949912800000e+001) (21, -6.91545348538368940000e-002) (22, 1.10097645877612800000e+001) (23, 2.09880593694753030000e+000) (24, 3.85954782230892520000e+001) (25, 4.04618528488642050000e-001) (26, 9.72825312681570150000e+000) (27, 3.47155435713057680000e-001) (0, -5.15074904921903640000e+001) (1, 9.38550620953482960000e-001) (2, -2.32032019640974880000e+001) (3, -2.95576975972059790000e-001) (4, -2.19820139649112040000e+001) (5, -7.39368732580246050000e-001) (6, 2.22532732946855740000e+001) (7, 2.36213630876592030000e-001) (8, 2.28011835948951040000e+001) (9, 2.59027795974174580000e-001) (10, -2.25065976515317740000e+001) (11, 9.13827458069821910000e-001) (12, 7.44658920611299960000e-002) (13, 4.82208106119360320000e-001) (14, 5.27246954256711500000e+001) (15, 5.49823293395522720000e-001) (16, -6.52735200252463430000e+000) (17, -9.23274745328443780000e-001) (18, 7.52133707081663960000e+000) (19, 1.38714732435380990000e+000) (20, 9.86589870986949790000e+000) (21, 5.05806314182906000000e-001) (22, -1.95480262358025470000e+000) (23, 2.37659952825455620000e+000) (24, 1.61810906738597500000e+001) (25, -6.51228862349228050000e-001) (26, -2.00282861731023370000e+001) (27, 6.40514942221619090000e-001) (0, 2.25846884930282490000e+001) (1, -8.47615092366180930000e-001) (2, 4.39764577336140670000e+000) (3, 2.18039178474039370000e+000) (4, 4.07458135623314490000e+001) (5, 1.25242112866725770000e+000) (6, 2.24592966699760370000e+001) (7, 2.22814432868615850000e-001) (8, 1.34816713848877840000e+001) (9, 5.98640387619478130000e-001) (10, -2.02195979050519730000e+001) (11, 2.98975119935580120000e+000) (12, 1.38394679728804230000e-001) (13, -6.13751032310888340000e-001) (14, 1.13112422202128900000e+001) (15, 1.08645865691071800000e+000) (16, -1.42111743490147230000e+001) (17, -1.78293952559920560000e-001) (18, -1.73785602506083700000e+001) (19, 1.39429761485613210000e+000) (20, -2.47821864525100500000e+001) (21, 4.60350392336134620000e-001) (22, 9.27013370420517550000e+000) (23, 5.55881283428166780000e-001) (24, -9.84912927276898030000e+000) (25, -2.27748987644239930000e-001) (26, -1.18263027806905950000e+001) (27, 2.11841271009123340000e-001) (0, -1.00732126628427810000e+001) (1, -1.81547478329080180000e+000) (2, -1.72369580787197420000e+000) (3, 1.25481335462924450000e-001) (4, 1.10961402843007790000e+001) (5, 2.19104027302995870000e+000) (6, 1.93546820219077560000e+001) (7, -2.09929387110776360000e+000) (8, 1.06235031538387070000e+001) (9, -1.27485072700334550000e-001) (10, -1.28622774907535950000e+001) (11, 8.42011181960651040000e-003) (12, 1.87214891369298190000e+001) (13, -1.25383749893205800000e+000) (14, 2.39386441883622410000e+000) (15, 1.18974536279130310000e+000) (16, -9.08238184515782620000e+000) (17, 1.02962804983204330000e-001) (18, -5.42473643953825760000e+000) (19, 5.93255308570218620000e+000) (20, 1.11415795414688960000e+000) (21, 1.58004052023860320000e+000) (22, 3.32264233617306740000e+001) (23, 3.59637435273932330000e-001) (24, -1.61257354758126290000e+001) (25, -1.26078886743353820000e-001) (26, 1.51459734096293150000e+001) (27, 1.30004053515265530000e-001) (28, -1.79025733348375770000e+000) (29, 1.32237523201431580000e+000) (30, 1.11597465232129830000e+000) (31, -3.59529531339123910000e-002) (32, 1.36688514795202210000e+000) (33, 3.94999582279413790000e-001) (28, 3.22859061037565180000e-001) (29, -1.28834209959547690000e+000) (30, 1.96011833422510410000e-001) (31, 1.42857895131194730000e+000) (32, -1.41056352033814520000e+000) (33, 8.50465403052536930000e-001) (28, 1.23548382594447580000e+000) (29, 8.68416384967728580000e-002) (30, -1.15931198270442090000e+000) (31, -1.17469101773624280000e+000) (32, 5.18921386375758920000e-002) (33, 1.10337164530239470000e+000) 

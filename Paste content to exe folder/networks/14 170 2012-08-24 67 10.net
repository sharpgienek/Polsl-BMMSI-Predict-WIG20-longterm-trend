FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.16308094786393850000e-001) (1, -1.99524815123577280000e-001) (2, 3.02710940625997700000e+000) (3, 1.23613296582252840000e-002) (4, 6.30510502119684290000e-001) (5, 1.88330907812760020000e-001) (6, -3.01628787289559860000e+000) (7, -1.47419695207934850000e-001) (8, -3.21310794418782120000e+000) (9, -1.64960605624155430000e-001) (10, -2.63323476346352610000e-001) (11, 6.29164941230127120000e-001) (12, -5.32441649233617590000e-001) (13, 1.86460860842604050000e-001) (14, 6.42433936444007040000e-001) (15, 4.50607535064039500000e-001) (16, 5.64952639814671140000e-001) (17, 1.74791527573166740000e-001) (18, 5.72880421261163340000e-001) (19, 7.68938297934203680000e-002) (20, 4.14952526762539190000e-001) (21, 2.02782250646511040000e-001) (22, -2.41757120880483070000e-001) (23, 5.32932970949174690000e-001) (24, 2.00062318581479160000e-001) (25, -2.19776874020515820000e-001) (26, 4.87254179816048180000e-001) (27, -2.04328602835711850000e-002) (0, -1.09022811912297830000e+000) (1, -9.10433773408419880000e-002) (2, -1.49737649478572930000e-002) (3, -1.68678925027889170000e-002) (4, 5.82552391707421010000e-001) (5, -7.85008401360207660000e-001) (6, -9.33331144128781260000e-001) (7, -1.23063637111963800000e-001) (8, 1.01303160525256390000e+000) (9, -4.07070844046974470000e-001) (10, -3.17683475028793350000e+000) (11, 1.94129676049495770000e-001) (12, 3.90951629640294840000e-001) (13, -2.27041494408407600000e-002) (14, 6.93727811605852400000e-001) (15, 2.10008322176426730000e-001) (16, 1.09567734272254970000e+000) (17, -1.54072407606945010000e+000) (18, -5.58173320980436930000e-001) (19, 1.15349313838744570000e-001) (20, 3.07700564723786400000e+000) (21, -2.30899364926569460000e-001) (22, -7.75826726746534520000e-001) (23, -3.24842781995990650000e-001) (24, 1.12876450141871180000e+000) (25, 2.92855159799124410000e-002) (26, 1.14440781219869030000e+000) (27, -1.50186473098853690000e-001) (0, -4.23031972912595760000e-001) (1, -2.36714252445323130000e-001) (2, 3.10312869450212770000e+000) (3, 5.53808907316998280000e-002) (4, 2.46705750635890290000e-001) (5, 2.30885615505136670000e-001) (6, -2.73738426497083080000e-001) (7, -4.09059225716588370000e-001) (8, -3.03125369343110670000e+000) (9, 4.74579096059500190000e-002) (10, -1.73294896790449070000e-002) (11, 1.22787037733599600000e-001) (12, -3.12680408768229330000e-001) (13, 1.95673890781711490000e-001) (14, 3.50233388797111740000e-001) (15, 3.86499096288310310000e-001) (16, 1.21667343827553200000e+000) (17, 3.47913200249993500000e-002) (18, 1.03784042779821250000e+000) (19, -3.08819082493039910000e-001) (20, 7.38698952099422770000e-002) (21, -1.15970572698098710000e-001) (22, -5.97795722575167400000e-002) (23, 1.16119824523749080000e-001) (24, 7.17262968206553440000e-001) (25, 1.43230047288865350000e-001) (26, 1.08582016484129130000e+000) (27, 6.99207200245962470000e-002) (0, -1.80225452618701990000e-001) (1, -4.28903555031339150000e-001) (2, -3.03791262907720760000e+000) (3, 1.18389755888088330000e+000) (4, 3.71551508392728990000e-001) (5, 2.21166039982950840000e-001) (6, 1.66259185856208330000e-001) (7, -1.62586931762069290000e-001) (8, 4.68006595355536290000e-001) (9, -3.75839589396874450000e-001) (10, -3.31969717603636250000e-001) (11, 1.11437851487621890000e+000) (12, 3.15954583736145270000e-001) (13, -3.96579335799670750000e-001) (14, 5.08122804983465630000e-001) (15, 5.06586462827912090000e-002) (16, 3.79527721547168520000e-001) (17, -1.19487112133435850000e-001) (18, 5.35114545923942590000e-002) (19, 1.08929306528366650000e+000) (20, 5.09618055516915520000e-001) (21, 1.89568139121480430000e-001) (22, 5.02961064505667470000e-001) (23, -2.98495838244362770000e-001) (24, -1.04197372387268180000e+000) (25, -1.65186378764722890000e-001) (26, 7.01772316234467790000e-001) (27, 3.24125149698278740000e-002) (0, -3.03738162320992000000e+000) (1, -2.27362950304022820000e-001) (2, 3.53386363735756940000e-001) (3, 2.67003465845575600000e-001) (4, 2.66709632118972310000e-001) (5, 6.90187891358189920000e-001) (6, 6.95106384232047070000e-003) (7, -1.78187517932036130000e-001) (8, 4.18115081533554140000e-001) (9, -1.19239891588253210000e-001) (10, -2.07131412011026230000e+000) (11, 2.40239549431137180000e-001) (12, -4.38701903554565120000e-001) (13, 1.76790969913293430000e-001) (14, 1.37410509078318950000e+000) (15, 4.07886512781444390000e-001) (16, 4.66508924015164360000e-001) (17, 3.06730638025388360000e-001) (18, 8.34130774133599150000e-001) (19, 3.43586145326594870000e-001) (20, 4.39342175563473270000e-001) (21, 1.01240781088328970000e+000) (22, 1.96974684186676410000e-001) (23, 4.73517787887727190000e-001) (24, 1.26838089115637210000e-001) (25, 4.50611122793090680000e-001) (26, 8.31738195972946960000e-001) (27, 1.69768356974784570000e-001) (28, 2.03583204733304990000e-001) (29, 3.68590221384187070000e-001) (30, 4.07386024492736530000e-001) (31, -6.92773142508521510000e-002) (32, 9.62634938546341610000e-002) (33, 8.49099699765917700000e-001) (28, -3.06360217272653310000e-002) (29, -1.04877161647935420000e-001) (30, -2.47682147873836800000e-001) (31, 2.45468040390855010000e-001) (32, -1.01584629922696370000e-001) (33, 7.90173040074366060000e-001) (28, -3.81262054402577850000e-003) (29, -2.76563972682830340000e-001) (30, -1.51848443014217320000e-001) (31, -1.53450062010861620000e-001) (32, -9.49991453403108560000e-002) (33, 5.65890471269645870000e-001) 

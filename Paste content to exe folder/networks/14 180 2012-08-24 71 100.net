FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.30981069102395240000e+000) (1, -9.52516647439168580000e-002) (2, 1.38214098457656550000e+000) (3, -2.44379582716260950000e-001) (4, 6.68466589208369210000e+000) (5, 3.42260325704721420000e-001) (6, 3.99885047803475800000e+000) (7, 1.73873910755281720000e-001) (8, -4.12190049098997240000e+000) (9, 7.64505426442556450000e-002) (10, 8.00994865666407390000e+000) (11, -3.12303903061822930000e-001) (12, 1.73609445839974400000e+000) (13, 4.93532690002536490000e-002) (14, 9.20292404370249000000e+000) (15, -3.74086080094088890000e-001) (16, 7.55837961280648060000e-001) (17, 1.66035729900804900000e-001) (18, 4.75750480563789770000e+000) (19, 1.90881334713390250000e-001) (20, 2.33966482753123460000e+000) (21, 4.59481792572916240000e-002) (22, -2.99922137527824570000e+000) (23, 5.65231884021054690000e-002) (24, 3.62701306732843110000e+000) (25, 2.43884988577716540000e-002) (26, 3.03846091809262740000e+000) (27, -1.42338920852783550000e-001) (0, 1.83148961920626970000e+001) (1, -3.24263694115445030000e-002) (2, 2.99802407314576750000e-001) (3, -1.15262841563927120000e-001) (4, 8.16043930189435330000e+000) (5, 1.88155712084336750000e+000) (6, 1.45630960832573780000e+001) (7, 8.08665418572297180000e-002) (8, -1.37797210214685910000e+001) (9, 1.37866384249235270000e+000) (10, 2.08097226344766390000e+001) (11, -4.90554225721223650000e-001) (12, 5.01885612550359350000e-001) (13, 2.56493860964133980000e+000) (14, 4.18500916845294850000e+000) (15, -9.06549692981064470000e-001) (16, -1.81946793771658060000e+000) (17, 2.50396708771917130000e+000) (18, 9.36273977672655850000e-001) (19, 1.13179013624962610000e+000) (20, -4.40358443026401060000e+000) (21, 8.97583163144401790000e-001) (22, -2.86125326187177940000e+000) (23, 5.61604855366807270000e-001) (24, -7.88108926576030470000e+000) (25, 4.35666277213808240000e-001) (26, -7.75333454725198030000e+000) (27, 7.46447128172480710000e-001) (0, -2.29687435259317500000e+000) (1, 3.47391496110506510000e-001) (2, -2.50025574016102640000e+000) (3, 4.51654197237152610000e-001) (4, 6.98935593104447420000e+000) (5, 9.90803668254045980000e-001) (6, 6.14270819409530060000e+000) (7, -4.45095504326589840000e-001) (8, -1.17452240932281060000e+000) (9, 1.00075965401166030000e+000) (10, -1.54090729587916450000e+001) (11, 1.33695087589815810000e+000) (12, -2.69454496151616230000e+000) (13, 1.73135796393351480000e+000) (14, -1.03870221684421010000e+001) (15, 4.29880365942563460000e-001) (16, 1.35802638297797080000e+001) (17, 6.82278683768457020000e-001) (18, -9.50219133374826000000e-001) (19, 1.90655400244241810000e+000) (20, 4.37147086198571340000e+000) (21, 8.71557907423078810000e-001) (22, 7.07600617931386110000e+000) (23, 1.87622494841520990000e-001) (24, -1.88662721416970380000e+001) (25, 1.59448683373383330000e-001) (26, 4.25539487413403260000e+000) (27, -2.48386510053215580000e-001) (0, 2.99766052319482450000e+001) (1, 2.15299593821769890000e+000) (2, -5.05146407972588380000e+000) (3, 4.18477164663401010000e-001) (4, 9.43747925674810340000e+000) (5, 5.90927223287868520000e-002) (6, 1.09953921654929520000e+001) (7, -2.46336526320930750000e-001) (8, -2.72893071200557810000e+001) (9, -7.19350578256211850000e-001) (10, 3.11736285322914530000e+001) (11, -1.86045593856185650000e-002) (12, -2.67534171436095750000e+000) (13, -9.31510022022029480000e-001) (14, -6.97586997435061700000e+001) (15, -8.46927938655853140000e-001) (16, -7.02283256085901810000e+000) (17, -1.82901448369458250000e+000) (18, -1.58691024866454120000e+001) (19, -6.53144295390507420000e-002) (20, -5.06124283837429980000e+000) (21, -5.44376677239350900000e-001) (22, 3.27541379349654660000e+000) (23, -8.87941213192987580000e-001) (24, -2.19073185191028830000e+001) (25, -1.84079681591229620000e-001) (26, -2.11381572334138350000e+000) (27, -9.06893084204319020000e-001) (0, 8.79095044257785400000e+000) (1, -3.15176098595131240000e-001) (2, 2.96637013114421220000e+001) (3, 1.42040214670387160000e-001) (4, 1.41264840413927790000e+000) (5, -5.05314697794269850000e-001) (6, -2.42795863847956710000e+001) (7, 2.71135734234159820000e-001) (8, -7.93925692596989220000e+000) (9, 2.45095414901596610000e+000) (10, -6.54126260385188020000e+000) (11, 6.42472740897993220000e-001) (12, -1.26810439022688760000e-001) (13, 4.82341024031840200000e-001) (14, 2.98190078233107190000e+000) (15, 2.96116581838646590000e-001) (16, 3.27790254213699010000e+000) (17, 1.76671580750954990000e+000) (18, -2.47858452252811750000e+001) (19, -3.33187273791826720000e-001) (20, -1.17490342197294520000e+001) (21, 2.33640853542027960000e-001) (22, 8.11577605005838270000e+000) (23, 6.60428968043430880000e-001) (24, 1.15921068245254430000e+001) (25, 8.43684270111013550000e-001) (26, -3.37302151200894240000e+000) (27, 9.73138430354696270000e-001) (28, 2.30176409360264160000e+000) (29, -1.85618260893212720000e+000) (30, 1.08474994795101790000e+000) (31, -7.38581117981536860000e-002) (32, 1.05395669717472340000e+000) (33, 6.98419154909580290000e-001) (28, -2.00497582335775130000e+000) (29, 1.31638877137671770000e+000) (30, 1.15501483680178730000e-002) (31, -7.13722963186037670000e-001) (32, -1.60856629397880660000e+000) (33, 6.59580915395285850000e-001) (28, -2.64815307101805670000e-001) (29, 4.27209557410808350000e-001) (30, -1.23918665469128020000e+000) (31, 7.57369909140374050000e-001) (32, 4.39385713249811400000e-001) (33, 1.14480892271039720000e+000) 

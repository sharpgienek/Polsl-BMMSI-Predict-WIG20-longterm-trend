FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 7.88200006893370070000e+001) (1, 9.57779608896491830000e-002) (2, 6.34141648912005560000e+001) (3, 2.86374123169567780000e+000) (4, -2.94341999339092230000e+001) (5, -1.76744309419421630000e+000) (6, 2.46066987534399710000e+001) (7, -2.22146133200058890000e+000) (8, 1.80139620246467370000e+001) (9, -2.30868899739002490000e+000) (10, -1.90716294322477430000e+001) (11, -2.47096308518893570000e+000) (12, -5.27900241526703770000e+001) (13, -3.41063589271307600000e+000) (14, -5.92054015338006680000e+001) (15, 3.36488257731821450000e-001) (16, 1.53432856395083950000e+001) (17, -5.57643036112057630000e+000) (18, -3.36984526087689960000e+001) (19, 6.02403409528438290000e-001) (20, -8.61556924431203620000e+000) (21, -2.34701748460306640000e-001) (22, 3.38198009972809000000e+001) (23, -1.02865627681661830000e+000) (24, 2.49042598384090330000e+001) (25, 1.13427984392080590000e+000) (26, 4.53053278493966900000e+001) (27, -1.42635729473981590000e-001) (0, -6.44879240659037580000e+002) (1, -1.11234751356710490000e+001) (2, -3.09122474469267960000e+002) (3, 8.22332838397015280000e+001) (4, -2.22526168105044750000e+002) (5, -6.18906890898868480000e+001) (6, -5.83409334129145350000e+002) (7, 3.93080998603128290000e+001) (8, 7.23246660130499090000e+002) (9, 6.10335144236006070000e+001) (10, -5.52198405031510900000e+002) (11, -2.50740614636004580000e+001) (12, -6.33390236609981460000e+002) (13, 3.96140592846929710000e+001) (14, 1.50000000000000000000e+003) (15, 5.62412153996319030000e+002) (16, -9.44336811701076900000e+001) (17, -9.00485246603516320000e+001) (18, 1.02932493031732060000e+003) (19, -1.83953682479254930000e+001) (20, 2.53694914651157920000e+002) (21, 2.88082288208396980000e+001) (22, 1.50000000000000000000e+003) (23, 3.18699926152640710000e+001) (24, 1.50000000000000000000e+003) (25, -1.27798355830484450000e+001) (26, -1.50000000000000000000e+003) (27, 6.27462834315224710000e+001) (0, -1.21395947042121680000e+002) (1, 7.94526024885183060000e-002) (2, -4.77438308010177290000e+001) (3, 6.09144041349698990000e+000) (4, 2.45184936910836660000e+001) (5, 4.00922538495142200000e-001) (6, -4.60707286321516420000e+001) (7, -1.84198743536538290000e+000) (8, 5.30736380393201370000e+001) (9, 5.54457130006127290000e-001) (10, -1.53236517909390840000e+002) (11, 3.89058040102585250000e+000) (12, -6.26435540392611190000e+001) (13, 3.22457958729709530000e+000) (14, 1.30148158758443260000e+002) (15, 5.83789913081437370000e+000) (16, 1.72881646046226020000e+002) (17, 1.05461928663534720000e+000) (18, -3.36121010131327440000e+001) (19, 4.64850567371066690000e+000) (20, -1.11784549673545190000e+002) (21, 2.27511451774127280000e+000) (22, 2.94056749941388100000e+001) (23, 7.60355764334870070000e-001) (24, 1.39669977082258360000e+001) (25, 5.31639737557494050000e-001) (26, 1.58163307236620930000e+001) (27, 2.18085311842131580000e+000) (0, 1.29669831268310440000e+003) (1, -4.19190533209835910000e+002) (2, -1.25309483034910840000e+003) (3, 9.01239627347770660000e+001) (4, -2.95360853263719090000e+002) (5, 3.12200692167959990000e+001) (6, 1.26433650946855820000e+003) (7, -9.38030938367078800000e+000) (8, 1.50000000000000000000e+003) (9, -3.38216703122018540000e+002) (10, 8.41137514106474440000e+002) (11, -1.91851824971666990000e+002) (12, -9.77345074333461100000e+001) (13, -2.30937448954446100000e+002) (14, -1.03905938892603190000e+003) (15, -3.33087268425566020000e+001) (16, 2.09549990948485320000e+001) (17, -2.67654207064503280000e+001) (18, -6.60089261178744440000e+002) (19, 4.32774087657648890000e+001) (20, 1.50000000000000000000e+003) (21, -1.10953328879838380000e+001) (22, 9.56083234295195100000e+002) (23, -1.17264101835855730000e+002) (24, 1.45755987605610080000e+003) (25, -9.47425805922579300000e+000) (26, 1.50000000000000000000e+003) (27, -1.76710339036824850000e+001) (0, -3.75907420276535690000e+001) (1, -4.49136689526160810000e+000) (2, 2.15289205321028520000e+001) (3, -4.90050067407311610000e-001) (4, 3.25921208501739980000e+001) (5, 3.03156355151770680000e+000) (6, 3.93416177136121230000e+001) (7, 1.39656506618197660000e+000) (8, 8.68223377235881770000e+001) (9, 2.41499554541434500000e+000) (10, -2.24095847535811610000e+001) (11, -3.26468951606461440000e-001) (12, 2.77671139621845170000e+001) (13, 3.17296506372065990000e+000) (14, 1.68632047105259320000e+002) (15, 8.33975523023179300000e+000) (16, -2.01596041060416520000e+001) (17, 1.00923520604421530000e+000) (18, -1.32943512004318820000e+000) (19, 7.55267135275973110000e-001) (20, 7.90775820013483750000e+001) (21, 9.97130427507890160000e-001) (22, 4.58509793551421300000e+001) (23, 2.06315766029019750000e+000) (24, -1.14801512863680970000e+001) (25, -1.76228009265654990000e-001) (26, -4.61094474191833330000e+001) (27, 1.34639441252514570000e+000) (28, 1.97926443950466370000e+000) (29, -1.78800018256032090000e+000) (30, 1.33805035709030570000e-001) (31, -1.96721993718661730000e+000) (32, 1.82892556658870360000e+000) (33, 2.46088937488796320000e-002) (28, -1.23628874752070250000e+000) (29, 9.77370930730594890000e-001) (30, 9.46569957550496110000e-001) (31, 1.24425930872623210000e+000) (32, -5.99823854639785490000e-001) (33, 7.37127423913401470000e-001) (28, -7.62285468838930500000e-002) (29, 1.40720933105309450000e-001) (30, -1.52733906849170480000e+000) (31, 8.60431487212754560000e-003) (32, -5.44485555488223530000e-001) (33, 1.95144217103499160000e+000) 

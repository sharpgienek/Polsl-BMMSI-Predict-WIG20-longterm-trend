FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 9.95367053605514580000e+000) (1, -4.84754647371772850000e+000) (2, 4.97653147645892910000e+001) (3, 1.59365599116956910000e-001) (4, -1.84995715370807580000e+001) (5, -4.06739902435477090000e-001) (6, -4.85440962904701720000e+001) (7, -5.45598604157486620000e-001) (8, 5.73892254305899170000e+001) (9, 2.73728400466532310000e+000) (10, -6.67805515935209680000e+001) (11, 2.01404728290113660000e-001) (12, 3.65014385358425240000e+001) (13, -5.18384716218711520000e-001) (14, 1.61667081272193940000e+001) (15, 9.46782882484641150000e-001) (16, 1.33944734622473240000e+001) (17, 1.81706212682453330000e+000) (18, -6.57895893316140070000e+000) (19, -1.74089696075160870000e+000) (20, -1.66435812553782150000e+000) (21, 6.12141247755568440000e-001) (22, 1.42314710780157230000e+001) (23, 1.83053927953997150000e+000) (24, -1.33040638021474480000e+001) (25, 1.32408508187269770000e+000) (26, 5.89794633439330200000e+001) (27, -1.47980816357312020000e+000) (0, -1.40985565823631530000e+002) (1, -1.18815263842437660000e+000) (2, -2.23420696740129650000e+001) (3, 3.43799380181969250000e+000) (4, 5.82923492022163930000e+001) (5, 5.29698081924468230000e+000) (6, 1.82569364957038720000e+001) (7, 1.35559975324374440000e-001) (8, 2.82838508886435460000e+001) (9, -1.76998563735952260000e+000) (10, -1.62281348096488110000e+001) (11, 6.56052851309108040000e+000) (12, -2.23871888613754950000e+001) (13, 4.63071829874078840000e+000) (14, 1.48797110043331290000e+002) (15, 5.28247823700191340000e+000) (16, 4.14802759425735770000e+001) (17, -1.73037701558060040000e+000) (18, -2.04018406971988500000e+001) (19, 7.02830536733614600000e+000) (20, -3.02656077570883540000e+001) (21, 4.61603398760466630000e+000) (22, 8.08780170053080950000e+001) (23, 2.59095306021989650000e+000) (24, 4.24587802393241450000e+000) (25, -2.50630868324790420000e+000) (26, -9.54953143935856450000e+001) (27, -4.90945409275972720000e+000) (0, -4.15098413042434940000e+001) (1, 1.96930105258355880000e+000) (2, -4.84969521454138000000e+001) (3, 3.39305500295122190000e-001) (4, -1.43483800209513980000e+001) (5, 1.16061143239051340000e-001) (6, 2.39896592560876480000e+001) (7, 5.54549109051677360000e-002) (8, 4.78603002052870820000e+001) (9, -3.30949213105928570000e+000) (10, 6.00099145539482000000e+001) (11, 4.91161446163780660000e-001) (12, -6.48979460319575740000e+001) (13, 2.65598831305923270000e-001) (14, 6.74953764468174460000e+000) (15, 3.22026995096617360000e-001) (16, 1.29860296051316870000e+001) (17, -4.24701919527682050000e-001) (18, 2.18264173186939060000e+001) (19, 3.66250059289892920000e+000) (20, -3.57130241728402750000e+000) (21, 3.51294137477836170000e-001) (22, 3.47113331853167250000e+001) (23, -2.47737881690413360000e-001) (24, 7.95709180526356350000e+000) (25, -3.13130885781425720000e+000) (26, -6.32217921240638960000e+001) (27, -1.40292104931121610000e+000) (0, -6.11909864481438110000e+001) (1, 7.58054015898060030000e+000) (2, 7.77033484789826100000e+000) (3, -2.27929941234562250000e+000) (4, -3.32813784636793810000e+001) (5, 2.94834309541126940000e-001) (6, -4.32881513198023310000e+001) (7, 4.14865044301559300000e+000) (8, -1.36019049007945320000e+001) (9, 1.03244722422659610000e+000) (10, -4.70019592102254360000e+001) (11, 3.28383868382494270000e+000) (12, -9.81957068317562830000e+001) (13, 7.16164930927637930000e+000) (14, -9.12486914713534960000e+000) (15, 4.18628840010056980000e+000) (16, 9.06350189324177220000e+001) (17, 7.62521804386051460000e+000) (18, 1.23114116418633770000e+002) (19, 5.21841488050556190000e+000) (20, 1.10375080495008210000e+002) (21, 1.04199006406223450000e+001) (22, -5.91534835060555370000e+001) (23, 2.54336223172964400000e+000) (24, 4.63886026962654010000e+001) (25, 5.56481392035777220000e+000) (26, 8.24452349655773130000e+001) (27, 6.17761523385228180000e+000) (0, -7.60963318446483040000e+001) (1, -2.62689413126873510000e+000) (2, -1.57397178028174270000e+002) (3, 1.05329053617043160000e+001) (4, 2.46523870724443500000e+002) (5, 5.46968676675913560000e+000) (6, -5.50524581032053600000e+001) (7, -6.14723063188913680000e-001) (8, -6.23041090375699870000e+001) (9, 8.04190449086695300000e+000) (10, -7.11635691088866820000e+000) (11, 3.30608796655806000000e+000) (12, 1.86456539050638040000e+002) (13, 7.08491930427961330000e+000) (14, 8.99436558754264150000e+001) (15, 4.68306554071645210000e+000) (16, -7.70774702796463870000e-001) (17, -4.35698662465502540000e-001) (18, -3.09041929987494090000e+001) (19, 2.64269976664340870000e+000) (20, 9.84455009895080480000e+000) (21, 9.75658383507016860000e+000) (22, 9.89111453251837070000e+000) (23, 5.42713509368157650000e-001) (24, -5.98219455395034960000e+001) (25, 2.66858071513998140000e+001) (26, 1.30784371127556260000e+001) (27, 2.66539290465197130000e+000) (28, -1.87634835790414580000e-002) (29, 1.59745856414331480000e+000) (30, -1.67463979201761480000e+000) (31, 2.89491417812201610000e-001) (32, -6.65095101766512210000e-001) (33, 5.42781979015777180000e-001) (28, 1.18134541309658350000e+000) (29, -1.09939079360620480000e+000) (30, 2.39832376146224570000e+000) (31, 1.15763518573039550000e+000) (32, 1.29488901741889850000e+000) (33, 5.47694634987958910000e-002) (28, -9.88168556185139660000e-001) (29, -1.67325677622294920000e-001) (30, -8.85412227989526230000e-001) (31, -2.12573921540576460000e+000) (32, -4.25869494916014340000e-001) (33, 2.53172222419379760000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.44312383666580320000e+000) (1, 4.66844079526335800000e-002) (2, 1.10665583267231970000e+000) (3, 1.88928027693464150000e-001) (4, 7.38252220706679550000e+000) (5, 5.51834816499739310000e-001) (6, 2.91391865923066500000e+000) (7, 1.81399555727419640000e-001) (8, -1.50372915426370210000e+000) (9, 1.56468776432136030000e-001) (10, 4.03892031800732910000e-001) (11, 7.56718916376378450000e-001) (12, 4.83629264782113690000e-003) (13, 1.06399051918214300000e+000) (14, 5.44620572100792260000e-002) (15, 9.07296169152255970000e-001) (16, -4.21089107740160080000e+000) (17, 3.43511937091517450000e-001) (18, 2.24303252786163390000e-001) (19, -2.49692571862071940000e-001) (20, 2.84840098286087120000e+000) (21, 1.29179424771507760000e-001) (22, 1.04203943223847960000e+000) (23, 8.35192688258340200000e-002) (24, 1.46164883586240050000e-001) (25, -9.90838244346796350000e-001) (26, -5.80273030856704610000e+000) (27, 5.22825451472383350000e-001) (0, -3.86946179934711190000e+000) (1, -2.69573231157857580000e-001) (2, 1.23077452517986670000e+000) (3, -1.14934606687480650000e-001) (4, -4.73710384970562170000e+000) (5, 3.23515207395028870000e-001) (6, 4.51092367040788390000e+000) (7, -5.91155905680071700000e-001) (8, 1.76618002995658500000e-001) (9, 4.97488924412903490000e-001) (10, 7.15526435654014660000e+000) (11, 3.53928412668034650000e-001) (12, -1.18496149589992510000e+000) (13, -5.52189836477524270000e-002) (14, 1.87063030693917510000e+001) (15, 9.34472485085621470000e-002) (16, -5.94650608234812970000e-002) (17, -2.64557365512506640000e+000) (18, 3.00550658827367820000e+000) (19, 3.22386087972314270000e-001) (20, -3.25151860825179050000e-001) (21, -3.63928563901724140000e+000) (22, 4.29111818252503270000e-001) (23, 2.99668795397299510000e-001) (24, 1.91692303432049950000e+000) (25, 7.06337218513621410000e+000) (26, 6.80774137740234320000e+000) (27, -3.08839572524331920000e-001) (0, 1.38993425773613330000e+000) (1, -9.09010008139760070000e-002) (2, -3.05993621185005680000e-002) (3, -3.32601946632844700000e-001) (4, -4.47810585632959710000e-002) (5, 5.19960038489972740000e-001) (6, 1.86779742310053940000e+000) (7, -4.22000334279004490000e-002) (8, 1.65509776551525120000e+000) (9, 1.21041261446715860000e-001) (10, 1.71825093661821220000e-001) (11, 8.20475850405178670000e-001) (12, 8.01550069645934000000e-001) (13, 3.11620106252173510000e+000) (14, 5.28441217935753240000e-002) (15, 1.77457848135254360000e+000) (16, 3.71610573632806010000e+000) (17, 8.45351824922771500000e-002) (18, 9.10253043757247860000e-002) (19, 9.98246562729689370000e-001) (20, -2.44695835105815440000e-001) (21, 1.78852006379198600000e-001) (22, 1.71968851405027820000e-001) (23, 3.25668680047743630000e-001) (24, -3.85467534549129990000e-002) (25, 2.67935784918159170000e-001) (26, 8.91076157494131850000e+000) (27, 2.36080776812223420000e-001) (0, -8.95548826954309930000e-001) (1, 1.64159168334774200000e+000) (2, 5.12638147076372120000e-001) (3, -1.59666763159368510000e-001) (4, -1.69881340217045280000e+000) (5, -1.31279729651122330000e-001) (6, 2.59117067147308980000e-001) (7, 1.58546775389069640000e-001) (8, -1.01841971961291610000e+000) (9, -2.56590596502790300000e-002) (10, 7.68229368771675800000e-001) (11, 5.35277211854744640000e-001) (12, -1.08307375931663060000e+000) (13, -1.37611482693358100000e+000) (14, 8.54999317509164490000e+000) (15, 4.69076626414822560000e-001) (16, 1.11895362722589860000e+000) (17, 8.45470663013562110000e-001) (18, 1.80677175573468000000e+001) (19, 2.22551651617274360000e-001) (20, 6.54073513456703640000e+000) (21, 1.89094723858600880000e-001) (22, -1.98125172022462560000e+000) (23, 3.29178687435517990000e-002) (24, 2.75643299893960950000e+000) (25, 6.27135268994322930000e-001) (26, 7.11458415157106280000e-001) (27, 6.34736640868143690000e-003) (0, -9.33306874489911920000e+000) (1, -2.24981481040293220000e-001) (2, 8.65885844775122070000e-002) (3, -2.41450187224028750000e-001) (4, -2.27699015859603190000e+000) (5, 6.67205006876545710000e-001) (6, 6.35494424804321940000e+000) (7, 5.47243743002834630000e-001) (8, 5.63662007053640220000e-001) (9, -1.79361230785824610000e-001) (10, 4.49548960098763930000e+000) (11, 2.89978233578087000000e-001) (12, -4.62179571072324260000e+000) (13, 1.95960991507409670000e+000) (14, 3.09805528489641360000e+000) (15, -7.92010766783054490000e-002) (16, 1.09499854907739970000e+000) (17, -9.97270505081757740000e-001) (18, 1.94229626320748430000e+000) (19, 5.34956683529360790000e-002) (20, -4.06847603003461930000e-002) (21, -3.26085578393407630000e-001) (22, 4.74402669560415550000e+000) (23, 2.45708813647124120000e-002) (24, -2.19915024769074920000e+000) (25, 2.98677137352862560000e-002) (26, -1.42048077640646710000e+000) (27, -2.10163621546958890000e-001) (28, -2.01919961611318890000e+000) (29, -7.04253138743597300000e-001) (30, 1.26003196973709410000e+000) (31, 1.15930973059391220000e+000) (32, 2.64853799550403500000e-001) (33, 4.05900410817781330000e-001) (28, 3.51875941675636210000e+000) (29, 2.34038796623979590000e+000) (30, 2.40234581169403160000e-001) (31, 1.01921596936932020000e-001) (32, 1.67136268959046790000e+000) (33, 7.65734840531856590000e-001) (28, 2.65585218679254940000e-001) (29, -1.95286038280112770000e+000) (30, 6.73793603673429890000e-002) (31, 4.22309625146155280000e-001) (32, -2.87596614102310650000e+000) (33, 8.53035869833774880000e-001) 

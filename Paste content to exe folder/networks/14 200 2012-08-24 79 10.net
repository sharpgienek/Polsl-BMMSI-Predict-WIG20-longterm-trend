FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.14314877680886540000e-001) (1, 3.60260527487294150000e-001) (2, 4.85033471277852290000e-002) (3, 1.60142058698865760000e-002) (4, 1.19849598764506950000e-001) (5, 1.90298318723118090000e-001) (6, 2.70266168355873760000e+000) (7, 2.40862323523974630000e-001) (8, 2.00887279023577530000e-001) (9, 2.34962034678730170000e-001) (10, 1.81888314376329110000e+000) (11, 1.62860286637012850000e-001) (12, 6.44968492615279330000e-001) (13, 4.95952251462226520000e-002) (14, -3.48913077231111980000e-001) (15, 5.49735984845492460000e-003) (16, -3.79238932399790160000e-002) (17, 2.51557493910396780000e-001) (18, -2.68236806497691940000e-001) (19, -4.81464113085636330000e-002) (20, 3.59279055799226890000e-002) (21, 6.74785904143831300000e-002) (22, 5.23181806997979750000e-002) (23, 1.47831834787247260000e-001) (24, 1.53283111444099760000e-001) (25, 6.53484349590554290000e-002) (26, -1.06119979837792270000e+000) (27, 7.35215309455624910000e-002) (0, 3.10433719061388570000e+000) (1, 2.56448265163848110000e-001) (2, 3.11245675835175040000e-001) (3, -9.02706086157991640000e-002) (4, 1.43375474987516370000e+000) (5, -5.60050513284411130000e-001) (6, 2.39529009825039950000e+000) (7, 1.24081536638999280000e-001) (8, 1.09928206275185100000e-002) (9, -2.63679584878387880000e-001) (10, 3.02159793156847470000e+000) (11, -1.59803608864221560000e+000) (12, 7.49819245047426810000e-001) (13, -9.62432707062428340000e-001) (14, -3.09744021785486280000e+000) (15, -1.24919738626911460000e+000) (16, -1.20961045465740690000e+000) (17, -4.91752172422936620000e-001) (18, -1.01751422834166290000e+000) (19, -7.95004257984982530000e-001) (20, -3.07449695799660640000e-001) (21, -5.72336890420617420000e-001) (22, 7.78314982501982500000e-002) (23, -2.57704242992473350000e-001) (24, 3.15901858791307700000e+000) (25, -4.01851586507178120000e-002) (26, -9.90689276770065020000e-001) (27, 1.46868182922610890000e-001) (0, 1.95662757080216940000e-001) (1, -3.79331089445086640000e-001) (2, 3.08877322553821450000e+000) (3, -5.88096091068194720000e-001) (4, -2.19395274335960440000e+000) (5, 2.62634182728078480000e-001) (6, 3.73217846090404260000e-001) (7, 1.10223291785104230000e-001) (8, -3.09093997361737660000e+000) (9, -1.87348334905346330000e-002) (10, 1.33554113507625070000e+000) (11, 3.29514255474746280000e-002) (12, -1.23616319181225930000e+000) (13, -5.34913573098577120000e-001) (14, 3.12347483855240190000e-001) (15, 6.81752784686153520000e-001) (16, 4.43045219329854910000e-001) (17, -1.28698225403167140000e-001) (18, 3.09944827452541020000e+000) (19, -9.68304052029751890000e-001) (20, -7.87679754266908390000e-001) (21, -1.50038594070274020000e+000) (22, 5.39092043726193240000e-001) (23, 8.71066486355111970000e-001) (24, 8.35326965354412920000e-002) (25, 3.93499884827666400000e-001) (26, 4.76632829290685900000e-001) (27, 2.26535342831846870000e-002) (0, 2.81522677817459430000e-001) (1, -6.18458723603728670000e-002) (2, 1.06014349691291530000e+000) (3, 4.93055530275871730000e-001) (4, 1.59591201633645240000e+000) (5, 5.76405327579285530000e-001) (6, -3.06291262944973660000e+000) (7, 1.30167477450317590000e-001) (8, -3.14676883187116640000e+000) (9, 3.23916742645030450000e-001) (10, -3.07652497159506130000e-002) (11, 8.53553182883922680000e-001) (12, 4.32641834522588140000e-001) (13, 2.48944409069359110000e-001) (14, -8.19869981011760670000e-001) (15, 7.19366684934187320000e-001) (16, 2.25955147220497140000e-001) (17, 8.20778771243517170000e-002) (18, 3.66480343889480640000e-001) (19, 5.90138079724225380000e-001) (20, -5.93973776702654050000e-001) (21, 5.32991482943110380000e-001) (22, 2.73617949298489700000e-001) (23, 4.92939563477268690000e-001) (24, 2.24761352837539010000e-001) (25, 1.22885983201189870000e-001) (26, 5.35942629616763310000e-001) (27, 6.95501938484824890000e-001) (0, -2.78966787126331050000e-001) (1, -4.14950918104678660000e-001) (2, 4.49339173511126510000e-001) (3, 6.27249021988652430000e-002) (4, -2.49928241657306200000e-001) (5, 2.08922506542604410000e-001) (6, 1.85535466241060990000e-001) (7, -1.16809913200107390000e-001) (8, 3.28526292647043920000e-001) (9, 2.13548971455294110000e-001) (10, -9.32913911059898290000e-002) (11, 8.35380520351927670000e-003) (12, -2.56794696837749360000e-001) (13, 5.26160893097102900000e-001) (14, 5.94225101188364800000e-001) (15, 3.95547490593679330000e-001) (16, 4.99358156415362130000e-001) (17, 4.40736637732042500000e-002) (18, 1.27836541821904510000e-001) (19, 2.14482716960232860000e-001) (20, 2.51577659622520430000e-001) (21, 2.31034682111661230000e-001) (22, 1.84790479843896570000e-001) (23, 3.50994041862760230000e-001) (24, 2.16972690153311890000e-001) (25, 5.49274907113403540000e-001) (26, 6.18572025379287130000e-001) (27, 7.01094509653660410000e-002) (28, -9.95052278940307120000e-002) (29, -3.99197744041813070000e-001) (30, 2.18325944327682600000e-001) (31, 3.71340020573372510000e-001) (32, 1.63223166118435880000e-001) (33, 3.39021904857420060000e-001) (28, -1.14314676424185150000e-002) (29, 1.16979053397940100000e-001) (30, -3.44524347243492960000e-001) (31, 4.79652238234108130000e-001) (32, -3.46736554887540970000e-002) (33, 5.05933976906986600000e-001) (28, 1.36101581199676020000e-001) (29, 1.02825864119761050000e+000) (30, 5.72834273048510310000e-002) (31, 7.49292222489487570000e-001) (32, -4.18397604761991060000e-001) (33, 6.40790023607054060000e-001) 

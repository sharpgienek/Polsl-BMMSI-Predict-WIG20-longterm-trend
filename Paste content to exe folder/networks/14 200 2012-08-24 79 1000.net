FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -2.20655323154078540000e+001) (1, 4.44684033370663820000e+000) (2, -2.48768502433503760000e+002) (3, 3.54354978354088730000e+000) (4, -9.17641798793472530000e+001) (5, 1.84680961216846940000e+000) (6, -1.50692787688756000000e+002) (7, 1.63002748558383210000e+000) (8, 1.40032551523392130000e+002) (9, 3.97553249859478160000e+001) (10, -3.79993199702427030000e+002) (11, 4.53821193746904040000e+001) (12, 1.15322183939377170000e+002) (13, 2.35512243246745610000e+001) (14, 3.74923653207789070000e+002) (15, 4.72924371942105350000e+001) (16, 6.35388151971659910000e+002) (17, 4.32254496881101740000e+001) (18, 4.57019504303968010000e+002) (19, 1.49150760031888400000e+001) (20, -6.45013898409768670000e+002) (21, -5.05423205883727690000e-001) (22, -5.00216711107116440000e+001) (23, -3.33603485109825200000e+000) (24, 1.70056113548534060000e+002) (25, 1.00920756813946030000e+000) (26, 6.07402807774481060000e+001) (27, -1.13467218019611330000e+000) (0, 2.59226080316465660000e+000) (1, 7.32234221755463470000e+000) (2, 1.53238284604545640000e+002) (3, 2.41072623971551230000e+000) (4, 2.01734797637905020000e+002) (5, 1.06450208641828480000e+000) (6, 4.25453584806776770000e+001) (7, -4.35025367556284400000e-001) (8, -6.19170925690266430000e+001) (9, 3.79729968677857380000e+000) (10, -4.76868450237138930000e+001) (11, 2.36906665856782530000e+000) (12, -2.55736092315540800000e+001) (13, -1.20219397799932870000e+000) (14, 7.40213108433786290000e+001) (15, -7.98920062870377980000e-001) (16, 5.35438909610106750000e+001) (17, 2.28469729727292090000e+000) (18, -1.35021644942895510000e+002) (19, -2.63144861745919290000e+000) (20, 9.00163566123140550000e+001) (21, 1.72503464732224710000e+000) (22, 6.33013811283536610000e+001) (23, 3.77871351080931990000e+000) (24, 6.40704417949909410000e+001) (25, 4.87291138972241900000e+000) (26, 8.89398291621758550000e+001) (27, 2.49895114347472890000e+000) (0, -1.10060965486091470000e+001) (1, -1.31371011830502590000e+000) (2, -3.75648655247488320000e+001) (3, -4.50529984922451550000e-001) (4, -3.91299062462294390000e+001) (5, -4.47931328540386750000e-001) (6, 7.65225107710162610000e+000) (7, -2.90083045585455830000e-001) (8, 2.83500191334939730000e+001) (9, -1.94926109180228520000e+000) (10, 2.24685002178138120000e+001) (11, -1.10125114644322710000e+000) (12, -4.22966349011127280000e+000) (13, -7.01885957637446850000e-002) (14, -1.08196254805944940000e+001) (15, -9.42540046750234010000e-002) (16, -1.74496798947419940000e+001) (17, -1.46629234822273150000e+000) (18, 1.60917723929169650000e+001) (19, 4.02853371320882390000e-001) (20, 8.18915815840295740000e+000) (21, -1.72786734024961970000e-001) (22, -9.52131378883919060000e+000) (23, -5.38813647224136050000e-001) (24, -1.71502005917960220000e+001) (25, -1.44313488759293660000e+000) (26, -1.48173174392510240000e+001) (27, -3.31879880802134490000e-001) (0, 4.31249321942926970000e+001) (1, 3.47683664637193250000e+000) (2, 2.13534092032885140000e+001) (3, -2.91447170249680530000e-001) (4, 1.08910018296934550000e+001) (5, -8.06411071716438070000e+000) (6, -4.84331679189405830000e+001) (7, 8.22934529697280870000e-001) (8, -6.37339419642461850000e+001) (9, 2.02631650938837730000e+000) (10, -4.73879949157926030000e+001) (11, -2.75989961170212390000e+000) (12, 3.39956808402826200000e+000) (13, 1.36634830805105940000e+000) (14, -3.03432948315526050000e+001) (15, -6.57233270788098260000e+000) (16, -1.04744271358634490000e+002) (17, 4.33163571407495060000e+000) (18, -6.88744941975920140000e+001) (19, -3.36204413962794080000e+000) (20, 2.85742317210782280000e+001) (21, -4.17948782460447800000e+000) (22, -1.89937016259447300000e+001) (23, -3.02677848775021110000e+000) (24, -9.83481127673169020000e+000) (25, 1.52516433524764030000e+000) (26, 1.57995376997183480000e+001) (27, 4.50999022167898110000e+000) (0, -1.93166956197101490000e+001) (1, 3.39579143393105420000e+000) (2, 8.93056981048465560000e+001) (3, 4.25928364093416080000e+000) (4, 1.57425448504332990000e+002) (5, 1.21052152183433040000e+001) (6, 3.32197695421011760000e+001) (7, 1.11813662843264530000e+000) (8, -1.18901887393297510000e+001) (9, 5.16061954816079190000e+000) (10, 6.51886971045327780000e+001) (11, 6.69468058540615820000e+000) (12, 4.01517286800836500000e+001) (13, -3.62630019442420610000e+000) (14, -1.17445449973889590000e+002) (15, 7.23820651024077550000e-001) (16, 4.50487683186538060000e+001) (17, -7.35994076756999240000e-001) (18, 6.69780207408173710000e+001) (19, -1.52880563635363690000e+000) (20, -3.65484784820052510000e+001) (21, 1.85966444834830220000e+000) (22, 5.55471444591180670000e+000) (23, 3.45103802094761570000e+000) (24, 2.67740522333407110000e+001) (25, 1.36827870644235540000e+000) (26, -2.86235910343833980000e+000) (27, -6.03313361801336550000e-001) (28, 6.05695567034309540000e-003) (29, -5.15123512618866700000e-002) (30, -2.44928660186442700000e+000) (31, -1.25724341957067480000e+000) (32, -1.38654977179360550000e+000) (33, 1.93151987866353180000e-001) (28, 9.94415211571866410000e-001) (29, 9.98519557749036670000e-001) (30, 2.93873398213988370000e+000) (31, 8.05049907075907840000e-001) (32, 8.67259353758214390000e-001) (33, 9.23847271730076860000e-001) (28, -1.96600277176351870000e+000) (29, -8.60888708291946860000e-001) (30, -5.31386667735415540000e-001) (31, 3.44921395483772210000e-001) (32, 5.38533207123437440000e-001) (33, 2.18388758638866330000e+000) 

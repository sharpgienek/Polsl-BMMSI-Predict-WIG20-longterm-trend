FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.85048616745634380000e+000) (1, -1.14484244496959510000e+000) (2, -4.66768413245467690000e+000) (3, -4.54684395829535510000e-001) (4, 4.80278659880811750000e-002) (5, 1.60594763891282110000e-001) (6, -5.23915192331366250000e+000) (7, 7.62733703067633770000e-001) (8, 6.58291279383511440000e+000) (9, -7.17891167976029140000e-001) (10, 3.01157501896423980000e-001) (11, 8.36999611514812840000e-001) (12, -4.90581307641746010000e+000) (13, -1.60983040401650480000e+000) (14, 2.36036295988957650000e+001) (15, 1.31534213926404810000e+000) (16, 7.79037711755312050000e+000) (17, -4.85728241486873100000e+000) (18, 3.37459762334328120000e-001) (19, 2.70294502887525830000e+000) (20, 1.44112941024320450000e+001) (21, 8.98256123628060620000e-001) (22, -4.29039453750027900000e+000) (23, 1.83634018254031290000e+000) (24, -1.25809082162822690000e+001) (25, 4.94795805430022820000e+000) (26, -3.94493742884484180000e+001) (27, -6.33345951645987840000e-001) (0, -2.76267954166103990000e+001) (1, -1.91869562489641020000e-001) (2, 1.49863193865875320000e-001) (3, 2.95226714493275200000e-001) (4, 7.41374773794122350000e+000) (5, 1.91329790546953260000e-001) (6, 4.42991723638123070000e+000) (7, 9.14815025872911970000e-001) (8, 5.53822748528825400000e+000) (9, -2.94283398320635050000e-001) (10, 7.09169609758329770000e+000) (11, 1.18401775586552180000e+000) (12, -1.06343750129539810000e+001) (13, 8.30587088716950530000e-001) (14, 5.62391560096341510000e+001) (15, 6.95315692294269370000e-001) (16, -1.25431092143657600000e+001) (17, 5.93696300806672370000e+000) (18, 3.86694643329434910000e+001) (19, -1.10092221946974590000e+000) (20, 9.06008443846420990000e-001) (21, -4.84401457099342260000e-002) (22, 3.07761115904864240000e+000) (23, 1.88418742953262400000e+000) (24, 1.45782147095038680000e+001) (25, -4.69307669779034540000e-001) (26, 8.32546747280639610000e+001) (27, -1.79126497047350450000e-001) (0, -7.17385489036400870000e-001) (1, 1.47629495382993950000e+000) (2, -1.89730519631734790000e+001) (3, -3.05005914201431690000e-001) (4, -4.73794315634188950000e-001) (5, 1.35920241822138740000e-001) (6, 1.85878908608083260000e+001) (7, -1.89154161436109610000e+000) (8, 2.20636016855477910000e+001) (9, 9.20878585784022490000e-001) (10, 1.98125301814723120000e+001) (11, -1.79455143964366350000e+000) (12, 1.66541365714838710000e+001) (13, -3.39667379681071800000e-001) (14, -4.13076599838799350000e-001) (15, -7.96618431005503670000e-001) (16, 1.78178857403902560000e+001) (17, 7.00902717132904530000e-001) (18, -5.97124398137304550000e+001) (19, 1.28442165413142840000e+000) (20, -1.19086564546148850000e+001) (21, 7.73821925211767960000e-001) (22, -2.99932776503610030000e+000) (23, 3.22315713625189470000e+000) (24, -1.90941510754537980000e+001) (25, -3.96025119172637370000e-002) (26, -1.09036591824651510000e+002) (27, 7.30594428988403430000e-001) (0, 6.37171631502167160000e-001) (1, -1.03031974203338630000e+000) (2, 4.11878232725975680000e-001) (3, 2.82721888555947980000e+000) (4, 3.01695714509262630000e+001) (5, 1.28106721830012800000e+001) (6, 2.45379315455361760000e+002) (7, -7.01307028569222580000e-002) (8, -5.99964305277484390000e+000) (9, 4.53510398840972110000e-001) (10, 2.69207778704807990000e+000) (11, 2.83556632483822120000e+000) (12, 4.86959848925490050000e-001) (13, 5.99304178783567230000e-001) (14, -7.41961347155633750000e+001) (15, 3.01017677184588180000e+000) (16, -5.99246100422481260000e+001) (17, 2.60140416957413430000e+000) (18, -2.79845650860557240000e-001) (19, 2.20433204578874750000e-001) (20, 5.32655806454185310000e-002) (21, 1.00589359121459230000e+000) (22, 1.82965861423240030000e+001) (23, 1.32067528093151230000e+001) (24, -7.38357747000005560000e+001) (25, -2.97001394938695150000e-001) (26, 1.20469556766383830000e+001) (27, 4.52551431275343850000e+000) (0, -4.09379559242004820000e+000) (1, 1.08995706522535610000e+000) (2, 7.37482966433798110000e+000) (3, -2.29762503433133650000e-001) (4, 1.76009914863162290000e+000) (5, -4.38727973052234820000e-001) (6, 7.16077130354912160000e-001) (7, -1.25074458494988110000e+000) (8, -5.76718760862302290000e+000) (9, 5.34727208903370330000e-001) (10, -2.27919049328156960000e+000) (11, -3.05170289408169590000e-001) (12, 1.67381057093839080000e+000) (13, 1.93240734827579890000e+000) (14, 5.70698576642571260000e+000) (15, 1.22027536606097490000e+000) (16, 3.11522306675380630000e+001) (17, 5.48635093941201290000e+000) (18, 3.92054660256650250000e+001) (19, -1.79702321644255420000e-001) (20, -5.77380911943270100000e+000) (21, 5.04915604633379920000e-001) (22, 2.03004422896577850000e+000) (23, -9.85307537482927430000e-001) (24, 1.83753168692266660000e+001) (25, -1.90620916860654340000e+000) (26, 8.08216939965062830000e+001) (27, 6.55930432709150860000e-001) (28, 1.97594256099835210000e+000) (29, -3.23349018469428760000e-001) (30, 4.25306574549817240000e-001) (31, -5.83606127802769770000e-001) (32, 2.30829532975271600000e+000) (33, 1.48542909762444940000e-001) (28, -4.18024054698569870000e-002) (29, 2.06713647305922480000e+000) (30, -1.75608302529253860000e+000) (31, -2.10476920890610320000e+000) (32, -2.09184606255850800000e+000) (33, 3.75589824703634840000e+000) (28, -2.50801908266861370000e+000) (29, -2.81918178708094080000e+000) (30, 1.13987135876080760000e+000) (31, 2.85657039148355810000e+000) (32, 1.19596147269263310000e-001) (33, 1.25227585915736640000e+000) 

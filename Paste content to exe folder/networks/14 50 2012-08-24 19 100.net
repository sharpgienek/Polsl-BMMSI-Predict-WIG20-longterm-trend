FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.43664997873725040000e+000) (1, 1.53129350760195070000e+000) (2, 2.69268712088863770000e-001) (3, 6.59966105910711480000e-002) (4, -1.01238683780478330000e+001) (5, -4.75079360589598040000e-001) (6, -1.38259663106960980000e+000) (7, 3.96220001095385190000e-001) (8, -5.81176925513783440000e+000) (9, -1.66678156609064320000e-001) (10, 5.59308344026282600000e-001) (11, -3.63551236534358670000e-001) (12, 7.79025442634810620000e+000) (13, 2.02411686624687310000e+000) (14, 2.91577114530371300000e+000) (15, -4.10971485192264170000e-001) (16, -3.35144852812773670000e-001) (17, 4.45331239674043810000e-001) (18, -9.84993623941689830000e+000) (19, 5.15438819048334660000e-001) (20, -5.09488640151121070000e+000) (21, -1.50278524418794380000e-001) (22, -1.29687885742247350000e+001) (23, -2.87025320701800360000e+000) (24, 4.06669592620197950000e+001) (25, 6.93278686344557920000e-001) (26, -1.76448732171359200000e+001) (27, -1.33651562849698970000e+000) (0, -1.46356807812954750000e+001) (1, 5.61001970424803780000e-002) (2, 1.17233448075658620000e+001) (3, 1.54955106569515090000e-002) (4, 1.06566191863644700000e+001) (5, 4.24280109149658410000e-002) (6, 6.92872217837435580000e-001) (7, 1.19405150677821740000e-001) (8, 6.64514586184918430000e+000) (9, -1.51098121873030930000e-001) (10, 3.84510354828298100000e-001) (11, 3.96365552384564000000e-001) (12, -1.63426937783869090000e+001) (13, 1.10878095269132990000e+000) (14, -2.99526886175110360000e-001) (15, -5.91479261807539960000e-001) (16, 7.22186524261639560000e+000) (17, -1.22862799075278000000e-001) (18, -6.27584878674311140000e+000) (19, 5.24520766804166930000e-001) (20, 6.70970184610798830000e-001) (21, -5.01877245562474370000e-001) (22, 7.25457116091483820000e+000) (23, 3.52707603822232600000e-001) (24, 1.33702914323316990000e+001) (25, 7.27689616583003350000e-001) (26, -5.15508119585651840000e+001) (27, -8.61962018827632900000e-001) (0, 1.76793644243482430000e+001) (1, -1.37538585082805850000e+000) (2, 1.74329971007540080000e+001) (3, 1.84777492821523890000e-001) (4, 1.13438871321812140000e+000) (5, 8.05283525380178220000e-002) (6, 3.97894045149636580000e+000) (7, 4.37022419458511280000e+000) (8, 3.46601798223250320000e+000) (9, 1.05177432031270130000e-001) (10, 1.36343735140614120000e+001) (11, 1.18009507325324760000e+000) (12, -1.01792805472656380000e+001) (13, -4.81470315289122490000e-001) (14, -2.66565258344099650000e+001) (15, -2.41185578209060330000e-002) (16, -2.47821455118083270000e+001) (17, -4.88907925133457710000e-001) (18, -2.03557739897306110000e+001) (19, -6.48634194054497290000e-001) (20, -1.79110755760629590000e+001) (21, 1.02683392811652490000e+000) (22, 6.67036266958345530000e+000) (23, -3.32422514920454220000e-001) (24, -3.16635299050591710000e+000) (25, 2.82086294144046850000e-001) (26, -2.36682418291583190000e+001) (27, 1.56852097156706430000e+000) (0, 1.89698562379284010000e+001) (1, -6.03422324562378430000e-001) (2, 8.28255493368546070000e+000) (3, 2.35347839437304920000e-001) (4, 7.68298974625951470000e+000) (5, 2.82657205317723200000e-001) (6, 1.73120705698807850000e+001) (7, 1.61798473847790910000e+000) (8, -9.63958907804916550000e-002) (9, -3.64036717930595670000e-001) (10, 1.12578725911367750000e+000) (11, 6.34647226757270260000e-001) (12, -1.09011794893191830000e+001) (13, -1.39735238226898280000e+000) (14, -2.65963622887480470000e+001) (15, 3.60641166016080370000e-001) (16, -1.15787769291753070000e+001) (17, -1.86133097807506500000e-001) (18, -9.55685668144931260000e-003) (19, -2.09165318218421490000e-001) (20, 1.65584336500021580000e+000) (21, 1.39784611840052040000e+000) (22, 1.27691477870074160000e+001) (23, -3.84132460228498170000e-001) (24, -3.77250949972976100000e+001) (25, -3.75704966537791660000e+000) (26, -3.74869691093524840000e+000) (27, 5.38664694197569130000e-001) (0, -2.89400429162773070000e+001) (1, -1.03451620493777810000e+000) (2, -1.45108837184255670000e+000) (3, 6.59314114984704600000e-001) (4, -5.71833633686582130000e-001) (5, 1.66321913248003360000e-001) (6, 1.21952839541991810000e+000) (7, 8.34487834933193560000e-001) (8, 2.40645765183116750000e+001) (9, -1.63523172485440600000e-001) (10, -2.23022253889895560000e+000) (11, 1.19588729500293090000e+000) (12, 2.80223187620739630000e+000) (13, -4.03464335640505270000e-001) (14, 3.88582314101968150000e+001) (15, 1.18346436873840630000e+000) (16, 4.39154310950720230000e+001) (17, 1.14558299891908200000e-001) (18, 2.43896010713177080000e+000) (19, 9.24662336540456380000e-001) (20, 3.57711240497417080000e+001) (21, -2.18572622718566810000e-001) (22, 1.54819558827663480000e+001) (23, -6.94482711713536370000e-001) (24, 2.91003925860675460000e+001) (25, -3.58301687487748100000e-001) (26, 8.71977224991422450000e+001) (27, -7.62962718914784070000e-001) (28, 1.35033047464996950000e-001) (29, -3.74549152591377390000e-001) (30, -1.81480337730396090000e+000) (31, -3.82997545367151030000e-001) (32, 1.28855275229593720000e-001) (33, 1.76732769492341090000e+000) (28, -1.26464593805304100000e+000) (29, 2.32264337908502630000e+000) (30, 1.44823548601600290000e+000) (31, 1.05365128917112340000e+000) (32, 1.73708459393272800000e+000) (33, 3.03118198678342830000e-001) (28, 1.68521159111701090000e+000) (29, -1.87098469097631440000e+000) (30, 3.00703750619385980000e-001) (31, -2.45589658746687780000e-001) (32, -1.64816161236340130000e+000) (33, 1.35972288000470170000e+000) 

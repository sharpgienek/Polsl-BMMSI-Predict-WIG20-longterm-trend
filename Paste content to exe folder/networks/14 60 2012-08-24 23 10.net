FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.02331912300037240000e+000) (1, 6.46610627883235370000e-002) (2, -1.16605382099648020000e-001) (3, 2.94874048179061880000e-001) (4, -7.78992267290238570000e-002) (5, 6.57252959404125650000e-001) (6, -1.53044809965135140000e-001) (7, 1.83522765033326820000e-004) (8, 1.49474435290850920000e-001) (9, -2.76618136955841670000e-002) (10, -5.65435681938879830000e-001) (11, 1.74596517457828120000e+000) (12, -1.10526341164033540000e-001) (13, 7.88838895682046460000e-001) (14, -1.43952745522747730000e-001) (15, 4.59462985804663440000e-001) (16, 1.11219955976562490000e+000) (17, 2.63321486643217690000e-001) (18, 2.60651393940621310000e-001) (19, 2.36510610463063400000e-001) (20, 5.04472791768370120000e-001) (21, -1.51363016819998430000e-002) (22, 5.03929339268513580000e-001) (23, 2.40042677702586470000e-001) (24, 2.28546135168032900000e-001) (25, 5.70011220943456300000e-002) (26, 5.66270648791221460000e-001) (27, -1.06277611903678240000e-001) (0, 3.13531863638804520000e+000) (1, 5.78070578488046880000e-001) (2, -8.89812827246977000000e-002) (3, -4.25365965049193000000e-001) (4, 3.06239993412959690000e+000) (5, -4.97373083391549400000e-001) (6, -3.99076783775959010000e-001) (7, 2.25369422927814760000e-001) (8, -1.28663719853679190000e-001) (9, -4.11429478595264910000e-001) (10, 4.09967811640583160000e-001) (11, 1.72915465564010550000e-001) (12, -8.81424790154906600000e-002) (13, -1.83253622742098390000e-001) (14, 5.34526503153705310000e-001) (15, -1.62610774117147350000e+000) (16, -3.09235598926347690000e+000) (17, -1.10421959814821610000e-001) (18, -1.50159443681449820000e+000) (19, -6.34908446321039490000e-001) (20, 1.72293037045869400000e-001) (21, 6.42238671893690880000e-001) (22, -1.01970809854089820000e+000) (23, -4.43430211493987980000e-001) (24, 3.59740283633711850000e-001) (25, 3.02940871954817840000e-001) (26, -3.02019412295380630000e+000) (27, -3.22337746011705560000e-001) (0, -1.10129989663171070000e+000) (1, -4.63067920927391240000e-001) (2, -7.13484704205785030000e-001) (3, -3.73105571241157260000e-002) (4, -1.53138572199877190000e+000) (5, 1.32840499197188630000e-001) (6, 1.46408773390031440000e+000) (7, -4.07832747204195170000e-002) (8, 1.03160958038226350000e-001) (9, -1.28672089611002770000e-001) (10, 5.48934628220520970000e-003) (11, -2.02165637067112100000e-002) (12, -3.04848391829723210000e+000) (13, 5.48761909835327580000e-001) (14, 3.93846635028169250000e-001) (15, 4.93306980449603250000e-001) (16, 7.56454443455023000000e-001) (17, -3.47774152559252380000e-002) (18, 1.18254257839194250000e+000) (19, 4.60234949993719440000e-001) (20, 4.90672742734608370000e-001) (21, -1.07093844279246840000e-002) (22, 3.17350833422274100000e+000) (23, 4.64937839401870110000e-001) (24, -1.60489606183927940000e+000) (25, -5.62618190465287090000e-002) (26, 1.13210922803105210000e+000) (27, 2.41330519518651810000e-001) (0, 1.05957504726270860000e+000) (1, 6.24771464035623890000e-001) (2, 5.00551451231536550000e-001) (3, 3.13476772502438720000e-001) (4, 1.97030918664266070000e+000) (5, -3.30713849992997470000e-001) (6, -1.92702700858521680000e+000) (7, -1.02738288521011860000e-001) (8, 6.11411084522314190000e-002) (9, 7.10178744290230090000e-001) (10, 1.16971739307662800000e+000) (11, 2.40039772635099620000e-001) (12, 1.13458312073569760000e+000) (13, -2.42212872111730090000e-001) (14, -1.38931601975789380000e-001) (15, 1.66348656029460250000e-002) (16, 3.66531041920176210000e-001) (17, 4.80080905150133300000e-001) (18, -9.22086074017016480000e-001) (19, -9.57342374955326480000e-001) (20, -3.01291248442267620000e-001) (21, 2.90366157863372050000e-002) (22, -3.17153079513077340000e+000) (23, 3.89064633164003580000e-001) (24, 3.02195803899571570000e+000) (25, 3.59219086942901890000e-001) (26, -3.09237429981062470000e+000) (27, 3.31728852158265470000e-001) (0, 1.33899156486933220000e+000) (1, 2.48428292086623090000e-001) (2, 8.79464416829721790000e-002) (3, -8.96010257402162500000e-002) (4, -2.14783423028403890000e-001) (5, 1.67427893378234690000e-001) (6, 3.75915627274130030000e-001) (7, 7.71732015182265090000e-001) (8, 4.48006658335364960000e-001) (9, 6.84090118007155470000e-001) (10, 3.16570804113775760000e+000) (11, 4.29932017535331450000e-001) (12, -1.50156628400403220000e-001) (13, -4.80050406256291920000e-001) (14, -1.72712302701177680000e-001) (15, -5.34293517462978480000e-001) (16, -3.11213138018315320000e+000) (17, -2.77293368083606610000e-001) (18, -1.54072407606945010000e+000) (19, 2.49655592058477290000e-001) (20, -1.02772811819165580000e+000) (21, 4.09608263407410690000e-001) (22, -4.02273430613316880000e-002) (23, 1.59107095496298090000e-001) (24, 1.51720580264771810000e-001) (25, -3.16322820635866750000e-002) (26, -1.54546040426502680000e+000) (27, 6.32083279046770090000e-001) (28, 4.39547214023520320000e-001) (29, -3.12138771250354000000e-001) (30, 2.29332411821247810000e-001) (31, 2.61854370413205810000e-001) (32, -1.95388941356540450000e-001) (33, 2.21617567956287680000e-001) (28, 3.04410325972528210000e-001) (29, -3.71601766706710500000e-002) (30, 4.89815769460080150000e-001) (31, -2.40957876257332530000e-001) (32, 3.35587112720059420000e-001) (33, 3.71268265595500020000e-001) (28, -3.04867908651814010000e-001) (29, 3.68420482737667980000e-001) (30, -3.44968006905602030000e-001) (31, 2.20838232515906900000e-001) (32, 5.37898060240952440000e-001) (33, 7.96540242581238680000e-001) 

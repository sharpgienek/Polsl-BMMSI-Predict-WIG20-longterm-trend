FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 8.28605288397503950000e+002) (1, -2.07777543632898760000e+001) (2, -2.94903094611699090000e+002) (3, 1.22985518165081070000e+001) (4, -1.20079001415265570000e+001) (5, -1.27249697689574350000e+000) (6, 8.35993252749893830000e+002) (7, 1.87792592134808520000e+001) (8, 4.70291515419400380000e+001) (9, 4.67532279547032940000e+002) (10, 1.24441750474037920000e+003) (11, 2.38012926081707430000e+000) (12, 1.75862007969502550000e+001) (13, -1.30223759331391240000e+001) (14, 3.96206132520444640000e+001) (15, 1.15963876144525600000e+001) (16, -3.13096506119508890000e+002) (17, 3.23906295400136770000e+001) (18, 1.50000000000000000000e+003) (19, 1.74887952656826760000e+001) (20, -1.50000000000000000000e+003) (21, -1.42671004541405700000e+001) (22, 2.07848077161412700000e+002) (23, -7.31687789520803590000e+001) (24, -5.37364528833186000000e+002) (25, 3.18427439735117020000e+001) (26, -1.31738300053221290000e+003) (27, 3.36063497313101590000e+000) (0, 3.88474959688291790000e+001) (1, -1.45184901213761130000e+000) (2, 1.42743276662056720000e+001) (3, 1.88281399056474650000e+000) (4, -1.55991639648838610000e+001) (5, -2.86136760240482680000e-001) (6, -7.74222337519216190000e+000) (7, -1.27989645933319930000e-001) (8, 5.17849009197157710000e+000) (9, 6.32120059776477120000e-001) (10, 9.50268362717602240000e+000) (11, -1.57350571980636650000e-001) (12, -2.19413966653269380000e+001) (13, -3.86903320576058760000e+000) (14, -3.22482601340721830000e+001) (15, -5.11233354182107690000e-001) (16, -5.63602671792318120000e+001) (17, -1.32113585768351470000e-001) (18, -4.65983608898596200000e+000) (19, 3.87026202957735940000e-003) (20, -2.49146669125513400000e+001) (21, -6.93936715352655000000e-001) (22, -2.18850501761358130000e+001) (23, -2.55724344178410230000e+000) (24, -9.58487739674665380000e+000) (25, 1.01939989714915400000e+000) (26, -7.16092007949536220000e+001) (27, -9.68697748615286240000e-001) (0, -2.19630700636249190000e+001) (1, 3.72796184892308650000e-001) (2, 3.59122630808237990000e+001) (3, 1.52737438921136670000e-001) (4, -1.12769252626059150000e+000) (5, 1.29489413579492480000e+000) (6, -1.85790650341642520000e+001) (7, -6.51144783805037800000e+000) (8, 1.18657303747242170000e+001) (9, -8.78522232079565150000e-001) (10, -1.41945831839136050000e+000) (11, 7.25266306411239550000e+000) (12, -6.75128657762643150000e+000) (13, -9.83793924520103060000e-001) (14, 1.16786614677485150000e+001) (15, 4.01779432803609340000e-001) (16, 7.85417083255712890000e+000) (17, 3.98838293847287150000e+000) (18, -1.69738396082918080000e+001) (19, 1.34765655563931960000e+000) (20, 8.51576681913604720000e+000) (21, 1.66030776158429320000e-001) (22, 1.17955439723225500000e+001) (23, 1.04293903798481420000e+000) (24, -1.01640679350735720000e+001) (25, 4.89174630197767170000e+000) (26, -4.50916990134885420000e+000) (27, -1.70297973431426630000e+000) (0, -3.11177175213020090000e+001) (1, 1.11165551076476560000e+001) (2, 6.87987668549368150000e+001) (3, 3.17330254362619750000e+000) (4, -4.05833892169846780000e+000) (5, 2.85293838376082860000e+001) (6, 2.22922720044263970000e+002) (7, -7.39832719207062150000e+001) (8, -2.47477377616067110000e+001) (9, -3.24704525221320270000e+000) (10, -8.35171615974726760000e+000) (11, 2.08754496848652270000e+001) (12, -7.04168977200821760000e+001) (13, -2.81730499188408650000e-001) (14, 3.93706013524825020000e+001) (15, -3.74082547127711740000e+000) (16, 1.47310375856908170000e+002) (17, 5.23355013297889910000e-001) (18, -1.08081878628639170000e+001) (19, 2.69582418362407730000e+000) (20, 8.09711846943123350000e+000) (21, -3.40003125192989590000e+000) (22, 1.51805187438090430000e+002) (23, 2.89990942847931120000e+000) (24, 2.23604274848404460000e+002) (25, 2.90562645140157900000e+001) (26, 6.30888447562652030000e+001) (27, -2.24742683487847520000e+000) (0, 1.50000000000000000000e+003) (1, 3.17469953596161960000e+001) (2, 1.80163935720533490000e+002) (3, -2.52605033658891570000e+001) (4, 1.02654321700747970000e+002) (5, -3.37142157450147990000e+000) (6, -7.38017870725087500000e+002) (7, -4.85399806574663230000e+001) (8, -1.50000000000000000000e+003) (9, 6.39181885683693380000e+001) (10, 1.30793675730145440000e+001) (11, 9.06509431641142170000e+000) (12, -1.73234420478280630000e+001) (13, -4.05515297934542930000e+001) (14, -3.00904051615654390000e+001) (15, -6.06941323070050490000e+000) (16, 8.50728510101264530000e+002) (17, -3.31751018308006440000e+000) (18, -2.30794810303007300000e+002) (19, -1.41074862047848450000e+000) (20, 8.06522466617166290000e+002) (21, -5.44019585004919290000e+001) (22, 5.67789146804487700000e+002) (23, 2.79003540544751100000e+002) (24, 1.50000000000000000000e+003) (25, 1.04012083517519200000e+002) (26, -1.50000000000000000000e+003) (27, -7.20779670908095140000e+000) (28, 2.35825432748521770000e+000) (29, -2.40513565088428380000e+000) (30, -4.21402990869698050000e-002) (31, 6.77737294230759400000e-002) (32, 1.56130100627848260000e-002) (33, -4.16457869815985410000e-003) (28, 7.38384111026717110000e-002) (29, -1.90366355122755830000e-002) (30, 3.71323692214122400000e+000) (31, -3.68324496953156140000e+000) (32, -2.58577821435730120000e+000) (33, 2.47064545763544090000e+000) (28, -2.31407308859012460000e+000) (29, 2.39210407198274980000e+000) (30, -4.75121559952454580000e+000) (31, 4.65906788696647300000e+000) (32, 2.32036791850081460000e+000) (33, 2.25354403710133600000e+000) 

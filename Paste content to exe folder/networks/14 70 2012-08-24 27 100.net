FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.80114910569092960000e+001) (1, 3.08015502842677310000e-001) (2, 1.45791329352950250000e+001) (3, -1.00741161005475100000e-001) (4, -7.48551373061958760000e-002) (5, -6.63922669282317910000e-001) (6, 1.17919560125721560000e+001) (7, 2.00141794865528140000e+000) (8, 2.45673041134574210000e+001) (9, 1.57362083476358910000e-001) (10, 1.40034341772555190000e+001) (11, 8.34729977945573910000e-001) (12, 9.40841567476052630000e-001) (13, -9.89256059121551570000e-003) (14, -2.17698817555636880000e+001) (15, -7.02559563621396740000e-002) (16, -3.57951799158601100000e+001) (17, -3.44668514646095990000e-001) (18, -2.72926593299181060000e-001) (19, -5.53247422252810650000e-001) (20, -9.30481954261632380000e-001) (21, 1.27674669754478990000e+000) (22, -6.70972506893754160000e+000) (23, 2.24709495452314530000e-001) (24, -6.69734233347459720000e+000) (25, -2.93312076701822910000e-001) (26, -1.89189165531420330000e+001) (27, 7.02067809477262770000e-001) (0, 4.42647071797885160000e+001) (1, 3.65546561285186260000e-001) (2, -9.73654346364487890000e-001) (3, -1.94046073538443910000e-001) (4, 3.94700222864199090000e-001) (5, -3.30904163656281720000e-001) (6, -2.54006189074973100000e+000) (7, 1.89350969996901710000e-001) (8, -1.18276092865307680000e+001) (9, 1.64182815640554040000e+000) (10, 4.69504964792926030000e+001) (11, 2.25405998916756460000e+000) (12, 1.82383707942886940000e+000) (13, -6.05171680015249240000e-001) (14, 1.05441276095810470000e+000) (15, -2.32915322615765460000e+000) (16, 2.46637308089487690000e+000) (17, -6.09954725595616360000e-001) (18, -4.62508700134436450000e+001) (19, 5.49047572848459840000e-001) (20, 4.48074646589982790000e+000) (21, 4.80810652088970170000e-001) (22, 9.24850668383616900000e-002) (23, -1.73038524648744860000e-001) (24, -9.88765230106030660000e+000) (25, 4.25439503675379030000e-001) (26, 2.19344112526373430000e+001) (27, 7.38131652471179510000e-001) (0, -4.04414881886132440000e+000) (1, 3.59368906725167250000e-001) (2, -1.60996865778675470000e+000) (3, 4.14154570333752980000e-002) (4, 3.17477217624943590000e+000) (5, -1.29029111925949080000e+000) (6, -1.61286377941549470000e+000) (7, 1.12703003313601260000e+000) (8, 6.44259485557648890000e-001) (9, 3.59533023945547480000e-001) (10, 4.25781816653825680000e-002) (11, 8.10113100370384310000e-001) (12, 7.20200289084999450000e-001) (13, 2.32469463504251380000e-001) (14, 1.17875255648683040000e+000) (15, 5.67625635548969500000e-001) (16, 2.46075853705549590000e+000) (17, 1.32652323711347650000e+000) (18, 1.05360576360205300000e+001) (19, 1.88040000607531730000e-001) (20, 1.59221155159295760000e+001) (21, 3.77024913050589830000e+000) (22, 9.88754653864850060000e-002) (23, 1.26876596780393450000e+000) (24, 1.42192627083216760000e+001) (25, 1.83921665896971790000e-001) (26, 2.94954921225944710000e+000) (27, 8.78939346738546600000e-002) (0, 2.81236018961556090000e+001) (1, -5.95100615561023560000e-001) (2, 2.46050845464593200000e+001) (3, -7.08008319763208330000e-001) (4, 4.65853994871994100000e+000) (5, -6.44969762399599580000e-001) (6, 6.95034505103285750000e+000) (7, 1.82796037351234760000e-001) (8, -2.06403358371162890000e+001) (9, -8.09762302010268110000e-001) (10, 1.17508588033637750000e+000) (11, -1.14986304367590830000e+000) (12, 5.57908630661676240000e+001) (13, 1.48993037169424360000e+000) (14, 1.09519811479126810000e+001) (15, 3.69971921170408450000e-001) (16, -8.17327019165903400000e+000) (17, 7.87115377875648230000e-001) (18, 9.66879746044052800000e+000) (19, -1.75151045959056480000e+000) (20, -1.15193937048149400000e+001) (21, 9.20451639031362620000e-001) (22, -7.58154371815536890000e+000) (23, 1.77719820603112310000e+000) (24, -3.06034531218894940000e+001) (25, -2.57079047378055370000e-001) (26, -1.11861587059485900000e+002) (27, 4.34070121462140020000e-001) (0, 1.93799415270323330000e+001) (1, 1.06925212619849130000e+000) (2, 6.89837175504212750000e-001) (3, -5.60016923511203260000e-002) (4, 1.62206687591411840000e+000) (5, -7.92769095258645030000e-001) (6, 8.40294331058770720000e+000) (7, 2.44445777821923960000e-002) (8, -2.85658497526614640000e+001) (9, -6.70135317721940020000e-001) (10, 1.59625198201003320000e-001) (11, -4.04844056473588230000e+000) (12, 2.47799196940019330000e+001) (13, 3.10702002286895370000e-001) (14, 2.69283922405837610000e+000) (15, 5.72372364569650350000e-001) (16, 1.05778403051439440000e+001) (17, 2.69819777340609250000e+000) (18, 3.39494584548949470000e+000) (19, -7.70277072927346820000e-001) (20, -2.45358105015743320000e+001) (21, 2.71154816129406010000e-001) (22, -5.19919027148223730000e+000) (23, -1.96141945139657100000e+000) (24, 5.67225173069390730000e+000) (25, -2.73870675447668970000e-001) (26, 1.73880126378428910000e+001) (27, 1.01005618948252840000e-001) (28, -2.00320019449404050000e+000) (29, 4.47513086434052690000e-001) (30, 1.33801799797425660000e+000) (31, 3.34683029357826680000e-001) (32, -1.56485107730492760000e-001) (33, 3.59042766549487580000e-001) (28, 1.61526526865326000000e+000) (29, -2.15600230858219710000e+000) (30, 3.57782601420495510000e-001) (31, -1.31408911391970130000e+000) (32, -9.98676717299433300000e-001) (33, 9.69149744320373820000e-001) (28, 7.25007650409720710000e-001) (29, 1.11750272986843440000e+000) (30, -1.46191463758364250000e+000) (31, 6.92219842759136510000e-001) (32, 1.11999863422407640000e+000) (33, 1.39957569694589750000e+000) 

FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -7.01426402366487430000e+000) (1, -4.52306124558878250000e-001) (2, 3.43645243445053560000e+000) (3, -4.35300116101086040000e-001) (4, 8.65283582445950120000e+000) (5, -4.96500394794394400000e-001) (6, -1.13624666591712400000e+001) (7, -6.82026539879496680000e-001) (8, -3.63162034281531870000e+001) (9, -2.88396682212418760000e-001) (10, -3.85769562081951860000e+000) (11, -2.16848548950895740000e+000) (12, 6.28719068132602600000e+001) (13, -7.41539734643513970000e-001) (14, 4.67038769697859810000e+001) (15, 6.67954269264386170000e-001) (16, 5.69064821716149820000e+001) (17, 1.57991063016327330000e+000) (18, 1.55517657573478370000e+001) (19, 3.42012526010984090000e-001) (20, 2.70686751069855540000e+000) (21, -1.80362238630259740000e-001) (22, 5.48123108688331670000e+000) (23, -3.06913237434959960000e-001) (24, 2.68071679033586180000e+001) (25, 3.80511369181371850000e-001) (26, 5.12574857737401360000e+001) (27, 3.35796561054238880000e-001) (0, 1.49825897069895750000e+001) (1, -8.83507040247600260000e-003) (2, 8.43719793766364390000e+000) (3, -7.24096893541642640000e-001) (4, -1.60822213948182370000e+001) (5, -2.15223175615433610000e-001) (6, 1.88792027181419610000e+000) (7, 2.44476591464910160000e-001) (8, -2.93475916968712450000e+001) (9, -5.45303506783742510000e-001) (10, 1.10389521035998670000e+001) (11, 2.34327759775097730000e-001) (12, 2.30817156117232610000e+001) (13, -4.47129270860352590000e-001) (14, -1.35477935386711950000e+001) (15, -3.69628684938443860000e-001) (16, 1.41809242786119840000e+001) (17, 1.13356337719615230000e-001) (18, -1.25893184898053710000e-001) (19, -5.78444773876244600000e-001) (20, -2.05542812171625090000e+000) (21, -6.76564810265115500000e-001) (22, -7.80828743380977650000e+000) (23, -1.54735591812610980000e+000) (24, 2.65850820589043690000e+001) (25, 1.91673781731302250000e+000) (26, -1.91214524730487700000e+001) (27, -2.95229970976210510000e+000) (0, 2.17762221136873400000e+000) (1, 6.69656798948855210000e-001) (2, -9.39159021855345170000e+000) (3, 9.95846554284224420000e-001) (4, 5.81564949080694490000e+000) (5, 9.80066384755470480000e-001) (6, 4.24251175245825960000e+000) (7, 1.80315804701195790000e+000) (8, -2.11682697088205710000e+000) (9, -9.88978167117957880000e-002) (10, 2.87776656639955310000e+001) (11, 1.14977003504487070000e+000) (12, -8.32226076153280300000e+000) (13, -5.02043643035744110000e-001) (14, 3.34220150623167030000e+001) (15, -9.37472549091600600000e-001) (16, -2.86044336460208580000e+001) (17, -2.19811414871567570000e+000) (18, -1.76651506407730960000e+001) (19, 7.10624354282385020000e-001) (20, 1.00528386394791890000e+001) (21, 1.11732285422216450000e-002) (22, 5.13440808987594090000e-003) (23, 5.32161813529093310000e-001) (24, -2.07431732497700660000e+001) (25, -2.03921793007617760000e-001) (26, -3.92522321804621800000e+001) (27, 5.83069915914531720000e-001) (0, -4.17884650762041830000e+001) (1, -5.27005525118469540000e-001) (2, 1.63870101651016850000e+001) (3, 6.69035961867974540000e-001) (4, -2.36923562160149050000e+000) (5, 2.16064361331333110000e+000) (6, 3.18227099078651290000e+001) (7, 9.96040013183150940000e-001) (8, 6.84834665811064980000e+001) (9, 8.17445906568944110000e-001) (10, -2.02202439857435260000e+001) (11, 5.69359695592596360000e+000) (12, -2.73744694503382140000e+001) (13, 8.20651639072461410000e-001) (14, 3.63131362754235310000e+001) (15, -2.62448064671237660000e-001) (16, 7.97013545116435010000e+001) (17, -2.23848910602215010000e+000) (18, 3.96264926799456420000e+001) (19, 6.91451328346725070000e-001) (20, 7.12066665455393210000e+001) (21, 6.44688468257779150000e-001) (22, 4.27312364690569170000e+001) (23, 8.41906684203400200000e-001) (24, 5.96089576915168530000e+000) (25, 1.72084323377335260000e+000) (26, -6.24095551346853410000e+001) (27, 1.47657742391728640000e+000) (0, 3.24245316279941210000e+001) (1, 2.82996552815982070000e-001) (2, -1.01526096439922180000e+001) (3, 3.92332950597704820000e-002) (4, 3.90088229478194110000e+001) (5, -1.69247813869307520000e+000) (6, 5.09517051329897370000e+001) (7, -2.69054392470236170000e+000) (8, -4.47236082881820170000e+000) (9, 7.27794050074799110000e-002) (10, -7.53574107223972240000e+000) (11, -4.84631900773786570000e+000) (12, 5.35441722610702000000e+000) (13, 2.10898186208629750000e+000) (14, 7.70100376745209390000e+000) (15, 9.52777304665583080000e-001) (16, 3.47725304689221420000e+001) (17, 2.82156389716496660000e+000) (18, -6.78370930250832950000e-001) (19, -1.51827200302138810000e+000) (20, -3.22247396747742270000e+001) (21, 4.46398958174331670000e-001) (22, -2.09462688817994510000e+001) (23, 9.76439408823271400000e-001) (24, 1.93172320336432540000e+001) (25, -6.39701656807678280000e+000) (26, -3.43649953536772230000e+001) (27, 5.50285063802113620000e-001) (28, 3.56211505188215760000e+000) (29, -9.86523929617741730000e-004) (30, 3.28822633571307810000e+000) (31, 1.37598927935008540000e+000) (32, 1.33534794604282100000e+000) (33, 1.11582604144687540000e-001) (28, -4.35516104734353340000e+000) (29, -3.00304837470521190000e+000) (30, -4.25222722121775740000e+000) (31, 2.17763862810236600000e-001) (32, -2.86053886873624790000e+000) (33, -2.55157042648092800000e-001) (28, -1.82106188189429340000e-001) (29, 2.96383605232678390000e+000) (30, 1.26430798304873090000e+000) (31, -9.65589260043922320000e-001) (32, 1.45986998742883570000e+000) (33, 3.77500415058347190000e+000) 

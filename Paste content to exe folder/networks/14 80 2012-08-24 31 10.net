FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.48227284297919050000e-001) (1, 2.55855263009777070000e-001) (2, -1.07733985330490530000e-001) (3, 4.92774296775747800000e-001) (4, 1.15903183585410520000e+000) (5, 5.85844974110366180000e-001) (6, -9.36967448706194080000e-002) (7, -1.58038062942760740000e-001) (8, 4.29524161463011310000e-001) (9, -9.47913731637540500000e-002) (10, -1.68139381452657110000e-001) (11, 1.70482210944924770000e-001) (12, 2.40064331100889680000e-001) (13, 2.07543937589450780000e-001) (14, 3.39786172551317450000e-002) (15, 4.81029298720365870000e-001) (16, 1.15178085918355720000e+000) (17, 4.80092377898223290000e-002) (18, 7.63259133556942750000e-001) (19, 4.25928592654669200000e-001) (20, -1.13682210827145210000e-001) (21, -2.14275856749519160000e-001) (22, 3.50210808552143090000e-001) (23, 1.43788446238537760000e-001) (24, 3.87567349778349330000e-001) (25, 1.54047913598936100000e-001) (26, 7.26259621286857060000e-001) (27, -4.58634496148194740000e-001) (0, 1.12057358332790760000e+000) (1, 6.13488267924402030000e-001) (2, -2.70097409763580130000e-002) (3, -2.09320635861584500000e-001) (4, 7.19293985528751120000e-002) (5, -6.19709897596258610000e-001) (6, -9.62601211339489060000e-001) (7, 5.78529351048435950000e-001) (8, -1.51986390096382930000e-001) (9, -3.00758397946323530000e-002) (10, 3.19465701617850590000e+000) (11, 4.02759536179967290000e-001) (12, 2.74751031703953430000e+000) (13, -4.50790497343564970000e-001) (14, -8.38952243461634770000e-001) (15, -1.01660140904147990000e+000) (16, -2.03889422611899350000e-001) (17, -1.46074389240475560000e-001) (18, -1.52492484862973040000e+000) (19, -8.56929718288370610000e-002) (20, -1.19068993148206630000e-001) (21, 2.34844954649544580000e-001) (22, -3.14132449585253950000e+000) (23, -6.11950575210130740000e-001) (24, -4.31724977157957880000e-001) (25, -2.89599900764391350000e-001) (26, -3.06429812751725720000e+000) (27, 1.20412414660345970000e-001) (0, -5.29484029647931950000e-001) (1, 1.15648836022922640000e-001) (2, -2.27371348673563210000e+000) (3, 1.03081697163782680000e-001) (4, -1.55697776339574800000e+000) (5, 1.48693856366739060000e+000) (6, 3.95335892862860920000e-001) (7, 8.75379355084157980000e-001) (8, -4.64194722034420470000e-001) (9, 5.45821072978036170000e-001) (10, 3.13237674181295760000e+000) (11, 8.63345786078666630000e-001) (12, -3.27369134458605270000e-001) (13, -6.01018192571248330000e-001) (14, 1.16860214849671400000e+000) (15, 1.73912997047376200000e-001) (16, -9.96844328668951560000e-001) (17, 5.72335955716773540000e-001) (18, 3.03327127093779680000e-001) (19, 7.81740506904397230000e-001) (20, -3.06319339117267030000e+000) (21, 3.42807224493907380000e-001) (22, -6.20241889521724880000e-003) (23, 8.83185751684857360000e-001) (24, -1.75461540381458200000e-001) (25, 2.88162767136670720000e-001) (26, 3.11869817893527470000e-001) (27, 7.23190024524853040000e-001) (0, 5.94529926556067510000e-001) (1, 2.48052428436108530000e-001) (2, 3.20904300272099880000e+000) (3, 1.50862854567217870000e-001) (4, 1.76178475424058380000e+000) (5, -7.02176054902027500000e-001) (6, -4.50147946835470880000e-001) (7, -4.09601801699592480000e-001) (8, -3.18865115671401170000e+000) (9, 5.42194624154443970000e-002) (10, -9.89849699658473360000e-001) (11, -1.92605395389297680000e+000) (12, 1.41351549176107530000e+000) (13, 7.68939409537003210000e-002) (14, -4.45547020141416450000e-001) (15, -3.35224348107084120000e-001) (16, 3.11271121417616840000e+000) (17, 9.18536292969464370000e-001) (18, -3.13742434931004780000e+000) (19, -5.85584014468375490000e-001) (20, 2.46212969885576220000e+000) (21, 3.55973108650653320000e-002) (22, -9.87796524214928470000e-001) (23, 5.03874758045164790000e-001) (24, 1.17932393525251490000e+000) (25, 1.98897198946310610000e-001) (26, -3.04135501194100310000e+000) (27, 8.88202106626655860000e-002) (0, 1.48563241130417740000e+000) (1, 4.68869782630634830000e-002) (2, 3.15948245510748920000e+000) (3, -4.22183495054200280000e-001) (4, -5.61809207611988940000e-001) (5, -1.55444789354576780000e-001) (6, 7.10950641696479370000e-001) (7, 1.48480054295965090000e-001) (8, 2.65792794298499340000e-001) (9, -1.14392485708177980000e-001) (10, 6.29152686246100990000e-001) (11, -1.11917523986118680000e-001) (12, -1.37703391305812570000e+000) (13, -3.88937298854888590000e-001) (14, 3.55503747651735040000e-001) (15, -3.86280828133660660000e-001) (16, -5.18401003840156300000e-001) (17, -1.49548793172969600000e-001) (18, -1.56027173421478870000e-001) (19, -3.13600162988134370000e-001) (20, 1.30044210111981620000e+000) (21, -3.05423868024641420000e-002) (22, 4.89029150500908840000e-001) (23, -9.43974251636501840000e-002) (24, -3.22109976865905260000e-002) (25, -9.25926280795569270000e-003) (26, -3.06300418218547590000e+000) (27, -2.55780484209070120000e-001) (28, 1.45223586630402770000e-001) (29, -1.93421299407627810000e-001) (30, 7.35239934700130520000e-002) (31, 1.10453444570383350000e-001) (32, -2.31610561973910220000e-001) (33, 3.73221043306483590000e-001) (28, -8.71889337041572150000e-002) (29, -1.08477996521388970000e-001) (30, 6.04722075738056470000e-001) (31, -7.75203113917802830000e-001) (32, -2.41620327748067350000e-001) (33, 4.86869290778788040000e-001) (28, -1.20888082422560490000e-001) (29, 4.92965183569510080000e-001) (30, 4.92581282946725150000e-001) (31, 5.85653923795137480000e-001) (32, 1.75242867271056810000e-001) (33, 5.24032699431012720000e-001) 

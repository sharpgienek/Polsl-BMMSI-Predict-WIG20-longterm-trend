FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 3.86166268999517340000e+000) (1, 2.28001916819228700000e+000) (2, -4.03972130188450650000e+001) (3, -1.85579789536130590000e+000) (4, 2.13765557660797190000e+001) (5, -5.40862460043935680000e-001) (6, -2.22737483374272130000e+000) (7, 1.26111396264312230000e+001) (8, -2.76844943754706120000e+000) (9, -2.47797434128300270000e-001) (10, 9.51841190204824720000e-001) (11, -2.73272681868032220000e+000) (12, -2.45434606334964790000e+000) (13, -3.34915278449831670000e+000) (14, 2.14024003622196950000e-001) (15, -2.45944144635370510000e-001) (16, -2.86482419607063900000e+001) (17, 5.55391232166520640000e-001) (18, 2.87884258338137220000e+001) (19, -1.23921365209047800000e+000) (20, -1.93604249415623320000e+001) (21, 9.23363503846520550000e-001) (22, -8.74551086948108790000e-001) (23, 1.50901805328458780000e+000) (24, 2.01978773189753300000e+001) (25, 3.21864013686585440000e+000) (26, 1.08519915922296250000e+001) (27, 5.57822530794570890000e-001) (0, 1.40356669726412450000e+000) (1, -2.51376934305183760000e-001) (2, 6.03695153873103060000e+000) (3, 4.47200671600674950000e-001) (4, -6.22715309336516580000e+000) (5, 6.33065719305085590000e-001) (6, 2.05388490574852330000e+000) (7, -4.92929324473161350000e-001) (8, 3.47919109604696710000e+001) (9, 8.66126840684373030000e-003) (10, -7.17239652527326800000e-001) (11, 1.74989266859064600000e-001) (12, -3.28177631350237590000e+000) (13, 5.34762535856888930000e-001) (14, -2.96613599435633240000e+000) (15, 4.65002742738605370000e-001) (16, -2.94011993106885080000e+001) (17, -8.39517923378708120000e-001) (18, 6.33534477988168200000e+000) (19, 6.00734588282220590000e-001) (20, 3.66277529519069930000e+000) (21, 6.73534718836111580000e-003) (22, -1.83422490338644620000e+001) (23, -1.57229424240036300000e+000) (24, -3.26002075913745560000e+001) (25, -9.93207737118571580000e-001) (26, -9.17770210507058160000e+000) (27, 2.09376100618750480000e-001) (0, -1.77424182773535360000e+001) (1, -1.30401070539572790000e+000) (2, 4.46808563232457700000e+000) (3, 7.66716306562831070000e-001) (4, -2.97296396483798690000e+000) (5, 1.68978641249783950000e+000) (6, 1.84496316894448160000e+000) (7, 3.38351170930017850000e-002) (8, 2.11217362639074860000e+001) (9, 2.46409722798997200000e-001) (10, -7.07629155070474520000e+000) (11, 3.55292939813874440000e+000) (12, 1.55073287772084040000e-001) (13, 8.79017521488892340000e-002) (14, 1.20295022263171990000e+001) (15, 2.04107430426536630000e+000) (16, 2.23539145903240060000e+001) (17, -8.51963548711077160000e-001) (18, 8.72420359870649160000e+000) (19, 9.80961297702733990000e-001) (20, 2.98736575664588920000e+001) (21, 9.27046516389547910000e-002) (22, 1.15910495041106110000e+001) (23, 1.47820449583302760000e+000) (24, 1.09463721037500220000e+000) (25, 6.67891018284705040000e-002) (26, -1.16350369393112100000e+000) (27, -8.08841284864655200000e-003) (0, 7.42406708747947610000e+000) (1, -2.26321685743336050000e-001) (2, 2.05365312797514110000e+001) (3, -2.28178816388341890000e-001) (4, -2.34712583390111060000e-001) (5, -1.36815312728534820000e+000) (6, -4.46016270800975940000e-001) (7, 3.82798701286411970000e-001) (8, 1.21829355720846950000e+001) (9, -1.17018115110667090000e-001) (10, 6.23028105002760180000e-001) (11, -7.51630966844484830000e-001) (12, -2.52969579529139480000e+000) (13, 7.16968540592465730000e-001) (14, 5.47165075784934630000e+000) (15, 2.44740746709908720000e-001) (16, 6.95301366578459580000e+000) (17, -1.00660322449555320000e+000) (18, -2.10444475292592560000e+000) (19, 3.46142697928635890000e-001) (20, 3.37292593864784720000e-001) (21, -6.64101501179419350000e-002) (22, -1.00377826451804130000e+000) (23, -2.02426166956060080000e+000) (24, 9.55895191675294420000e+000) (25, -2.39784320734120760000e-001) (26, 1.41126852716689230000e+001) (27, -1.06689086406966620000e+000) (0, -3.09957273214022290000e+000) (1, 2.86972407390104820000e-001) (2, 1.95173039232946020000e+001) (3, -6.92514412101717940000e-001) (4, 8.87147518771445930000e+000) (5, -6.62865516270701120000e-001) (6, -8.16518626464471930000e-001) (7, 1.29391254372528320000e+000) (8, 4.71982651271099400000e+000) (9, 9.89917570831517210000e-002) (10, 8.38649464296357650000e+000) (11, 1.92845819781770360000e+000) (12, -7.16989009460616430000e+000) (13, 3.23680085400976210000e+000) (14, 3.02205316764043940000e+000) (15, 3.21119625345230590000e-001) (16, 1.31355555541729330000e+001) (17, 7.77472902674198550000e-001) (18, -1.58738091064717680000e+001) (19, -1.66750263120770930000e-001) (20, 9.58378162885770930000e-001) (21, 1.09423644608148090000e+000) (22, 1.53400902631882530000e+001) (23, 4.44386916924363810000e+000) (24, -9.81850023499477050000e+000) (25, 3.47451727445568270000e+000) (26, -5.04517736648419020000e+001) (27, -2.21733220010413500000e-002) (28, -9.47120305302150080000e-001) (29, -1.53136664463221830000e+000) (30, 5.43774482306141780000e-001) (31, 1.37324908135667090000e+000) (32, -1.16046600629780730000e-001) (33, 1.11020966179127730000e+000) (28, 1.33475425679101490000e+000) (29, 6.12177307381971180000e-001) (30, 1.15214783855956430000e+000) (31, -4.66011042928972550000e-001) (32, -1.17618681335186200000e+000) (33, 9.42037083849278530000e-001) (28, -3.53203907004783550000e-001) (29, 8.97710036243423710000e-001) (30, -2.11705664732718010000e+000) (31, -7.72956799412832350000e-001) (32, 1.08444883760893030000e+000) (33, 1.00968758528831710000e+000) 

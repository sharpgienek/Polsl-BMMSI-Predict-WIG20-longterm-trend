FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.29677426737931360000e-001) (1, 1.29689122868489130000e-001) (2, 3.19477298297710900000e+000) (3, 3.57616289609254260000e-002) (4, 3.30890430830157900000e-001) (5, -2.65464754626096530000e-001) (6, -1.57940205516142180000e+000) (7, -1.32496022381488190000e-002) (8, -5.34964636686082180000e-001) (9, 2.21343165033805020000e-001) (10, 3.03045413287231740000e+000) (11, 1.53269267129199080000e-002) (12, 3.19795901818083460000e+000) (13, 4.83810530862905760000e-001) (14, -4.23222344911856010000e-001) (15, -1.88107447107412730000e-001) (16, 5.59091531416291640000e-001) (17, 6.28452431140801740000e-001) (18, -3.13212039415288770000e+000) (19, -2.11392540555541520000e-001) (20, 2.53228042002912100000e-001) (21, 9.71451770710465570000e-002) (22, -2.29364146554820710000e+000) (23, 6.09303868521973050000e-001) (24, 3.62363268950469220000e-001) (25, 1.52949130707155180000e-001) (26, -3.18890140085836560000e+000) (27, 5.13209776672693740000e-001) (0, -1.24560899035007690000e+000) (1, -9.33362661970345560000e-002) (2, 3.07193362567791000000e+000) (3, 3.91318612844806240000e-001) (4, 3.06540286386184400000e+000) (5, -1.67638036675250290000e-001) (6, -3.16393802158013230000e+000) (7, -4.22995640876989150000e-001) (8, -1.20957993707882720000e+000) (9, -1.08293681809930690000e-001) (10, 4.37189468333638310000e-001) (11, 2.55887911810471660000e-001) (12, -3.28335316104936050000e-001) (13, 4.63015475208338580000e-001) (14, 5.64767599421717170000e-002) (15, 4.46474819177258450000e-001) (16, 3.10277469059060260000e+000) (17, 5.84367237838580240000e-001) (18, -3.08462283485136890000e+000) (19, -1.46155719975710200000e-002) (20, 3.05235354726114410000e+000) (21, 1.44523692835030910000e-001) (22, -2.06383778377106640000e-002) (23, 6.05496286403124580000e-001) (24, 1.63290055106291510000e+000) (25, 5.17234668478852020000e-001) (26, 9.11153644504029580000e-001) (27, -3.02830909783531050000e-001) (0, 7.17433752945733860000e-001) (1, 2.39500510115894570000e-001) (2, 3.04945437729606810000e+000) (3, -1.27044172644144830000e-001) (4, 4.10256442102678810000e-001) (5, -4.54837682367097540000e-001) (6, -3.78996217070485250000e-001) (7, 1.27397236961050650000e-001) (8, -5.95658184334152410000e-002) (9, 5.30424169027629700000e-002) (10, 5.63876482934467570000e-001) (11, -2.57807518812945220000e-001) (12, 2.96966003383727530000e-001) (13, -1.54748030478839480000e-001) (14, -6.25083981103697340000e-001) (15, -3.18363199399324450000e-001) (16, 6.50258117020962030000e-001) (17, 3.38873419169918590000e-001) (18, -7.26091744655714800000e-001) (19, -1.29806578474794180000e-001) (20, 1.35472066638175480000e+000) (21, 3.99890265782265500000e-001) (22, -1.25513657838267400000e+000) (23, -4.91532018851385750000e-001) (24, 9.16625892550372190000e-001) (25, 1.71351681594783730000e-001) (26, -3.07224490497942340000e+000) (27, -3.09386576217278220000e-001) (0, -4.43118932192474560000e-001) (1, -6.68929403482902700000e-002) (2, -1.09165023828479460000e+000) (3, 5.49126504254961460000e-002) (4, -4.15268589980597120000e-001) (5, 6.55049718813014330000e-001) (6, -3.07946536407139160000e+000) (7, 1.02465141368458470000e-001) (8, -3.98972299693133970000e-001) (9, 1.96703480963640960000e-001) (10, -1.24454697861550170000e+000) (11, 7.16713538091251820000e-001) (12, 4.58892545777092210000e-001) (13, 7.45171429051258440000e-002) (14, 6.11872152081676220000e-001) (15, 4.99398942911177420000e-001) (16, 3.24809456593120050000e-001) (17, 3.80687423015824090000e-001) (18, 5.41697559468377500000e-001) (19, 5.79282508533112810000e-001) (20, -1.77430868749082590000e-001) (21, 5.47539590168814590000e-002) (22, 7.54707886134371560000e-001) (23, 2.38664715821395920000e-001) (24, -1.12375691469882240000e-001) (25, 5.77996133591402450000e-002) (26, 3.18460452579433720000e+000) (27, 6.54219640675645200000e-001) (0, -2.59541218161878220000e-002) (1, -3.62166703599282320000e-002) (2, -3.18552005315172960000e+000) (3, 1.11504448143779630000e-001) (4, -6.33503626078102260000e-002) (5, -2.73527826040245730000e-004) (6, 2.89739835479988880000e-001) (7, 9.87786178760249880000e-002) (8, 7.19685912956253500000e-001) (9, 8.63824343978543550000e-002) (10, -1.54811181180806720000e-001) (11, 5.13362000048377180000e-001) (12, 2.81889163761947170000e-001) (13, -1.57802117002161570000e-001) (14, 2.52478839119569900000e+000) (15, 4.90316911525844610000e-001) (16, -1.43036030489365200000e+000) (17, -2.00880730925332930000e-001) (18, 3.88936031581576800000e-001) (19, 6.19284950535445630000e-001) (20, -9.86282119243934500000e-001) (21, 4.67176296840315360000e-001) (22, -5.15969303370712450000e-002) (23, 4.09343429302206850000e-001) (24, -3.00528284071267580000e-001) (25, 9.72344283998897720000e-002) (26, -2.50034340959270130000e-001) (27, 6.37428868941068210000e-001) (28, -1.13693383498556840000e-001) (29, 7.11527331497708420000e-001) (30, -2.80081948828889370000e-001) (31, 2.86630690265699210000e-001) (32, 1.55931787105974610000e-001) (33, 1.54473046849862680000e-001) (28, -3.15375461752120810000e-002) (29, -5.81321034058176480000e-001) (30, -2.56971337159860150000e-001) (31, 4.32308444384404240000e-001) (32, 5.12295017841922110000e-001) (33, 4.66189060123639750000e-001) (28, 6.90934121524976460000e-001) (29, -1.19940388368666370000e-002) (30, 7.78531084585602050000e-001) (31, 5.55614339434654380000e-002) (32, 1.61168812465383140000e-001) (33, 3.85499813832167080000e-001) 

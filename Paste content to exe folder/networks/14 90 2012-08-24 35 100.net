FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999980000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=28 6 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (28, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (6, 5, 5.00000000000000000000e-001) (0, 5, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -3.33238525329664540000e+000) (1, -1.98591544601364500000e-002) (2, 2.17139464244572660000e+001) (3, -1.29467016182005680000e-001) (4, 2.50262875031508010000e+001) (5, -6.20542451128920920000e-001) (6, -1.24632622574676950000e+001) (7, 2.08631976786844750000e+000) (8, 3.95403561901136640000e+000) (9, 1.50015023036975740000e+000) (10, 1.28947847031952440000e+001) (11, 6.30508221694682350000e-001) (12, 2.08695546975590140000e+000) (13, -1.91040835660114570000e-001) (14, 5.54349556073580450000e+000) (15, -7.16172584985729670000e-001) (16, 1.37326077261397580000e+001) (17, 2.19922212839369990000e+000) (18, -7.20414721973031470000e+000) (19, -2.31450061709319500000e+000) (20, 6.16139393130836410000e+000) (21, 1.81032610199281590000e+000) (22, 6.02723565127760890000e+000) (23, 1.18401348956456260000e+000) (24, 3.34122265249387880000e+001) (25, 1.52496155244176720000e+000) (26, 1.17990599840969350000e+001) (27, -7.08267760640673650000e-001) (0, -4.95996718819796630000e+000) (1, -1.91938322274919360000e+000) (2, -3.71220827451276620000e+000) (3, 2.03707523352957050000e+000) (4, -9.15577310713386770000e-001) (5, 8.72640916977924230000e-001) (6, 1.72184897889523860000e+001) (7, 6.18071568948622140000e-001) (8, -1.74897361992143980000e+000) (9, -1.66379682325178830000e-001) (10, 6.72403041346260900000e+000) (11, 2.37720293366456880000e+000) (12, 1.80978937863431180000e+001) (13, 6.38939863077003260000e+000) (14, -3.21336905191910840000e+001) (15, 1.10725364940877150000e+000) (16, 5.67321326071675290000e-001) (17, 1.58695457346632570000e-001) (18, -1.00759306788230350000e+001) (19, 1.04873178922509460000e-002) (20, 2.06579568402558140000e+001) (21, -4.15151361124700900000e-002) (22, -1.26228616814834480000e+001) (23, 2.61692257723023490000e+000) (24, -2.77699911705660090000e+001) (25, 1.94186492374527850000e+000) (26, -1.55546611813003890000e+001) (27, 4.56067841971939560000e-001) (0, 8.29616776794062010000e+000) (1, 2.83161111599227850000e-001) (2, 4.34125107017861820000e+001) (3, -2.15306533469356740000e-001) (4, 1.35073861334647080000e+001) (5, -9.18409421199298690000e-001) (6, -1.03849107796422580000e+001) (7, -4.70512654583228660000e-001) (8, -5.83339687142905830000e+000) (9, 1.63030549482419820000e-001) (10, 1.45333686586402030000e+001) (11, 1.35989564198839030000e+000) (12, 7.50905780541155730000e+000) (13, 2.29980078097589390000e-001) (14, 3.62796040903957340000e-001) (15, 7.84636904506369050000e-002) (16, -1.75236070462557470000e+000) (17, 1.89246821696403880000e+000) (18, -4.61027931445066490000e+001) (19, 1.71873618582029990000e-001) (20, 5.89701289425054620000e-001) (21, 2.48604661817394130000e+000) (22, 1.47994958148169470000e+001) (23, 2.17545639090496000000e+000) (24, -1.25175837297864680000e+000) (25, 1.66043234010706150000e+000) (26, -2.64633998495875140000e+001) (27, 7.34715965273743390000e-001) (0, 1.52474633952484240000e+001) (1, 2.82687756317974050000e-001) (2, 6.65260064401529760000e+000) (3, -7.53691087973532900000e-001) (4, 8.30506529367194620000e+000) (5, -7.96161050898263610000e-001) (6, -3.05018262377289150000e+000) (7, 7.18720551137676300000e-001) (8, 1.01373370165289800000e+001) (9, 8.04058782623764510000e-001) (10, 2.22801171959681670000e+001) (11, -2.53571142369894310000e-001) (12, -4.86322766710224740000e+000) (13, 5.42715901526519000000e-002) (14, -2.86727444458641270000e+000) (15, -9.13702262447760540000e-001) (16, -4.36262303944621800000e+000) (17, 8.37219054622507900000e-001) (18, 4.07757053132036700000e+000) (19, -9.76192427846379160000e-001) (20, -6.39055844032569100000e+000) (21, 1.00095037263082240000e+000) (22, -1.07733914296484730000e+001) (23, -2.11019773016233060000e-001) (24, 1.64694432049217830000e+000) (25, 5.75455708976188810000e-001) (26, -9.08427834813191910000e+000) (27, 6.36173925301809270000e-001) (0, 1.52850816007673200000e+001) (1, 1.45371862903010100000e+000) (2, -2.79306033471248270000e+000) (3, -9.91013526708241280000e-001) (4, 1.20865728201665220000e+001) (5, -6.55491663465469500000e-001) (6, 4.43016611168835440000e+000) (7, -8.04708929258384640000e-002) (8, -1.77858668130015970000e+001) (9, 5.90592557218364570000e-002) (10, 2.22458425536652060000e+001) (11, -2.28240968620659280000e+000) (12, 3.18592952184950700000e+000) (13, 3.14008277099193210000e-001) (14, -1.97882214668000290000e+000) (15, -1.38085158458631980000e+000) (16, -3.77333974496702580000e+000) (17, 7.23126233613097360000e-001) (18, 5.21179077292425190000e-001) (19, -7.06722681664648800000e-001) (20, -1.42480568293485220000e+001) (21, -9.91168412459690620000e-002) (22, -2.66079151844059370000e+000) (23, -1.57654727860829590000e+000) (24, -3.84108788204867450000e+000) (25, -3.46380415613515460000e-001) (26, 8.60028222128084050000e-001) (27, -2.36787129533429090000e-001) (28, 1.87884659395303540000e+000) (29, 2.20787773202910310000e-002) (30, 4.42937896071996020000e-001) (31, -2.35165700339154470000e+000) (32, 8.76138696739674070000e-002) (33, 1.01193448075285410000e-001) (28, -7.29139869523999230000e-001) (29, -8.30216118127547140000e-001) (30, -1.58459366959272900000e+000) (31, 1.50043671958683670000e+000) (32, -1.70193238162788880000e+000) (33, 1.72756367391679480000e+000) (28, -6.39047756789361430000e-001) (29, 9.14600145912059630000e-001) (30, 6.54221309392881150000e-001) (31, 3.83300564120733430000e-001) (32, 1.91050466180272640000e+000) (33, 1.15331098416116730000e+000) 
